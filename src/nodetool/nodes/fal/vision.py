from enum import Enum
from pydantic import Field
from typing import Any
from nodetool.metadata.types import ImageRef
from nodetool.nodes.fal.fal_node import FALNode
from nodetool.workflows.processing_context import ProcessingContext


class AIDetectorImage(FALNode):
    """
    AI Detector analyzes images to determine if they were generated by AI or are real photos.
    vision, ai-detection, analysis, classification

    Use cases:
    - Detect AI-generated images
    - Verify image authenticity
    - Filter synthetic content
    - Content moderation for AI images
    - Analyze image provenance
    """

    image_url: ImageRef = Field(
        default=ImageRef(), description="URL pointing to an image to analyze for AI generation.(Max: 3000 characters)"
    )

    async def process(self, context: ProcessingContext) -> dict[str, Any]:
        image_url_base64 = await context.image_to_base64(self.image_url)
        arguments = {
            "image_url": f"data:image/png;base64,{image_url_base64}",
        }

        # Remove None values
        arguments = {k: v for k, v in arguments.items() if v is not None}

        res = await self.submit_request(
            context=context,
            application="half-moon-ai/ai-detector/detect-image",
            arguments=arguments,
        )
        return res

    @classmethod
    def get_basic_fields(cls):
        return ["image"]

class ArbiterImageText(FALNode):
    """
    Arbiter measures semantic alignment between images and text descriptions.
    vision, alignment, similarity, text-image, analysis

    Use cases:
    - Measure image-text alignment
    - Verify prompt accuracy
    - Quality control for generated images
    - Rank images by text relevance
    - Evaluate caption accuracy
    """

    measurements: list[str] = Field(
        default=[], description="The measurements to use for the measurement."
    )
    inputs: list[str] = Field(
        default=[], description="The inputs to use for the measurement."
    )

    async def process(self, context: ProcessingContext) -> Any:
        arguments = {
            "measurements": self.measurements,
            "inputs": self.inputs,
        }

        # Remove None values
        arguments = {k: v for k, v in arguments.items() if v is not None}

        res = await self.submit_request(
            context=context,
            application="fal-ai/arbiter/image/text",
            arguments=arguments,
        )
        return res

    @classmethod
    def get_basic_fields(cls):
        return ["image", "text"]

class ArbiterImageImage(FALNode):
    """
    Arbiter measures similarity and alignment between reference images.
    vision, similarity, comparison, image-matching, analysis

    Use cases:
    - Compare image similarity
    - Measure visual alignment
    - Find duplicate images
    - Rank image variations
    - Evaluate image consistency
    """

    measurements: list[str] = Field(
        default=[], description="The measurements to use for the measurement."
    )
    inputs: list[str] = Field(
        default=[], description="The inputs to use for the measurement."
    )

    async def process(self, context: ProcessingContext) -> Any:
        arguments = {
            "measurements": self.measurements,
            "inputs": self.inputs,
        }

        # Remove None values
        arguments = {k: v for k, v in arguments.items() if v is not None}

        res = await self.submit_request(
            context=context,
            application="fal-ai/arbiter/image/image",
            arguments=arguments,
        )
        return res

    @classmethod
    def get_basic_fields(cls):
        return ["image1", "image2"]

class ArbiterImage(FALNode):
    """
    Arbiter provides comprehensive image analysis and quality metrics.
    vision, analysis, quality, metrics, image-evaluation

    Use cases:
    - Analyze image quality
    - Extract image metrics
    - Evaluate visual properties
    - Assess image characteristics
    - Generate quality reports
    """

    measurements: list[str] = Field(
        default=[], description="The measurements to use for the measurement."
    )
    inputs: list[str] = Field(
        default=[], description="The inputs to use for the measurement."
    )

    async def process(self, context: ProcessingContext) -> Any:
        arguments = {
            "measurements": self.measurements,
            "inputs": self.inputs,
        }

        # Remove None values
        arguments = {k: v for k, v in arguments.items() if v is not None}

        res = await self.submit_request(
            context=context,
            application="fal-ai/arbiter/image",
            arguments=arguments,
        )
        return res

    @classmethod
    def get_basic_fields(cls):
        return ["image"]

class Florence2RegionToDescription(FALNode):
    """
    Florence-2 Large generates detailed descriptions of specific image regions.
    vision, captioning, region-description, florence, ocr

    Use cases:
    - Describe specific image regions
    - Generate region captions
    - Extract region information
    - Annotate image areas
    - Create detailed region descriptions
    """

    region: str = Field(
        default="", description="The user input coordinates"
    )
    image_url: ImageRef = Field(
        default=ImageRef(), description="The URL of the image to be processed."
    )

    async def process(self, context: ProcessingContext) -> Any:
        image_url_base64 = await context.image_to_base64(self.image_url)
        arguments = {
            "region": self.region,
            "image_url": f"data:image/png;base64,{image_url_base64}",
        }

        # Remove None values
        arguments = {k: v for k, v in arguments.items() if v is not None}

        res = await self.submit_request(
            context=context,
            application="fal-ai/florence-2-large/region-to-description",
            arguments=arguments,
        )
        return res

    @classmethod
    def get_basic_fields(cls):
        return ["image", "region"]

class Florence2OCR(FALNode):
    """
    Florence-2 Large performs optical character recognition to extract text from images.
    vision, ocr, text-extraction, florence, reading

    Use cases:
    - Extract text from images
    - Read document images
    - Digitize printed text
    - Parse image text content
    - Convert images to text
    """

    image_url: ImageRef = Field(
        default=ImageRef(), description="The URL of the image to be processed."
    )

    async def process(self, context: ProcessingContext) -> Any:
        image_url_base64 = await context.image_to_base64(self.image_url)
        arguments = {
            "image_url": f"data:image/png;base64,{image_url_base64}",
        }

        # Remove None values
        arguments = {k: v for k, v in arguments.items() if v is not None}

        res = await self.submit_request(
            context=context,
            application="fal-ai/florence-2-large/ocr",
            arguments=arguments,
        )
        return res

    @classmethod
    def get_basic_fields(cls):
        return ["image"]

class Florence2MoreDetailedCaption(FALNode):
    """
    Florence-2 Large generates highly detailed, comprehensive image captions.
    vision, captioning, detailed-description, florence, analysis

    Use cases:
    - Generate detailed image descriptions
    - Create comprehensive captions
    - Produce rich image narratives
    - Analyze image content thoroughly
    - Generate long-form descriptions
    """

    image_url: ImageRef = Field(
        default=ImageRef(), description="The URL of the image to be processed."
    )

    async def process(self, context: ProcessingContext) -> Any:
        image_url_base64 = await context.image_to_base64(self.image_url)
        arguments = {
            "image_url": f"data:image/png;base64,{image_url_base64}",
        }

        # Remove None values
        arguments = {k: v for k, v in arguments.items() if v is not None}

        res = await self.submit_request(
            context=context,
            application="fal-ai/florence-2-large/more-detailed-caption",
            arguments=arguments,
        )
        return res

    @classmethod
    def get_basic_fields(cls):
        return ["image"]

class Florence2RegionToCategory(FALNode):
    """
    Florence-2 Large classifies image regions into semantic categories.
    vision, classification, region-analysis, florence, categorization

    Use cases:
    - Classify image regions
    - Categorize image areas
    - Label image segments
    - Identify region types
    - Semantic region analysis
    """

    region: str = Field(
        default="", description="The user input coordinates"
    )
    image_url: ImageRef = Field(
        default=ImageRef(), description="The URL of the image to be processed."
    )

    async def process(self, context: ProcessingContext) -> Any:
        image_url_base64 = await context.image_to_base64(self.image_url)
        arguments = {
            "region": self.region,
            "image_url": f"data:image/png;base64,{image_url_base64}",
        }

        # Remove None values
        arguments = {k: v for k, v in arguments.items() if v is not None}

        res = await self.submit_request(
            context=context,
            application="fal-ai/florence-2-large/region-to-category",
            arguments=arguments,
        )
        return res

    @classmethod
    def get_basic_fields(cls):
        return ["image", "region"]

class Florence2Caption(FALNode):
    """
    Florence-2 Large generates concise, accurate captions for images.
    vision, captioning, description, florence, analysis

    Use cases:
    - Generate image captions
    - Create alt text for images
    - Describe images concisely
    - Automate image descriptions
    - Produce accessibility captions
    """

    image_url: ImageRef = Field(
        default=ImageRef(), description="The URL of the image to be processed."
    )

    async def process(self, context: ProcessingContext) -> Any:
        image_url_base64 = await context.image_to_base64(self.image_url)
        arguments = {
            "image_url": f"data:image/png;base64,{image_url_base64}",
        }

        # Remove None values
        arguments = {k: v for k, v in arguments.items() if v is not None}

        res = await self.submit_request(
            context=context,
            application="fal-ai/florence-2-large/caption",
            arguments=arguments,
        )
        return res

    @classmethod
    def get_basic_fields(cls):
        return ["image"]

class Florence2DetailedCaption(FALNode):
    """
    Florence-2 Large generates detailed captions with rich contextual information.
    vision, captioning, detailed-description, florence, analysis

    Use cases:
    - Generate detailed captions
    - Create rich image descriptions
    - Produce comprehensive captions
    - Analyze image context
    - Generate informative descriptions
    """

    image_url: ImageRef = Field(
        default=ImageRef(), description="The URL of the image to be processed."
    )

    async def process(self, context: ProcessingContext) -> Any:
        image_url_base64 = await context.image_to_base64(self.image_url)
        arguments = {
            "image_url": f"data:image/png;base64,{image_url_base64}",
        }

        # Remove None values
        arguments = {k: v for k, v in arguments.items() if v is not None}

        res = await self.submit_request(
            context=context,
            application="fal-ai/florence-2-large/detailed-caption",
            arguments=arguments,
        )
        return res

    @classmethod
    def get_basic_fields(cls):
        return ["image"]

class Sam3ImageEmbed(FALNode):
    """
    Sam 3
    vision, analysis, image-understanding, detection

    Use cases:
    - Automated content generation
    - Creative workflows
    - Batch processing
    - Professional applications
    - Rapid prototyping
    """

    image_url: ImageRef = Field(
        default=ImageRef(), description="URL of the image to embed."
    )

    async def process(self, context: ProcessingContext) -> Any:
        image_url_base64 = await context.image_to_base64(self.image_url)
        arguments = {
            "image_url": f"data:image/png;base64,{image_url_base64}",
        }

        # Remove None values
        arguments = {k: v for k, v in arguments.items() if v is not None}

        res = await self.submit_request(
            context=context,
            application="fal-ai/sam-3/image/embed",
            arguments=arguments,
        )
        return res

    @classmethod
    def get_basic_fields(cls):
        return ["image"]

class OpenrouterRouterVision(FALNode):
    """
    OpenRouter [Vision]
    vision, analysis, image-understanding, detection

    Use cases:
    - Automated content generation
    - Creative workflows
    - Batch processing
    - Professional applications
    - Rapid prototyping
    """

    prompt: str = Field(
        default="", description="Prompt to be used for the image"
    )
    reasoning: bool = Field(
        default=False, description="Should reasoning be the part of the final answer."
    )
    system_prompt: str = Field(
        default="", description="System prompt to provide context or instructions to the model"
    )
    model: str = Field(
        default="", description="Name of the model to use. Charged based on actual token usage."
    )
    max_tokens: str = Field(
        default="", description="This sets the upper limit for the number of tokens the model can generate in response. It won't produce more than this limit. The maximum value is the context length minus the prompt length."
    )
    temperature: float = Field(
        default=1, description="This setting influences the variety in the model's responses. Lower values lead to more predictable and typical responses, while higher values encourage more diverse and less common responses. At 0, the model always gives the same response for a given input."
    )
    image_urls: list[str] = Field(
        default=[], description="List of image URLs to be processed"
    )

    async def process(self, context: ProcessingContext) -> dict[str, Any]:
        arguments = {
            "prompt": self.prompt,
            "reasoning": self.reasoning,
            "system_prompt": self.system_prompt,
            "model": self.model,
            "max_tokens": self.max_tokens,
            "temperature": self.temperature,
            "image_urls": self.image_urls,
        }

        # Remove None values
        arguments = {k: v for k, v in arguments.items() if v is not None}

        res = await self.submit_request(
            context=context,
            application="openrouter/router/vision",
            arguments=arguments,
        )
        return res

    @classmethod
    def get_basic_fields(cls):
        return ["image"]

class Moondream3PreviewDetect(FALNode):
    """
    Moondream3 Preview [Detect]
    vision, analysis, image-understanding, detection

    Use cases:
    - Automated content generation
    - Creative workflows
    - Batch processing
    - Professional applications
    - Rapid prototyping
    """

    prompt: str = Field(
        default="", description="Object to be detected in the image"
    )
    preview: bool = Field(
        default=False, description="Whether to preview the output"
    )
    image_url: ImageRef = Field(
        default=ImageRef(), description="URL of the image to be processed Max width: 7000px, Max height: 7000px, Timeout: 20.0s"
    )

    async def process(self, context: ProcessingContext) -> dict[str, Any]:
        image_url_base64 = await context.image_to_base64(self.image_url)
        arguments = {
            "prompt": self.prompt,
            "preview": self.preview,
            "image_url": f"data:image/png;base64,{image_url_base64}",
        }

        # Remove None values
        arguments = {k: v for k, v in arguments.items() if v is not None}

        res = await self.submit_request(
            context=context,
            application="fal-ai/moondream3-preview/detect",
            arguments=arguments,
        )
        return res

    @classmethod
    def get_basic_fields(cls):
        return ["image"]

class Moondream3PreviewPoint(FALNode):
    """
    Moondream3 Preview [Point]
    vision, analysis, image-understanding, detection

    Use cases:
    - Automated content generation
    - Creative workflows
    - Batch processing
    - Professional applications
    - Rapid prototyping
    """

    prompt: str = Field(
        default="", description="Object to be located in the image"
    )
    preview: bool = Field(
        default=False, description="Whether to preview the output"
    )
    image_url: ImageRef = Field(
        default=ImageRef(), description="URL of the image to be processed Max width: 7000px, Max height: 7000px, Timeout: 20.0s"
    )

    async def process(self, context: ProcessingContext) -> dict[str, Any]:
        image_url_base64 = await context.image_to_base64(self.image_url)
        arguments = {
            "prompt": self.prompt,
            "preview": self.preview,
            "image_url": f"data:image/png;base64,{image_url_base64}",
        }

        # Remove None values
        arguments = {k: v for k, v in arguments.items() if v is not None}

        res = await self.submit_request(
            context=context,
            application="fal-ai/moondream3-preview/point",
            arguments=arguments,
        )
        return res

    @classmethod
    def get_basic_fields(cls):
        return ["image"]

class Moondream3PreviewQuery(FALNode):
    """
    Moondream 3 Preview [Query]
    vision, analysis, image-understanding, detection

    Use cases:
    - Automated content generation
    - Creative workflows
    - Batch processing
    - Professional applications
    - Rapid prototyping
    """

    prompt: str = Field(
        default="", description="Query to be asked in the image"
    )
    top_p: float = Field(
        default=0.0, description="Nucleus sampling probability mass to use, between 0 and 1."
    )
    temperature: float = Field(
        default=0.0, description="Sampling temperature to use, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If not set, defaults to 0."
    )
    reasoning: bool = Field(
        default=True, description="Whether to include detailed reasoning behind the answer"
    )
    image_url: ImageRef = Field(
        default=ImageRef(), description="URL of the image to be processed Max width: 7000px, Max height: 7000px, Timeout: 20.0s"
    )

    async def process(self, context: ProcessingContext) -> dict[str, Any]:
        image_url_base64 = await context.image_to_base64(self.image_url)
        arguments = {
            "prompt": self.prompt,
            "top_p": self.top_p,
            "temperature": self.temperature,
            "reasoning": self.reasoning,
            "image_url": f"data:image/png;base64,{image_url_base64}",
        }

        # Remove None values
        arguments = {k: v for k, v in arguments.items() if v is not None}

        res = await self.submit_request(
            context=context,
            application="fal-ai/moondream3-preview/query",
            arguments=arguments,
        )
        return res

    @classmethod
    def get_basic_fields(cls):
        return ["image"]

class Moondream3PreviewCaption(FALNode):
    """
    Moondream3 Preview [Caption]
    vision, analysis, image-understanding, detection

    Use cases:
    - Automated content generation
    - Creative workflows
    - Batch processing
    - Professional applications
    - Rapid prototyping
    """

    class Length(Enum):
        """
        Length of the caption to generate
        """
        SHORT = "short"
        NORMAL = "normal"
        LONG = "long"


    top_p: float = Field(
        default=0.0, description="Nucleus sampling probability mass to use, between 0 and 1."
    )
    length: Length = Field(
        default=Length.NORMAL, description="Length of the caption to generate"
    )
    temperature: float = Field(
        default=0.0, description="Sampling temperature to use, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If not set, defaults to 0."
    )
    image_url: ImageRef = Field(
        default=ImageRef(), description="URL of the image to be processed Max width: 7000px, Max height: 7000px, Timeout: 20.0s"
    )

    async def process(self, context: ProcessingContext) -> dict[str, Any]:
        image_url_base64 = await context.image_to_base64(self.image_url)
        arguments = {
            "top_p": self.top_p,
            "length": self.length.value,
            "temperature": self.temperature,
            "image_url": f"data:image/png;base64,{image_url_base64}",
        }

        # Remove None values
        arguments = {k: v for k, v in arguments.items() if v is not None}

        res = await self.submit_request(
            context=context,
            application="fal-ai/moondream3-preview/caption",
            arguments=arguments,
        )
        return res

    @classmethod
    def get_basic_fields(cls):
        return ["image"]

class PerceptronIsaac01OpenaiV1ChatCompletions(FALNode):
    """
    Isaac 0.1 [OpenAI Compatible Endpoint]
    vision, analysis, image-understanding, detection

    Use cases:
    - Automated content generation
    - Creative workflows
    - Batch processing
    - Professional applications
    - Rapid prototyping
    """


    async def process(self, context: ProcessingContext) -> Any:
        arguments = {
        }

        # Remove None values
        arguments = {k: v for k, v in arguments.items() if v is not None}

        res = await self.submit_request(
            context=context,
            application="perceptron/isaac-01/openai/v1/chat/completions",
            arguments=arguments,
        )
        return res

    @classmethod
    def get_basic_fields(cls):
        return ["image"]