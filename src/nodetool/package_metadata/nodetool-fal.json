{
  "name": "nodetool-fal",
  "description": "Nodetool FAL nodes",
  "version": "0.6.3-rc.17",
  "authors": [
    "Matthias Georgi <matti.georgi@gmail.com>"
  ],
  "repo_id": "",
  "nodes": [
    {
      "title": "Ai Baby And Aging Generator Multi",
      "description": "AI Baby and Aging Generator Multi shows age progression or regression for multiple people in one image.\n    image, aging, age-progression, multi-face\n\n    Use cases:\n    - Show age progression for multiple people\n    - Generate family aging visualizations\n    - Create multi-person aging results\n    - Produce group age transformations\n    - Visualize multiple people at different ages",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.AiBabyAndAgingGeneratorMulti",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "a newborn baby, well dressed",
          "title": "Prompt",
          "description": "Text prompt to guide the image generation"
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "Number of images to generate"
        },
        {
          "name": "image_size",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Image Size",
          "description": "The size of the generated image"
        },
        {
          "name": "father_weight",
          "type": {
            "type": "float"
          },
          "default": 0.5,
          "title": "Father Weight",
          "description": "Weight of the father's influence in multi mode generation"
        },
        {
          "name": "mother_image_urls",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "str"
              }
            ]
          },
          "default": [],
          "title": "Mother Image Urls",
          "description": "List of mother images for multi mode"
        },
        {
          "name": "output_format",
          "type": {
            "type": "enum",
            "values": [
              "jpeg",
              "png"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.OutputFormat"
          },
          "default": "jpeg",
          "title": "Output Format",
          "description": "The format of the generated image. Choose from: 'jpeg' or 'png'."
        },
        {
          "name": "age_group",
          "type": {
            "type": "enum",
            "values": [
              "baby",
              "toddler",
              "preschool",
              "gradeschooler",
              "teen",
              "adult",
              "mid",
              "senior"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.AgeGroup"
          },
          "default": "",
          "title": "Age Group",
          "description": "Age group for the generated image. Choose from: 'baby' (0-12 months), 'toddler' (1-3 years), 'preschool' (3-5 years), 'gradeschooler' (6-12 years), 'teen' (13-19 years), 'adult' (20-40 years), 'mid' (40-60 years), 'senior' (60+ years)."
        },
        {
          "name": "gender",
          "type": {
            "type": "enum",
            "values": [
              "male",
              "female"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.Gender"
          },
          "default": "",
          "title": "Gender",
          "description": "Gender for the generated image. Choose from: 'male' or 'female'."
        },
        {
          "name": "father_image_urls",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "str"
              }
            ]
          },
          "default": [],
          "title": "Father Image Urls",
          "description": "List of father images for multi mode"
        },
        {
          "name": "seed",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Seed",
          "description": "Random seed for reproducibility. If None, a random seed will be used"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image"
      ]
    },
    {
      "title": "Ai Baby And Aging Generator Single",
      "description": "AI Baby and Aging Generator Single shows age progression or regression for a single person.\n    image, aging, age-progression, face-manipulation\n\n    Use cases:\n    - Show age progression of person\n    - Generate younger or older versions\n    - Create aging visualizations\n    - Produce age transformation results\n    - Visualize person at different ages",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.AiBabyAndAgingGeneratorSingle",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "a newborn baby, well dressed",
          "title": "Prompt",
          "description": "Text prompt to guide the image generation"
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "Number of images to generate"
        },
        {
          "name": "image_size",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Image Size",
          "description": "The size of the generated image"
        },
        {
          "name": "id_image_urls",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "str"
              }
            ]
          },
          "default": [],
          "title": "Id Image Urls",
          "description": "List of ID images for single mode (or general reference images)"
        },
        {
          "name": "output_format",
          "type": {
            "type": "enum",
            "values": [
              "jpeg",
              "png"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.OutputFormat"
          },
          "default": "jpeg",
          "title": "Output Format",
          "description": "The format of the generated image. Choose from: 'jpeg' or 'png'."
        },
        {
          "name": "age_group",
          "type": {
            "type": "enum",
            "values": [
              "baby",
              "toddler",
              "preschool",
              "gradeschooler",
              "teen",
              "adult",
              "mid",
              "senior"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.AgeGroup"
          },
          "default": "",
          "title": "Age Group",
          "description": "Age group for the generated image. Choose from: 'baby' (0-12 months), 'toddler' (1-3 years), 'preschool' (3-5 years), 'gradeschooler' (6-12 years), 'teen' (13-19 years), 'adult' (20-40 years), 'mid' (40-60 years), 'senior' (60+ years)."
        },
        {
          "name": "gender",
          "type": {
            "type": "enum",
            "values": [
              "male",
              "female"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.Gender"
          },
          "default": "",
          "title": "Gender",
          "description": "Gender for the generated image. Choose from: 'male' or 'female'."
        },
        {
          "name": "seed",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Seed",
          "description": "Random seed for reproducibility. If None, a random seed will be used"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image"
      ]
    },
    {
      "title": "Ai Face Swap Image",
      "description": "AI Face Swap replaces faces in images with source faces while maintaining natural appearance.\n    image, face-swap, ai, face-manipulation\n\n    Use cases:\n    - Swap faces between images\n    - Replace faces in photos\n    - Create face-swapped variations\n    - Generate face replacement results\n    - Produce face-substituted images",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.AiFaceSwapImage",
      "properties": [
        {
          "name": "enable_occlusion_prevention",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Enable Occlusion Prevention",
          "description": "Enable occlusion prevention for handling faces covered by hands/objects. Warning: Enabling this runs an occlusion-aware model which costs 2x more."
        },
        {
          "name": "source_face_url",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Source Face Url",
          "description": "Source face image. Allowed items: bmp, jpeg, png, tiff, webp"
        },
        {
          "name": "target_image_url",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Target Image Url",
          "description": "Target image URL. Allowed items: bmp, jpeg, png, tiff, webp"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "dict",
            "type_args": [
              {
                "type": "str"
              },
              {
                "type": "any"
              }
            ]
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image"
      ]
    },
    {
      "title": "Ai Home Edit",
      "description": "AI Home Edit modifies interior spaces with renovations, furniture changes, and design adjustments.\n    image, interior-design, editing, home, renovation\n\n    Use cases:\n    - Edit interior spaces\n    - Modify room furniture and decor\n    - Create renovation visualizations\n    - Generate design modification options\n    - Produce home editing results",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.AiHomeEdit",
      "properties": [
        {
          "name": "input_image_url",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Input Image Url",
          "description": "URL of the image to do architectural editing"
        },
        {
          "name": "editing_type",
          "type": {
            "type": "enum",
            "values": [
              "structural editing",
              "virtual staging",
              "both"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.EditingType"
          },
          "default": "",
          "title": "Editing Type",
          "description": "Type of editing. Structural editing only edits structural elements such as windows, walls etc. Virtual staging edits your furniture. Both do full editing including structural and furniture"
        },
        {
          "name": "style",
          "type": {
            "type": "enum",
            "values": [
              "auto",
              "general",
              "realistic",
              "design",
              "render_3D",
              "anime"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.Style"
          },
          "default": "",
          "title": "Style",
          "description": "Style for furniture and decor"
        },
        {
          "name": "additional_elements",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Additional Elements",
          "description": "Additional elements to include in the options above (e.g., plants, lighting)"
        },
        {
          "name": "output_format",
          "type": {
            "type": "enum",
            "values": [
              "jpeg",
              "png"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.OutputFormat"
          },
          "default": "jpeg",
          "title": "Output Format",
          "description": "The format of the generated image. Choose from: 'jpeg' or 'png'."
        },
        {
          "name": "architecture_type",
          "type": {
            "type": "enum",
            "values": [
              "living room-interior",
              "bedroom-interior",
              "kitchen-interior",
              "dining room-interior",
              "bathroom-interior",
              "laundry room-interior",
              "home office-interior",
              "study room-interior",
              "dorm room-interior",
              "coffee shop-interior",
              "gaming room-interior",
              "restaurant-interior",
              "office-interior",
              "attic-interior",
              "toilet-interior",
              "other-interior",
              "house-exterior",
              "villa-exterior",
              "backyard-exterior",
              "courtyard-exterior",
              "ranch-exterior",
              "office-exterior",
              "retail-exterior",
              "tower-exterior",
              "apartment-exterior",
              "school-exterior",
              "museum-exterior",
              "commercial-exterior",
              "residential-exterior",
              "other-exterior"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.ArchitectureType"
          },
          "default": "",
          "title": "Architecture Type",
          "description": "Type of architecture for appropriate furniture selection"
        },
        {
          "name": "color_palette",
          "type": {
            "type": "enum",
            "values": [
              "surprise me",
              "golden beige",
              "refined blues",
              "dusky elegance",
              "emerald charm",
              "crimson luxury",
              "golden sapphire",
              "soft pastures",
              "candy sky",
              "peach meadow",
              "muted sands",
              "ocean breeze",
              "frosted pastels",
              "spring bloom",
              "gentle horizon",
              "seaside breeze",
              "azure coast",
              "golden shore",
              "mediterranean gem",
              "ocean serenity",
              "serene blush",
              "muted horizon",
              "pastel shores",
              "dusky calm",
              "woodland retreat",
              "meadow glow",
              "forest canopy",
              "riverbank calm",
              "earthy tones",
              "earthy neutrals",
              "arctic mist",
              "aqua drift",
              "blush bloom",
              "coral haze",
              "retro rust",
              "autumn glow",
              "rustic charm",
              "vintage sage",
              "faded plum",
              "electric lime",
              "violet pulse",
              "neon sorbet",
              "aqua glow",
              "fluorescent sunset",
              "lavender bloom",
              "petal fresh",
              "meadow light",
              "sunny pastures",
              "frosted mauve",
              "snowy hearth",
              "icy blues",
              "winter twilight",
              "earthy hues",
              "stone balance",
              "neutral sands",
              "slate shades"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.ColorPalette"
          },
          "default": "",
          "title": "Color Palette",
          "description": "Color palette for furniture and decor"
        },
        {
          "name": "custom_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Custom Prompt",
          "description": "Custom prompt for architectural editing, it overrides above options when used"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "dict",
            "type_args": [
              {
                "type": "str"
              },
              {
                "type": "any"
              }
            ]
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "Ai Home Style",
      "description": "AI Home Style transforms interior spaces with different design styles and aesthetics.\n    image, interior-design, style-transfer, home, decoration\n\n    Use cases:\n    - Transform interior design styles\n    - Apply different home aesthetics\n    - Create styled room variations\n    - Generate interior design options\n    - Produce home styling transformations",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.AiHomeStyle",
      "properties": [
        {
          "name": "input_image_url",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Input Image Url",
          "description": "URL of the image to do architectural styling"
        },
        {
          "name": "input_image_strength",
          "type": {
            "type": "float"
          },
          "default": 0.85,
          "title": "Input Image Strength",
          "description": "Strength of the input image"
        },
        {
          "name": "additional_elements",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Additional Elements",
          "description": "Additional elements to include in the options above (e.g., plants, lighting)"
        },
        {
          "name": "output_format",
          "type": {
            "type": "enum",
            "values": [
              "jpeg",
              "png"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.OutputFormat"
          },
          "default": "jpeg",
          "title": "Output Format",
          "description": "The format of the generated image. Choose from: 'jpeg' or 'png'."
        },
        {
          "name": "style",
          "type": {
            "type": "enum",
            "values": [
              "auto",
              "general",
              "realistic",
              "design",
              "render_3D",
              "anime"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.Style"
          },
          "default": "",
          "title": "Style",
          "description": "Style for furniture and decor"
        },
        {
          "name": "architecture_type",
          "type": {
            "type": "enum",
            "values": [
              "living room-interior",
              "bedroom-interior",
              "kitchen-interior",
              "dining room-interior",
              "bathroom-interior",
              "laundry room-interior",
              "home office-interior",
              "study room-interior",
              "dorm room-interior",
              "coffee shop-interior",
              "gaming room-interior",
              "restaurant-interior",
              "office-interior",
              "attic-interior",
              "toilet-interior",
              "other-interior",
              "house-exterior",
              "villa-exterior",
              "backyard-exterior",
              "courtyard-exterior",
              "ranch-exterior",
              "office-exterior",
              "retail-exterior",
              "tower-exterior",
              "apartment-exterior",
              "school-exterior",
              "museum-exterior",
              "commercial-exterior",
              "residential-exterior",
              "other-exterior"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.ArchitectureType"
          },
          "default": "",
          "title": "Architecture Type",
          "description": "Type of architecture for appropriate furniture selection"
        },
        {
          "name": "color_palette",
          "type": {
            "type": "enum",
            "values": [
              "surprise me",
              "golden beige",
              "refined blues",
              "dusky elegance",
              "emerald charm",
              "crimson luxury",
              "golden sapphire",
              "soft pastures",
              "candy sky",
              "peach meadow",
              "muted sands",
              "ocean breeze",
              "frosted pastels",
              "spring bloom",
              "gentle horizon",
              "seaside breeze",
              "azure coast",
              "golden shore",
              "mediterranean gem",
              "ocean serenity",
              "serene blush",
              "muted horizon",
              "pastel shores",
              "dusky calm",
              "woodland retreat",
              "meadow glow",
              "forest canopy",
              "riverbank calm",
              "earthy tones",
              "earthy neutrals",
              "arctic mist",
              "aqua drift",
              "blush bloom",
              "coral haze",
              "retro rust",
              "autumn glow",
              "rustic charm",
              "vintage sage",
              "faded plum",
              "electric lime",
              "violet pulse",
              "neon sorbet",
              "aqua glow",
              "fluorescent sunset",
              "lavender bloom",
              "petal fresh",
              "meadow light",
              "sunny pastures",
              "frosted mauve",
              "snowy hearth",
              "icy blues",
              "winter twilight",
              "earthy hues",
              "stone balance",
              "neutral sands",
              "slate shades"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.ColorPalette"
          },
          "default": "",
          "title": "Color Palette",
          "description": "Color palette for furniture and decor"
        },
        {
          "name": "style_image_url",
          "type": {
            "type": "image"
          },
          "default": "",
          "title": "Style Image Url",
          "description": "URL of the style image, optional. If given, other parameters are ignored"
        },
        {
          "name": "custom_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Custom Prompt",
          "description": "Custom prompt for architectural editing, it overrides above options when used"
        },
        {
          "name": "enhanced_rendering",
          "type": {
            "type": "str"
          },
          "default": false,
          "title": "Enhanced Rendering",
          "description": "It gives better rendering quality with more processing time, additional cost is 0.01 USD per image"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "dict",
            "type_args": [
              {
                "type": "str"
              },
              {
                "type": "any"
              }
            ]
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "Bi Ref Net",
      "description": "BiRefNet (Bilateral Reference Network) performs high-quality background removal with precise edge detection and detail preservation.\n    image, background-removal, segmentation, birefnet, mask\n\n    Use cases:\n    - Remove backgrounds from product photos\n    - Create transparent PNGs from images\n    - Extract subjects for compositing\n    - Generate clean cutouts for design work\n    - Prepare images for background replacement",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.BiRefNet",
      "properties": [
        {
          "name": "operating_resolution",
          "type": {
            "type": "enum",
            "values": [
              "1024x1024",
              "2048x2048"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.OperatingResolution"
          },
          "default": "1024x1024",
          "title": "Operating Resolution",
          "description": "The resolution to operate on. The higher the resolution, the more accurate the output will be for high res input images."
        },
        {
          "name": "output_format",
          "type": {
            "type": "enum",
            "values": [
              "jpeg",
              "png"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.OutputFormat"
          },
          "default": "png",
          "title": "Output Format",
          "description": "The format of the output image"
        },
        {
          "name": "image_url",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image Url",
          "description": "URL of the image to remove background from"
        },
        {
          "name": "model",
          "type": {
            "type": "enum",
            "values": [
              "General Use (Light)",
              "General Use (Heavy)",
              "Portrait"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.Model"
          },
          "default": "General Use (Light)",
          "title": "Model",
          "description": "Model to use for background removal. The 'General Use (Light)' model is the original model used in the BiRefNet repository. The 'General Use (Heavy)' model is a slower but more accurate model. The 'Portrait' model is a model trained specifically for portrait images. The 'General Use (Light)' model is recommended for most use cases. The corresponding models are as follows: - 'General Use (Light)': BiRefNet-DIS_ep580.pth - 'General Use (Heavy)': BiRefNet-massive-epoch_240.pth - 'Portrait': BiRefNet-portrait-TR_P3M_10k-epoch_120.pth"
        },
        {
          "name": "sync_mode",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Sync Mode",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history."
        },
        {
          "name": "output_mask",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Output Mask",
          "description": "Whether to output the mask used to remove the background"
        },
        {
          "name": "refine_foreground",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Refine Foreground",
          "description": "Whether to refine the foreground using the estimated mask"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "dict",
            "type_args": [
              {
                "type": "str"
              },
              {
                "type": "any"
              }
            ]
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image"
      ]
    },
    {
      "title": "Bria Background Replace",
      "description": "Bria Background Replace swaps image backgrounds with new content. Intelligently separates subjects and generates contextually appropriate backgrounds.\n    image, background, replacement, segmentation, bria\n\n    Use cases:\n    - Replace photo backgrounds with custom scenes\n    - Create product shots with various backgrounds\n    - Change image context while preserving subject\n    - Generate professional portraits with studio backgrounds\n    - Create marketing materials with branded backgrounds",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.BriaBackgroundReplace",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "Description of the new background to generate"
        },
        {
          "name": "steps_num",
          "type": {
            "type": "int"
          },
          "default": 30,
          "title": "Steps Num",
          "description": "Number of inference steps."
        },
        {
          "name": "sync_mode",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Sync Mode",
          "description": "If true, returns the image directly in the response (increases latency)."
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": 4925634,
          "title": "Seed",
          "description": "Random seed for reproducibility."
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "Negative prompt for background replacement."
        },
        {
          "name": "image_url",
          "type": {
            "type": "image"
          },
          "default": "https://v3b.fal.media/files/b/0a8bea8c/Mztgx0NG3HPdby-4iPqwH_a_coffee_machine_standing_in_the_kitchen.png",
          "title": "Image Url",
          "description": "Reference image (file or URL)."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "Bria Eraser",
      "description": "Bria Eraser removes unwanted objects from images using intelligent inpainting. Seamlessly fill removed areas with contextually appropriate content.\n    image, eraser, removal, inpainting, bria, cleanup\n\n    Use cases:\n    - Remove unwanted objects from photos\n    - Clean up image backgrounds\n    - Erase text or watermarks\n    - Delete distracting elements\n    - Create clean product shots",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.BriaEraser",
      "properties": [
        {
          "name": "sync_mode",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Sync Mode",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history."
        },
        {
          "name": "preserve_alpha",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Preserve Alpha",
          "description": "If set to true, attempts to preserve the alpha channel of the input image."
        },
        {
          "name": "mask_url",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Mask Url",
          "description": "The URL of the binary mask image that represents the area that will be cleaned."
        },
        {
          "name": "mask_type",
          "type": {
            "type": "enum",
            "values": [
              "manual",
              "automatic"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.MaskType"
          },
          "default": "manual",
          "title": "Mask Type",
          "description": "You can use this parameter to specify the type of the input mask from the list. 'manual' opttion should be used in cases in which the mask had been generated by a user (e.g. with a brush tool), and 'automatic' mask type should be used when mask had been generated by an algorithm like 'SAM'."
        },
        {
          "name": "image_url",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image Url",
          "description": "Input Image to erase from"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "mask"
      ]
    },
    {
      "title": "Bria Fibo Edit",
      "description": "Bria FIBO Edit provides general-purpose image editing with AI-powered modifications and enhancements.\n    image, editing, bria, fibo, general\n\n    Use cases:\n    - Edit images with general-purpose AI\n    - Apply various modifications to photos\n    - Create edited versions of images\n    - Transform images with flexible edits\n    - Produce AI-powered modifications",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.BriaFiboEdit",
      "properties": [
        {
          "name": "steps_num",
          "type": {
            "type": "int"
          },
          "default": 50,
          "title": "Steps Num",
          "description": "Number of inference steps."
        },
        {
          "name": "instruction",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Instruction",
          "description": "Instruction for image editing."
        },
        {
          "name": "image_url",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image Url",
          "description": "Reference image (file or URL)."
        },
        {
          "name": "sync_mode",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Sync Mode",
          "description": "If true, returns the image directly in the response (increases latency)."
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "str"
          },
          "default": 5,
          "title": "Guidance Scale",
          "description": "Guidance scale for text."
        },
        {
          "name": "structured_instruction",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Structured Instruction",
          "description": "The structured prompt to generate an image from."
        },
        {
          "name": "mask_url",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Mask Url",
          "description": "Mask image (file or URL). Optional"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "Negative prompt for image generation."
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": 5555,
          "title": "Seed",
          "description": "Random seed for reproducibility."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "Bria Fibo Edit Add Object By Text",
      "description": "Bria FIBO Edit Add Object by Text inserts new objects into images using text descriptions.\n    image, editing, bria, fibo, object-insertion\n\n    Use cases:\n    - Add objects to images with text\n    - Insert elements using descriptions\n    - Place new items in scenes\n    - Augment images with additional objects\n    - Generate object additions",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.BriaFiboEditAddObjectByText",
      "properties": [
        {
          "name": "instruction",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Instruction",
          "description": "The full natural language command describing what to add and where."
        },
        {
          "name": "image_url",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image Url",
          "description": "The source image."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "Bria Fibo Edit Blend",
      "description": "Bria FIBO Edit Blend seamlessly combines multiple images or elements with natural transitions.\n    image, editing, bria, fibo, blending\n\n    Use cases:\n    - Blend multiple images together\n    - Create seamless compositions\n    - Merge elements naturally\n    - Combine images with smooth transitions\n    - Generate blended composites",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.BriaFiboEditBlend",
      "properties": [
        {
          "name": "instruction",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Instruction",
          "description": "Instruct what elements you would like to blend in your image."
        },
        {
          "name": "image_url",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image Url",
          "description": "The source image."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "Bria Fibo Edit Colorize",
      "description": "Bria FIBO Edit Colorize adds realistic colors to grayscale or black-and-white images.\n    image, editing, bria, fibo, colorization\n\n    Use cases:\n    - Colorize black and white photos\n    - Add colors to grayscale images\n    - Restore color in old photographs\n    - Transform monochrome to color\n    - Generate colored versions of grayscale images",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.BriaFiboEditColorize",
      "properties": [
        {
          "name": "color",
          "type": {
            "type": "enum",
            "values": [
              "contemporary color",
              "vivid color",
              "black and white colors",
              "sepia vintage"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.Color"
          },
          "default": "",
          "title": "Color",
          "description": "Select the color palette or aesthetic for the output image"
        },
        {
          "name": "image_url",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image Url",
          "description": "The source image."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image"
      ]
    },
    {
      "title": "Bria Fibo Edit Erase By Text",
      "description": "Bria FIBO Edit Erase by Text removes objects from images using natural language descriptions.\n    image, editing, bria, fibo, object-removal\n\n    Use cases:\n    - Remove objects using text descriptions\n    - Erase unwanted elements from photos\n    - Clean up images by describing what to remove\n    - Delete specific items from scenes\n    - Remove objects with natural language",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.BriaFiboEditEraseByText",
      "properties": [
        {
          "name": "object_name",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Object Name",
          "description": "The name of the object to remove."
        },
        {
          "name": "image_url",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image Url",
          "description": "The source image."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "Bria Fibo Edit Relight",
      "description": "Bria FIBO Edit Relight adjusts lighting conditions in images for dramatic or natural effects.\n    image, editing, bria, fibo, relighting\n\n    Use cases:\n    - Adjust lighting in photos\n    - Change illumination conditions\n    - Create dramatic lighting effects\n    - Relight scenes for better ambiance\n    - Transform lighting in images",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.BriaFiboEditRelight",
      "properties": [
        {
          "name": "light_type",
          "type": {
            "type": "enum",
            "values": [
              "midday",
              "blue hour light",
              "low-angle sunlight",
              "sunrise light",
              "spotlight on subject",
              "overcast light",
              "soft overcast daylight lighting",
              "cloud-filtered lighting",
              "fog-diffused lighting",
              "moonlight lighting",
              "starlight nighttime",
              "soft bokeh lighting",
              "harsh studio lighting"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.LightType"
          },
          "default": "",
          "title": "Light Type",
          "description": "The quality/style/time of day."
        },
        {
          "name": "light_direction",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Light Direction",
          "description": "Where the light comes from."
        },
        {
          "name": "image_url",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image Url",
          "description": "The source image."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "Bria Fibo Edit Replace Object By Text",
      "description": "Bria FIBO Edit Replace Object by Text replaces objects in images with new ones specified by text.\n    image, editing, bria, fibo, object-replacement\n\n    Use cases:\n    - Replace objects using text descriptions\n    - Swap elements in photos\n    - Change specific items in scenes\n    - Transform objects with text guidance\n    - Substitute objects with new ones",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.BriaFiboEditReplaceObjectByText",
      "properties": [
        {
          "name": "instruction",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Instruction",
          "description": "The full natural language command describing what to replace."
        },
        {
          "name": "image_url",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image Url",
          "description": "The source image."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "Bria Fibo Edit Reseason",
      "description": "Bria FIBO Edit Reseason changes the seasonal appearance of outdoor scenes in images.\n    image, editing, bria, fibo, seasonal\n\n    Use cases:\n    - Change seasons in outdoor photos\n    - Transform summer to winter scenes\n    - Modify seasonal appearance\n    - Create seasonal variations\n    - Generate different season versions",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.BriaFiboEditReseason",
      "properties": [
        {
          "name": "season",
          "type": {
            "type": "enum",
            "values": [
              "spring",
              "summer",
              "autumn",
              "winter"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.Season"
          },
          "default": "",
          "title": "Season",
          "description": "The desired season."
        },
        {
          "name": "image_url",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image Url",
          "description": "The source image."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "Bria Fibo Edit Restore",
      "description": "Bria FIBO Edit Restore repairs and enhances damaged or degraded images with AI reconstruction.\n    image, editing, bria, fibo, restoration\n\n    Use cases:\n    - Restore damaged photographs\n    - Repair degraded images\n    - Enhance old photo quality\n    - Fix scratches and artifacts\n    - Reconstruct missing image parts",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.BriaFiboEditRestore",
      "properties": [
        {
          "name": "image_url",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image Url",
          "description": "The source image."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image"
      ]
    },
    {
      "title": "Bria Fibo Edit Restyle",
      "description": "Bria FIBO Edit Restyle transforms images with artistic style transfers and visual aesthetics.\n    image, editing, bria, fibo, style-transfer\n\n    Use cases:\n    - Apply artistic styles to images\n    - Transform photos with new aesthetics\n    - Create stylized versions of images\n    - Generate artistic variations\n    - Produce style-transferred images",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.BriaFiboEditRestyle",
      "properties": [
        {
          "name": "style",
          "type": {
            "type": "enum",
            "values": [
              "auto",
              "general",
              "realistic",
              "design",
              "render_3D",
              "anime"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.Style"
          },
          "default": "",
          "title": "Style",
          "description": "Select the desired artistic style for the output image."
        },
        {
          "name": "image_url",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image Url",
          "description": "The source image."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "Bria Fibo Edit Rewrite Text",
      "description": "Bria FIBO Edit Rewrite Text modifies or replaces text content within images naturally.\n    image, editing, bria, fibo, text-editing\n\n    Use cases:\n    - Change text in images\n    - Replace written content in photos\n    - Modify signs and labels\n    - Update text naturally in scenes\n    - Edit textual elements in images",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.BriaFiboEditRewriteText",
      "properties": [
        {
          "name": "new_text",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "New Text",
          "description": "The new text string to appear in the image."
        },
        {
          "name": "image_url",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image Url",
          "description": "The source image."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "Bria Fibo Edit Sketch To Colored Image",
      "description": "Bria FIBO Edit Sketch to Colored Image transforms sketches and line art into full-color images.\n    image, editing, bria, fibo, sketch-to-image\n\n    Use cases:\n    - Convert sketches to colored images\n    - Transform line art to full color\n    - Generate colored versions of drawings\n    - Create realistic images from sketches\n    - Produce colored artwork from outlines",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.BriaFiboEditSketchToColoredImage",
      "properties": [
        {
          "name": "image_url",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image Url",
          "description": "The source image."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "Bytedance Seedream V45 Edit",
      "description": "ByteDance SeeDream v4.5 Edit provides advanced image editing with cutting-edge AI technology.\n    image, editing, bytedance, seedream, v4.5\n\n    Use cases:\n    - Edit images with SeeDream v4.5\n    - Apply advanced modifications\n    - Create high-quality edits\n    - Transform images with latest tech\n    - Produce cutting-edge modifications",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.BytedanceSeedreamV45Edit",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The text prompt used to edit the image"
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "Number of separate model generations to be run with the prompt."
        },
        {
          "name": "image_size",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Image Size",
          "description": "The size of the generated image. Width and height must be between 1920 and 4096, or total number of pixels must be between 2560*1440 and 4096*4096."
        },
        {
          "name": "max_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Max Images",
          "description": "If set to a number greater than one, enables multi-image generation. The model will potentially return up to `max_images` images every generation, and in total, `num_images` generations will be carried out. In total, the number of images generated will be between `num_images` and `max_images*num_images`. The total number of images (image inputs + image outputs) must not exceed 15"
        },
        {
          "name": "sync_mode",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Sync Mode",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history."
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If set to true, the safety checker will be enabled."
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Random seed to control the stochasticity of image generation."
        },
        {
          "name": "image_urls",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "str"
              }
            ]
          },
          "default": [],
          "title": "Image Urls",
          "description": "List of URLs of input images for editing. Presently, up to 10 image inputs are allowed. If over 10 images are sent, only the last 10 will be used."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "Clarity Upscaler",
      "description": "Clarity Upscaler increases image resolution using AI-powered super-resolution. Enhance image quality, sharpness, and detail up to 4x scale.\n    image, upscaling, enhancement, super-resolution, clarity\n\n    Use cases:\n    - Increase image resolution for printing\n    - Improve clarity of low-quality images\n    - Enhance textures and fine details\n    - Prepare images for large displays\n    - Restore detail in compressed images",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.ClarityUpscaler",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "masterpiece, best quality, highres",
          "title": "Prompt",
          "description": "The prompt to use for generating the image. Be as descriptive as possible for best results."
        },
        {
          "name": "resemblance",
          "type": {
            "type": "float"
          },
          "default": 0.6,
          "title": "Resemblance",
          "description": "The resemblance of the upscaled image to the original image. The higher the resemblance, the more the model will try to keep the original image. Refers to the strength of the ControlNet."
        },
        {
          "name": "creativity",
          "type": {
            "type": "float"
          },
          "default": 0.35,
          "title": "Creativity",
          "description": "The creativity of the model. The higher the creativity, the more the model will deviate from the prompt. Refers to the denoise strength of the sampling."
        },
        {
          "name": "image_url",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image Url",
          "description": "The URL of the image to upscale."
        },
        {
          "name": "upscale_factor",
          "type": {
            "type": "float"
          },
          "default": 2,
          "title": "Upscale Factor",
          "description": "The upscale factor"
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 4,
          "title": "Guidance Scale",
          "description": "The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you."
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 18,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform."
        },
        {
          "name": "seed",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Seed",
          "description": "The same seed and the same prompt given to the same version of Stable Diffusion will output the same image every time."
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "(worst quality, low quality, normal quality:2)",
          "title": "Negative Prompt",
          "description": "The negative prompt to use. Use it to address details that you don't want in the image."
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If set to false, the safety checker will be disabled."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "dict",
            "type_args": [
              {
                "type": "str"
              },
              {
                "type": "any"
              }
            ]
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "scale"
      ]
    },
    {
      "title": "Code Former",
      "description": "CodeFormer restores and enhances face quality in images. Advanced face restoration with fidelity control for natural-looking results.\n    image, face-restoration, enhancement, codeformer, quality\n\n    Use cases:\n    - Restore quality in degraded face photos\n    - Enhance facial details in low-quality images\n    - Improve portrait quality for professional use\n    - Fix compressed or damaged face images\n    - Enhance facial features while maintaining identity",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.CodeFormer",
      "properties": [
        {
          "name": "aligned",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Aligned",
          "description": "Should faces etc should be aligned."
        },
        {
          "name": "image_url",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image Url",
          "description": "URL of image to be used for relighting"
        },
        {
          "name": "upscale_factor",
          "type": {
            "type": "float"
          },
          "default": 2,
          "title": "Upscale Factor",
          "description": "Upscaling factor"
        },
        {
          "name": "fidelity",
          "type": {
            "type": "float"
          },
          "default": 0.5,
          "title": "Fidelity",
          "description": "Fidelity level (0-1, higher = more faithful to input)"
        },
        {
          "name": "face_upscale",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Face Upscale",
          "description": "Should faces be upscaled"
        },
        {
          "name": "only_center_face",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Only Center Face",
          "description": "Should only center face be restored"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Random seed for reproducible generation."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "dict",
            "type_args": [
              {
                "type": "str"
              },
              {
                "type": "any"
              }
            ]
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "fidelity"
      ]
    },
    {
      "title": "Flux 2 Flash Edit",
      "description": "FLUX-2 Flash Edit provides ultra-fast image editing for rapid iteration and quick modifications.\n    image, editing, flux-2, flash, ultra-fast\n\n    Use cases:\n    - Edit images with ultra-fast processing\n    - Apply instant modifications to photos\n    - Create rapid edits for quick turnaround\n    - Transform images at maximum speed\n    - Produce instant image modifications",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.Flux2FlashEdit",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to edit the image."
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "The number of images to generate."
        },
        {
          "name": "image_size",
          "type": {
            "type": "str"
          },
          "default": "square_hd",
          "title": "Image Size",
          "description": "The size of the image to generate. The width and height must be between 512 and 2048 pixels."
        },
        {
          "name": "output_format",
          "type": {
            "type": "enum",
            "values": [
              "jpeg",
              "png"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.OutputFormat"
          },
          "default": "png",
          "title": "Output Format",
          "description": "The format of the generated image."
        },
        {
          "name": "sync_mode",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Sync Mode",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history."
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 2.5,
          "title": "Guidance Scale",
          "description": "Guidance Scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you."
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The seed to use for the generation. If not provided, a random seed will be used."
        },
        {
          "name": "image_urls",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "str"
              }
            ]
          },
          "default": [],
          "title": "Image Urls",
          "description": "The URLs of the images for editing. A maximum of 4 images are allowed, if more are provided, only the first 4 will be used."
        },
        {
          "name": "enable_prompt_expansion",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Enable Prompt Expansion",
          "description": "If set to true, the prompt will be expanded for better results."
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If set to true, the safety checker will be enabled."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "Flux 2 Flex Edit",
      "description": "FLUX-2 Flex Edit provides flexible image editing with customizable parameters and versatile control.\n    image, editing, flux-2, flex, versatile\n\n    Use cases:\n    - Edit images with flexible controls\n    - Apply customizable modifications\n    - Create versatile edits\n    - Transform images with adaptable settings\n    - Produce flexible image modifications",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.Flux2FlexEdit",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from."
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 3.5,
          "title": "Guidance Scale",
          "description": "The guidance scale to use for the generation."
        },
        {
          "name": "image_size",
          "type": {
            "type": "str"
          },
          "default": "auto",
          "title": "Image Size",
          "description": "The size of the generated image. If `auto`, the size will be determined by the model."
        },
        {
          "name": "output_format",
          "type": {
            "type": "enum",
            "values": [
              "jpeg",
              "png"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.OutputFormat"
          },
          "default": "jpeg",
          "title": "Output Format",
          "description": "The format of the generated image."
        },
        {
          "name": "sync_mode",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Sync Mode",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history."
        },
        {
          "name": "safety_tolerance",
          "type": {
            "type": "enum",
            "values": [
              "1",
              "2",
              "3",
              "4",
              "5",
              "6"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.SafetyTolerance"
          },
          "default": "2",
          "title": "Safety Tolerance",
          "description": "The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive."
        },
        {
          "name": "enable_prompt_expansion",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Prompt Expansion",
          "description": "Whether to expand the prompt using the model's own knowledge."
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 28,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform."
        },
        {
          "name": "image_urls",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "str"
              }
            ]
          },
          "default": [],
          "title": "Image Urls",
          "description": "List of URLs of input images for editing"
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "Whether to enable the safety checker."
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The seed to use for the generation."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "Flux 2 Klein 4B Base Edit",
      "description": "FLUX-2 Klein 4B Base Edit provides fast image editing with the 4-billion parameter model.\n    image, editing, flux-2, klein, 4b\n\n    Use cases:\n    - Edit images with FLUX-2 Klein 4B\n    - Apply fast modifications to photos\n    - Create quick edits with AI assistance\n    - Transform images efficiently\n    - Produce rapid image modifications",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.Flux2Klein4BBaseEdit",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to edit the image."
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "The number of images to generate."
        },
        {
          "name": "image_size",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Image Size",
          "description": "The size of the generated image. If not provided, uses the input image size."
        },
        {
          "name": "acceleration",
          "type": {
            "type": "enum",
            "values": [
              "none",
              "regular",
              "high"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.Acceleration"
          },
          "default": "regular",
          "title": "Acceleration",
          "description": "The acceleration level to use for image generation."
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 5,
          "title": "Guidance Scale",
          "description": "Guidance scale for classifier-free guidance."
        },
        {
          "name": "output_format",
          "type": {
            "type": "enum",
            "values": [
              "jpeg",
              "png"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.OutputFormat"
          },
          "default": "png",
          "title": "Output Format",
          "description": "The format of the generated image."
        },
        {
          "name": "sync_mode",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Sync Mode",
          "description": "If `True`, the media will be returned as a data URI. Output is not stored when this is True."
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If set to true, the safety checker will be enabled."
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 28,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform."
        },
        {
          "name": "image_urls",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "str"
              }
            ]
          },
          "default": [],
          "title": "Image Urls",
          "description": "The URLs of the images for editing. A maximum of 4 images are allowed."
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "Negative prompt for classifier-free guidance. Describes what to avoid in the image."
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The seed to use for the generation. If not provided, a random seed will be used."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "Flux 2 Klein 4B Base Edit Lora",
      "description": "FLUX-2 Klein 4B Base Edit with LoRA enables custom-trained models for specialized editing.\n    image, editing, flux-2, klein, 4b, lora\n\n    Use cases:\n    - Edit images with custom FLUX-2 models\n    - Apply specialized modifications using LoRA\n    - Create domain-specific edits\n    - Transform images with fine-tuned 4B model\n    - Produce customized modifications",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.Flux2Klein4BBaseEditLora",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to edit the image."
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "The number of images to generate."
        },
        {
          "name": "image_size",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Image Size",
          "description": "The size of the generated image. If not provided, uses the input image size."
        },
        {
          "name": "acceleration",
          "type": {
            "type": "enum",
            "values": [
              "none",
              "regular",
              "high"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.Acceleration"
          },
          "default": "regular",
          "title": "Acceleration",
          "description": "The acceleration level to use for image generation."
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 5,
          "title": "Guidance Scale",
          "description": "Guidance scale for classifier-free guidance."
        },
        {
          "name": "output_format",
          "type": {
            "type": "enum",
            "values": [
              "jpeg",
              "png"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.OutputFormat"
          },
          "default": "png",
          "title": "Output Format",
          "description": "The format of the generated image."
        },
        {
          "name": "loras",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "str"
              }
            ]
          },
          "default": [],
          "title": "Loras",
          "description": "List of LoRA weights to apply (maximum 3)."
        },
        {
          "name": "sync_mode",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Sync Mode",
          "description": "If `True`, the media will be returned as a data URI. Output is not stored when this is True."
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If set to true, the safety checker will be enabled."
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 28,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform."
        },
        {
          "name": "image_urls",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "str"
              }
            ]
          },
          "default": [],
          "title": "Image Urls",
          "description": "The URLs of the images for editing. A maximum of 4 images are allowed."
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "Negative prompt for classifier-free guidance. Describes what to avoid in the image."
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The seed to use for the generation. If not provided, a random seed will be used."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "Flux 2 Klein 4B Edit",
      "description": "FLUX-2 Klein 4B Edit provides efficient image editing with the streamlined 4-billion parameter model.\n    image, editing, flux-2, klein, 4b, efficient\n\n    Use cases:\n    - Edit images efficiently with FLUX-2\n    - Apply quick modifications to photos\n    - Create fast edits for rapid workflows\n    - Transform images with streamlined model\n    - Produce quick image modifications",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.Flux2Klein4BEdit",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to edit the image."
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "The number of images to generate."
        },
        {
          "name": "image_size",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Image Size",
          "description": "The size of the generated image. If not provided, uses the input image size."
        },
        {
          "name": "output_format",
          "type": {
            "type": "enum",
            "values": [
              "jpeg",
              "png"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.OutputFormat"
          },
          "default": "png",
          "title": "Output Format",
          "description": "The format of the generated image."
        },
        {
          "name": "sync_mode",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Sync Mode",
          "description": "If `True`, the media will be returned as a data URI. Output is not stored when this is True."
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If set to true, the safety checker will be enabled."
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 4,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform."
        },
        {
          "name": "image_urls",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "str"
              }
            ]
          },
          "default": [],
          "title": "Image Urls",
          "description": "The URLs of the images for editing. A maximum of 4 images are allowed."
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The seed to use for the generation. If not provided, a random seed will be used."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "Flux 2 Klein 9B Base Edit",
      "description": "FLUX-2 Klein 9B Base Edit provides high-quality image editing with the 9-billion parameter model.\n    image, editing, flux-2, klein, 9b\n\n    Use cases:\n    - Edit images with FLUX-2 Klein 9B\n    - Apply high-quality modifications to photos\n    - Create advanced edits with powerful AI\n    - Transform images with superior quality\n    - Produce professional image modifications",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.Flux2Klein9BBaseEdit",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to edit the image."
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "The number of images to generate."
        },
        {
          "name": "image_size",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Image Size",
          "description": "The size of the generated image. If not provided, uses the input image size."
        },
        {
          "name": "acceleration",
          "type": {
            "type": "enum",
            "values": [
              "none",
              "regular",
              "high"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.Acceleration"
          },
          "default": "regular",
          "title": "Acceleration",
          "description": "The acceleration level to use for image generation."
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 5,
          "title": "Guidance Scale",
          "description": "Guidance scale for classifier-free guidance."
        },
        {
          "name": "output_format",
          "type": {
            "type": "enum",
            "values": [
              "jpeg",
              "png"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.OutputFormat"
          },
          "default": "png",
          "title": "Output Format",
          "description": "The format of the generated image."
        },
        {
          "name": "sync_mode",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Sync Mode",
          "description": "If `True`, the media will be returned as a data URI. Output is not stored when this is True."
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If set to true, the safety checker will be enabled."
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 28,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform."
        },
        {
          "name": "image_urls",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "str"
              }
            ]
          },
          "default": [],
          "title": "Image Urls",
          "description": "The URLs of the images for editing. A maximum of 4 images are allowed."
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "Negative prompt for classifier-free guidance. Describes what to avoid in the image."
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The seed to use for the generation. If not provided, a random seed will be used."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "Flux 2 Klein 9B Base Edit Lora",
      "description": "FLUX-2 Klein 9B Base Edit with LoRA combines powerful editing with custom-trained models.\n    image, editing, flux-2, klein, 9b, lora\n\n    Use cases:\n    - Edit images with custom 9B models\n    - Apply specialized high-quality modifications\n    - Create professional custom edits\n    - Transform images with fine-tuned powerful model\n    - Produce advanced customized results",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.Flux2Klein9BBaseEditLora",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to edit the image."
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "The number of images to generate."
        },
        {
          "name": "image_size",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Image Size",
          "description": "The size of the generated image. If not provided, uses the input image size."
        },
        {
          "name": "acceleration",
          "type": {
            "type": "enum",
            "values": [
              "none",
              "regular",
              "high"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.Acceleration"
          },
          "default": "regular",
          "title": "Acceleration",
          "description": "The acceleration level to use for image generation."
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 5,
          "title": "Guidance Scale",
          "description": "Guidance scale for classifier-free guidance."
        },
        {
          "name": "output_format",
          "type": {
            "type": "enum",
            "values": [
              "jpeg",
              "png"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.OutputFormat"
          },
          "default": "png",
          "title": "Output Format",
          "description": "The format of the generated image."
        },
        {
          "name": "loras",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "str"
              }
            ]
          },
          "default": [],
          "title": "Loras",
          "description": "List of LoRA weights to apply (maximum 3)."
        },
        {
          "name": "sync_mode",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Sync Mode",
          "description": "If `True`, the media will be returned as a data URI. Output is not stored when this is True."
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If set to true, the safety checker will be enabled."
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 28,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform."
        },
        {
          "name": "image_urls",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "str"
              }
            ]
          },
          "default": [],
          "title": "Image Urls",
          "description": "The URLs of the images for editing. A maximum of 4 images are allowed."
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "Negative prompt for classifier-free guidance. Describes what to avoid in the image."
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The seed to use for the generation. If not provided, a random seed will be used."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "Flux 2 Klein 9B Edit",
      "description": "FLUX-2 Klein 9B Edit provides advanced image editing with the full 9-billion parameter model.\n    image, editing, flux-2, klein, 9b, advanced\n\n    Use cases:\n    - Edit images with advanced FLUX-2 model\n    - Apply sophisticated modifications\n    - Create high-quality edits\n    - Transform images with powerful AI\n    - Produce superior image modifications",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.Flux2Klein9BEdit",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to edit the image."
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "The number of images to generate."
        },
        {
          "name": "image_size",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Image Size",
          "description": "The size of the generated image. If not provided, uses the input image size."
        },
        {
          "name": "output_format",
          "type": {
            "type": "enum",
            "values": [
              "jpeg",
              "png"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.OutputFormat"
          },
          "default": "png",
          "title": "Output Format",
          "description": "The format of the generated image."
        },
        {
          "name": "sync_mode",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Sync Mode",
          "description": "If `True`, the media will be returned as a data URI. Output is not stored when this is True."
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If set to true, the safety checker will be enabled."
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 4,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform."
        },
        {
          "name": "image_urls",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "str"
              }
            ]
          },
          "default": [],
          "title": "Image Urls",
          "description": "The URLs of the images for editing. A maximum of 4 images are allowed."
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The seed to use for the generation. If not provided, a random seed will be used."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "Flux 2 Lora Gallery Add Background",
      "description": "FLUX-2 LoRA Gallery Add Background places subjects in new environments with realistic integration.\n    image, editing, flux-2, background, compositing\n\n    Use cases:\n    - Add backgrounds to cutout images\n    - Place subjects in new environments\n    - Create realistic background compositions\n    - Generate contextual settings\n    - Produce integrated background images",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.Flux2LoraGalleryAddBackground",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "Add Background forest",
          "title": "Prompt",
          "description": "The prompt describing the background to add. Must start with 'Add Background' followed by your description."
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "Number of images to generate"
        },
        {
          "name": "image_size",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Image Size",
          "description": "The size of the generated image. If not provided, the size of the input image will be used."
        },
        {
          "name": "acceleration",
          "type": {
            "type": "enum",
            "values": [
              "none",
              "regular",
              "high"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.Acceleration"
          },
          "default": "regular",
          "title": "Acceleration",
          "description": "Acceleration level for image generation. 'regular' balances speed and quality."
        },
        {
          "name": "lora_scale",
          "type": {
            "type": "float"
          },
          "default": 1,
          "title": "Lora Scale",
          "description": "The strength of the add background effect."
        },
        {
          "name": "output_format",
          "type": {
            "type": "enum",
            "values": [
              "jpeg",
              "png"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.OutputFormat"
          },
          "default": "png",
          "title": "Output Format",
          "description": "The format of the output image"
        },
        {
          "name": "sync_mode",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Sync Mode",
          "description": "If `True`, the media will be returned as a data URI and won't be saved in history."
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 2.5,
          "title": "Guidance Scale",
          "description": "The CFG (Classifier Free Guidance) scale. Controls how closely the model follows the prompt."
        },
        {
          "name": "seed",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Seed",
          "description": "Random seed for reproducibility. Same seed with same prompt will produce same result."
        },
        {
          "name": "image_urls",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "str"
              }
            ]
          },
          "default": [],
          "title": "Image Urls",
          "description": "The URLs of the images. Provide an image with a white or clean background."
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "Whether to enable the safety checker for the generated image."
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 40,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "Flux 2 Lora Gallery Face To Full Portrait",
      "description": "FLUX-2 LoRA Gallery Face to Full Portrait expands face crops into complete portrait images.\n    image, editing, flux-2, portrait, expansion\n\n    Use cases:\n    - Expand face crops to full portraits\n    - Generate complete portrait from face\n    - Create full-body images from headshots\n    - Extend facial images to portraits\n    - Produce complete portrait compositions",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.Flux2LoraGalleryFaceToFullPortrait",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "Face to full portrait",
          "title": "Prompt",
          "description": "The prompt describing the full portrait to generate from the face."
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "Number of images to generate"
        },
        {
          "name": "image_size",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Image Size",
          "description": "The size of the generated image. If not provided, the size of the input image will be used."
        },
        {
          "name": "acceleration",
          "type": {
            "type": "enum",
            "values": [
              "none",
              "regular",
              "high"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.Acceleration"
          },
          "default": "regular",
          "title": "Acceleration",
          "description": "Acceleration level for image generation. 'regular' balances speed and quality."
        },
        {
          "name": "lora_scale",
          "type": {
            "type": "float"
          },
          "default": 1,
          "title": "Lora Scale",
          "description": "The strength of the face to full portrait effect."
        },
        {
          "name": "output_format",
          "type": {
            "type": "enum",
            "values": [
              "jpeg",
              "png"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.OutputFormat"
          },
          "default": "png",
          "title": "Output Format",
          "description": "The format of the output image"
        },
        {
          "name": "sync_mode",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Sync Mode",
          "description": "If `True`, the media will be returned as a data URI and won't be saved in history."
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 2.5,
          "title": "Guidance Scale",
          "description": "The CFG (Classifier Free Guidance) scale. Controls how closely the model follows the prompt."
        },
        {
          "name": "seed",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Seed",
          "description": "Random seed for reproducibility. Same seed with same prompt will produce same result."
        },
        {
          "name": "image_urls",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "str"
              }
            ]
          },
          "default": [],
          "title": "Image Urls",
          "description": "The URL of the cropped face image."
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "Whether to enable the safety checker for the generated image."
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 40,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "Flux 2 Lora Gallery Multiple Angles",
      "description": "FLUX-2 LoRA Gallery Multiple Angles generates images from different viewpoints for comprehensive visualization.\n    image, editing, flux-2, multi-angle, viewpoint\n\n    Use cases:\n    - Generate multiple product angles\n    - Create viewpoint variations\n    - Visualize objects from different sides\n    - Produce multi-angle image sets\n    - Generate comprehensive views",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.Flux2LoraGalleryMultipleAngles",
      "properties": [
        {
          "name": "image_size",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Image Size",
          "description": "The size of the generated image. If not provided, the size of the input image will be used."
        },
        {
          "name": "acceleration",
          "type": {
            "type": "enum",
            "values": [
              "none",
              "regular",
              "high"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.Acceleration"
          },
          "default": "regular",
          "title": "Acceleration",
          "description": "Acceleration level for image generation."
        },
        {
          "name": "horizontal_angle",
          "type": {
            "type": "float"
          },
          "default": 0,
          "title": "Horizontal Angle",
          "description": "Horizontal rotation angle around the object in degrees. 0\u00b0=front view, 90\u00b0=right side, 180\u00b0=back view, 270\u00b0=left side, 360\u00b0=front view again."
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 2.5,
          "title": "Guidance Scale",
          "description": "The CFG (Classifier Free Guidance) scale."
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "Whether to enable the safety checker."
        },
        {
          "name": "image_urls",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "str"
              }
            ]
          },
          "default": [],
          "title": "Image Urls",
          "description": "The URL of the image to adjust camera angle for."
        },
        {
          "name": "zoom",
          "type": {
            "type": "float"
          },
          "default": 5,
          "title": "Zoom",
          "description": "Camera zoom/distance. 0=wide shot (far away), 5=medium shot (normal), 10=close-up (very close)."
        },
        {
          "name": "vertical_angle",
          "type": {
            "type": "float"
          },
          "default": 0,
          "title": "Vertical Angle",
          "description": "Vertical camera angle in degrees. 0\u00b0=eye-level shot, 30\u00b0=elevated shot, 60\u00b0=high-angle shot (looking down from above)."
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "Number of images to generate."
        },
        {
          "name": "lora_scale",
          "type": {
            "type": "float"
          },
          "default": 1,
          "title": "Lora Scale",
          "description": "The strength of the multiple angles effect."
        },
        {
          "name": "output_format",
          "type": {
            "type": "enum",
            "values": [
              "jpeg",
              "png"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.OutputFormat"
          },
          "default": "png",
          "title": "Output Format",
          "description": "The format of the output image."
        },
        {
          "name": "sync_mode",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Sync Mode",
          "description": "If True, the media will be returned as a data URI."
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 40,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform."
        },
        {
          "name": "seed",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Seed",
          "description": "Random seed for reproducibility."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "Flux 2 Lora Gallery Virtual Tryon",
      "description": "FLUX-2 LoRA Gallery Virtual Try-on enables realistic clothing and accessory visualization on people.\n    image, editing, flux-2, virtual-tryon, fashion\n\n    Use cases:\n    - Visualize clothing on models\n    - Try on accessories virtually\n    - Create fashion previews\n    - Test product appearances\n    - Generate try-on images",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.Flux2LoraGalleryVirtualTryon",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate a virtual try-on image."
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "Number of images to generate"
        },
        {
          "name": "image_size",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Image Size",
          "description": "The size of the generated image. If not provided, the size of the input image will be used."
        },
        {
          "name": "acceleration",
          "type": {
            "type": "enum",
            "values": [
              "none",
              "regular",
              "high"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.Acceleration"
          },
          "default": "regular",
          "title": "Acceleration",
          "description": "Acceleration level for image generation. 'regular' balances speed and quality."
        },
        {
          "name": "lora_scale",
          "type": {
            "type": "float"
          },
          "default": 1,
          "title": "Lora Scale",
          "description": "The strength of the virtual try-on effect."
        },
        {
          "name": "output_format",
          "type": {
            "type": "enum",
            "values": [
              "jpeg",
              "png"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.OutputFormat"
          },
          "default": "png",
          "title": "Output Format",
          "description": "The format of the output image"
        },
        {
          "name": "sync_mode",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Sync Mode",
          "description": "If `True`, the media will be returned as a data URI and won't be saved in history."
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 2.5,
          "title": "Guidance Scale",
          "description": "The CFG (Classifier Free Guidance) scale. Controls how closely the model follows the prompt."
        },
        {
          "name": "seed",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Seed",
          "description": "Random seed for reproducibility. Same seed with same prompt will produce same result."
        },
        {
          "name": "image_urls",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "str"
              }
            ]
          },
          "default": [],
          "title": "Image Urls",
          "description": "The URLs of the images for virtual try-on. Provide person image and clothing image."
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "Whether to enable the safety checker for the generated image."
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 40,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "Flux 2 Max Edit",
      "description": "FLUX-2 Max Edit provides maximum quality image editing with the most advanced FLUX-2 model.\n    image, editing, flux-2, max, premium\n\n    Use cases:\n    - Edit images with maximum quality\n    - Apply premium modifications to photos\n    - Create professional-grade edits\n    - Transform images with best quality\n    - Produce highest quality modifications",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.Flux2MaxEdit",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from."
        },
        {
          "name": "image_size",
          "type": {
            "type": "str"
          },
          "default": "auto",
          "title": "Image Size",
          "description": "The size of the generated image. If `auto`, the size will be determined by the model."
        },
        {
          "name": "output_format",
          "type": {
            "type": "enum",
            "values": [
              "jpeg",
              "png"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.OutputFormat"
          },
          "default": "jpeg",
          "title": "Output Format",
          "description": "The format of the generated image."
        },
        {
          "name": "sync_mode",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Sync Mode",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history."
        },
        {
          "name": "safety_tolerance",
          "type": {
            "type": "enum",
            "values": [
              "1",
              "2",
              "3",
              "4",
              "5",
              "6"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.SafetyTolerance"
          },
          "default": "2",
          "title": "Safety Tolerance",
          "description": "The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive."
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "Whether to enable the safety checker."
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The seed to use for the generation."
        },
        {
          "name": "image_urls",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "str"
              }
            ]
          },
          "default": [],
          "title": "Image Urls",
          "description": "List of URLs of input images for editing"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "Flux 2 Turbo Edit",
      "description": "FLUX-2 Turbo Edit provides accelerated image editing with balanced quality and speed.\n    image, editing, flux-2, turbo, fast\n\n    Use cases:\n    - Edit images with turbo speed\n    - Apply fast modifications with good quality\n    - Create quick edits efficiently\n    - Transform images rapidly\n    - Produce fast quality modifications",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.Flux2TurboEdit",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to edit the image."
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "The number of images to generate."
        },
        {
          "name": "image_size",
          "type": {
            "type": "str"
          },
          "default": "square_hd",
          "title": "Image Size",
          "description": "The size of the image to generate. The width and height must be between 512 and 2048 pixels."
        },
        {
          "name": "output_format",
          "type": {
            "type": "enum",
            "values": [
              "jpeg",
              "png"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.OutputFormat"
          },
          "default": "png",
          "title": "Output Format",
          "description": "The format of the generated image."
        },
        {
          "name": "sync_mode",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Sync Mode",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history."
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 2.5,
          "title": "Guidance Scale",
          "description": "Guidance Scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you."
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The seed to use for the generation. If not provided, a random seed will be used."
        },
        {
          "name": "image_urls",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "str"
              }
            ]
          },
          "default": [],
          "title": "Image Urls",
          "description": "The URLs of the images for editing. A maximum of 4 images are allowed, if more are provided, only the first 4 will be used."
        },
        {
          "name": "enable_prompt_expansion",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Enable Prompt Expansion",
          "description": "If set to true, the prompt will be expanded for better results."
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If set to true, the safety checker will be enabled."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "Flux Dev Redux",
      "description": "FLUX.1 [dev] Redux provides advanced image transformation capabilities with superior quality and more control over the style transfer process.\n    image, transformation, style-transfer, development, flux, redux\n\n    Use cases:\n    - Transform images with advanced quality controls\n    - Create customized image variations with guidance\n    - Apply precise style modifications\n    - Generate high-quality artistic transformations\n    - Produce refined image edits with better prompt adherence",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.FluxDevRedux",
      "properties": [
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "The number of images to generate (1-4)"
        },
        {
          "name": "image_size",
          "type": {
            "type": "enum",
            "values": [
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.ImageSizePreset"
          },
          "default": "landscape_4_3",
          "title": "Image Size",
          "description": "The size of the generated image"
        },
        {
          "name": "acceleration",
          "type": {
            "type": "enum",
            "values": [
              "none",
              "regular",
              "high"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.Acceleration"
          },
          "default": "none",
          "title": "Acceleration",
          "description": "The speed of the generation. The higher the speed, the faster the generation."
        },
        {
          "name": "output_format",
          "type": {
            "type": "enum",
            "values": [
              "jpeg",
              "png"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.OutputFormat"
          },
          "default": "jpeg",
          "title": "Output Format",
          "description": "Output format (jpeg or png)"
        },
        {
          "name": "image_url",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image Url",
          "description": "The URL of the image to generate an image from."
        },
        {
          "name": "sync_mode",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Sync Mode",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history."
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "Enable safety checker to filter unsafe content"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for reproducible results. Use -1 for random"
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 3.5,
          "title": "Guidance Scale",
          "description": "How strictly to follow the image structure (1-20)"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 28,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform (1-50)"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "image_size",
        "guidance_scale"
      ]
    },
    {
      "title": "Flux Pro Canny",
      "description": "FLUX.1 Pro with Canny edge detection control. Generate images guided by edge maps for precise structural control while maintaining FLUX's quality.\n    image, controlnet, canny, edges, flux, professional\n\n    Use cases:\n    - Generate images following edge structures\n    - Transform images while preserving edges\n    - Create controlled variations with edge guidance\n    - Apply style transfers with structural constraints\n    - Generate content from edge maps",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.FluxProCanny",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The text prompt describing the desired output"
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "The number of images to generate."
        },
        {
          "name": "image_size",
          "type": {
            "type": "enum",
            "values": [
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.ImageSizePreset"
          },
          "default": "landscape_4_3",
          "title": "Image Size",
          "description": "The size of the generated image"
        },
        {
          "name": "output_format",
          "type": {
            "type": "enum",
            "values": [
              "jpeg",
              "png"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.OutputFormat"
          },
          "default": "jpeg",
          "title": "Output Format",
          "description": "The format of the generated image."
        },
        {
          "name": "sync_mode",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Sync Mode",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history."
        },
        {
          "name": "safety_tolerance",
          "type": {
            "type": "enum",
            "values": [
              "1",
              "2",
              "3",
              "4",
              "5",
              "6"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.SafetyTolerance"
          },
          "default": "2",
          "title": "Safety Tolerance",
          "description": "The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive."
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 3.5,
          "title": "Guidance Scale",
          "description": "How strictly to follow the prompt"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 28,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform"
        },
        {
          "name": "control_image_url",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Control Image Url",
          "description": "The control image URL to generate the Canny edge map from."
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for reproducible results. Use -1 for random"
        },
        {
          "name": "enhance_prompt",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Enhance Prompt",
          "description": "Whether to enhance the prompt for better results."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "image",
        "control_strength"
      ]
    },
    {
      "title": "Flux Pro Depth",
      "description": "FLUX.1 Pro with depth map control. Generate images guided by depth information for precise 3D structure control while maintaining FLUX's quality.\n    image, controlnet, depth, 3d, flux, professional\n\n    Use cases:\n    - Generate images following depth structures\n    - Transform images while preserving 3D composition\n    - Create controlled variations with depth guidance\n    - Apply style transfers with spatial constraints\n    - Generate content from depth maps",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.FluxProDepth",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The text prompt describing the desired output"
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "The number of images to generate."
        },
        {
          "name": "image_size",
          "type": {
            "type": "enum",
            "values": [
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.ImageSizePreset"
          },
          "default": "landscape_4_3",
          "title": "Image Size",
          "description": "The size of the generated image"
        },
        {
          "name": "output_format",
          "type": {
            "type": "enum",
            "values": [
              "jpeg",
              "png"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.OutputFormat"
          },
          "default": "jpeg",
          "title": "Output Format",
          "description": "The format of the generated image."
        },
        {
          "name": "sync_mode",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Sync Mode",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history."
        },
        {
          "name": "safety_tolerance",
          "type": {
            "type": "enum",
            "values": [
              "1",
              "2",
              "3",
              "4",
              "5",
              "6"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.SafetyTolerance"
          },
          "default": "2",
          "title": "Safety Tolerance",
          "description": "The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive."
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 3.5,
          "title": "Guidance Scale",
          "description": "How strictly to follow the prompt"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 28,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform"
        },
        {
          "name": "control_image_url",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Control Image Url",
          "description": "The control image URL to generate the depth map from."
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for reproducible results. Use -1 for random"
        },
        {
          "name": "enhance_prompt",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Enhance Prompt",
          "description": "Whether to enhance the prompt for better results."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "image",
        "control_strength"
      ]
    },
    {
      "title": "Flux Pro Fill",
      "description": "FLUX.1 Pro Fill provides professional inpainting and outpainting capabilities. Generate or modify image content within masked regions with precise prompt control.\n    image, inpainting, outpainting, fill, flux, professional\n\n    Use cases:\n    - Fill masked regions with new content\n    - Extend images beyond their boundaries (outpainting)\n    - Remove unwanted objects and fill gaps\n    - Generate content-aware image expansions\n    - Create seamless image modifications",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.FluxProFill",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt describing what to generate in the masked area"
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "The number of images to generate."
        },
        {
          "name": "output_format",
          "type": {
            "type": "enum",
            "values": [
              "jpeg",
              "png"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.OutputFormat"
          },
          "default": "jpeg",
          "title": "Output Format",
          "description": "The format of the generated image."
        },
        {
          "name": "image_url",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image Url",
          "description": "The image URL to generate an image from. Needs to match the dimensions of the mask."
        },
        {
          "name": "sync_mode",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Sync Mode",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history."
        },
        {
          "name": "safety_tolerance",
          "type": {
            "type": "enum",
            "values": [
              "1",
              "2",
              "3",
              "4",
              "5",
              "6"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.SafetyTolerance"
          },
          "default": "2",
          "title": "Safety Tolerance",
          "description": "Safety tolerance level (1-6, higher is stricter)"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for reproducible results. Use -1 for random"
        },
        {
          "name": "mask_url",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Mask Url",
          "description": "The mask URL to inpaint the image. Needs to match the dimensions of the input image."
        },
        {
          "name": "enhance_prompt",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Enhance Prompt",
          "description": "Whether to enhance the prompt for better results."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "image",
        "mask"
      ]
    },
    {
      "title": "Flux Pro Redux",
      "description": "FLUX.1 Pro Redux delivers professional-grade image transformations with the highest quality and safety controls for commercial use.\n    image, transformation, style-transfer, professional, flux, redux\n\n    Use cases:\n    - Create professional-quality image transformations\n    - Apply commercial-grade style transfers\n    - Generate high-fidelity image variations\n    - Produce brand-safe image modifications\n    - Transform images for production use",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.FluxProRedux",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from."
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "The number of images to generate (1-4)"
        },
        {
          "name": "image_size",
          "type": {
            "type": "enum",
            "values": [
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.ImageSizePreset"
          },
          "default": "landscape_4_3",
          "title": "Image Size",
          "description": "The size of the generated image"
        },
        {
          "name": "output_format",
          "type": {
            "type": "enum",
            "values": [
              "jpeg",
              "png"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.OutputFormat"
          },
          "default": "jpeg",
          "title": "Output Format",
          "description": "Output format (jpeg or png)"
        },
        {
          "name": "image_url",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image Url",
          "description": "The image URL to generate an image from. Needs to match the dimensions of the mask."
        },
        {
          "name": "sync_mode",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Sync Mode",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history."
        },
        {
          "name": "safety_tolerance",
          "type": {
            "type": "enum",
            "values": [
              "1",
              "2",
              "3",
              "4",
              "5",
              "6"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.SafetyTolerance"
          },
          "default": "2",
          "title": "Safety Tolerance",
          "description": "Safety tolerance level (1-6, higher is stricter)"
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 3.5,
          "title": "Guidance Scale",
          "description": "How strictly to follow the image structure (1-20)"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 28,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform (1-50)"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for reproducible results. Use -1 for random"
        },
        {
          "name": "enhance_prompt",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Enhance Prompt",
          "description": "Whether to enhance the prompt for better results."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "image_size",
        "guidance_scale"
      ]
    },
    {
      "title": "Flux Schnell Redux",
      "description": "FLUX.1 [schnell] Redux enables rapid transformation of existing images with high-quality style transfers and modifications using the fast FLUX.1 schnell model.\n    image, transformation, style-transfer, fast, flux, redux\n\n    Use cases:\n    - Transform images with artistic style transfers\n    - Apply quick modifications to photos\n    - Create image variations for rapid iteration\n    - Generate stylized versions of existing images\n    - Produce fast image transformations",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.FluxSchnellRedux",
      "properties": [
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "The number of images to generate (1-4)"
        },
        {
          "name": "image_size",
          "type": {
            "type": "enum",
            "values": [
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.ImageSizePreset"
          },
          "default": "landscape_4_3",
          "title": "Image Size",
          "description": "The size of the generated image"
        },
        {
          "name": "acceleration",
          "type": {
            "type": "enum",
            "values": [
              "none",
              "regular",
              "high"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.Acceleration"
          },
          "default": "none",
          "title": "Acceleration",
          "description": "Acceleration speed: 'none', 'regular', or 'high'"
        },
        {
          "name": "output_format",
          "type": {
            "type": "enum",
            "values": [
              "jpeg",
              "png"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.OutputFormat"
          },
          "default": "jpeg",
          "title": "Output Format",
          "description": "Output format (jpeg or png)"
        },
        {
          "name": "image_url",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image Url",
          "description": "The URL of the image to generate an image from."
        },
        {
          "name": "sync_mode",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Sync Mode",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history."
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "Enable safety checker to filter unsafe content"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for reproducible results. Use -1 for random"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 4,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform (1-50)"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "image_size",
        "num_inference_steps"
      ]
    },
    {
      "title": "Glm Image Image To Image",
      "description": "GLM Image image-to-image transforms and modifies images using advanced AI understanding.\n    image, transformation, glm, ai-editing\n\n    Use cases:\n    - Transform images with GLM AI\n    - Apply modifications using advanced understanding\n    - Create variations with GLM model\n    - Generate modified versions\n    - Produce AI-powered transformations",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.GlmImageImageToImage",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "Text prompt for image generation."
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "Number of images to generate."
        },
        {
          "name": "image_size",
          "type": {
            "type": "str"
          },
          "default": "square_hd",
          "title": "Image Size",
          "description": "Output image size."
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "Enable NSFW safety checking on the generated images."
        },
        {
          "name": "output_format",
          "type": {
            "type": "enum",
            "values": [
              "jpeg",
              "png"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.OutputFormat"
          },
          "default": "jpeg",
          "title": "Output Format",
          "description": "Output image format."
        },
        {
          "name": "sync_mode",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Sync Mode",
          "description": "If True, the image will be returned as a base64 data URI instead of a URL."
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 1.5,
          "title": "Guidance Scale",
          "description": "Classifier-free guidance scale. Higher values make the model follow the prompt more closely."
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Random seed for reproducibility. The same seed with the same prompt will produce the same image."
        },
        {
          "name": "image_urls",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "str"
              }
            ]
          },
          "default": [],
          "title": "Image Urls",
          "description": "URL(s) of the condition image(s) for image-to-image generation. Supports up to 4 URLs for multi-image references."
        },
        {
          "name": "enable_prompt_expansion",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Enable Prompt Expansion",
          "description": "If True, the prompt will be enhanced using an LLM for more detailed and higher quality results."
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 30,
          "title": "Num Inference Steps",
          "description": "Number of diffusion denoising steps. More steps generally produce higher quality images."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "Gpt Image 15 Edit",
      "description": "GPT Image 1.5 Edit provides intelligent image editing with GPT-powered understanding and control.\n    image, editing, gpt, intelligent, ai-editing\n\n    Use cases:\n    - Edit images with GPT intelligence\n    - Apply smart modifications to photos\n    - Create intelligent edits\n    - Transform images with language understanding\n    - Produce GPT-powered modifications",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.GptImage15Edit",
      "properties": [
        {
          "name": "background",
          "type": {
            "type": "enum",
            "values": [
              "auto",
              "transparent",
              "opaque"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.Background"
          },
          "default": "auto",
          "title": "Background",
          "description": "Background for the generated image"
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "Number of images to generate"
        },
        {
          "name": "image_size",
          "type": {
            "type": "enum",
            "values": [
              "auto",
              "1024x1024",
              "1536x1024",
              "1024x1536"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.ImageSize"
          },
          "default": "auto",
          "title": "Image Size",
          "description": "Aspect ratio for the generated image"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt for image generation"
        },
        {
          "name": "quality",
          "type": {
            "type": "enum",
            "values": [
              "low",
              "medium",
              "high"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.Quality"
          },
          "default": "high",
          "title": "Quality",
          "description": "Quality for the generated image"
        },
        {
          "name": "output_format",
          "type": {
            "type": "enum",
            "values": [
              "jpeg",
              "png"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.OutputFormat"
          },
          "default": "png",
          "title": "Output Format",
          "description": "Output format for the images"
        },
        {
          "name": "input_fidelity",
          "type": {
            "type": "enum",
            "values": [
              "low",
              "high"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.InputFidelity"
          },
          "default": "high",
          "title": "Input Fidelity",
          "description": "Input fidelity for the generated image"
        },
        {
          "name": "mask_image_url",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Mask Image Url",
          "description": "The URL of the mask image to use for the generation. This indicates what part of the image to edit."
        },
        {
          "name": "sync_mode",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Sync Mode",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history."
        },
        {
          "name": "image_urls",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "str"
              }
            ]
          },
          "default": [],
          "title": "Image Urls",
          "description": "The URLs of the images to use as a reference for the generation."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "Hunyuan Image V3 Instruct Edit",
      "description": "Hunyuan Image v3 Instruct Edit allows precise image editing through natural language instructions with advanced understanding.\n    image, editing, hunyuan, instruct, ai-editing\n\n    Use cases:\n    - Edit images using natural language instructions\n    - Modify specific elements in photos with text commands\n    - Apply precise adjustments through conversational editing\n    - Transform images with instruction-based control\n    - Create variations with detailed text guidance",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.HunyuanImageV3InstructEdit",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The text prompt to generate an image from."
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "The number of images to generate."
        },
        {
          "name": "image_size",
          "type": {
            "type": "str"
          },
          "default": "auto",
          "title": "Image Size",
          "description": "The desired size of the generated image. If auto, image size will be determined by the model."
        },
        {
          "name": "output_format",
          "type": {
            "type": "enum",
            "values": [
              "jpeg",
              "png"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.OutputFormat"
          },
          "default": "png",
          "title": "Output Format",
          "description": "The format of the generated image."
        },
        {
          "name": "sync_mode",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Sync Mode",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history."
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If set to true, the safety checker will be enabled."
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Random seed for reproducible results. If None, a random seed is used."
        },
        {
          "name": "image_urls",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "str"
              }
            ]
          },
          "default": [],
          "title": "Image Urls",
          "description": "The URLs of the images to use as a reference for the generation. A maximum of 2 images are supported."
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 3.5,
          "title": "Guidance Scale",
          "description": "Controls how much the model adheres to the prompt. Higher values mean stricter adherence."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "Ideogram V2 Edit",
      "description": "Transform existing images with Ideogram V2's editing capabilities. Modify, adjust, and refine images while maintaining high fidelity with precise prompt and mask control.\n    image, editing, inpainting, mask, ideogram, transformation\n\n    Use cases:\n    - Edit specific parts of images with precision\n    - Create targeted image modifications using masks\n    - Refine and enhance image details\n    - Generate contextual image edits\n    - Replace or modify masked regions",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.IdeogramV2Edit",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to fill the masked part of the image"
        },
        {
          "name": "style",
          "type": {
            "type": "enum",
            "values": [
              "auto",
              "general",
              "realistic",
              "design",
              "render_3D",
              "anime"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.Style"
          },
          "default": "auto",
          "title": "Style",
          "description": "Style of generated image (auto, general, realistic, design, render_3D, anime)"
        },
        {
          "name": "expand_prompt",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Expand Prompt",
          "description": "Whether to expand the prompt with MagicPrompt functionality"
        },
        {
          "name": "image_url",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image Url",
          "description": "The image URL to generate an image from. Needs to match the dimensions of the mask."
        },
        {
          "name": "sync_mode",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Sync Mode",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history."
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for reproducible results. Use -1 for random"
        },
        {
          "name": "mask_url",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Mask Url",
          "description": "The mask URL to inpaint the image. Needs to match the dimensions of the input image."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "image",
        "mask"
      ]
    },
    {
      "title": "Ideogram V2 Remix",
      "description": "Reimagine existing images with Ideogram V2's remix feature. Create variations and adaptations while preserving core elements through prompt guidance and strength control.\n    image, remix, variation, creativity, ideogram, adaptation\n\n    Use cases:\n    - Create artistic variations of images\n    - Generate style-transferred versions\n    - Produce creative image adaptations\n    - Transform images while preserving key elements\n    - Generate alternative interpretations",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.IdeogramV2Remix",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to remix the image with"
        },
        {
          "name": "aspect_ratio",
          "type": {
            "type": "enum",
            "values": [
              "10:16",
              "16:10",
              "9:16",
              "16:9",
              "4:3",
              "3:4",
              "1:1",
              "1:3",
              "3:1",
              "3:2",
              "2:3"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.AspectRatio"
          },
          "default": "1:1",
          "title": "Aspect Ratio",
          "description": "The aspect ratio of the generated image"
        },
        {
          "name": "style",
          "type": {
            "type": "enum",
            "values": [
              "auto",
              "general",
              "realistic",
              "design",
              "render_3D",
              "anime"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.Style"
          },
          "default": "auto",
          "title": "Style",
          "description": "Style of generated image (auto, general, realistic, design, render_3D, anime)"
        },
        {
          "name": "expand_prompt",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Expand Prompt",
          "description": "Whether to expand the prompt with MagicPrompt functionality"
        },
        {
          "name": "image_url",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image Url",
          "description": "The image URL to remix"
        },
        {
          "name": "strength",
          "type": {
            "type": "float"
          },
          "default": 0.8,
          "title": "Strength",
          "description": "Strength of the input image in the remix (0-1, higher = more variation)"
        },
        {
          "name": "sync_mode",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Sync Mode",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history."
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for reproducible results. Use -1 for random"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "image",
        "strength"
      ]
    },
    {
      "title": "Ideogram V3 Edit",
      "description": "Transform images with Ideogram V3's enhanced editing capabilities. Latest generation editing with improved quality, control, and style consistency.\n    image, editing, inpainting, mask, ideogram, v3\n\n    Use cases:\n    - Edit images with the latest Ideogram technology\n    - Apply high-fidelity masked edits\n    - Generate professional image modifications\n    - Create precise content-aware fills\n    - Refine image details with advanced controls",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.IdeogramV3Edit",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to fill the masked part of the image"
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "Number of images to generate."
        },
        {
          "name": "style_preset",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Style Preset",
          "description": "Style preset for generation. The chosen style preset will guide the generation."
        },
        {
          "name": "expand_prompt",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Expand Prompt",
          "description": "Determine if MagicPrompt should be used in generating the request or not."
        },
        {
          "name": "rendering_speed",
          "type": {
            "type": "enum",
            "values": [
              "TURBO",
              "BALANCED",
              "QUALITY"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.RenderingSpeed"
          },
          "default": "BALANCED",
          "title": "Rendering Speed",
          "description": "The rendering speed to use."
        },
        {
          "name": "style_codes",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Style Codes",
          "description": "A list of 8 character hexadecimal codes representing the style of the image. Cannot be used in conjunction with style_reference_images or style"
        },
        {
          "name": "color_palette",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Color Palette",
          "description": "A color palette for generation, must EITHER be specified via one of the presets (name) or explicitly via hexadecimal representations of the color with optional weights (members)"
        },
        {
          "name": "image_url",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image Url",
          "description": "The image URL to generate an image from. MUST have the exact same dimensions (width and height) as the mask image."
        },
        {
          "name": "sync_mode",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Sync Mode",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history."
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for reproducible results. Use -1 for random"
        },
        {
          "name": "image_urls",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image Urls",
          "description": "A set of images to use as style references (maximum total size 10MB across all style references). The images should be in JPEG, PNG or WebP format"
        },
        {
          "name": "mask_url",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Mask Url",
          "description": "The mask URL to inpaint the image. MUST have the exact same dimensions (width and height) as the input image."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "image",
        "mask"
      ]
    },
    {
      "title": "Kling Image O1",
      "description": "Kling Image O1 provides advanced image generation and transformation with optimized quality.\n    image, generation, kling, o1, optimized\n\n    Use cases:\n    - Generate images with Kling O1\n    - Transform images with optimization\n    - Create optimized quality results\n    - Produce advanced image generations\n    - Generate with balanced quality-speed",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.KlingImageO1",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "Text prompt for image generation. Reference images using @Image1, @Image2, etc. (or @Image if only one image). Max 2500 characters."
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "Number of images to generate (1-9)."
        },
        {
          "name": "resolution",
          "type": {
            "type": "enum",
            "values": [
              "1K",
              "2K"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.Resolution"
          },
          "default": "1K",
          "title": "Resolution",
          "description": "Image generation resolution. 1K: standard, 2K: high-res."
        },
        {
          "name": "aspect_ratio",
          "type": {
            "type": "enum",
            "values": [
              "auto",
              "16:9",
              "9:16",
              "1:1",
              "4:3",
              "3:4",
              "3:2",
              "2:3",
              "21:9"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.KlingImageO1AspectRatio"
          },
          "default": "auto",
          "title": "Aspect Ratio",
          "description": "Aspect ratio of generated images. 'auto' intelligently determines based on input content."
        },
        {
          "name": "output_format",
          "type": {
            "type": "enum",
            "values": [
              "jpeg",
              "png"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.OutputFormat"
          },
          "default": "png",
          "title": "Output Format",
          "description": "The format of the generated image."
        },
        {
          "name": "sync_mode",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Sync Mode",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history."
        },
        {
          "name": "elements",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "str"
              }
            ]
          },
          "default": [],
          "title": "Elements",
          "description": "Elements (characters/objects) to include in the image. Reference in prompt as @Element1, @Element2, etc. Maximum 10 total (elements + reference images)."
        },
        {
          "name": "image_urls",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "str"
              }
            ]
          },
          "default": [],
          "title": "Image Urls",
          "description": "List of reference images. Reference images in prompt using @Image1, @Image2, etc. (1-indexed). Max 10 images."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "Kolors Image To Image",
      "description": "Kolors transforms images using an advanced diffusion model. High-quality image-to-image generation with natural color preservation and detail retention.\n    image, transformation, kolors, diffusion, quality\n\n    Use cases:\n    - Transform images with natural color handling\n    - Create variations with preserved color harmony\n    - Apply modifications with detail retention\n    - Generate style transfers with color consistency\n    - Produce high-fidelity image transformations",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.KolorsImageToImage",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The text prompt describing the desired transformation"
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "The number of images to generate."
        },
        {
          "name": "image_size",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Image Size",
          "description": "The size of the generated image."
        },
        {
          "name": "output_format",
          "type": {
            "type": "enum",
            "values": [
              "jpeg",
              "png"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.OutputFormat"
          },
          "default": "png",
          "title": "Output Format",
          "description": "The format of the generated image."
        },
        {
          "name": "image_url",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image Url",
          "description": "URL of image to use for image to image"
        },
        {
          "name": "sync_mode",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Sync Mode",
          "description": "If set to true, the function will wait for the image to be generated and uploaded before returning the response. This will increase the latency of the function but it allows you to get the image directly in the response without going through the CDN."
        },
        {
          "name": "scheduler",
          "type": {
            "type": "enum",
            "values": [
              "EulerDiscreteScheduler",
              "EulerAncestralDiscreteScheduler",
              "DPMSolverMultistepScheduler",
              "DPMSolverMultistepScheduler_SDE_karras",
              "UniPCMultistepScheduler",
              "DEISMultistepScheduler"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.Scheduler"
          },
          "default": "EulerDiscreteScheduler",
          "title": "Scheduler",
          "description": "The scheduler to use for the model."
        },
        {
          "name": "strength",
          "type": {
            "type": "float"
          },
          "default": 0.85,
          "title": "Strength",
          "description": "Strength of the transformation (0-1, higher = more change)"
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 5,
          "title": "Guidance Scale",
          "description": "The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you."
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 50,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform."
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for reproducible results. Use -1 for random"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "The negative prompt to use. Use it to address details that you don't want in the image. This could be colors, objects, scenery and even the small details (e.g. moustache, blurry, low resolution)."
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "Enable safety checker."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "image",
        "strength"
      ]
    },
    {
      "title": "Longcat Image Edit",
      "description": "Longcat Image Edit transforms images with unique AI-powered modifications and creative control.\n    image, editing, longcat, creative\n\n    Use cases:\n    - Edit images with Longcat AI\n    - Apply creative modifications\n    - Create unique image variations\n    - Transform images creatively\n    - Produce artistic modifications",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.LongcatImageEdit",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to edit the image with."
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "The number of images to generate."
        },
        {
          "name": "acceleration",
          "type": {
            "type": "enum",
            "values": [
              "none",
              "regular",
              "high"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.Acceleration"
          },
          "default": "regular",
          "title": "Acceleration",
          "description": "The acceleration level to use."
        },
        {
          "name": "output_format",
          "type": {
            "type": "enum",
            "values": [
              "jpeg",
              "png"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.OutputFormat"
          },
          "default": "png",
          "title": "Output Format",
          "description": "The format of the generated image."
        },
        {
          "name": "image_url",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image Url",
          "description": "The URL of the image to edit."
        },
        {
          "name": "sync_mode",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Sync Mode",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history."
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If set to true, the safety checker will be enabled."
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 28,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform."
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 4.5,
          "title": "Guidance Scale",
          "description": "The guidance scale to use for the image generation."
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed and the same prompt given to the same version of the model will output the same image every time."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "Qwen Image Edit 2509",
      "description": "Qwen Image Edit 2509 provides powerful image editing with advanced AI capabilities and high-quality output.\n    image, editing, qwen, 2509, ai-editing\n\n    Use cases:\n    - Edit images with Qwen 2509 technology\n    - Apply sophisticated modifications to photos\n    - Create quality edits with AI assistance\n    - Transform images with advanced models\n    - Produce professional image changes",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.QwenImageEdit2509",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate the image with"
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "The number of images to generate."
        },
        {
          "name": "image_size",
          "type": {
            "type": "str"
          },
          "default": "square_hd",
          "title": "Image Size",
          "description": "The size of the generated image."
        },
        {
          "name": "acceleration",
          "type": {
            "type": "enum",
            "values": [
              "none",
              "regular",
              "high"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.Acceleration"
          },
          "default": "regular",
          "title": "Acceleration",
          "description": "Acceleration level for image generation. Options: 'none', 'regular'. Higher acceleration increases speed. 'regular' balances speed and quality."
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If set to true, the safety checker will be enabled."
        },
        {
          "name": "output_format",
          "type": {
            "type": "enum",
            "values": [
              "jpeg",
              "png"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.OutputFormat"
          },
          "default": "png",
          "title": "Output Format",
          "description": "The format of the generated image."
        },
        {
          "name": "sync_mode",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Sync Mode",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history."
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 4,
          "title": "Guidance Scale",
          "description": "The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you."
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed and the same prompt given to the same version of the model will output the same image every time."
        },
        {
          "name": "image_urls",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "str"
              }
            ]
          },
          "default": [],
          "title": "Image Urls",
          "description": "The URLs of the images to edit."
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": " ",
          "title": "Negative Prompt",
          "description": "The negative prompt for the generation"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 50,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "Qwen Image Edit 2509 Lora",
      "description": "Qwen Image Edit 2509 with LoRA enables fine-tuned models for specialized image editing applications.\n    image, editing, qwen, lora, fine-tuned\n\n    Use cases:\n    - Edit images with fine-tuned models\n    - Apply custom modifications using LoRA\n    - Create specialized edits for specific domains\n    - Transform images with trained models\n    - Produce tailored image modifications",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.QwenImageEdit2509Lora",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate the image with"
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "The number of images to generate."
        },
        {
          "name": "image_size",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Image Size",
          "description": "The size of the generated image. If not provided, the size of the final input image will be used to calculate the size of the output image."
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed and the same prompt given to the same version of the model will output the same image every time."
        },
        {
          "name": "acceleration",
          "type": {
            "type": "enum",
            "values": [
              "none",
              "regular",
              "high"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.Acceleration"
          },
          "default": "regular",
          "title": "Acceleration",
          "description": "Acceleration level for image generation. Options: 'none', 'regular'. Higher acceleration increases speed. 'regular' balances speed and quality."
        },
        {
          "name": "output_format",
          "type": {
            "type": "enum",
            "values": [
              "jpeg",
              "png"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.OutputFormat"
          },
          "default": "png",
          "title": "Output Format",
          "description": "The format of the generated image."
        },
        {
          "name": "loras",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "str"
              }
            ]
          },
          "default": [],
          "title": "Loras",
          "description": "The LoRAs to use for the image generation. You can use up to 3 LoRAs and they will be merged together to generate the final image."
        },
        {
          "name": "sync_mode",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Sync Mode",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history."
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If set to true, the safety checker will be enabled."
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 28,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform."
        },
        {
          "name": "image_urls",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "str"
              }
            ]
          },
          "default": [],
          "title": "Image Urls",
          "description": "The URLs of the images to edit."
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": " ",
          "title": "Negative Prompt",
          "description": "The negative prompt for the generation"
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 4,
          "title": "Guidance Scale",
          "description": "The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "Qwen Image Edit 2511",
      "description": "Qwen Image Edit 2511 provides state-of-the-art image editing with latest AI advancements and improved quality.\n    image, editing, qwen, 2511, latest\n\n    Use cases:\n    - Edit images with latest Qwen technology\n    - Apply advanced modifications to photos\n    - Create high-quality edits with AI assistance\n    - Transform images with cutting-edge models\n    - Produce professional image modifications",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.QwenImageEdit2511",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to edit the image with."
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "The number of images to generate."
        },
        {
          "name": "acceleration",
          "type": {
            "type": "enum",
            "values": [
              "none",
              "regular",
              "high"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.Acceleration"
          },
          "default": "regular",
          "title": "Acceleration",
          "description": "The acceleration level to use."
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 28,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform."
        },
        {
          "name": "image_size",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Image Size",
          "description": "The size of the generated image. If None, uses the input image dimensions."
        },
        {
          "name": "output_format",
          "type": {
            "type": "enum",
            "values": [
              "jpeg",
              "png"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.OutputFormat"
          },
          "default": "png",
          "title": "Output Format",
          "description": "The format of the generated image."
        },
        {
          "name": "sync_mode",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Sync Mode",
          "description": "If `True`, the media will be returned as a data URI."
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 4.5,
          "title": "Guidance Scale",
          "description": "The guidance scale to use for the image generation."
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed and the same prompt given to the same version of the model will output the same image every time."
        },
        {
          "name": "image_urls",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "str"
              }
            ]
          },
          "default": [],
          "title": "Image Urls",
          "description": "The URLs of the images to edit."
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "The negative prompt to generate an image from."
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If set to true, the safety checker will be enabled."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "Qwen Image Edit 2511 Lora",
      "description": "Qwen Image Edit 2511 with LoRA support enables custom-trained models for specialized editing tasks.\n    image, editing, qwen, lora, custom\n\n    Use cases:\n    - Edit images with custom-trained models\n    - Apply specialized modifications using LoRA\n    - Create domain-specific edits\n    - Transform images with fine-tuned models\n    - Produce customized image modifications",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.QwenImageEdit2511Lora",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to edit the image with."
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "The number of images to generate."
        },
        {
          "name": "acceleration",
          "type": {
            "type": "enum",
            "values": [
              "none",
              "regular",
              "high"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.Acceleration"
          },
          "default": "regular",
          "title": "Acceleration",
          "description": "The acceleration level to use."
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 28,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform."
        },
        {
          "name": "image_size",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Image Size",
          "description": "The size of the generated image. If None, uses the input image dimensions."
        },
        {
          "name": "output_format",
          "type": {
            "type": "enum",
            "values": [
              "jpeg",
              "png"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.OutputFormat"
          },
          "default": "png",
          "title": "Output Format",
          "description": "The format of the generated image."
        },
        {
          "name": "loras",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "str"
              }
            ]
          },
          "default": [],
          "title": "Loras",
          "description": "The LoRAs to use for the image generation. You can use up to 3 LoRAs and they will be merged together to generate the final image."
        },
        {
          "name": "sync_mode",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Sync Mode",
          "description": "If `True`, the media will be returned as a data URI."
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 4.5,
          "title": "Guidance Scale",
          "description": "The guidance scale to use for the image generation."
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed and the same prompt given to the same version of the model will output the same image every time."
        },
        {
          "name": "image_urls",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "str"
              }
            ]
          },
          "default": [],
          "title": "Image Urls",
          "description": "The URLs of the images to edit."
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "The negative prompt to generate an image from."
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If set to true, the safety checker will be enabled."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "Qwen Image Edit 2511 Multiple Angles",
      "description": "Qwen Image Edit 2511 Multiple Angles generates images from different viewpoints based on a single input image.\n    image, editing, qwen, multi-angle, viewpoint\n\n    Use cases:\n    - Generate multiple viewpoints from single image\n    - Create product views from different angles\n    - Visualize objects from various perspectives\n    - Produce multi-angle image sets\n    - Transform images to show different sides",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.QwenImageEdit2511MultipleAngles",
      "properties": [
        {
          "name": "acceleration",
          "type": {
            "type": "enum",
            "values": [
              "none",
              "regular",
              "high"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.Acceleration"
          },
          "default": "regular",
          "title": "Acceleration",
          "description": "Acceleration level for image generation."
        },
        {
          "name": "image_size",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Image Size",
          "description": "The size of the generated image. If not provided, the size of the input image will be used."
        },
        {
          "name": "horizontal_angle",
          "type": {
            "type": "float"
          },
          "default": 0,
          "title": "Horizontal Angle",
          "description": "Horizontal rotation angle around the object in degrees. 0\u00b0=front view, 90\u00b0=right side, 180\u00b0=back view, 270\u00b0=left side, 360\u00b0=front view again."
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 4.5,
          "title": "Guidance Scale",
          "description": "The CFG (Classifier Free Guidance) scale."
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "Whether to enable the safety checker."
        },
        {
          "name": "image_urls",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "str"
              }
            ]
          },
          "default": [],
          "title": "Image Urls",
          "description": "The URL of the image to adjust camera angle for."
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "The negative prompt for the generation"
        },
        {
          "name": "zoom",
          "type": {
            "type": "float"
          },
          "default": 5,
          "title": "Zoom",
          "description": "Camera zoom/distance. 0=wide shot (far away), 5=medium shot (normal), 10=close-up (very close)."
        },
        {
          "name": "vertical_angle",
          "type": {
            "type": "float"
          },
          "default": 0,
          "title": "Vertical Angle",
          "description": "Vertical camera angle in degrees. -30\u00b0=low-angle shot (looking up), 0\u00b0=eye-level, 30\u00b0=elevated, 60\u00b0=high-angle, 90\u00b0=bird's-eye view (looking down)."
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "Number of images to generate"
        },
        {
          "name": "lora_scale",
          "type": {
            "type": "float"
          },
          "default": 1,
          "title": "Lora Scale",
          "description": "The scale factor for the LoRA model. Controls the strength of the camera control effect."
        },
        {
          "name": "output_format",
          "type": {
            "type": "enum",
            "values": [
              "jpeg",
              "png"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.OutputFormat"
          },
          "default": "png",
          "title": "Output Format",
          "description": "The format of the output image"
        },
        {
          "name": "sync_mode",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Sync Mode",
          "description": "If `True`, the media will be returned as a data URI."
        },
        {
          "name": "additional_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Additional Prompt",
          "description": "Additional text to append to the automatically generated prompt."
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Random seed for reproducibility."
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 28,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "Qwen Image Layered",
      "description": "Qwen Image Layered provides layer-based image editing for complex compositions and precise control.\n    image, editing, qwen, layered, composition\n\n    Use cases:\n    - Edit images with layer-based control\n    - Create complex compositions\n    - Apply modifications to specific layers\n    - Build multi-layer image edits\n    - Produce sophisticated image compositions",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.QwenImageLayered",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "A caption for the input image."
        },
        {
          "name": "acceleration",
          "type": {
            "type": "enum",
            "values": [
              "none",
              "regular",
              "high"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.Acceleration"
          },
          "default": "regular",
          "title": "Acceleration",
          "description": "The acceleration level to use."
        },
        {
          "name": "num_layers",
          "type": {
            "type": "int"
          },
          "default": 4,
          "title": "Num Layers",
          "description": "The number of layers to generate."
        },
        {
          "name": "output_format",
          "type": {
            "type": "enum",
            "values": [
              "jpeg",
              "png"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.OutputFormat"
          },
          "default": "png",
          "title": "Output Format",
          "description": "The format of the generated image."
        },
        {
          "name": "image_url",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image Url",
          "description": "The URL of the input image."
        },
        {
          "name": "sync_mode",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Sync Mode",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history."
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If set to true, the safety checker will be enabled."
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 28,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform."
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 5,
          "title": "Guidance Scale",
          "description": "The guidance scale to use for the image generation."
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "The negative prompt to generate an image from."
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed and the same prompt given to the same version of the model will output the same image every time."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "Qwen Image Layered Lora",
      "description": "Qwen Image Layered with LoRA combines layer-based editing with custom-trained models for specialized tasks.\n    image, editing, qwen, layered, lora\n\n    Use cases:\n    - Edit layered images with custom models\n    - Create specialized layer compositions\n    - Apply fine-tuned modifications\n    - Build complex edits with trained models\n    - Produce custom layer-based results",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.QwenImageLayeredLora",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "A caption for the input image."
        },
        {
          "name": "acceleration",
          "type": {
            "type": "enum",
            "values": [
              "none",
              "regular",
              "high"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.Acceleration"
          },
          "default": "regular",
          "title": "Acceleration",
          "description": "The acceleration level to use."
        },
        {
          "name": "num_layers",
          "type": {
            "type": "int"
          },
          "default": 4,
          "title": "Num Layers",
          "description": "The number of layers to generate."
        },
        {
          "name": "output_format",
          "type": {
            "type": "enum",
            "values": [
              "jpeg",
              "png"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.OutputFormat"
          },
          "default": "png",
          "title": "Output Format",
          "description": "The format of the generated image."
        },
        {
          "name": "image_url",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image Url",
          "description": "The URL of the input image."
        },
        {
          "name": "loras",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "str"
              }
            ]
          },
          "default": [],
          "title": "Loras",
          "description": "List of LoRA weights to apply (maximum 3)."
        },
        {
          "name": "sync_mode",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Sync Mode",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history."
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 5,
          "title": "Guidance Scale",
          "description": "The guidance scale to use for the image generation."
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed and the same prompt given to the same version of the model will output the same image every time."
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 28,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform."
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "The negative prompt to generate an image from."
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If set to true, the safety checker will be enabled."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "Qwen Image Max Edit",
      "description": "Qwen Image Max Edit provides powerful image editing capabilities with advanced AI understanding and high-quality results.\n    image, editing, qwen, max, ai-editing\n\n    Use cases:\n    - Edit images with advanced AI understanding\n    - Apply complex modifications to photos\n    - Transform images with high-quality results\n    - Create professional edits with natural prompts\n    - Modify images with precise control",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.QwenImageMaxEdit",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "Text prompt describing the desired image. Supports Chinese and English. Max 800 characters."
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "The number of images to generate."
        },
        {
          "name": "image_size",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Image Size",
          "description": "The size of the generated image. If not provided, the size of the final input image will be used."
        },
        {
          "name": "output_format",
          "type": {
            "type": "enum",
            "values": [
              "jpeg",
              "png"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.OutputFormat"
          },
          "default": "png",
          "title": "Output Format",
          "description": "The format of the generated image."
        },
        {
          "name": "sync_mode",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Sync Mode",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history."
        },
        {
          "name": "enable_prompt_expansion",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Prompt Expansion",
          "description": "Enable LLM prompt optimization for better results."
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Random seed for reproducibility (0-2147483647)."
        },
        {
          "name": "image_urls",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "str"
              }
            ]
          },
          "default": [],
          "title": "Image Urls",
          "description": "Reference images for editing (1-3 images required). Order matters: reference as 'image 1', 'image 2', 'image 3' in prompt. Resolution: 384-5000px each dimension. Max size: 10MB each. Formats: JPEG, JPG, PNG (no alpha), WEBP."
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "Content to avoid in the generated image. Max 500 characters."
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "Enable content moderation for input and output."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "Recraft V3 Image To Image",
      "description": "Recraft V3 transforms images with advanced style control and quality preservation. Professional-grade image-to-image generation with fine-tuned artistic control.\n    image, transformation, recraft, style, professional\n\n    Use cases:\n    - Transform images with precise style control\n    - Create high-quality image variations\n    - Apply artistic modifications with consistency\n    - Generate professional design alternatives\n    - Produce style-coherent image transformations",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.RecraftV3ImageToImage",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The text prompt describing the desired transformation"
        },
        {
          "name": "style",
          "type": {
            "type": "enum",
            "values": [
              "any",
              "realistic_image",
              "digital_illustration",
              "vector_illustration",
              "realistic_image/b_and_w",
              "realistic_image/hard_flash",
              "realistic_image/hdr",
              "realistic_image/natural_light",
              "realistic_image/studio_portrait",
              "realistic_image/enterprise",
              "realistic_image/motion_blur",
              "realistic_image/evening_light",
              "realistic_image/faded_nostalgia",
              "realistic_image/forest_life",
              "realistic_image/mystic_naturalism",
              "realistic_image/natural_tones",
              "realistic_image/organic_calm",
              "realistic_image/real_life_glow",
              "realistic_image/retro_realism",
              "realistic_image/retro_snapshot",
              "realistic_image/urban_drama",
              "realistic_image/village_realism",
              "realistic_image/warm_folk",
              "digital_illustration/pixel_art",
              "digital_illustration/hand_drawn",
              "digital_illustration/grain",
              "digital_illustration/infantile_sketch",
              "digital_illustration/2d_art_poster",
              "digital_illustration/handmade_3d",
              "digital_illustration/hand_drawn_outline",
              "digital_illustration/engraving_color",
              "digital_illustration/2d_art_poster_2",
              "digital_illustration/antiquarian",
              "digital_illustration/bold_fantasy",
              "digital_illustration/child_book",
              "digital_illustration/child_books",
              "digital_illustration/cover",
              "digital_illustration/crosshatch",
              "digital_illustration/digital_engraving",
              "digital_illustration/expressionism",
              "digital_illustration/freehand_details",
              "digital_illustration/grain_20",
              "digital_illustration/graphic_intensity",
              "digital_illustration/hard_comics",
              "digital_illustration/long_shadow",
              "digital_illustration/modern_folk",
              "digital_illustration/multicolor",
              "digital_illustration/neon_calm",
              "digital_illustration/noir",
              "digital_illustration/nostalgic_pastel",
              "digital_illustration/outline_details",
              "digital_illustration/pastel_gradient",
              "digital_illustration/pastel_sketch",
              "digital_illustration/pop_art",
              "digital_illustration/pop_renaissance",
              "digital_illustration/street_art",
              "digital_illustration/tablet_sketch",
              "digital_illustration/urban_glow",
              "digital_illustration/urban_sketching",
              "digital_illustration/vanilla_dreams",
              "digital_illustration/young_adult_book",
              "digital_illustration/young_adult_book_2",
              "vector_illustration/bold_stroke",
              "vector_illustration/chemistry",
              "vector_illustration/colored_stencil",
              "vector_illustration/contour_pop_art",
              "vector_illustration/cosmics",
              "vector_illustration/cutout",
              "vector_illustration/depressive",
              "vector_illustration/editorial",
              "vector_illustration/emotional_flat",
              "vector_illustration/infographical",
              "vector_illustration/marker_outline",
              "vector_illustration/mosaic",
              "vector_illustration/naivector",
              "vector_illustration/roundish_flat",
              "vector_illustration/segmented_colors",
              "vector_illustration/sharp_contrast",
              "vector_illustration/thin",
              "vector_illustration/vector_photo",
              "vector_illustration/vivid_shapes",
              "vector_illustration/engraving",
              "vector_illustration/line_art",
              "vector_illustration/line_circuit",
              "vector_illustration/linocut"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.RecraftV3ImageToImageStyle"
          },
          "default": "realistic_image",
          "title": "Style",
          "description": "The artistic style to apply"
        },
        {
          "name": "style_id",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Style Id",
          "description": "The ID of the custom style reference (optional)"
        },
        {
          "name": "image_url",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image Url",
          "description": "The URL of the image to modify. Must be less than 5 MB in size, have resolution less than 16 MP and max dimension less than 4096 pixels."
        },
        {
          "name": "sync_mode",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Sync Mode",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history."
        },
        {
          "name": "strength",
          "type": {
            "type": "float"
          },
          "default": 0.5,
          "title": "Strength",
          "description": "Defines the difference with the original image, should lie in [0, 1], where 0 means almost identical, and 1 means miserable similarity"
        },
        {
          "name": "colors",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "str"
              }
            ]
          },
          "default": [],
          "title": "Colors",
          "description": "An array of preferable colors"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "A text description of undesired elements on an image"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "image",
        "style"
      ]
    },
    {
      "title": "Stepx Edit 2",
      "description": "StepX Edit 2 provides multi-step image editing with progressive refinement and control.\n    image, editing, stepx, progressive, refinement\n\n    Use cases:\n    - Edit images with progressive steps\n    - Apply multi-stage modifications\n    - Create refined edits gradually\n    - Transform images with step control\n    - Produce progressively refined results",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.StepxEdit2",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from."
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed and the same prompt given to the same version of the model will output the same image every time."
        },
        {
          "name": "enable_reflection_mode",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Reflection Mode",
          "description": "Enable reflection mode. Reviews outputs, corrects unintended changes, and determines when editing is complete."
        },
        {
          "name": "output_format",
          "type": {
            "type": "enum",
            "values": [
              "jpeg",
              "png"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.OutputFormat"
          },
          "default": "jpeg",
          "title": "Output Format",
          "description": "The format of the generated image."
        },
        {
          "name": "image_url",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image Url",
          "description": "The image URL to generate an image from. Needs to match the dimensions of the mask."
        },
        {
          "name": "sync_mode",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Sync Mode",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history."
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 6,
          "title": "Guidance Scale",
          "description": "The true CFG scale. Controls how closely the model follows the prompt."
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 50,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform. Recommended: 50."
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If set to true, the safety checker will be enabled."
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "The negative prompt to use. Use it to address details that you don't want in the image. This could be colors, objects, scenery and even the small details (e.g. moustache, blurry, low resolution)."
        },
        {
          "name": "enable_thinking_mode",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Thinking Mode",
          "description": "Enable thinking mode. Uses multimodal language model knowledge to interpret abstract editing instructions."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "Vidu Q2 Reference To Image",
      "description": "Vidu Q2 Reference-to-Image generates images based on reference images with style and content transfer.\n    image, generation, vidu, reference, style-transfer\n\n    Use cases:\n    - Generate images from references\n    - Transfer style and content\n    - Create reference-based variations\n    - Transform using reference images\n    - Produce style-transferred results",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.ViduQ2ReferenceToImage",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "Text prompt for video generation, max 1500 characters"
        },
        {
          "name": "aspect_ratio",
          "type": {
            "type": "enum",
            "values": [
              "10:16",
              "16:10",
              "9:16",
              "16:9",
              "4:3",
              "3:4",
              "1:1",
              "1:3",
              "3:1",
              "3:2",
              "2:3"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.AspectRatio"
          },
          "default": "16:9",
          "title": "Aspect Ratio",
          "description": "The aspect ratio of the output video"
        },
        {
          "name": "reference_image_urls",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "str"
              }
            ]
          },
          "default": [],
          "title": "Reference Image Urls",
          "description": "URLs of the reference images to use for consistent subject appearance"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Random seed for generation"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "Wan V26 Image To Image",
      "description": "Wan v2.6 image-to-image provides high-quality image transformations with advanced AI capabilities.\n    image, transformation, wan, v2.6, quality\n\n    Use cases:\n    - Transform images with Wan v2.6\n    - Apply quality modifications to photos\n    - Create high-quality variations\n    - Generate advanced transformations\n    - Produce quality image modifications",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.WanV26ImageToImage",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "Text prompt describing the desired image. Supports Chinese and English. Max 2000 characters. Example: 'Generate an image using the style of image 1 and background of image 2'."
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "Number of images to generate (1-4). Directly affects billing cost."
        },
        {
          "name": "image_size",
          "type": {
            "type": "str"
          },
          "default": "square_hd",
          "title": "Image Size",
          "description": "Output image size. Use presets like 'square_hd', 'landscape_16_9', 'portrait_9_16', or specify exact dimensions with ImageSize(width=1280, height=720). Total pixels must be between 768*768 and 1280*1280."
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "Enable content moderation for input and output."
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Random seed for reproducibility (0-2147483647). Same seed produces more consistent results."
        },
        {
          "name": "image_urls",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "str"
              }
            ]
          },
          "default": [],
          "title": "Image Urls",
          "description": "Reference images for editing (1-3 images required). Order matters: reference as 'image 1', 'image 2', 'image 3' in prompt. Resolution: 384-5000px each dimension. Max size: 10MB each. Formats: JPEG, JPG, PNG (no alpha), BMP, WEBP."
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "Content to avoid in the generated image. Max 500 characters."
        },
        {
          "name": "enable_prompt_expansion",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Prompt Expansion",
          "description": "Enable LLM prompt optimization. Significantly improves results for simple prompts but adds 3-4 seconds processing time."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "ZImage Turbo Controlnet",
      "description": "Z-Image Turbo ControlNet provides fast controlled image generation with structural guidance.\n    image, controlnet, z-image, turbo, controlled\n\n    Use cases:\n    - Generate images with fast structural control\n    - Apply quick controlled modifications\n    - Create rapid guided generations\n    - Transform images with fast ControlNet\n    - Produce speedy controlled outputs",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.ZImageTurboControlnet",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from."
        },
        {
          "name": "image_size",
          "type": {
            "type": "str"
          },
          "default": "auto",
          "title": "Image Size",
          "description": "The size of the generated image."
        },
        {
          "name": "acceleration",
          "type": {
            "type": "enum",
            "values": [
              "none",
              "regular",
              "high"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.Acceleration"
          },
          "default": "regular",
          "title": "Acceleration",
          "description": "The acceleration level to use."
        },
        {
          "name": "control_end",
          "type": {
            "type": "float"
          },
          "default": 0.8,
          "title": "Control End",
          "description": "The end of the controlnet conditioning."
        },
        {
          "name": "control_start",
          "type": {
            "type": "float"
          },
          "default": 0,
          "title": "Control Start",
          "description": "The start of the controlnet conditioning."
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If set to true, the safety checker will be enabled."
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "The number of images to generate."
        },
        {
          "name": "output_format",
          "type": {
            "type": "enum",
            "values": [
              "jpeg",
              "png"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.OutputFormat"
          },
          "default": "png",
          "title": "Output Format",
          "description": "The format of the generated image."
        },
        {
          "name": "image_url",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image Url",
          "description": "URL of Image for ControlNet generation."
        },
        {
          "name": "sync_mode",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Sync Mode",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history."
        },
        {
          "name": "control_scale",
          "type": {
            "type": "float"
          },
          "default": 0.75,
          "title": "Control Scale",
          "description": "The scale of the controlnet conditioning."
        },
        {
          "name": "enable_prompt_expansion",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Enable Prompt Expansion",
          "description": "Whether to enable prompt expansion. Note: this will increase the price by 0.0025 credits per request."
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 8,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform."
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed and the same prompt given to the same version of the model will output the same image every time."
        },
        {
          "name": "preprocess",
          "type": {
            "type": "enum",
            "values": [
              "none",
              "canny",
              "depth",
              "pose"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.Preprocess"
          },
          "default": "none",
          "title": "Preprocess",
          "description": "What kind of preprocessing to apply to the image, if any."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "ZImage Turbo Controlnet Lora",
      "description": "Z-Image Turbo ControlNet with LoRA combines fast controlled generation with custom models.\n    image, controlnet, z-image, turbo, lora\n\n    Use cases:\n    - Generate with fast custom ControlNet\n    - Apply quick specialized controlled generation\n    - Create rapid custom guided outputs\n    - Transform images with fast custom control\n    - Produce speedy fine-tuned controlled results",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.ZImageTurboControlnetLora",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from."
        },
        {
          "name": "image_size",
          "type": {
            "type": "str"
          },
          "default": "auto",
          "title": "Image Size",
          "description": "The size of the generated image."
        },
        {
          "name": "acceleration",
          "type": {
            "type": "enum",
            "values": [
              "none",
              "regular",
              "high"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.Acceleration"
          },
          "default": "regular",
          "title": "Acceleration",
          "description": "The acceleration level to use."
        },
        {
          "name": "loras",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "str"
              }
            ]
          },
          "default": [],
          "title": "Loras",
          "description": "List of LoRA weights to apply (maximum 3)."
        },
        {
          "name": "control_end",
          "type": {
            "type": "float"
          },
          "default": 0.8,
          "title": "Control End",
          "description": "The end of the controlnet conditioning."
        },
        {
          "name": "control_start",
          "type": {
            "type": "float"
          },
          "default": 0,
          "title": "Control Start",
          "description": "The start of the controlnet conditioning."
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If set to true, the safety checker will be enabled."
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "The number of images to generate."
        },
        {
          "name": "output_format",
          "type": {
            "type": "enum",
            "values": [
              "jpeg",
              "png"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.OutputFormat"
          },
          "default": "png",
          "title": "Output Format",
          "description": "The format of the generated image."
        },
        {
          "name": "image_url",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image Url",
          "description": "URL of Image for ControlNet generation."
        },
        {
          "name": "sync_mode",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Sync Mode",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history."
        },
        {
          "name": "control_scale",
          "type": {
            "type": "float"
          },
          "default": 0.75,
          "title": "Control Scale",
          "description": "The scale of the controlnet conditioning."
        },
        {
          "name": "enable_prompt_expansion",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Enable Prompt Expansion",
          "description": "Whether to enable prompt expansion. Note: this will increase the price by 0.0025 credits per request."
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 8,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform."
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed and the same prompt given to the same version of the model will output the same image every time."
        },
        {
          "name": "preprocess",
          "type": {
            "type": "enum",
            "values": [
              "none",
              "canny",
              "depth",
              "pose"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.Preprocess"
          },
          "default": "none",
          "title": "Preprocess",
          "description": "What kind of preprocessing to apply to the image, if any."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "ZImage Turbo Image To Image",
      "description": "Z-Image Turbo image-to-image provides fast image transformations with quality output.\n    image, transformation, z-image, turbo, fast\n\n    Use cases:\n    - Transform images quickly with Z-Image\n    - Apply fast modifications to photos\n    - Create rapid image variations\n    - Generate speedy transformations\n    - Produce quick image modifications",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.ZImageTurboImageToImage",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from."
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "The number of images to generate."
        },
        {
          "name": "image_size",
          "type": {
            "type": "str"
          },
          "default": "auto",
          "title": "Image Size",
          "description": "The size of the generated image."
        },
        {
          "name": "acceleration",
          "type": {
            "type": "enum",
            "values": [
              "none",
              "regular",
              "high"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.Acceleration"
          },
          "default": "regular",
          "title": "Acceleration",
          "description": "The acceleration level to use."
        },
        {
          "name": "output_format",
          "type": {
            "type": "enum",
            "values": [
              "jpeg",
              "png"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.OutputFormat"
          },
          "default": "png",
          "title": "Output Format",
          "description": "The format of the generated image."
        },
        {
          "name": "image_url",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image Url",
          "description": "URL of Image for Image-to-Image generation."
        },
        {
          "name": "sync_mode",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Sync Mode",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history."
        },
        {
          "name": "strength",
          "type": {
            "type": "float"
          },
          "default": 0.6,
          "title": "Strength",
          "description": "The strength of the image-to-image conditioning."
        },
        {
          "name": "enable_prompt_expansion",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Enable Prompt Expansion",
          "description": "Whether to enable prompt expansion. Note: this will increase the price by 0.0025 credits per request."
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed and the same prompt given to the same version of the model will output the same image every time."
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If set to true, the safety checker will be enabled."
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 8,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "ZImage Turbo Image To Image Lora",
      "description": "Z-Image Turbo image-to-image with LoRA enables fast custom-trained model transformations.\n    image, transformation, z-image, turbo, lora\n\n    Use cases:\n    - Transform images with custom Z-Image models\n    - Apply fast specialized modifications\n    - Create rapid custom edits\n    - Generate quick customized transformations\n    - Produce fast fine-tuned modifications",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.ZImageTurboImageToImageLora",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from."
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "The number of images to generate."
        },
        {
          "name": "image_size",
          "type": {
            "type": "str"
          },
          "default": "auto",
          "title": "Image Size",
          "description": "The size of the generated image."
        },
        {
          "name": "acceleration",
          "type": {
            "type": "enum",
            "values": [
              "none",
              "regular",
              "high"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.Acceleration"
          },
          "default": "regular",
          "title": "Acceleration",
          "description": "The acceleration level to use."
        },
        {
          "name": "output_format",
          "type": {
            "type": "enum",
            "values": [
              "jpeg",
              "png"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.OutputFormat"
          },
          "default": "png",
          "title": "Output Format",
          "description": "The format of the generated image."
        },
        {
          "name": "image_url",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image Url",
          "description": "URL of Image for Image-to-Image generation."
        },
        {
          "name": "sync_mode",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Sync Mode",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history."
        },
        {
          "name": "loras",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "str"
              }
            ]
          },
          "default": [],
          "title": "Loras",
          "description": "List of LoRA weights to apply (maximum 3)."
        },
        {
          "name": "strength",
          "type": {
            "type": "float"
          },
          "default": 0.6,
          "title": "Strength",
          "description": "The strength of the image-to-image conditioning."
        },
        {
          "name": "enable_prompt_expansion",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Enable Prompt Expansion",
          "description": "Whether to enable prompt expansion. Note: this will increase the price by 0.0025 credits per request."
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed and the same prompt given to the same version of the model will output the same image every time."
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If set to true, the safety checker will be enabled."
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 8,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "ZImage Turbo Inpaint",
      "description": "Z-Image Turbo Inpaint fills masked regions in images quickly with contextually appropriate content.\n    image, inpainting, z-image, turbo, fast\n\n    Use cases:\n    - Fill masked regions in images quickly\n    - Remove unwanted objects fast\n    - Repair image areas with turbo speed\n    - Generate quick inpainting results\n    - Produce rapid contextual fills",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.ZImageTurboInpaint",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from."
        },
        {
          "name": "image_size",
          "type": {
            "type": "str"
          },
          "default": "auto",
          "title": "Image Size",
          "description": "The size of the generated image."
        },
        {
          "name": "acceleration",
          "type": {
            "type": "enum",
            "values": [
              "none",
              "regular",
              "high"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.Acceleration"
          },
          "default": "regular",
          "title": "Acceleration",
          "description": "The acceleration level to use."
        },
        {
          "name": "mask_image_url",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Mask Image Url",
          "description": "URL of Mask for Inpaint generation."
        },
        {
          "name": "control_end",
          "type": {
            "type": "float"
          },
          "default": 0.8,
          "title": "Control End",
          "description": "The end of the controlnet conditioning."
        },
        {
          "name": "control_start",
          "type": {
            "type": "float"
          },
          "default": 0,
          "title": "Control Start",
          "description": "The start of the controlnet conditioning."
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If set to true, the safety checker will be enabled."
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "The number of images to generate."
        },
        {
          "name": "output_format",
          "type": {
            "type": "enum",
            "values": [
              "jpeg",
              "png"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.OutputFormat"
          },
          "default": "png",
          "title": "Output Format",
          "description": "The format of the generated image."
        },
        {
          "name": "image_url",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image Url",
          "description": "URL of Image for Inpaint generation."
        },
        {
          "name": "sync_mode",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Sync Mode",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history."
        },
        {
          "name": "strength",
          "type": {
            "type": "float"
          },
          "default": 1,
          "title": "Strength",
          "description": "The strength of the inpaint conditioning."
        },
        {
          "name": "control_scale",
          "type": {
            "type": "float"
          },
          "default": 0.75,
          "title": "Control Scale",
          "description": "The scale of the controlnet conditioning."
        },
        {
          "name": "enable_prompt_expansion",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Enable Prompt Expansion",
          "description": "Whether to enable prompt expansion. Note: this will increase the price by 0.0025 credits per request."
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 8,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform."
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed and the same prompt given to the same version of the model will output the same image every time."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "ZImage Turbo Inpaint Lora",
      "description": "Z-Image Turbo Inpaint with LoRA provides fast custom-trained inpainting for specialized tasks.\n    image, inpainting, z-image, turbo, lora\n\n    Use cases:\n    - Inpaint with custom fast models\n    - Fill regions using specialized training\n    - Repair images with custom inpainting\n    - Generate quick custom fills\n    - Produce rapid specialized inpainting",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.ZImageTurboInpaintLora",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from."
        },
        {
          "name": "image_size",
          "type": {
            "type": "str"
          },
          "default": "auto",
          "title": "Image Size",
          "description": "The size of the generated image."
        },
        {
          "name": "acceleration",
          "type": {
            "type": "enum",
            "values": [
              "none",
              "regular",
              "high"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.Acceleration"
          },
          "default": "regular",
          "title": "Acceleration",
          "description": "The acceleration level to use."
        },
        {
          "name": "mask_image_url",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Mask Image Url",
          "description": "URL of Mask for Inpaint generation."
        },
        {
          "name": "loras",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "str"
              }
            ]
          },
          "default": [],
          "title": "Loras",
          "description": "List of LoRA weights to apply (maximum 3)."
        },
        {
          "name": "control_end",
          "type": {
            "type": "float"
          },
          "default": 0.8,
          "title": "Control End",
          "description": "The end of the controlnet conditioning."
        },
        {
          "name": "control_start",
          "type": {
            "type": "float"
          },
          "default": 0,
          "title": "Control Start",
          "description": "The start of the controlnet conditioning."
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If set to true, the safety checker will be enabled."
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "The number of images to generate."
        },
        {
          "name": "output_format",
          "type": {
            "type": "enum",
            "values": [
              "jpeg",
              "png"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.OutputFormat"
          },
          "default": "png",
          "title": "Output Format",
          "description": "The format of the generated image."
        },
        {
          "name": "image_url",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image Url",
          "description": "URL of Image for Inpaint generation."
        },
        {
          "name": "sync_mode",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Sync Mode",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history."
        },
        {
          "name": "strength",
          "type": {
            "type": "float"
          },
          "default": 1,
          "title": "Strength",
          "description": "The strength of the inpaint conditioning."
        },
        {
          "name": "control_scale",
          "type": {
            "type": "float"
          },
          "default": 0.75,
          "title": "Control Scale",
          "description": "The scale of the controlnet conditioning."
        },
        {
          "name": "enable_prompt_expansion",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Enable Prompt Expansion",
          "description": "Whether to enable prompt expansion. Note: this will increase the price by 0.0025 credits per request."
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 8,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform."
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed and the same prompt given to the same version of the model will output the same image every time."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "Eleven Labs Scribe V2",
      "description": "ElevenLabs Scribe V2 is a state-of-the-art speech-to-text model with improved accuracy, word-level timestamps, and speaker identification.\n    speech, audio, transcription, scribe, elevenlabs, speech-to-text, audio-to-text, diarization\n\n    Use cases:\n    - Transcribe audio with high accuracy\n    - Generate subtitles with word-level timestamps\n    - Identify different speakers in conversations\n    - Support for 99 languages with biasing via keyterms\n    - Tag audio events like laughter and applause",
      "namespace": "fal.speech_to_text",
      "node_type": "fal.speech_to_text.ElevenLabsScribeV2",
      "properties": [
        {
          "name": "audio",
          "type": {
            "type": "audio"
          },
          "default": {
            "type": "audio",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Audio",
          "description": "The audio file to transcribe"
        },
        {
          "name": "language_code",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Language Code",
          "description": "Language code of the audio (e.g., 'eng', 'spa'). Auto-detected if empty"
        },
        {
          "name": "tag_audio_events",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Tag Audio Events",
          "description": "Whether to tag audio events like laughter, applause, etc."
        },
        {
          "name": "diarize",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Diarize",
          "description": "Whether to annotate who is speaking"
        },
        {
          "name": "keyterms",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "str"
              }
            ]
          },
          "default": null,
          "title": "Keyterms",
          "description": "Words or phrases to bias the model towards transcribing (up to 100, max 50 chars each)",
          "required": true
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "str"
          },
          "name": "text"
        },
        {
          "type": {
            "type": "str"
          },
          "name": "language_code"
        },
        {
          "type": {
            "type": "float"
          },
          "name": "language_probability"
        },
        {
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "dict"
              }
            ]
          },
          "name": "words"
        }
      ],
      "basic_fields": [
        "audio",
        "diarize",
        "language_code"
      ]
    },
    {
      "title": "Whisper",
      "description": "Whisper is a model for speech transcription and translation that can transcribe audio in multiple languages and optionally translate to English.\n    speech, audio, transcription, translation, transcribe, translate, multilingual, speech-to-text, audio-to-text\n\n    Use cases:\n    - Transcribe spoken content to text\n    - Translate speech to English\n    - Generate subtitles and captions\n    - Create text records of audio content\n    - Analyze multilingual audio content",
      "namespace": "fal.speech_to_text",
      "node_type": "fal.speech_to_text.Whisper",
      "properties": [
        {
          "name": "audio",
          "type": {
            "type": "audio"
          },
          "default": {
            "type": "audio",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Audio",
          "description": "The audio file to transcribe"
        },
        {
          "name": "task",
          "type": {
            "type": "enum",
            "values": [
              "transcribe",
              "translate"
            ],
            "type_name": "nodetool.nodes.fal.speech_to_text.TaskEnum"
          },
          "default": "transcribe",
          "title": "Task",
          "description": "Task to perform on the audio file"
        },
        {
          "name": "language",
          "type": {
            "type": "enum",
            "values": [
              "af",
              "am",
              "ar",
              "as",
              "az",
              "ba",
              "be",
              "bg",
              "bn",
              "bo",
              "br",
              "bs",
              "ca",
              "cs",
              "cy",
              "da",
              "de",
              "el",
              "en",
              "es",
              "et",
              "eu",
              "fa",
              "fi",
              "fo",
              "fr",
              "gl",
              "gu",
              "ha",
              "haw",
              "he",
              "hi",
              "hr",
              "ht",
              "hu",
              "hy",
              "id",
              "is",
              "it",
              "ja",
              "jw",
              "ka",
              "kk",
              "km",
              "kn",
              "ko",
              "la",
              "lb",
              "ln",
              "lo",
              "lt",
              "lv",
              "mg",
              "mi",
              "mk",
              "ml",
              "mn",
              "mr",
              "ms",
              "mt",
              "my",
              "ne",
              "nl",
              "nn",
              "no",
              "oc",
              "pa",
              "pl",
              "ps",
              "pt",
              "ro",
              "ru",
              "sa",
              "sd",
              "si",
              "sk",
              "sl",
              "sn",
              "so",
              "sq",
              "sr",
              "su",
              "sv",
              "sw",
              "ta",
              "te",
              "tg",
              "th",
              "tk",
              "tl",
              "tr",
              "tt",
              "uk",
              "ur",
              "uz",
              "vi",
              "yi",
              "yo",
              "yue",
              "zh"
            ],
            "type_name": "nodetool.nodes.fal.speech_to_text.LanguageEnum"
          },
          "default": "en",
          "title": "Language",
          "description": "Language of the audio file. If not set, will be auto-detected"
        },
        {
          "name": "diarize",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Diarize",
          "description": "Whether to perform speaker diarization"
        },
        {
          "name": "chunk_level",
          "type": {
            "type": "enum",
            "values": [
              "segment",
              "word"
            ],
            "type_name": "nodetool.nodes.fal.speech_to_text.ChunkLevelEnum"
          },
          "default": "segment",
          "title": "Chunk Level",
          "description": "Level of detail for timestamp chunks"
        },
        {
          "name": "num_speakers",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Speakers",
          "description": "Number of speakers in the audio. If not set, will be auto-detected",
          "min": 1.0,
          "max": 10.0
        },
        {
          "name": "batch_size",
          "type": {
            "type": "int"
          },
          "default": 64,
          "title": "Batch Size",
          "description": "Batch size for processing"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "Optional prompt to guide the transcription"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "str"
          },
          "name": "text"
        },
        {
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "dict"
              }
            ]
          },
          "name": "chunks"
        },
        {
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "str"
              }
            ]
          },
          "name": "inferred_languages"
        },
        {
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "dict"
              }
            ]
          },
          "name": "diarization_segments"
        }
      ],
      "basic_fields": [
        "audio",
        "task",
        "diarize"
      ]
    },
    {
      "title": "DWPose",
      "description": "DWPose detects human poses and keypoints in images.\n    pose, detection, keypoints, human\n\n    Use cases:\n    - Detect human poses\n    - Extract body keypoints\n    - Enable pose-guided generation\n    - Analyze body positions\n    - Create pose references",
      "namespace": "fal.segmentation",
      "node_type": "fal.segmentation.DWPose",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The image to analyze"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "image"
        },
        {
          "type": {
            "type": "list"
          },
          "name": "poses"
        }
      ],
      "basic_fields": [
        "image"
      ]
    },
    {
      "title": "Image Preprocessor Depth Anything V2",
      "description": "Depth Anything V2 generates high-quality depth maps from images.\n    depth, preprocessor, depth-map, estimation\n\n    Use cases:\n    - Generate accurate depth maps\n    - Enable depth-aware effects\n    - Create 3D visualizations\n    - Prepare ControlNet inputs\n    - Analyze image depth",
      "namespace": "fal.segmentation",
      "node_type": "fal.segmentation.ImagePreprocessorDepthAnythingV2",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The image to process"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image"
      ]
    },
    {
      "title": "Marigold Depth",
      "description": "Marigold Depth generates high-quality monocular depth maps.\n    depth, marigold, depth-map, estimation\n\n    Use cases:\n    - Generate precise depth maps\n    - Create depth visualizations\n    - Enable depth-based effects\n    - Prepare 3D conversions\n    - Analyze scene depth",
      "namespace": "fal.segmentation",
      "node_type": "fal.segmentation.MarigoldDepth",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The image to process"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image"
      ]
    },
    {
      "title": "SAM2 Image",
      "description": "SAM 2 Image segments objects in images with high accuracy.\n    segmentation, sam, image, masks\n\n    Use cases:\n    - Segment objects in images\n    - Create object masks\n    - Enable object selection\n    - Generate cutouts\n    - Create selection masks",
      "namespace": "fal.segmentation",
      "node_type": "fal.segmentation.SAM2Image",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The image to segment"
        },
        {
          "name": "point_coords",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "list",
                "type_args": [
                  {
                    "type": "float"
                  }
                ]
              }
            ]
          },
          "default": [],
          "title": "Point Coords",
          "description": "Point coordinates for prompts [[x, y], ...]"
        },
        {
          "name": "point_labels",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "int"
              }
            ]
          },
          "default": [],
          "title": "Point Labels",
          "description": "Labels for points (1=foreground, 0=background)"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "list"
          },
          "name": "masks"
        }
      ],
      "basic_fields": [
        "image"
      ]
    },
    {
      "title": "SAM2 Video",
      "description": "SAM 2 Video segments and tracks objects across video frames.\n    segmentation, sam, video, tracking\n\n    Use cases:\n    - Track objects in videos\n    - Create video masks\n    - Segment moving objects\n    - Generate video cutouts\n    - Enable video object selection",
      "namespace": "fal.segmentation",
      "node_type": "fal.segmentation.SAM2Video",
      "properties": [
        {
          "name": "video",
          "type": {
            "type": "video"
          },
          "default": {
            "type": "video",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null,
            "duration": null,
            "format": null
          },
          "title": "Video",
          "description": "The video to segment"
        },
        {
          "name": "point_coords",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "list",
                "type_args": [
                  {
                    "type": "float"
                  }
                ]
              }
            ]
          },
          "default": [],
          "title": "Point Coords",
          "description": "Point coordinates for prompts [[x, y], ...]"
        },
        {
          "name": "point_labels",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "int"
              }
            ]
          },
          "default": [],
          "title": "Point Labels",
          "description": "Labels for points (1=foreground, 0=background)"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "str"
          },
          "name": "masks_video"
        }
      ],
      "basic_fields": [
        "video"
      ]
    },
    {
      "title": "SAM3 Image",
      "description": "SAM 3 Image provides advanced segmentation with improved accuracy.\n    segmentation, sam3, image, masks, advanced\n\n    Use cases:\n    - High-accuracy object segmentation\n    - Complex scene segmentation\n    - Precise mask generation\n    - Advanced object selection\n    - Detailed cutout creation",
      "namespace": "fal.segmentation",
      "node_type": "fal.segmentation.SAM3Image",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The image to segment"
        },
        {
          "name": "point_coords",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "list",
                "type_args": [
                  {
                    "type": "float"
                  }
                ]
              }
            ]
          },
          "default": [],
          "title": "Point Coords",
          "description": "Point coordinates for prompts [[x, y], ...]"
        },
        {
          "name": "point_labels",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "int"
              }
            ]
          },
          "default": [],
          "title": "Point Labels",
          "description": "Labels for points (1=foreground, 0=background)"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "list"
          },
          "name": "masks"
        }
      ],
      "basic_fields": [
        "image"
      ]
    },
    {
      "title": "Fal AI",
      "description": "Dynamic FAL node for running any fal.ai endpoint.\n    fal, schema, dynamic, openapi, inference, runtime, model\n\n    Use cases:\n    - Call new fal.ai endpoints without adding new Python nodes\n    - Prototype workflows with experimental FAL models\n    - Run custom endpoints by sharing model info (llms.txt)\n    - Build flexible pipelines that depend on runtime model selection",
      "namespace": "fal.dynamic_schema",
      "node_type": "fal.dynamic_schema.FalAI",
      "properties": [
        {
          "name": "model_info",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Model Info",
          "description": "Paste the full llms.txt from the fal.ai model page (e.g. fal.ai/models/... \u2192 copy all)."
        }
      ],
      "basic_fields": [
        "model_info"
      ],
      "is_dynamic": true,
      "supports_dynamic_outputs": true
    },
    {
      "title": "Era 3D",
      "description": "Era3D creates multi-view consistent 3D models from images.\n    3d, generation, image-to-3d, era3d, multi-view\n\n    Use cases:\n    - Generate multi-view 3D models\n    - Create consistent 3D assets\n    - Produce 3D content with multiple views\n    - Generate detailed 3D models\n    - Create multi-view 3D for games",
      "namespace": "fal.model3d",
      "node_type": "fal.model3d.Era3D",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The image to convert to 3D"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 40,
          "title": "Num Inference Steps",
          "description": "Number of inference steps",
          "min": 10.0,
          "max": 100.0
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for reproducible generation"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "list"
          },
          "name": "mv_images"
        },
        {
          "type": {
            "type": "model_3d"
          },
          "name": "model"
        }
      ],
      "basic_fields": [
        "image"
      ]
    },
    {
      "title": "Hunyuan 3DV 2",
      "description": "Hunyuan3D V2 generates high-quality 3D models from images.\n    3d, generation, image-to-3d, hunyuan\n\n    Use cases:\n    - Generate detailed 3D models\n    - Create 3D assets from photos\n    - Produce high-quality 3D content\n    - Create 3D visualizations\n    - Generate 3D for productions",
      "namespace": "fal.model3d",
      "node_type": "fal.model3d.Hunyuan3DV2",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The image to convert to 3D"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 50,
          "title": "Num Inference Steps",
          "description": "Number of inference steps",
          "min": 1.0,
          "max": 100.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 2.0,
          "title": "Guidance Scale",
          "description": "Guidance scale for generation",
          "min": 1.0,
          "max": 10.0
        },
        {
          "name": "octree_resolution",
          "type": {
            "type": "int"
          },
          "default": 256,
          "title": "Octree Resolution",
          "description": "Octree resolution for 3D structure"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for reproducible generation"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "model_3d"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image"
      ]
    },
    {
      "title": "Trellis",
      "description": "Trellis generates 3D models from single images.\n    3d, generation, image-to-3d, trellis\n\n    Use cases:\n    - Generate 3D models from images\n    - Create 3D assets from photos\n    - Produce 3D content for games\n    - Create 3D visualizations\n    - Generate 3D for AR/VR",
      "namespace": "fal.model3d",
      "node_type": "fal.model3d.Trellis",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The image to convert to 3D"
        },
        {
          "name": "ss_guidance_strength",
          "type": {
            "type": "float"
          },
          "default": 7.5,
          "title": "Ss Guidance Strength",
          "description": "Guidance strength for sparse structure",
          "min": 0.0,
          "max": 20.0
        },
        {
          "name": "ss_sampling_steps",
          "type": {
            "type": "int"
          },
          "default": 12,
          "title": "Ss Sampling Steps",
          "description": "Sampling steps for sparse structure",
          "min": 1.0,
          "max": 50.0
        },
        {
          "name": "slat_guidance_strength",
          "type": {
            "type": "float"
          },
          "default": 3.0,
          "title": "Slat Guidance Strength",
          "description": "Guidance strength for structured latent",
          "min": 0.0,
          "max": 20.0
        },
        {
          "name": "slat_sampling_steps",
          "type": {
            "type": "int"
          },
          "default": 12,
          "title": "Slat Sampling Steps",
          "description": "Sampling steps for structured latent",
          "min": 1.0,
          "max": 50.0
        },
        {
          "name": "mesh_simplify",
          "type": {
            "type": "float"
          },
          "default": 0.95,
          "title": "Mesh Simplify",
          "description": "Mesh simplification ratio",
          "min": 0.9,
          "max": 0.98
        },
        {
          "name": "texture_size",
          "type": {
            "type": "enum",
            "values": [
              512,
              1024,
              2048
            ],
            "type_name": "nodetool.nodes.fal.model3d.TextureSizeEnum"
          },
          "default": 1024,
          "title": "Texture Size",
          "description": "Texture resolution"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for reproducible generation"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "model_3d"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "texture_size"
      ]
    },
    {
      "title": "Tripo SR",
      "description": "TripoSR generates 3D models from images with fast processing.\n    3d, generation, image-to-3d, triposr, fast\n\n    Use cases:\n    - Quick 3D model generation\n    - Rapid prototyping\n    - Create 3D assets from photos\n    - Generate 3D content quickly\n    - Fast 3D for AR/VR",
      "namespace": "fal.model3d",
      "node_type": "fal.model3d.TripoSR",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The input image to convert to 3D"
        },
        {
          "name": "foreground_ratio",
          "type": {
            "type": "float"
          },
          "default": 0.85,
          "title": "Foreground Ratio",
          "description": "Foreground ratio for cropping",
          "min": 0.5,
          "max": 1.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "model_3d"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image"
      ]
    },
    {
      "title": "Chatterbox TTS",
      "description": "Chatterbox Text-to-Speech with conversational voice synthesis.\n    audio, tts, text-to-speech, chatterbox, conversational\n\n    Use cases:\n    - Generate conversational speech\n    - Create chat bot voices\n    - Produce dialogue audio\n    - Create interactive content\n    - Generate voice assistants",
      "namespace": "fal.text_to_audio",
      "node_type": "fal.text_to_audio.ChatterboxTTS",
      "properties": [
        {
          "name": "text",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Text",
          "description": "The text to convert to speech"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "audio"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "text"
      ]
    },
    {
      "title": "Demucs",
      "description": "Demucs separates audio tracks into stems (vocals, drums, bass, other).\n    audio, separation, stems, demucs\n\n    Use cases:\n    - Separate music into stems\n    - Extract vocals or instruments\n    - Create remix material\n    - Analyze music components\n    - Isolate specific tracks",
      "namespace": "fal.text_to_audio",
      "node_type": "fal.text_to_audio.Demucs",
      "properties": [
        {
          "name": "audio",
          "type": {
            "type": "audio"
          },
          "default": {
            "type": "audio",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Audio",
          "description": "The audio file to separate"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "audio"
          },
          "name": "vocals"
        },
        {
          "type": {
            "type": "audio"
          },
          "name": "drums"
        },
        {
          "type": {
            "type": "audio"
          },
          "name": "bass"
        },
        {
          "type": {
            "type": "audio"
          },
          "name": "other"
        }
      ],
      "basic_fields": [
        "audio"
      ]
    },
    {
      "title": "Dia TTS",
      "description": "Dia TTS generates natural speech with emotion and expression control.\n    audio, tts, text-to-speech, dia, expressive\n\n    Use cases:\n    - Generate expressive speech\n    - Create emotional voiceovers\n    - Produce dynamic audio content\n    - Create character voices\n    - Generate storytelling audio",
      "namespace": "fal.text_to_audio",
      "node_type": "fal.text_to_audio.DiaTTS",
      "properties": [
        {
          "name": "text",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Text",
          "description": "The text to convert to speech"
        },
        {
          "name": "voice",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Voice",
          "description": "The voice preset to use"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "audio"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "text"
      ]
    },
    {
      "title": "Eleven Labs Audio Isolation",
      "description": "ElevenLabs Audio Isolation separates vocals from audio tracks.\n    audio, isolation, separation, elevenlabs\n\n    Use cases:\n    - Extract vocals from music\n    - Remove background noise\n    - Isolate speech\n    - Create acapella tracks\n    - Clean audio recordings",
      "namespace": "fal.text_to_audio",
      "node_type": "fal.text_to_audio.ElevenLabsAudioIsolation",
      "properties": [
        {
          "name": "audio",
          "type": {
            "type": "audio"
          },
          "default": {
            "type": "audio",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Audio",
          "description": "The audio file to process"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "audio"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "audio"
      ]
    },
    {
      "title": "Eleven Labs Multilingual",
      "description": "ElevenLabs Multilingual V2 Text-to-Speech with support for 29 languages.\n    audio, tts, text-to-speech, elevenlabs, multilingual\n\n    Use cases:\n    - Generate speech in multiple languages\n    - Create localized content\n    - Produce multilingual voiceovers\n    - Create international audio\n    - Generate language learning content",
      "namespace": "fal.text_to_audio",
      "node_type": "fal.text_to_audio.ElevenLabsMultilingual",
      "properties": [
        {
          "name": "text",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Text",
          "description": "The text to convert to speech"
        },
        {
          "name": "voice_id",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Voice Id",
          "description": "The voice ID to use for synthesis"
        },
        {
          "name": "language_code",
          "type": {
            "type": "str"
          },
          "default": "en",
          "title": "Language Code",
          "description": "Language code (e.g., en, es, fr)"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "audio"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "text",
        "voice_id",
        "language_code"
      ]
    },
    {
      "title": "Eleven Labs Music",
      "description": "ElevenLabs Music generates music from text descriptions.\n    audio, music, generation, elevenlabs, creative\n\n    Use cases:\n    - Generate custom music tracks\n    - Create background music\n    - Produce jingles\n    - Create audio branding\n    - Generate ambient music",
      "namespace": "fal.text_to_audio",
      "node_type": "fal.text_to_audio.ElevenLabsMusic",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt describing the music to generate"
        },
        {
          "name": "duration",
          "type": {
            "type": "float"
          },
          "default": 30.0,
          "title": "Duration",
          "description": "Duration in seconds",
          "min": 1.0,
          "max": 120.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "audio"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "duration"
      ]
    },
    {
      "title": "Eleven Labs Sound Effects",
      "description": "ElevenLabs Sound Effects V2 generates sound effects from text descriptions.\n    audio, sound-effects, generation, elevenlabs\n\n    Use cases:\n    - Generate custom sound effects\n    - Create audio for videos\n    - Produce game audio\n    - Create ambient sounds\n    - Generate UI sounds",
      "namespace": "fal.text_to_audio",
      "node_type": "fal.text_to_audio.ElevenLabsSoundEffects",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt describing the sound effect"
        },
        {
          "name": "duration",
          "type": {
            "type": "float"
          },
          "default": 5.0,
          "title": "Duration",
          "description": "Duration in seconds",
          "min": 0.5,
          "max": 22.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "audio"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "duration"
      ]
    },
    {
      "title": "Eleven Labs TTSTurbo",
      "description": "ElevenLabs Turbo V2.5 Text-to-Speech for fast voice synthesis.\n    audio, tts, text-to-speech, elevenlabs, fast, turbo\n\n    Use cases:\n    - Quick voice generation\n    - Real-time speech synthesis\n    - Rapid prototyping\n    - Fast audio content\n    - Interactive applications",
      "namespace": "fal.text_to_audio",
      "node_type": "fal.text_to_audio.ElevenLabsTTSTurbo",
      "properties": [
        {
          "name": "text",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Text",
          "description": "The text to convert to speech"
        },
        {
          "name": "voice_id",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Voice Id",
          "description": "The voice ID to use for synthesis"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "audio"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "text",
        "voice_id"
      ]
    },
    {
      "title": "Eleven Labs TTSV3",
      "description": "ElevenLabs Eleven V3 Text-to-Speech with high-quality voice synthesis.\n    audio, tts, text-to-speech, elevenlabs, voice, synthesis\n\n    Use cases:\n    - Generate natural speech from text\n    - Create voiceovers\n    - Produce audio content\n    - Create audiobooks\n    - Generate voice notifications",
      "namespace": "fal.text_to_audio",
      "node_type": "fal.text_to_audio.ElevenLabsTTSV3",
      "properties": [
        {
          "name": "text",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Text",
          "description": "The text to convert to speech"
        },
        {
          "name": "voice_id",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Voice Id",
          "description": "The voice ID to use for synthesis"
        },
        {
          "name": "model_id",
          "type": {
            "type": "str"
          },
          "default": "eleven_multilingual_v2",
          "title": "Model Id",
          "description": "The model ID (e.g., eleven_multilingual_v2)"
        },
        {
          "name": "stability",
          "type": {
            "type": "float"
          },
          "default": 0.5,
          "title": "Stability",
          "description": "Voice stability",
          "min": 0.0,
          "max": 1.0
        },
        {
          "name": "similarity_boost",
          "type": {
            "type": "float"
          },
          "default": 0.75,
          "title": "Similarity Boost",
          "description": "Voice similarity boost",
          "min": 0.0,
          "max": 1.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "audio"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "text",
        "voice_id"
      ]
    },
    {
      "title": "F5 TTS",
      "description": "F5 TTS (Text-to-Speech) model for generating natural-sounding speech from text with voice cloning capabilities.\n    audio, tts, voice-cloning, speech, synthesis, text-to-speech, tts, text-to-audio\n\n    Use cases:\n    - Generate natural speech from text\n    - Clone and replicate voices\n    - Create custom voiceovers\n    - Produce multilingual speech content\n    - Generate personalized audio content",
      "namespace": "fal.text_to_audio",
      "node_type": "fal.text_to_audio.F5TTS",
      "properties": [
        {
          "name": "gen_text",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Gen Text",
          "description": "The text to be converted to speech"
        },
        {
          "name": "ref_audio_url",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Ref Audio Url",
          "description": "URL of the reference audio file to clone the voice from"
        },
        {
          "name": "ref_text",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Ref Text",
          "description": "Optional reference text. If not provided, ASR will be used"
        },
        {
          "name": "model_type",
          "type": {
            "type": "str"
          },
          "default": "F5-TTS",
          "title": "Model Type",
          "description": "Model type to use (F5-TTS or E2-TTS)"
        },
        {
          "name": "remove_silence",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Remove Silence",
          "description": "Whether to remove silence from the generated audio"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "audio"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "gen_text",
        "ref_audio_url",
        "model_type"
      ]
    },
    {
      "title": "Kokoro TTS",
      "description": "Kokoro American English Text-to-Speech with natural voice synthesis.\n    audio, tts, text-to-speech, kokoro, english\n\n    Use cases:\n    - Generate natural English speech\n    - Create voiceovers\n    - Produce audio content\n    - Create educational material\n    - Generate voice notifications",
      "namespace": "fal.text_to_audio",
      "node_type": "fal.text_to_audio.KokoroTTS",
      "properties": [
        {
          "name": "text",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Text",
          "description": "The text to convert to speech"
        },
        {
          "name": "voice",
          "type": {
            "type": "str"
          },
          "default": "af_sky",
          "title": "Voice",
          "description": "The voice to use"
        },
        {
          "name": "speed",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Speed",
          "description": "Speech speed multiplier",
          "min": 0.5,
          "max": 2.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "audio"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "text",
        "voice"
      ]
    },
    {
      "title": "MMAudio V2",
      "description": "MMAudio V2 generates synchronized audio given text inputs. It can generate sounds described by a prompt.\n    audio, generation, synthesis, text-to-audio, synchronization\n\n    Use cases:\n    - Generate synchronized audio from text descriptions\n    - Create custom sound effects\n    - Produce ambient soundscapes\n    - Generate audio for multimedia content\n    - Create sound design elements",
      "namespace": "fal.text_to_audio",
      "node_type": "fal.text_to_audio.MMAudioV2",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate the audio for"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "The negative prompt to avoid certain elements in the generated audio"
        },
        {
          "name": "num_steps",
          "type": {
            "type": "int"
          },
          "default": 25,
          "title": "Num Steps",
          "description": "The number of steps to generate the audio for",
          "min": 1.0
        },
        {
          "name": "duration",
          "type": {
            "type": "float"
          },
          "default": 8.0,
          "title": "Duration",
          "description": "The duration of the audio to generate in seconds",
          "min": 1.0
        },
        {
          "name": "cfg_strength",
          "type": {
            "type": "float"
          },
          "default": 4.5,
          "title": "Cfg Strength",
          "description": "The strength of Classifier Free Guidance"
        },
        {
          "name": "mask_away_clip",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Mask Away Clip",
          "description": "Whether to mask away the clip"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed will output the same audio every time"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "audio"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "duration",
        "num_steps"
      ]
    },
    {
      "title": "Mini Max Music",
      "description": "MiniMax Music generates music tracks from text descriptions.\n    audio, music, generation, minimax\n\n    Use cases:\n    - Generate custom music\n    - Create background tracks\n    - Produce audio content\n    - Create music for videos\n    - Generate jingles",
      "namespace": "fal.text_to_audio",
      "node_type": "fal.text_to_audio.MiniMaxMusic",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt describing the music to generate"
        },
        {
          "name": "reference_audio",
          "type": {
            "type": "audio"
          },
          "default": {
            "type": "audio",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Reference Audio",
          "description": "Reference audio for music generation"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "audio"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "reference_audio"
      ]
    },
    {
      "title": "Mini Max Speech 02HD",
      "description": "MiniMax Speech 02 HD generates high-quality speech synthesis.\n    audio, tts, text-to-speech, minimax, hd\n\n    Use cases:\n    - Generate HD quality speech\n    - Create professional audio\n    - Produce voiceovers\n    - Create content narration\n    - Generate announcements",
      "namespace": "fal.text_to_audio",
      "node_type": "fal.text_to_audio.MiniMaxSpeech02HD",
      "properties": [
        {
          "name": "text",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Text",
          "description": "The text to convert to speech"
        },
        {
          "name": "voice_id",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Voice Id",
          "description": "The voice ID to use"
        },
        {
          "name": "reference_audio_url",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Reference Audio Url",
          "description": "URL of reference audio for voice cloning"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "audio"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "text",
        "voice_id",
        "reference_audio_url"
      ]
    },
    {
      "title": "Nova SR",
      "description": "Nova SR enhances muffled 16 kHz speech audio into crystal-clear 48 kHz audio using super-resolution.\n    audio, enhancement, super-resolution, speech, upsampling, audio-to-audio, nova-sr\n\n    Use cases:\n    - Enhance low-quality speech recordings\n    - Upsample audio from 16kHz to 48kHz\n    - Improve audio clarity for voice content\n    - Prepare speech for downstream processing\n    - Recover details from compressed audio",
      "namespace": "fal.text_to_audio",
      "node_type": "fal.text_to_audio.NovaSR",
      "properties": [
        {
          "name": "audio",
          "type": {
            "type": "audio"
          },
          "default": {
            "type": "audio",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Audio",
          "description": "The audio file to enhance"
        },
        {
          "name": "audio_format",
          "type": {
            "type": "enum",
            "values": [
              "mp3",
              "aac",
              "m4a",
              "ogg",
              "opus",
              "flac",
              "wav"
            ],
            "type_name": "nodetool.nodes.fal.text_to_audio.AudioFormatEnum"
          },
          "default": "mp3",
          "title": "Audio Format",
          "description": "Output audio format"
        },
        {
          "name": "bitrate",
          "type": {
            "type": "str"
          },
          "default": "192k",
          "title": "Bitrate",
          "description": "Output audio bitrate"
        },
        {
          "name": "sync_mode",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Sync Mode",
          "description": "If True, media returned as data URI"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "audio"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "audio",
        "audio_format",
        "bitrate"
      ]
    },
    {
      "title": "Orpheus TTS",
      "description": "Orpheus TTS generates high-quality speech with natural prosody.\n    audio, tts, text-to-speech, orpheus, natural\n\n    Use cases:\n    - Generate natural-sounding speech\n    - Create professional voiceovers\n    - Produce high-quality audio\n    - Create audiobooks\n    - Generate podcast content",
      "namespace": "fal.text_to_audio",
      "node_type": "fal.text_to_audio.OrpheusTTS",
      "properties": [
        {
          "name": "text",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Text",
          "description": "The text to convert to speech"
        },
        {
          "name": "voice",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Voice",
          "description": "The voice to use"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "audio"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "text"
      ]
    },
    {
      "title": "PlayAI Dialog TTS",
      "description": "PlayAI Dialog TTS generates speech for multi speaker dialogs.\n    audio, tts, dialog, speech, synthesis\n\n    Use cases:\n    - Generate interactive conversations\n    - Create voice overs with multiple characters\n    - Produce spoken dialogs for games\n    - Synthesize narration with distinct voices\n    - Prototype conversational audio",
      "namespace": "fal.text_to_audio",
      "node_type": "fal.text_to_audio.PlayAITTSDialog",
      "properties": [
        {
          "name": "text",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Text",
          "description": "Text to convert into speech"
        },
        {
          "name": "voice",
          "type": {
            "type": "str"
          },
          "default": "nova",
          "title": "Voice",
          "description": "Voice preset to use for the spoken dialog"
        },
        {
          "name": "speed",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Speed",
          "description": "Playback speed of the generated audio",
          "min": 0.5,
          "max": 2.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "audio"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "text",
        "voice"
      ]
    },
    {
      "title": "Qwen 3 Clone Voice 0.6B",
      "description": "Clone a voice from an audio sample using the efficient 0.6B model. Creates a speaker embedding for fast voice cloning.\n    tts, voice-cloning, speaker-embedding, fast, qwen\n\n    Use cases:\n    - Quick voice cloning from audio samples\n    - Create lightweight speaker embeddings\n    - Generate fast voice profiles\n    - Clone voices for real-time applications\n    - Create efficient voice profiles",
      "namespace": "fal.text_to_audio",
      "node_type": "fal.text_to_audio.Qwen3CloneVoice06B",
      "properties": [
        {
          "name": "audio",
          "type": {
            "type": "audio"
          },
          "default": {
            "type": "audio",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Audio",
          "description": "Reference audio file used for voice cloning"
        },
        {
          "name": "reference_text",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Reference Text",
          "description": "Optional reference text that corresponds to the audio sample"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "str"
          },
          "name": "speaker_embedding_url"
        }
      ],
      "basic_fields": [
        "audio",
        "reference_text"
      ]
    },
    {
      "title": "Qwen 3 Clone Voice 1.7B",
      "description": "Clone a voice from an audio sample for text-to-speech synthesis. Creates a speaker embedding that can be used with other Qwen 3 TTS models.\n    tts, voice-cloning, speaker-embedding, voice-synthesis, qwen\n\n    Use cases:\n    - Clone custom voices from audio samples\n    - Create personalized text-to-speech voices\n    - Preserve voice characteristics for content creation\n    - Generate speaker embeddings for consistent voices\n    - Create voice profiles for character consistency",
      "namespace": "fal.text_to_audio",
      "node_type": "fal.text_to_audio.Qwen3CloneVoice17B",
      "properties": [
        {
          "name": "audio",
          "type": {
            "type": "audio"
          },
          "default": {
            "type": "audio",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Audio",
          "description": "Reference audio file used for voice cloning"
        },
        {
          "name": "reference_text",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Reference Text",
          "description": "Optional reference text that corresponds to the audio sample"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "str"
          },
          "name": "speaker_embedding_url"
        }
      ],
      "basic_fields": [
        "audio",
        "reference_text"
      ]
    },
    {
      "title": "Qwen 3 TTS 0.6B",
      "description": "Efficient text-to-speech synthesis with the lighter Qwen 3 TTS 0.6B model. Provides fast speech generation with multiple voice options.\n    tts, text-to-speech, voice, synthesis, fast, qwen\n\n    Use cases:\n    - Generate quick speech output from text\n    - Create fast voiceovers for applications\n    - Produce audio content efficiently\n    - Generate speech for real-time applications\n    - Create lightweight audio content",
      "namespace": "fal.text_to_audio",
      "node_type": "fal.text_to_audio.Qwen3TTS06B",
      "properties": [
        {
          "name": "text",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Text",
          "description": "The text to be converted to speech"
        },
        {
          "name": "voice",
          "type": {
            "type": "enum",
            "values": [
              "Vivian",
              "Serena",
              "Uncle_Fu",
              "Dylan",
              "Eric",
              "Ryan",
              "Aiden",
              "Ono_Anna",
              "Sohee"
            ],
            "type_name": "nodetool.nodes.fal.text_to_audio.Qwen3Voice"
          },
          "default": "Vivian",
          "title": "Voice",
          "description": "The voice to be used for speech synthesis"
        },
        {
          "name": "language",
          "type": {
            "type": "enum",
            "values": [
              "Auto",
              "English",
              "Chinese",
              "Spanish",
              "French",
              "German",
              "Italian",
              "Japanese",
              "Korean",
              "Portuguese",
              "Russian"
            ],
            "type_name": "nodetool.nodes.fal.text_to_audio.Qwen3Language"
          },
          "default": "Auto",
          "title": "Language",
          "description": "The language of the voice"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "Optional prompt to guide the style of the generated speech"
        },
        {
          "name": "speaker_voice_embedding_file_url",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Speaker Voice Embedding File Url",
          "description": "URL to a speaker embedding file from clone-voice endpoint"
        },
        {
          "name": "reference_text",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Reference Text",
          "description": "Optional reference text used when creating the speaker embedding"
        },
        {
          "name": "top_k",
          "type": {
            "type": "int"
          },
          "default": 50,
          "title": "Top K",
          "description": "Top-k sampling parameter"
        },
        {
          "name": "top_p",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Top P",
          "description": "Top-p sampling parameter"
        },
        {
          "name": "temperature",
          "type": {
            "type": "float"
          },
          "default": 0.9,
          "title": "Temperature",
          "description": "Sampling temperature; higher => more random"
        },
        {
          "name": "repetition_penalty",
          "type": {
            "type": "float"
          },
          "default": 1.05,
          "title": "Repetition Penalty",
          "description": "Penalty to reduce repeated tokens/codes"
        },
        {
          "name": "max_new_tokens",
          "type": {
            "type": "int"
          },
          "default": 200,
          "title": "Max New Tokens",
          "description": "Maximum number of new codec tokens to generate"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "audio"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "text",
        "voice",
        "language"
      ]
    },
    {
      "title": "Qwen 3 TTS 1.7B",
      "description": "High-quality text-to-speech synthesis with multiple voice options and language support. Uses the Qwen 3 TTS 1.7B model for natural-sounding speech generation.\n    tts, text-to-speech, voice, synthesis, multilingual, qwen\n\n    Use cases:\n    - Generate natural-sounding speech from text\n    - Create voiceovers in multiple languages\n    - Produce audio content with custom voice characteristics\n    - Generate speech with specific emotional tones\n    - Create multilingual audio content",
      "namespace": "fal.text_to_audio",
      "node_type": "fal.text_to_audio.Qwen3TTS17B",
      "properties": [
        {
          "name": "text",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Text",
          "description": "The text to be converted to speech"
        },
        {
          "name": "voice",
          "type": {
            "type": "enum",
            "values": [
              "Vivian",
              "Serena",
              "Uncle_Fu",
              "Dylan",
              "Eric",
              "Ryan",
              "Aiden",
              "Ono_Anna",
              "Sohee"
            ],
            "type_name": "nodetool.nodes.fal.text_to_audio.Qwen3Voice"
          },
          "default": "Vivian",
          "title": "Voice",
          "description": "The voice to be used for speech synthesis"
        },
        {
          "name": "language",
          "type": {
            "type": "enum",
            "values": [
              "Auto",
              "English",
              "Chinese",
              "Spanish",
              "French",
              "German",
              "Italian",
              "Japanese",
              "Korean",
              "Portuguese",
              "Russian"
            ],
            "type_name": "nodetool.nodes.fal.text_to_audio.Qwen3Language"
          },
          "default": "Auto",
          "title": "Language",
          "description": "The language of the voice"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "Optional prompt to guide the style of the generated speech"
        },
        {
          "name": "speaker_voice_embedding_file_url",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Speaker Voice Embedding File Url",
          "description": "URL to a speaker embedding file from clone-voice endpoint"
        },
        {
          "name": "reference_text",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Reference Text",
          "description": "Optional reference text used when creating the speaker embedding"
        },
        {
          "name": "top_k",
          "type": {
            "type": "int"
          },
          "default": 50,
          "title": "Top K",
          "description": "Top-k sampling parameter"
        },
        {
          "name": "top_p",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Top P",
          "description": "Top-p sampling parameter"
        },
        {
          "name": "temperature",
          "type": {
            "type": "float"
          },
          "default": 0.9,
          "title": "Temperature",
          "description": "Sampling temperature; higher => more random"
        },
        {
          "name": "repetition_penalty",
          "type": {
            "type": "float"
          },
          "default": 1.05,
          "title": "Repetition Penalty",
          "description": "Penalty to reduce repeated tokens/codes"
        },
        {
          "name": "max_new_tokens",
          "type": {
            "type": "int"
          },
          "default": 200,
          "title": "Max New Tokens",
          "description": "Maximum number of new codec tokens to generate"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "audio"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "text",
        "voice",
        "language"
      ]
    },
    {
      "title": "Qwen 3 Voice Design 1.7B",
      "description": "Design custom voice styles and emotions using text prompts. Create expressive speech with specific tones and characteristics using the 1.7B model.\n    tts, text-to-speech, voice-design, emotion, synthesis, qwen\n\n    Use cases:\n    - Create speech with specific emotional characteristics\n    - Design custom voice styles for creative content\n    - Generate expressive voiceovers with nuanced tones\n    - Produce character voices with distinct personalities\n    - Create contextually appropriate speech delivery",
      "namespace": "fal.text_to_audio",
      "node_type": "fal.text_to_audio.Qwen3VoiceDesign17B",
      "properties": [
        {
          "name": "text",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Text",
          "description": "The text to be converted to speech"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "Prompt to guide the style and emotion of the generated speech"
        },
        {
          "name": "language",
          "type": {
            "type": "enum",
            "values": [
              "Auto",
              "English",
              "Chinese",
              "Spanish",
              "French",
              "German",
              "Italian",
              "Japanese",
              "Korean",
              "Portuguese",
              "Russian"
            ],
            "type_name": "nodetool.nodes.fal.text_to_audio.Qwen3Language"
          },
          "default": "Auto",
          "title": "Language",
          "description": "The language of the voice to be designed"
        },
        {
          "name": "top_k",
          "type": {
            "type": "int"
          },
          "default": 50,
          "title": "Top K",
          "description": "Top-k sampling parameter"
        },
        {
          "name": "top_p",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Top P",
          "description": "Top-p sampling parameter"
        },
        {
          "name": "temperature",
          "type": {
            "type": "float"
          },
          "default": 0.9,
          "title": "Temperature",
          "description": "Sampling temperature; higher => more random"
        },
        {
          "name": "repetition_penalty",
          "type": {
            "type": "float"
          },
          "default": 1.05,
          "title": "Repetition Penalty",
          "description": "Penalty to reduce repeated tokens/codes"
        },
        {
          "name": "max_new_tokens",
          "type": {
            "type": "int"
          },
          "default": 200,
          "title": "Max New Tokens",
          "description": "Maximum number of new codec tokens to generate"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "audio"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "text",
        "prompt",
        "language"
      ]
    },
    {
      "title": "Stable Audio",
      "description": "Stable Audio generates audio from text prompts. Open source text-to-audio model from fal.ai.\n    audio, generation, synthesis, text-to-audio, open-source\n\n    Use cases:\n    - Generate custom audio content from text\n    - Create background music and sounds\n    - Produce audio assets for projects\n    - Generate sound effects\n    - Create experimental audio content",
      "namespace": "fal.text_to_audio",
      "node_type": "fal.text_to_audio.StableAudio",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate the audio from"
        },
        {
          "name": "seconds_start",
          "type": {
            "type": "int"
          },
          "default": 0,
          "title": "Seconds Start",
          "description": "The start point of the audio clip to generate"
        },
        {
          "name": "seconds_total",
          "type": {
            "type": "int"
          },
          "default": 30,
          "title": "Seconds Total",
          "description": "The duration of the audio clip to generate in seconds"
        },
        {
          "name": "steps",
          "type": {
            "type": "int"
          },
          "default": 100,
          "title": "Steps",
          "description": "The number of steps to denoise the audio for"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "audio"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "seconds_total",
        "steps"
      ]
    },
    {
      "title": "Hunyuan Video",
      "description": "Hunyuan Video generates videos from text prompts using Tencent's model.\n    video, generation, hunyuan, tencent, text-to-video\n\n    Use cases:\n    - Create videos from descriptions\n    - Generate animated content\n    - Produce motion graphics\n    - Create promotional clips\n    - Generate concept videos",
      "namespace": "fal.text_to_video",
      "node_type": "fal.text_to_video.HunyuanVideo",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt describing the desired video"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 30,
          "title": "Num Inference Steps",
          "description": "Number of inference steps",
          "min": 1.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 7.0,
          "title": "Guidance Scale",
          "description": "How closely to follow the prompt"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for reproducible generation"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "guidance_scale"
      ]
    },
    {
      "title": "Hunyuan Video V15 Text To Video",
      "description": "Hunyuan Video V1.5 Text-to-Video with improved quality and motion.\n    video, generation, hunyuan, v1.5, text-to-video\n\n    Use cases:\n    - Create high-quality video content\n    - Generate smooth animations\n    - Produce professional videos\n    - Create motion graphics\n    - Generate video effects",
      "namespace": "fal.text_to_video",
      "node_type": "fal.text_to_video.HunyuanVideoV15TextToVideo",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt describing the desired video"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 30,
          "title": "Num Inference Steps",
          "description": "Number of inference steps",
          "min": 1.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 7.0,
          "title": "Guidance Scale",
          "description": "How closely to follow the prompt"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for reproducible generation"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "guidance_scale"
      ]
    },
    {
      "title": "Kandinsky 5 Text To Video",
      "description": "Kandinsky 5 Text-to-Video generates creative videos from text prompts.\n    video, generation, kandinsky, text-to-video, artistic\n\n    Use cases:\n    - Create artistic video content\n    - Generate creative animations\n    - Produce stylized videos\n    - Create video art\n    - Generate experimental content",
      "namespace": "fal.text_to_video",
      "node_type": "fal.text_to_video.Kandinsky5TextToVideo",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt describing the desired video"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "What to avoid in the generated video"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 50,
          "title": "Num Inference Steps",
          "description": "Number of inference steps",
          "min": 1.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 4.0,
          "title": "Guidance Scale",
          "description": "How closely to follow the prompt"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for reproducible generation"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "guidance_scale"
      ]
    },
    {
      "title": "Kling O3 Pro Text To Video",
      "description": "Generate premium cinematic videos with Kling Video O3 Pro featuring higher-end customization and storyboard-first creation.\n    video, generation, kling, o3, pro, text-to-video, premium, storyboard\n\n    Use cases:\n    - Create professional multi-shot sequences\n    - Generate premium story-driven content\n    - Produce high-quality character-consistent videos\n    - Create broadcast-quality narrative videos\n    - Generate cinematic content with advanced controls",
      "namespace": "fal.text_to_video",
      "node_type": "fal.text_to_video.KlingO3ProTextToVideo",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The text prompt describing the desired video"
        },
        {
          "name": "duration",
          "type": {
            "type": "enum",
            "values": [
              "3",
              "4",
              "5",
              "6",
              "7",
              "8",
              "9",
              "10",
              "11",
              "12",
              "13",
              "14",
              "15"
            ],
            "type_name": "nodetool.nodes.fal.text_to_video.Kling3Duration"
          },
          "default": "5",
          "title": "Duration",
          "description": "The duration of the generated video in seconds (3-15)"
        },
        {
          "name": "aspect_ratio",
          "type": {
            "type": "enum",
            "values": [
              "16:9",
              "9:16",
              "1:1"
            ],
            "type_name": "nodetool.nodes.fal.text_to_video.Kling3AspectRatio"
          },
          "default": "16:9",
          "title": "Aspect Ratio",
          "description": "The aspect ratio of the generated video"
        },
        {
          "name": "generate_audio",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Generate Audio",
          "description": "Generate native audio for the video"
        },
        {
          "name": "voice_ids",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "str"
              }
            ]
          },
          "default": [],
          "title": "Voice Ids",
          "description": "Voice IDs for audio. Reference in prompt with <<<voice_1>>> (max 2 voices)"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "duration",
        "aspect_ratio"
      ]
    },
    {
      "title": "Kling O3 Text To Video",
      "description": "Generate cinematic videos with Kling Video O3 Standard supporting storyboard-first creation and character consistency.\n    video, generation, kling, o3, text-to-video, storyboard, cinematic\n\n    Use cases:\n    - Create multi-shot video sequences\n    - Generate story-driven content\n    - Produce character-consistent videos\n    - Create structured narrative videos\n    - Generate cinematic sequences with continuity",
      "namespace": "fal.text_to_video",
      "node_type": "fal.text_to_video.KlingO3TextToVideo",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The text prompt describing the desired video"
        },
        {
          "name": "duration",
          "type": {
            "type": "enum",
            "values": [
              "3",
              "4",
              "5",
              "6",
              "7",
              "8",
              "9",
              "10",
              "11",
              "12",
              "13",
              "14",
              "15"
            ],
            "type_name": "nodetool.nodes.fal.text_to_video.Kling3Duration"
          },
          "default": "5",
          "title": "Duration",
          "description": "The duration of the generated video in seconds (3-15)"
        },
        {
          "name": "aspect_ratio",
          "type": {
            "type": "enum",
            "values": [
              "16:9",
              "9:16",
              "1:1"
            ],
            "type_name": "nodetool.nodes.fal.text_to_video.Kling3AspectRatio"
          },
          "default": "16:9",
          "title": "Aspect Ratio",
          "description": "The aspect ratio of the generated video"
        },
        {
          "name": "generate_audio",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Generate Audio",
          "description": "Generate native audio for the video"
        },
        {
          "name": "voice_ids",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "str"
              }
            ]
          },
          "default": [],
          "title": "Voice Ids",
          "description": "Voice IDs for audio. Reference in prompt with <<<voice_1>>> (max 2 voices)"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "duration",
        "aspect_ratio"
      ]
    },
    {
      "title": "Kling Text To Video V2",
      "description": "Generate videos directly from text prompts using Kling Video V2 Master.\n    video, generation, animation, text-to-video, kling-v2\n\n    Use cases:\n    - Visualize scripts or storyboards\n    - Produce short promotional videos from text\n    - Create animated social media content\n    - Generate concept previews for film ideas\n    - Produce text-driven motion graphics",
      "namespace": "fal.text_to_video",
      "node_type": "fal.text_to_video.KlingTextToVideoV2",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt describing the desired video"
        },
        {
          "name": "duration",
          "type": {
            "type": "enum",
            "values": [
              "5",
              "10"
            ],
            "type_name": "nodetool.nodes.fal.text_to_video.KlingDuration"
          },
          "default": "5",
          "title": "Duration",
          "description": "The duration of the generated video"
        },
        {
          "name": "aspect_ratio",
          "type": {
            "type": "enum",
            "values": [
              "16:9",
              "9:16",
              "4:3",
              "3:4",
              "21:9",
              "9:21"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.AspectRatio"
          },
          "default": "16:9",
          "title": "Aspect Ratio",
          "description": "The aspect ratio of the generated video frame"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "blur, distort, and low quality",
          "title": "Negative Prompt",
          "description": "Negative prompt to be used for the generation"
        },
        {
          "name": "cfg_scale",
          "type": {
            "type": "float"
          },
          "default": 0.5,
          "title": "Cfg Scale",
          "description": "Classifier Free Guidance scale (0.0 to 1.0)",
          "min": 0.0,
          "max": 1.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "duration"
      ]
    },
    {
      "title": "Kling V3 Pro Text To Video",
      "description": "Generate premium quality videos from text prompts using Kling Video 3.0 Pro with enhanced quality and performance.\n    video, generation, kling, v3, pro, text-to-video, premium\n\n    Use cases:\n    - Create high-end promotional content\n    - Generate professional cinematic sequences\n    - Produce premium marketing videos\n    - Create detailed visual narratives\n    - Generate broadcast-quality content",
      "namespace": "fal.text_to_video",
      "node_type": "fal.text_to_video.KlingV3ProTextToVideo",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The text prompt describing the desired video"
        },
        {
          "name": "duration",
          "type": {
            "type": "enum",
            "values": [
              "3",
              "4",
              "5",
              "6",
              "7",
              "8",
              "9",
              "10",
              "11",
              "12",
              "13",
              "14",
              "15"
            ],
            "type_name": "nodetool.nodes.fal.text_to_video.Kling3Duration"
          },
          "default": "5",
          "title": "Duration",
          "description": "The duration of the generated video in seconds (3-15)"
        },
        {
          "name": "aspect_ratio",
          "type": {
            "type": "enum",
            "values": [
              "16:9",
              "9:16",
              "1:1"
            ],
            "type_name": "nodetool.nodes.fal.text_to_video.Kling3AspectRatio"
          },
          "default": "16:9",
          "title": "Aspect Ratio",
          "description": "The aspect ratio of the generated video"
        },
        {
          "name": "generate_audio",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Generate Audio",
          "description": "Generate native audio for the video (supports Chinese/English)"
        },
        {
          "name": "voice_ids",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "str"
              }
            ]
          },
          "default": [],
          "title": "Voice Ids",
          "description": "Voice IDs for audio. Reference in prompt with <<<voice_1>>> (max 2 voices)"
        },
        {
          "name": "shot_type",
          "type": {
            "type": "enum",
            "values": [
              "customize",
              "intelligent"
            ],
            "type_name": "nodetool.nodes.fal.text_to_video.Kling3ShotType"
          },
          "default": "customize",
          "title": "Shot Type",
          "description": "Shot type for multi-shot generation"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "blur, distort, and low quality",
          "title": "Negative Prompt",
          "description": "What to avoid in the generated video"
        },
        {
          "name": "cfg_scale",
          "type": {
            "type": "float"
          },
          "default": 0.5,
          "title": "Cfg Scale",
          "description": "Classifier Free Guidance scale (0.0 to 1.0)",
          "min": 0.0,
          "max": 1.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "duration",
        "aspect_ratio"
      ]
    },
    {
      "title": "Kling V3 Text To Video",
      "description": "Generate high-quality videos from text prompts using Kling Video 3.0 Standard with improved motion and realistic acting.\n    video, generation, kling, v3, text-to-video, cinematic\n\n    Use cases:\n    - Create cinematic video clips from descriptions\n    - Generate marketing and promotional videos\n    - Produce dynamic social media content\n    - Visualize creative concepts and storyboards\n    - Create professional video content",
      "namespace": "fal.text_to_video",
      "node_type": "fal.text_to_video.KlingV3TextToVideo",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The text prompt describing the desired video"
        },
        {
          "name": "duration",
          "type": {
            "type": "enum",
            "values": [
              "3",
              "4",
              "5",
              "6",
              "7",
              "8",
              "9",
              "10",
              "11",
              "12",
              "13",
              "14",
              "15"
            ],
            "type_name": "nodetool.nodes.fal.text_to_video.Kling3Duration"
          },
          "default": "5",
          "title": "Duration",
          "description": "The duration of the generated video in seconds (3-15)"
        },
        {
          "name": "aspect_ratio",
          "type": {
            "type": "enum",
            "values": [
              "16:9",
              "9:16",
              "1:1"
            ],
            "type_name": "nodetool.nodes.fal.text_to_video.Kling3AspectRatio"
          },
          "default": "16:9",
          "title": "Aspect Ratio",
          "description": "The aspect ratio of the generated video"
        },
        {
          "name": "generate_audio",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Generate Audio",
          "description": "Generate native audio for the video (supports Chinese/English)"
        },
        {
          "name": "voice_ids",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "str"
              }
            ]
          },
          "default": [],
          "title": "Voice Ids",
          "description": "Voice IDs for audio. Reference in prompt with <<<voice_1>>> (max 2 voices)"
        },
        {
          "name": "shot_type",
          "type": {
            "type": "enum",
            "values": [
              "customize",
              "intelligent"
            ],
            "type_name": "nodetool.nodes.fal.text_to_video.Kling3ShotType"
          },
          "default": "customize",
          "title": "Shot Type",
          "description": "Shot type for multi-shot generation"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "blur, distort, and low quality",
          "title": "Negative Prompt",
          "description": "What to avoid in the generated video"
        },
        {
          "name": "cfg_scale",
          "type": {
            "type": "float"
          },
          "default": 0.5,
          "title": "Cfg Scale",
          "description": "Classifier Free Guidance scale (0.0 to 1.0)",
          "min": 0.0,
          "max": 1.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "duration",
        "aspect_ratio"
      ]
    },
    {
      "title": "Kling Video V2",
      "description": "Generate videos from images using Kling Video V2 Master. Create smooth and realistic animations from a single frame.\n    video, generation, animation, img2vid, kling-v2\n\n    Use cases:\n    - Convert artwork into animated clips\n    - Produce dynamic marketing visuals\n    - Generate motion graphics from static scenes\n    - Create short cinematic sequences\n    - Enhance presentations with video content",
      "namespace": "fal.text_to_video",
      "node_type": "fal.text_to_video.KlingVideoV2",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The image to transform into a video"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "A description of the desired video motion and style"
        },
        {
          "name": "duration",
          "type": {
            "type": "enum",
            "values": [
              "5",
              "10"
            ],
            "type_name": "nodetool.nodes.fal.text_to_video.KlingDuration"
          },
          "default": "5",
          "title": "Duration",
          "description": "The duration of the generated video"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "blur, distort, and low quality",
          "title": "Negative Prompt",
          "description": "Negative prompt to be used for the generation"
        },
        {
          "name": "cfg_scale",
          "type": {
            "type": "float"
          },
          "default": 0.5,
          "title": "Cfg Scale",
          "description": "Classifier Free Guidance scale (0.0 to 1.0)",
          "min": 0.0,
          "max": 1.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt",
        "duration"
      ]
    },
    {
      "title": "Kling Video V21 Text To Video",
      "description": "Kling Video V2.1 Master Text-to-Video with enhanced quality and motion.\n    video, generation, kling, v2.1, text-to-video\n\n    Use cases:\n    - Create professional video content\n    - Generate high-quality animations\n    - Produce cinematic clips\n    - Create promotional videos\n    - Generate concept previews",
      "namespace": "fal.text_to_video",
      "node_type": "fal.text_to_video.KlingVideoV21TextToVideo",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt describing the desired video"
        },
        {
          "name": "duration",
          "type": {
            "type": "enum",
            "values": [
              "5",
              "10"
            ],
            "type_name": "nodetool.nodes.fal.text_to_video.KlingDuration"
          },
          "default": "5",
          "title": "Duration",
          "description": "The duration of the generated video"
        },
        {
          "name": "aspect_ratio",
          "type": {
            "type": "enum",
            "values": [
              "16:9",
              "9:16",
              "4:3",
              "3:4",
              "21:9",
              "9:21"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.AspectRatio"
          },
          "default": "16:9",
          "title": "Aspect Ratio",
          "description": "The aspect ratio of the generated video"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "duration"
      ]
    },
    {
      "title": "LTX2 Text To Video",
      "description": "LTX 2 Text-to-Video generates videos from text with the LTX model.\n    video, generation, ltx, text-to-video\n\n    Use cases:\n    - Create videos from descriptions\n    - Generate animated content\n    - Produce motion graphics\n    - Create video clips\n    - Generate promotional content",
      "namespace": "fal.text_to_video",
      "node_type": "fal.text_to_video.LTX2TextToVideo",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt describing the desired video"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "What to avoid in the generated video"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 30,
          "title": "Num Inference Steps",
          "description": "Number of inference steps",
          "min": 1.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 3.0,
          "title": "Guidance Scale",
          "description": "How closely to follow the prompt"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for reproducible generation"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "guidance_scale"
      ]
    },
    {
      "title": "Luma Ray 2 Flash Text To Video",
      "description": "Luma Ray 2 Flash Text-to-Video is a fast version for quick video generation.\n    video, generation, luma, ray2, flash, text-to-video, fast\n\n    Use cases:\n    - Quick video prototyping\n    - Rapid content creation\n    - Fast video iterations\n    - Real-time video generation\n    - Quick concept tests",
      "namespace": "fal.text_to_video",
      "node_type": "fal.text_to_video.LumaRay2FlashTextToVideo",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt describing the desired video"
        },
        {
          "name": "aspect_ratio",
          "type": {
            "type": "enum",
            "values": [
              "16:9",
              "9:16",
              "4:3",
              "3:4",
              "21:9",
              "9:21"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.AspectRatio"
          },
          "default": "16:9",
          "title": "Aspect Ratio",
          "description": "The aspect ratio of the generated video"
        },
        {
          "name": "resolution",
          "type": {
            "type": "enum",
            "values": [
              "540p",
              "1080p"
            ],
            "type_name": "nodetool.nodes.fal.text_to_video.LumaRay2Resolution"
          },
          "default": "540p",
          "title": "Resolution",
          "description": "The resolution of the generated video"
        },
        {
          "name": "duration",
          "type": {
            "type": "enum",
            "values": [
              "5",
              "10"
            ],
            "type_name": "nodetool.nodes.fal.text_to_video.LumaRay2Duration"
          },
          "default": "5",
          "title": "Duration",
          "description": "The duration of the generated video"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for reproducible generation"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "aspect_ratio",
        "duration",
        "resolution"
      ]
    },
    {
      "title": "Luma Ray 2 Text To Video",
      "description": "Luma Ray 2 Text-to-Video generates high-quality videos from text prompts.\n    video, generation, luma, ray2, text-to-video, txt2vid\n\n    Use cases:\n    - Create videos from descriptions\n    - Generate cinematic content\n    - Produce creative videos\n    - Create marketing clips\n    - Generate concept videos",
      "namespace": "fal.text_to_video",
      "node_type": "fal.text_to_video.LumaRay2TextToVideo",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt describing the desired video"
        },
        {
          "name": "aspect_ratio",
          "type": {
            "type": "enum",
            "values": [
              "16:9",
              "9:16",
              "4:3",
              "3:4",
              "21:9",
              "9:21"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.AspectRatio"
          },
          "default": "16:9",
          "title": "Aspect Ratio",
          "description": "The aspect ratio of the generated video"
        },
        {
          "name": "loop",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Loop",
          "description": "Whether the video should loop"
        },
        {
          "name": "resolution",
          "type": {
            "type": "enum",
            "values": [
              "540p",
              "1080p"
            ],
            "type_name": "nodetool.nodes.fal.text_to_video.LumaRay2Resolution"
          },
          "default": "540p",
          "title": "Resolution",
          "description": "The resolution of the generated video"
        },
        {
          "name": "duration",
          "type": {
            "type": "enum",
            "values": [
              "5",
              "10"
            ],
            "type_name": "nodetool.nodes.fal.text_to_video.LumaRay2Duration"
          },
          "default": "5",
          "title": "Duration",
          "description": "The duration of the generated video"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for reproducible generation"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "aspect_ratio",
        "duration",
        "resolution"
      ]
    },
    {
      "title": "Mini Max Hailuo 23 Text To Video",
      "description": "MiniMax Hailuo 2.3 Standard Text-to-Video with improved quality.\n    video, generation, minimax, hailuo, 2.3, text-to-video\n\n    Use cases:\n    - Create videos from text\n    - Generate smooth animations\n    - Produce video content\n    - Create motion graphics\n    - Generate promotional clips",
      "namespace": "fal.text_to_video",
      "node_type": "fal.text_to_video.MiniMaxHailuo23TextToVideo",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt describing the desired video"
        },
        {
          "name": "prompt_optimizer",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Prompt Optimizer",
          "description": "Whether to use the prompt optimizer"
        },
        {
          "name": "duration",
          "type": {
            "type": "enum",
            "values": [
              "6",
              "10"
            ],
            "type_name": "nodetool.nodes.fal.text_to_video.MiniMaxDuration"
          },
          "default": "6",
          "title": "Duration",
          "description": "The duration of the video in seconds"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for reproducible generation"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "duration"
      ]
    },
    {
      "title": "Mochi V1",
      "description": "Mochi V1 generates creative videos from text prompts with unique style.\n    video, generation, mochi, text-to-video, creative\n\n    Use cases:\n    - Create creative video content\n    - Generate artistic animations\n    - Produce stylized videos\n    - Create experimental clips\n    - Generate unique video effects",
      "namespace": "fal.text_to_video",
      "node_type": "fal.text_to_video.MochiV1",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt describing the desired video"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "What to avoid in the generated video"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 50,
          "title": "Num Inference Steps",
          "description": "Number of inference steps",
          "min": 1.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 4.5,
          "title": "Guidance Scale",
          "description": "How closely to follow the prompt"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for reproducible generation"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "guidance_scale"
      ]
    },
    {
      "title": "Pika V21 Text To Video",
      "description": "Pika V2.1 Text-to-Video generates videos from text prompts.\n    video, generation, pika, v2.1, text-to-video\n\n    Use cases:\n    - Create video content from text\n    - Generate animated clips\n    - Produce motion graphics\n    - Create video effects\n    - Generate promotional content",
      "namespace": "fal.text_to_video",
      "node_type": "fal.text_to_video.PikaV21TextToVideo",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt describing the desired video"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for reproducible generation"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt"
      ]
    },
    {
      "title": "Pika V22 Text To Video",
      "description": "Pika V2.2 Text-to-Video generates creative videos from text prompts.\n    video, generation, pika, v2.2, text-to-video, creative\n\n    Use cases:\n    - Create creative video content\n    - Generate artistic animations\n    - Produce stylized videos\n    - Create unique video clips\n    - Generate experimental content",
      "namespace": "fal.text_to_video",
      "node_type": "fal.text_to_video.PikaV22TextToVideo",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt describing the desired video"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "What to avoid in the generated video"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for reproducible generation"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt"
      ]
    },
    {
      "title": "Pixverse Effects",
      "description": "Apply text-driven effects to a video with Pixverse 4.5.\n    video, effects, pixverse, text-guided\n\n    Use cases:\n    - Stylize existing footage\n    - Add visual effects via text\n    - Enhance marketing videos\n    - Create experimental clips\n    - Transform user content",
      "namespace": "fal.text_to_video",
      "node_type": "fal.text_to_video.PixverseEffects",
      "properties": [
        {
          "name": "video",
          "type": {
            "type": "video"
          },
          "default": {
            "type": "video",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null,
            "duration": null,
            "format": null
          },
          "title": "Video",
          "description": "The source video"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "Text describing the effect"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Optional seed for deterministic output"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "video",
        "prompt"
      ]
    },
    {
      "title": "Pixverse Image To Video",
      "description": "Animate an image into a video using Pixverse 4.5.\n    video, generation, pixverse, image-to-video\n\n    Use cases:\n    - Bring photos to life\n    - Create moving artwork\n    - Generate short clips from images\n    - Produce social media animations\n    - Experiment with visual storytelling",
      "namespace": "fal.text_to_video",
      "node_type": "fal.text_to_video.PixverseImageToVideo",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The source image"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "Optional style or motion prompt"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Optional seed for deterministic output"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "Pixverse Text To Video",
      "description": "Generate videos from text prompts with Pixverse 4.5 API.\n    video, generation, pixverse, text-to-video\n\n    Use cases:\n    - Create animated scenes from text\n    - Generate marketing clips\n    - Produce dynamic social posts\n    - Prototype video ideas\n    - Explore creative storytelling",
      "namespace": "fal.text_to_video",
      "node_type": "fal.text_to_video.PixverseTextToVideo",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt describing the video"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Optional seed for deterministic output"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt"
      ]
    },
    {
      "title": "Pixverse Text To Video Fast",
      "description": "Generate videos quickly from text prompts with Pixverse 4.5 Fast.\n    video, generation, pixverse, text-to-video, fast\n\n    Use cases:\n    - Rapid video prototyping\n    - Generate quick social posts\n    - Produce short marketing clips\n    - Test creative ideas fast\n    - Create video drafts",
      "namespace": "fal.text_to_video",
      "node_type": "fal.text_to_video.PixverseTextToVideoFast",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt describing the video"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Optional seed for deterministic output"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt"
      ]
    },
    {
      "title": "Pixverse Transition",
      "description": "Apply Pixverse transitions between images.\n    video, generation, transition, pixverse\n\n    Use cases:\n    - Blend between two images\n    - Create animated transitions\n    - Generate morphing effects\n    - Produce smooth scene changes\n    - Experiment with visual flows",
      "namespace": "fal.text_to_video",
      "node_type": "fal.text_to_video.PixverseTransition",
      "properties": [
        {
          "name": "start_image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Start Image",
          "description": "The starting image"
        },
        {
          "name": "end_image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "End Image",
          "description": "The ending image"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Optional seed for deterministic output"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "start_image",
        "end_image"
      ]
    },
    {
      "title": "Pixverse V56 Text To Video",
      "description": "Generate high-quality videos from text prompts with Pixverse v5.6.\n    video, generation, pixverse, v5.6, text-to-video, creative\n\n    Use cases:\n    - Create professional animated scenes from descriptions\n    - Generate marketing and promotional videos\n    - Produce dynamic social media content\n    - Prototype video concepts with various styles\n    - Create stylized video content with anime or cyberpunk themes",
      "namespace": "fal.text_to_video",
      "node_type": "fal.text_to_video.PixverseV56TextToVideo",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The text prompt describing the desired video"
        },
        {
          "name": "aspect_ratio",
          "type": {
            "type": "enum",
            "values": [
              "16:9",
              "9:16",
              "4:3",
              "3:4",
              "21:9",
              "9:21"
            ],
            "type_name": "nodetool.nodes.fal.text_to_video.PixverseV56AspectRatio"
          },
          "default": "16:9",
          "title": "Aspect Ratio",
          "description": "The aspect ratio of the generated video"
        },
        {
          "name": "resolution",
          "type": {
            "type": "enum",
            "values": [
              "360p",
              "540p",
              "720p",
              "1080p"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.PixverseV56Resolution"
          },
          "default": "720p",
          "title": "Resolution",
          "description": "The resolution quality of the output video"
        },
        {
          "name": "duration",
          "type": {
            "type": "enum",
            "values": [
              "5",
              "8",
              "10"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.PixverseV56Duration"
          },
          "default": "5",
          "title": "Duration",
          "description": "The duration of the generated video in seconds"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "What to avoid in the generated video"
        },
        {
          "name": "style",
          "type": {
            "type": "enum",
            "optional": true,
            "values": [
              "anime",
              "3d_animation",
              "clay",
              "comic",
              "cyberpunk"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.PixverseV56Style"
          },
          "default": null,
          "title": "Style",
          "description": "Optional visual style for the video"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Optional seed for reproducible generation"
        },
        {
          "name": "generate_audio_switch",
          "type": {
            "type": "bool",
            "optional": true
          },
          "default": null,
          "title": "Generate Audio Switch",
          "description": "Whether to generate audio for the video"
        },
        {
          "name": "thinking_type",
          "type": {
            "type": "enum",
            "optional": true,
            "values": [
              "enabled",
              "disabled",
              "auto"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.PixverseV56ThinkingType"
          },
          "default": null,
          "title": "Thinking Type",
          "description": "Thinking mode for video generation"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "resolution",
        "duration"
      ]
    },
    {
      "title": "Pixverse V56 Transition",
      "description": "Create smooth transitions between images with Pixverse v5.6.\n    video, generation, transition, pixverse, v5.6, morphing\n\n    Use cases:\n    - Create seamless transitions between two images\n    - Generate morphing effects for presentations\n    - Produce smooth scene changes for videos\n    - Create animated visual flows\n    - Generate creative blending effects",
      "namespace": "fal.text_to_video",
      "node_type": "fal.text_to_video.PixverseV56Transition",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "Text prompt describing the transition style"
        },
        {
          "name": "first_image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "First Image",
          "description": "The starting image for the transition"
        },
        {
          "name": "end_image",
          "type": {
            "type": "image",
            "optional": true
          },
          "default": null,
          "title": "End Image",
          "description": "Optional ending image for the transition"
        },
        {
          "name": "aspect_ratio",
          "type": {
            "type": "enum",
            "values": [
              "16:9",
              "9:16",
              "4:3",
              "3:4",
              "21:9",
              "9:21"
            ],
            "type_name": "nodetool.nodes.fal.text_to_video.PixverseV56AspectRatio"
          },
          "default": "16:9",
          "title": "Aspect Ratio",
          "description": "The aspect ratio of the generated video"
        },
        {
          "name": "resolution",
          "type": {
            "type": "enum",
            "values": [
              "360p",
              "540p",
              "720p",
              "1080p"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.PixverseV56Resolution"
          },
          "default": "720p",
          "title": "Resolution",
          "description": "The resolution quality of the output video"
        },
        {
          "name": "duration",
          "type": {
            "type": "int"
          },
          "default": 5,
          "title": "Duration",
          "description": "Duration in seconds (5 or 8)",
          "min": 5.0,
          "max": 8.0
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "What to avoid in the generated transition"
        },
        {
          "name": "style",
          "type": {
            "type": "enum",
            "optional": true,
            "values": [
              "anime",
              "3d_animation",
              "clay",
              "comic",
              "cyberpunk"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.PixverseV56Style"
          },
          "default": null,
          "title": "Style",
          "description": "Optional visual style for the transition"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Optional seed for reproducible generation"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "first_image",
        "resolution"
      ]
    },
    {
      "title": "Sora 2 Text To Video",
      "description": "OpenAI Sora 2 Text-to-Video generates high-quality videos from text.\n    video, generation, openai, sora, sora2, text-to-video\n\n    Use cases:\n    - Create cinematic videos from text\n    - Generate realistic motion\n    - Produce professional video content\n    - Create video narratives\n    - Generate concept videos",
      "namespace": "fal.text_to_video",
      "node_type": "fal.text_to_video.Sora2TextToVideo",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt describing the desired video"
        },
        {
          "name": "aspect_ratio",
          "type": {
            "type": "enum",
            "values": [
              "16:9",
              "9:16",
              "4:3",
              "3:4",
              "21:9",
              "9:21"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.AspectRatio"
          },
          "default": "16:9",
          "title": "Aspect Ratio",
          "description": "The aspect ratio of the generated video"
        },
        {
          "name": "duration",
          "type": {
            "type": "enum",
            "values": [
              4,
              8,
              12
            ],
            "type_name": "nodetool.nodes.fal.text_to_video.Sora2Duration"
          },
          "default": 4,
          "title": "Duration",
          "description": "Duration of the video in seconds"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for reproducible generation"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "duration"
      ]
    },
    {
      "title": "Veo 3",
      "description": "Generate high-quality videos from text prompts with Google's Veo 3 model.\n    video, generation, text-to-video, prompt, audio\n\n    Use cases:\n    - Produce short cinematic clips from descriptions\n    - Create social media videos\n    - Generate visual storyboards\n    - Experiment with video concepts\n    - Produce marketing content",
      "namespace": "fal.text_to_video",
      "node_type": "fal.text_to_video.Veo3",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The text prompt describing the video you want to generate"
        },
        {
          "name": "aspect_ratio",
          "type": {
            "type": "enum",
            "values": [
              "16:9",
              "9:16"
            ],
            "type_name": "nodetool.nodes.fal.text_to_video.Veo3AspectRatio"
          },
          "default": "16:9",
          "title": "Aspect Ratio",
          "description": "The aspect ratio of the generated video."
        },
        {
          "name": "duration",
          "type": {
            "type": "enum",
            "values": [
              "4s",
              "6s",
              "8s"
            ],
            "type_name": "nodetool.nodes.fal.text_to_video.Veo3Duration"
          },
          "default": "8s",
          "title": "Duration",
          "description": "The duration of the generated video in seconds"
        },
        {
          "name": "resolution",
          "type": {
            "type": "enum",
            "values": [
              "720p",
              "1080p"
            ],
            "type_name": "nodetool.nodes.fal.text_to_video.Veo3Resolution"
          },
          "default": "720p",
          "title": "Resolution",
          "description": "The resolution of the generated video"
        },
        {
          "name": "generate_audio",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Generate Audio",
          "description": "Whether to generate audio for the video. If false, %33 less credits will be used."
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "A seed to use for the video generation"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "A negative prompt to guide the video generation"
        },
        {
          "name": "auto_fix",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Auto Fix",
          "description": "Whether to automatically attempt to fix prompts"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "aspect_ratio",
        "duration"
      ]
    },
    {
      "title": "Wan Flf 2V",
      "description": "Generate video loops from text prompts using WAN-FLF2V.\n    video, generation, wan, text-to-video\n\n    Use cases:\n    - Generate looping videos from descriptions\n    - Produce motion graphics from prompts\n    - Create abstract video ideas\n    - Develop creative transitions\n    - Experiment with AI-generated motion",
      "namespace": "fal.text_to_video",
      "node_type": "fal.text_to_video.WanFlf2V",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt describing the desired video"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Randomization seed for reproducible results"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt"
      ]
    },
    {
      "title": "Wan Pro Image To Video",
      "description": "Convert an image into a short video clip using Wan Pro.\n    video, generation, wan, professional, image-to-video\n\n    Use cases:\n    - Create dynamic videos from product photos\n    - Generate animations from static artwork\n    - Produce short promotional clips\n    - Transform images into motion graphics\n    - Experiment with visual storytelling",
      "namespace": "fal.text_to_video",
      "node_type": "fal.text_to_video.WanProImageToVideo",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The input image to animate"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "Optional prompt describing the desired motion"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Randomization seed for reproducible results"
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "Whether to enable the safety checker"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "Wan Pro Text To Video",
      "description": "Generate a short video clip from a text prompt using Wan Pro.\n    video, generation, wan, professional, text-to-video\n\n    Use cases:\n    - Create animated scenes from descriptions\n    - Generate short creative videos\n    - Produce promotional content\n    - Visualize storyboards\n    - Experiment with narrative ideas",
      "namespace": "fal.text_to_video",
      "node_type": "fal.text_to_video.WanProTextToVideo",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt describing the desired video"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Randomization seed for reproducible results"
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "Whether to enable the safety checker"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt"
      ]
    },
    {
      "title": "Wan T2 V",
      "description": "Generate videos from text using the WAN-T2V model.\n    video, generation, wan, text-to-video\n\n    Use cases:\n    - Produce creative videos from prompts\n    - Experiment with motion concepts\n    - Generate quick animated drafts\n    - Visualize ideas for stories\n    - Create short social media clips",
      "namespace": "fal.text_to_video",
      "node_type": "fal.text_to_video.WanT2V",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt describing the desired video"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Randomization seed for reproducible results"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt"
      ]
    },
    {
      "title": "Wan V2 1 13B Text To Video",
      "description": "Create videos from text using WAN v2.1 1.3B, an open-source text-to-video model.\n    video, generation, wan, text-to-video\n\n    Use cases:\n    - Produce short clips from prompts\n    - Generate concept videos\n    - Create quick visualizations\n    - Iterate on storytelling ideas\n    - Experiment with AI video synthesis",
      "namespace": "fal.text_to_video",
      "node_type": "fal.text_to_video.WanV2_1_13BTextToVideo",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt describing the desired video"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Randomization seed for reproducible results"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt"
      ]
    },
    {
      "title": "Maya",
      "description": "Maya generates high-quality natural speech from text with advanced voice synthesis capabilities.\n    audio, tts, maya, high-quality, text-to-speech\n\n    Use cases:\n    - Generate high-quality speech from text\n    - Create professional voice-overs\n    - Produce premium audio narration\n    - Generate natural-sounding speech\n    - Create professional audio content",
      "namespace": "fal.text_to_speech",
      "node_type": "fal.text_to_speech.Maya",
      "properties": [
        {
          "name": "repetition_penalty",
          "type": {
            "type": "float"
          },
          "default": 1.1,
          "title": "Repetition Penalty",
          "description": "Penalty for repeating tokens. Higher values reduce repetition artifacts."
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "Description of the voice/character. Includes attributes like age, accent, pitch, timbre, pacing, tone, and intensity. See examples for format."
        },
        {
          "name": "top_p",
          "type": {
            "type": "float"
          },
          "default": 0.9,
          "title": "Top P",
          "description": "Nucleus sampling parameter. Controls diversity of token selection."
        },
        {
          "name": "text",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Text",
          "description": "The text to synthesize into speech. You can embed emotion tags anywhere in the text using the format <emotion_name>. Available emotions: laugh, laugh_harder, sigh, chuckle, gasp, angry, excited, whisper, cry, scream, sing, snort, exhale, gulp, giggle, sarcastic, curious. Example: 'Hello world! <excited> This is amazing!' or 'I can't believe this <sigh> happened again.'"
        },
        {
          "name": "output_format",
          "type": {
            "type": "enum",
            "values": [
              "wav",
              "mp3"
            ],
            "type_name": "nodetool.nodes.fal.text_to_speech.OutputFormat"
          },
          "default": "wav",
          "title": "Output Format",
          "description": "Output audio format for the generated speech"
        },
        {
          "name": "max_tokens",
          "type": {
            "type": "int"
          },
          "default": 2000,
          "title": "Max Tokens",
          "description": "Maximum number of SNAC tokens to generate (7 tokens per frame). Controls maximum audio length."
        },
        {
          "name": "temperature",
          "type": {
            "type": "float"
          },
          "default": 0.4,
          "title": "Temperature",
          "description": "Sampling temperature. Lower values (0.2-0.5) produce more stable/consistent audio. Higher values add variation."
        },
        {
          "name": "sample_rate",
          "type": {
            "type": "enum",
            "values": [
              "48 kHz",
              "24 kHz"
            ],
            "type_name": "nodetool.nodes.fal.text_to_speech.SampleRate"
          },
          "default": "48 kHz",
          "title": "Sample Rate",
          "description": "Output audio sample rate. 48 kHz provides higher quality audio, 24 kHz is faster."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "audio"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "text"
      ]
    },
    {
      "title": "Minimax Speech 26 Hd",
      "description": "Minimax Speech 2.6 HD generates high-definition speech from text with superior audio quality.\n    audio, tts, minimax, 2.6, hd, high-quality\n\n    Use cases:\n    - Generate HD quality speech from text\n    - Create premium voice-overs\n    - Produce high-fidelity audio narration\n    - Generate superior audio quality speech\n    - Create broadcast-quality audio",
      "namespace": "fal.text_to_speech",
      "node_type": "fal.text_to_speech.MinimaxSpeech26Hd",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "Text to convert to speech. Paragraph breaks should be marked with newline characters. **NOTE**: You can customize speech pauses by adding markers in the form `<#x#>`, where `x` is the pause duration in seconds. Valid range: `[0.01, 99.99]`, up to two decimal places. Pause markers must be placed between speakable text segments and cannot be used consecutively."
        },
        {
          "name": "language_boost",
          "type": {
            "type": "enum",
            "optional": true,
            "values": [
              "Chinese",
              "Chinese,Yue",
              "English",
              "Arabic",
              "Russian",
              "Spanish",
              "French",
              "Portuguese",
              "German",
              "Turkish",
              "Dutch",
              "Ukrainian",
              "Vietnamese",
              "Indonesian",
              "Japanese",
              "Italian",
              "Korean",
              "Thai",
              "Polish",
              "Romanian",
              "Greek",
              "Czech",
              "Finnish",
              "Hindi",
              "Bulgarian",
              "Danish",
              "Hebrew",
              "Malay",
              "Slovak",
              "Swedish",
              "Croatian",
              "Hungarian",
              "Norwegian",
              "Slovenian",
              "Catalan",
              "Nynorsk",
              "Afrikaans",
              "auto"
            ],
            "type_name": "nodetool.nodes.fal.text_to_speech.LanguageBoost"
          },
          "default": null,
          "title": "Language Boost",
          "description": "Enhance recognition of specified languages and dialects"
        },
        {
          "name": "output_format",
          "type": {
            "type": "enum",
            "values": [
              "url",
              "hex"
            ],
            "type_name": "nodetool.nodes.fal.text_to_speech.MinimaxSpeech26HdOutputFormat"
          },
          "default": "hex",
          "title": "Output Format",
          "description": "Format of the output content (non-streaming only)"
        },
        {
          "name": "pronunciation_dict",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Pronunciation Dict",
          "description": "Custom pronunciation dictionary for text replacement"
        },
        {
          "name": "voice_setting",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Voice Setting",
          "description": "Voice configuration settings"
        },
        {
          "name": "normalization_setting",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Normalization Setting",
          "description": "Loudness normalization settings for the audio"
        },
        {
          "name": "audio_setting",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Audio Setting",
          "description": "Audio configuration settings"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "audio"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "text"
      ]
    },
    {
      "title": "Minimax Speech 26 Turbo",
      "description": "Minimax Speech 2.6 Turbo generates speech from text with optimized speed and good quality.\n    audio, tts, minimax, 2.6, turbo, fast\n\n    Use cases:\n    - Generate speech quickly from text\n    - Create fast voice-overs\n    - Produce rapid audio narration\n    - Generate speech with turbo speed\n    - Create efficient audio content",
      "namespace": "fal.text_to_speech",
      "node_type": "fal.text_to_speech.MinimaxSpeech26Turbo",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "Text to convert to speech. Paragraph breaks should be marked with newline characters. **NOTE**: You can customize speech pauses by adding markers in the form `<#x#>`, where `x` is the pause duration in seconds. Valid range: `[0.01, 99.99]`, up to two decimal places. Pause markers must be placed between speakable text segments and cannot be used consecutively."
        },
        {
          "name": "language_boost",
          "type": {
            "type": "enum",
            "optional": true,
            "values": [
              "Chinese",
              "Chinese,Yue",
              "English",
              "Arabic",
              "Russian",
              "Spanish",
              "French",
              "Portuguese",
              "German",
              "Turkish",
              "Dutch",
              "Ukrainian",
              "Vietnamese",
              "Indonesian",
              "Japanese",
              "Italian",
              "Korean",
              "Thai",
              "Polish",
              "Romanian",
              "Greek",
              "Czech",
              "Finnish",
              "Hindi",
              "Bulgarian",
              "Danish",
              "Hebrew",
              "Malay",
              "Slovak",
              "Swedish",
              "Croatian",
              "Hungarian",
              "Norwegian",
              "Slovenian",
              "Catalan",
              "Nynorsk",
              "Afrikaans",
              "auto"
            ],
            "type_name": "nodetool.nodes.fal.text_to_speech.LanguageBoost"
          },
          "default": null,
          "title": "Language Boost",
          "description": "Enhance recognition of specified languages and dialects"
        },
        {
          "name": "output_format",
          "type": {
            "type": "enum",
            "values": [
              "url",
              "hex"
            ],
            "type_name": "nodetool.nodes.fal.text_to_speech.MinimaxSpeech26TurboOutputFormat"
          },
          "default": "hex",
          "title": "Output Format",
          "description": "Format of the output content (non-streaming only)"
        },
        {
          "name": "pronunciation_dict",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Pronunciation Dict",
          "description": "Custom pronunciation dictionary for text replacement"
        },
        {
          "name": "voice_setting",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Voice Setting",
          "description": "Voice configuration settings"
        },
        {
          "name": "normalization_setting",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Normalization Setting",
          "description": "Loudness normalization settings for the audio"
        },
        {
          "name": "audio_setting",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Audio Setting",
          "description": "Audio configuration settings"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "audio"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "text"
      ]
    },
    {
      "title": "Qwen 3 Tts Text To Speech 06B",
      "description": "Qwen-3 TTS 0.6B generates speech from text efficiently using the compact 600-million parameter model.\n    audio, tts, qwen, 0.6b, efficient, text-to-speech\n\n    Use cases:\n    - Generate speech efficiently from text\n    - Create fast voice-overs\n    - Produce quick audio narration\n    - Generate spoken content with low latency\n    - Create efficient text-to-speech",
      "namespace": "fal.text_to_speech",
      "node_type": "fal.text_to_speech.Qwen3TtsTextToSpeech06B",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "Optional prompt to guide the style of the generated speech. This prompt will be ignored if a speaker embedding is provided."
        },
        {
          "name": "speaker_voice_embedding_file_url",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Speaker Voice Embedding File Url",
          "description": "URL to a speaker embedding file in safetensors format, from `fal-ai/qwen-3-tts/clone-voice/0.6b` endpoint. If provided, the TTS model will use the cloned voice for synthesis instead of the predefined voices."
        },
        {
          "name": "top_p",
          "type": {
            "type": "float"
          },
          "default": 1,
          "title": "Top P",
          "description": "Top-p sampling parameter."
        },
        {
          "name": "repetition_penalty",
          "type": {
            "type": "float"
          },
          "default": 1.05,
          "title": "Repetition Penalty",
          "description": "Penalty to reduce repeated tokens/codes."
        },
        {
          "name": "subtalker_temperature",
          "type": {
            "type": "float"
          },
          "default": 0.9,
          "title": "Subtalker Temperature",
          "description": "Temperature for sub-talker sampling."
        },
        {
          "name": "top_k",
          "type": {
            "type": "int"
          },
          "default": 50,
          "title": "Top K",
          "description": "Top-k sampling parameter."
        },
        {
          "name": "voice",
          "type": {
            "type": "enum",
            "optional": true,
            "values": [
              "Vivian",
              "Serena",
              "Uncle_Fu",
              "Dylan",
              "Eric",
              "Ryan",
              "Aiden",
              "Ono_Anna",
              "Sohee"
            ],
            "type_name": "nodetool.nodes.fal.text_to_speech.Voice"
          },
          "default": null,
          "title": "Voice",
          "description": "The voice to be used for speech synthesis, will be ignored if a speaker embedding is provided. Check out the **[documentation](https://github.com/QwenLM/Qwen3-TTS/tree/main?tab=readme-ov-file#custom-voice-generate)** for each voice's details and which language they primarily support."
        },
        {
          "name": "reference_text",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Reference Text",
          "description": "Optional reference text that was used when creating the speaker embedding. Providing this can improve synthesis quality when using a cloned voice."
        },
        {
          "name": "temperature",
          "type": {
            "type": "float"
          },
          "default": 0.9,
          "title": "Temperature",
          "description": "Sampling temperature; higher => more random."
        },
        {
          "name": "language",
          "type": {
            "type": "enum",
            "values": [
              "Auto",
              "English",
              "Chinese",
              "Spanish",
              "French",
              "German",
              "Italian",
              "Japanese",
              "Korean",
              "Portuguese",
              "Russian"
            ],
            "type_name": "nodetool.nodes.fal.text_to_speech.Language"
          },
          "default": "Auto",
          "title": "Language",
          "description": "The language of the voice."
        },
        {
          "name": "subtalker_top_k",
          "type": {
            "type": "int"
          },
          "default": 50,
          "title": "Subtalker Top K",
          "description": "Top-k for sub-talker sampling."
        },
        {
          "name": "text",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Text",
          "description": "The text to be converted to speech."
        },
        {
          "name": "max_new_tokens",
          "type": {
            "type": "int"
          },
          "default": 200,
          "title": "Max New Tokens",
          "description": "Maximum number of new codec tokens to generate."
        },
        {
          "name": "subtalker_dosample",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Subtalker Dosample",
          "description": "Sampling switch for the sub-talker."
        },
        {
          "name": "subtalker_top_p",
          "type": {
            "type": "float"
          },
          "default": 1,
          "title": "Subtalker Top P",
          "description": "Top-p for sub-talker sampling."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "audio"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "text"
      ]
    },
    {
      "title": "Qwen 3 Tts Text To Speech 17B",
      "description": "Qwen-3 TTS 1.7B generates natural-sounding speech from text using the large 1.7-billion parameter model.\n    audio, tts, qwen, 1.7b, text-to-speech, speech-synthesis\n\n    Use cases:\n    - Generate natural-sounding speech from text\n    - Create voice-overs for videos\n    - Produce audiobook narration\n    - Generate spoken content for applications\n    - Create text-to-speech for accessibility",
      "namespace": "fal.text_to_speech",
      "node_type": "fal.text_to_speech.Qwen3TtsTextToSpeech17B",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "Optional prompt to guide the style of the generated speech. This prompt will be ignored if a speaker embedding is provided."
        },
        {
          "name": "speaker_voice_embedding_file_url",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Speaker Voice Embedding File Url",
          "description": "URL to a speaker embedding file in safetensors format, from `fal-ai/qwen-3-tts/clone-voice` endpoint. If provided, the TTS model will use the cloned voice for synthesis instead of the predefined voices."
        },
        {
          "name": "top_p",
          "type": {
            "type": "float"
          },
          "default": 1,
          "title": "Top P",
          "description": "Top-p sampling parameter."
        },
        {
          "name": "repetition_penalty",
          "type": {
            "type": "float"
          },
          "default": 1.05,
          "title": "Repetition Penalty",
          "description": "Penalty to reduce repeated tokens/codes."
        },
        {
          "name": "subtalker_temperature",
          "type": {
            "type": "float"
          },
          "default": 0.9,
          "title": "Subtalker Temperature",
          "description": "Temperature for sub-talker sampling."
        },
        {
          "name": "top_k",
          "type": {
            "type": "int"
          },
          "default": 50,
          "title": "Top K",
          "description": "Top-k sampling parameter."
        },
        {
          "name": "voice",
          "type": {
            "type": "enum",
            "optional": true,
            "values": [
              "Vivian",
              "Serena",
              "Uncle_Fu",
              "Dylan",
              "Eric",
              "Ryan",
              "Aiden",
              "Ono_Anna",
              "Sohee"
            ],
            "type_name": "nodetool.nodes.fal.text_to_speech.Voice"
          },
          "default": null,
          "title": "Voice",
          "description": "The voice to be used for speech synthesis, will be ignored if a speaker embedding is provided. Check out the **[documentation](https://github.com/QwenLM/Qwen3-TTS/tree/main?tab=readme-ov-file#custom-voice-generate)** for each voice's details and which language they primarily support."
        },
        {
          "name": "reference_text",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Reference Text",
          "description": "Optional reference text that was used when creating the speaker embedding. Providing this can improve synthesis quality when using a cloned voice."
        },
        {
          "name": "temperature",
          "type": {
            "type": "float"
          },
          "default": 0.9,
          "title": "Temperature",
          "description": "Sampling temperature; higher => more random."
        },
        {
          "name": "language",
          "type": {
            "type": "enum",
            "values": [
              "Auto",
              "English",
              "Chinese",
              "Spanish",
              "French",
              "German",
              "Italian",
              "Japanese",
              "Korean",
              "Portuguese",
              "Russian"
            ],
            "type_name": "nodetool.nodes.fal.text_to_speech.Language"
          },
          "default": "Auto",
          "title": "Language",
          "description": "The language of the voice."
        },
        {
          "name": "subtalker_top_k",
          "type": {
            "type": "int"
          },
          "default": 50,
          "title": "Subtalker Top K",
          "description": "Top-k for sub-talker sampling."
        },
        {
          "name": "text",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Text",
          "description": "The text to be converted to speech."
        },
        {
          "name": "max_new_tokens",
          "type": {
            "type": "int"
          },
          "default": 200,
          "title": "Max New Tokens",
          "description": "Maximum number of new codec tokens to generate."
        },
        {
          "name": "subtalker_dosample",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Subtalker Dosample",
          "description": "Sampling switch for the sub-talker."
        },
        {
          "name": "subtalker_top_p",
          "type": {
            "type": "float"
          },
          "default": 1,
          "title": "Subtalker Top P",
          "description": "Top-p for sub-talker sampling."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "audio"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "text"
      ]
    },
    {
      "title": "Qwen 3 Tts Voice Design 17B",
      "description": "Qwen-3 TTS Voice Design 1.7B creates custom voice characteristics for personalized speech synthesis.\n    audio, tts, qwen, voice-design, custom, 1.7b\n\n    Use cases:\n    - Design custom voice characteristics\n    - Create personalized speech synthesis\n    - Generate unique voice styles\n    - Produce custom voice-overs\n    - Create tailored speech synthesis",
      "namespace": "fal.text_to_speech",
      "node_type": "fal.text_to_speech.Qwen3TtsVoiceDesign17B",
      "properties": [
        {
          "name": "repetition_penalty",
          "type": {
            "type": "float"
          },
          "default": 1.05,
          "title": "Repetition Penalty",
          "description": "Penalty to reduce repeated tokens/codes."
        },
        {
          "name": "subtalker_top_k",
          "type": {
            "type": "int"
          },
          "default": 50,
          "title": "Subtalker Top K",
          "description": "Top-k for sub-talker sampling."
        },
        {
          "name": "top_p",
          "type": {
            "type": "float"
          },
          "default": 1,
          "title": "Top P",
          "description": "Top-p sampling parameter."
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "Optional prompt to guide the style of the generated speech."
        },
        {
          "name": "max_new_tokens",
          "type": {
            "type": "int"
          },
          "default": 200,
          "title": "Max New Tokens",
          "description": "Maximum number of new codec tokens to generate."
        },
        {
          "name": "text",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Text",
          "description": "The text to be converted to speech."
        },
        {
          "name": "language",
          "type": {
            "type": "enum",
            "values": [
              "Auto",
              "English",
              "Chinese",
              "Spanish",
              "French",
              "German",
              "Italian",
              "Japanese",
              "Korean",
              "Portuguese",
              "Russian"
            ],
            "type_name": "nodetool.nodes.fal.text_to_speech.Language"
          },
          "default": "Auto",
          "title": "Language",
          "description": "The language of the voice to be designed."
        },
        {
          "name": "top_k",
          "type": {
            "type": "int"
          },
          "default": 50,
          "title": "Top K",
          "description": "Top-k sampling parameter."
        },
        {
          "name": "subtalker_dosample",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Subtalker Dosample",
          "description": "Sampling switch for the sub-talker."
        },
        {
          "name": "subtalker_temperature",
          "type": {
            "type": "float"
          },
          "default": 0.9,
          "title": "Subtalker Temperature",
          "description": "Temperature for sub-talker sampling."
        },
        {
          "name": "subtalker_top_p",
          "type": {
            "type": "float"
          },
          "default": 1,
          "title": "Subtalker Top P",
          "description": "Top-p for sub-talker sampling."
        },
        {
          "name": "temperature",
          "type": {
            "type": "float"
          },
          "default": 0.9,
          "title": "Temperature",
          "description": "Sampling temperature; higher => more random."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "audio"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "text"
      ]
    },
    {
      "title": "Vibevoice 05B",
      "description": "VibeVoice 0.5B generates expressive and emotive speech from text with natural vocal characteristics.\n    audio, tts, vibevoice, 0.5b, expressive, text-to-speech\n\n    Use cases:\n    - Generate expressive speech from text\n    - Create emotive voice-overs\n    - Produce natural vocal narration\n    - Generate speech with personality\n    - Create engaging audio content",
      "namespace": "fal.text_to_speech",
      "node_type": "fal.text_to_speech.Vibevoice05B",
      "properties": [
        {
          "name": "script",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Script",
          "description": "The script to convert to speech."
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Random seed for reproducible generation."
        },
        {
          "name": "speaker",
          "type": {
            "type": "enum",
            "values": [
              "Frank",
              "Wayne",
              "Carter",
              "Emma",
              "Grace",
              "Mike"
            ],
            "type_name": "nodetool.nodes.fal.text_to_speech.Speaker"
          },
          "default": "",
          "title": "Speaker",
          "description": "Voice to use for speaking."
        },
        {
          "name": "cfg_scale",
          "type": {
            "type": "float"
          },
          "default": 1.3,
          "title": "Cfg Scale",
          "description": "CFG (Classifier-Free Guidance) scale for generation. Higher values increase adherence to text."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "audio"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "text"
      ]
    },
    {
      "title": "Any LLM",
      "description": "Use any large language model from a selected catalogue (powered by OpenRouter).\n    Supports various models including Claude 3, Gemini, Llama, and GPT-4.\n    llm, text, generation, ai, language\n\n    Use cases:\n    - Generate natural language responses\n    - Create conversational AI interactions\n    - Process and analyze text content\n    - Generate creative writing\n    - Assist with problem-solving tasks",
      "namespace": "fal.llm",
      "node_type": "fal.llm.AnyLLM",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to send to the language model"
        },
        {
          "name": "system_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "System Prompt",
          "description": "Optional system prompt to provide context or instructions"
        },
        {
          "name": "model",
          "type": {
            "type": "enum",
            "values": [
              "anthropic/claude-3.5-sonnet",
              "anthropic/claude-3-5-haiku",
              "anthropic/claude-3-haiku",
              "google/gemini-pro-1.5",
              "google/gemini-flash-1.5",
              "google/gemini-flash-1.5-8b",
              "meta-llama/llama-3.2-1b-instruct",
              "meta-llama/llama-3.2-3b-instruct",
              "meta-llama/llama-3.1-8b-instruct",
              "meta-llama/llama-3.1-70b-instruct",
              "openai/gpt-4o-mini",
              "openai/gpt-4o"
            ],
            "type_name": "nodetool.nodes.fal.llm.ModelEnum"
          },
          "default": "google/gemini-flash-1.5",
          "title": "Model",
          "description": "The language model to use for the completion"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "str"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "model",
        "system_prompt"
      ]
    },
    {
      "title": "Face Swap Video",
      "description": "Swap faces in videos using a source face image. Replaces faces in the target video with the source face while maintaining natural motion and expressions.\n    face-swap, video-editing, face-replacement, deep-fake, video-manipulation\n\n    Use cases:\n    - Create face-swapped video content\n    - Generate creative video edits\n    - Produce entertainment content\n    - Test different faces in video footage\n    - Create video memes and parodies",
      "namespace": "fal.video_processing",
      "node_type": "fal.video_processing.FaceSwapVideo",
      "properties": [
        {
          "name": "source_face",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Source Face",
          "description": "Source face image to swap into video"
        },
        {
          "name": "target_video",
          "type": {
            "type": "video"
          },
          "default": {
            "type": "video",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null,
            "duration": null,
            "format": null
          },
          "title": "Target Video",
          "description": "Target video to swap face in (max 25 minutes)"
        },
        {
          "name": "enable_occlusion_prevention",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Enable Occlusion Prevention",
          "description": "Enable occlusion prevention for faces covered by hands/objects (costs 2x more)"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "source_face",
        "target_video"
      ]
    },
    {
      "title": "Live Avatar",
      "description": "Live Avatar creates animated avatars from images and audio.\n    video, avatar, animation, audio-driven\n\n    Use cases:\n    - Create talking avatars\n    - Generate animated presentations\n    - Produce video content from photos\n    - Create virtual presenters\n    - Generate video messages",
      "namespace": "fal.video_processing",
      "node_type": "fal.video_processing.LiveAvatar",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The avatar image"
        },
        {
          "name": "audio",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Audio",
          "description": "URL to the driving audio"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "audio"
      ]
    },
    {
      "title": "RIFE",
      "description": "RIFE (Real-time Intermediate Flow Estimation) interpolates frames for smooth video.\n    video, interpolation, frame-rate, smoothing\n\n    Use cases:\n    - Increase video frame rate\n    - Create smooth slow motion\n    - Improve video fluidity\n    - Generate intermediate frames\n    - Enhance animation smoothness",
      "namespace": "fal.video_processing",
      "node_type": "fal.video_processing.RIFE",
      "properties": [
        {
          "name": "start_image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Start Image",
          "description": "The start frame"
        },
        {
          "name": "end_image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "End Image",
          "description": "The end frame"
        },
        {
          "name": "num_frames",
          "type": {
            "type": "int"
          },
          "default": 2,
          "title": "Num Frames",
          "description": "Number of intermediate frames",
          "min": 1.0,
          "max": 16.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "list"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "start_image",
        "end_image",
        "num_frames"
      ]
    },
    {
      "title": "RIFEVideo",
      "description": "RIFE Video interpolates video frames for increased frame rate.\n    video, interpolation, frame-rate, enhancement\n\n    Use cases:\n    - Double video frame rate\n    - Create slow motion videos\n    - Improve video smoothness\n    - Enhance low-fps footage\n    - Generate high-fps content",
      "namespace": "fal.video_processing",
      "node_type": "fal.video_processing.RIFEVideo",
      "properties": [
        {
          "name": "video",
          "type": {
            "type": "video"
          },
          "default": {
            "type": "video",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null,
            "duration": null,
            "format": null
          },
          "title": "Video",
          "description": "The video to interpolate"
        },
        {
          "name": "multiplier",
          "type": {
            "type": "int"
          },
          "default": 2,
          "title": "Multiplier",
          "description": "Frame rate multiplier",
          "min": 2.0,
          "max": 4.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "video",
        "multiplier"
      ]
    },
    {
      "title": "Sync Lipsync V2",
      "description": "Sync Lipsync V2 synchronizes lip movements to audio.\n    video, lipsync, audio, synchronization\n\n    Use cases:\n    - Sync lips to new audio\n    - Create talking head videos\n    - Dub videos in other languages\n    - Generate speaking animations\n    - Create video voice-overs",
      "namespace": "fal.video_processing",
      "node_type": "fal.video_processing.SyncLipsyncV2",
      "properties": [
        {
          "name": "video",
          "type": {
            "type": "video"
          },
          "default": {
            "type": "video",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null,
            "duration": null,
            "format": null
          },
          "title": "Video",
          "description": "The video with the face"
        },
        {
          "name": "audio",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Audio",
          "description": "URL to the audio file for lipsync"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "video",
        "audio"
      ]
    },
    {
      "title": "Topaz Video Upscale",
      "description": "Topaz Video Upscale enhances video quality using advanced AI.\n    video, upscaling, enhancement, topaz, professional\n\n    Use cases:\n    - Professional video upscaling\n    - Restore archival footage\n    - Enhance video for broadcast\n    - Improve video quality\n    - Prepare videos for 4K display",
      "namespace": "fal.video_processing",
      "node_type": "fal.video_processing.TopazVideoUpscale",
      "properties": [
        {
          "name": "video",
          "type": {
            "type": "video"
          },
          "default": {
            "type": "video",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null,
            "duration": null,
            "format": null
          },
          "title": "Video",
          "description": "The video to upscale"
        },
        {
          "name": "scale",
          "type": {
            "type": "int"
          },
          "default": 2,
          "title": "Scale",
          "description": "Upscaling factor",
          "min": 2.0,
          "max": 4.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "video",
        "scale"
      ]
    },
    {
      "title": "Video Upscaler",
      "description": "Video Upscaler enhances video resolution using AI.\n    video, upscaling, enhancement, super-resolution\n\n    Use cases:\n    - Upscale low-resolution videos\n    - Enhance video quality\n    - Improve video for larger displays\n    - Restore old videos\n    - Prepare videos for high-res output",
      "namespace": "fal.video_processing",
      "node_type": "fal.video_processing.VideoUpscaler",
      "properties": [
        {
          "name": "video",
          "type": {
            "type": "video"
          },
          "default": {
            "type": "video",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null,
            "duration": null,
            "format": null
          },
          "title": "Video",
          "description": "The video to upscale"
        },
        {
          "name": "scale",
          "type": {
            "type": "float"
          },
          "default": 2.0,
          "title": "Scale",
          "description": "Upscaling factor (1-8)",
          "min": 1.0,
          "max": 8.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "video",
        "scale"
      ]
    },
    {
      "title": "Bytedance Seedream V45 Text To Image",
      "description": "ByteDance SeeDream v4.5 generates advanced images from text with cutting-edge AI technology.\n    image, generation, bytedance, seedream, v4.5, text-to-image\n\n    Use cases:\n    - Generate images with SeeDream v4.5\n    - Create cutting-edge visual content\n    - Produce advanced AI artwork\n    - Generate images with latest tech\n    - Create modern AI visuals",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.BytedanceSeedreamV45TextToImage",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The text prompt used to generate the image"
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "Number of separate model generations to be run with the prompt."
        },
        {
          "name": "image_size",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Image Size",
          "description": "The size of the generated image. Width and height must be between 1920 and 4096, or total number of pixels must be between 2560*1440 and 4096*4096."
        },
        {
          "name": "max_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Max Images",
          "description": "If set to a number greater than one, enables multi-image generation. The model will potentially return up to `max_images` images every generation, and in total, `num_images` generations will be carried out. In total, the number of images generated will be between `num_images` and `max_images*num_images`."
        },
        {
          "name": "sync_mode",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Sync Mode",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history."
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If set to true, the safety checker will be enabled."
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Random seed to control the stochasticity of image generation."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt"
      ]
    },
    {
      "title": "Flux 2 Flash",
      "description": "FLUX.2 Flash is an ultra-fast variant of FLUX.2 designed for instant image generation with minimal latency.\n    image, generation, flux, ultra-fast, flash, text-to-image, txt2img\n\n    Use cases:\n    - Instant preview generation for user interfaces\n    - Real-time collaborative design tools\n    - Lightning-fast concept exploration\n    - High-speed batch processing\n    - Interactive gaming and entertainment applications",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.Flux2Flash",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "The number of images to generate."
        },
        {
          "name": "image_size",
          "type": {
            "type": "enum",
            "values": [
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
          },
          "default": "landscape_4_3",
          "title": "Image Size",
          "description": "Size preset for the generated image"
        },
        {
          "name": "output_format",
          "type": {
            "type": "enum",
            "values": [
              "jpeg",
              "png"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.OutputFormat"
          },
          "default": "png",
          "title": "Output Format",
          "description": "The format of the generated image."
        },
        {
          "name": "sync_mode",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Sync Mode",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history."
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 2.5,
          "title": "Guidance Scale",
          "description": "Guidance Scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you."
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for reproducible results. Use -1 for random"
        },
        {
          "name": "enable_prompt_expansion",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Enable Prompt Expansion",
          "description": "If set to true, the prompt will be expanded for better results."
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If set to true, the safety checker will be enabled."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "image_size"
      ]
    },
    {
      "title": "Flux 2 Klein 4B",
      "description": "FLUX-2 Klein 4B generates images with the efficient 4-billion parameter model for balanced quality and speed.\n    image, generation, flux-2, klein, 4b, text-to-image\n\n    Use cases:\n    - Generate images with 4B model\n    - Create balanced quality-speed content\n    - Produce efficient visual artwork\n    - Generate images with good performance\n    - Create optimized visuals",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.Flux2Klein4B",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from."
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "The number of images to generate."
        },
        {
          "name": "image_size",
          "type": {
            "type": "str"
          },
          "default": "landscape_4_3",
          "title": "Image Size",
          "description": "The size of the image to generate."
        },
        {
          "name": "output_format",
          "type": {
            "type": "enum",
            "values": [
              "jpeg",
              "png"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.OutputFormat"
          },
          "default": "png",
          "title": "Output Format",
          "description": "The format of the generated image."
        },
        {
          "name": "sync_mode",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Sync Mode",
          "description": "If `True`, the media will be returned as a data URI. Output is not stored when this is True."
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If set to true, the safety checker will be enabled."
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 4,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform."
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The seed to use for the generation. If not provided, a random seed will be used."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt"
      ]
    },
    {
      "title": "Flux 2 Klein 4B Base",
      "description": "FLUX-2 Klein 4B Base provides foundation model generation with 4-billion parameters.\n    image, generation, flux-2, klein, 4b, base\n\n    Use cases:\n    - Generate with base 4B model\n    - Create foundation quality content\n    - Produce standard visual artwork\n    - Generate images with base model\n    - Create baseline visuals",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.Flux2Klein4BBase",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from."
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "The number of images to generate."
        },
        {
          "name": "image_size",
          "type": {
            "type": "str"
          },
          "default": "landscape_4_3",
          "title": "Image Size",
          "description": "The size of the image to generate."
        },
        {
          "name": "acceleration",
          "type": {
            "type": "enum",
            "values": [
              "none",
              "regular",
              "high"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.Acceleration"
          },
          "default": "regular",
          "title": "Acceleration",
          "description": "The acceleration level to use for image generation."
        },
        {
          "name": "output_format",
          "type": {
            "type": "enum",
            "values": [
              "jpeg",
              "png"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.OutputFormat"
          },
          "default": "png",
          "title": "Output Format",
          "description": "The format of the generated image."
        },
        {
          "name": "sync_mode",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Sync Mode",
          "description": "If `True`, the media will be returned as a data URI. Output is not stored when this is True."
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If set to true, the safety checker will be enabled."
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 28,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform."
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The seed to use for the generation. If not provided, a random seed will be used."
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "Negative prompt for classifier-free guidance. Describes what to avoid in the image."
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 5,
          "title": "Guidance Scale",
          "description": "Guidance scale for classifier-free guidance."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt"
      ]
    },
    {
      "title": "Flux 2 Klein 4B Base Lora",
      "description": "FLUX-2 Klein 4B Base with LoRA enables custom-trained 4B models for specialized generation.\n    image, generation, flux-2, klein, 4b, base, lora\n\n    Use cases:\n    - Generate with custom 4B base model\n    - Create specialized foundation content\n    - Produce domain-specific visuals\n    - Generate with fine-tuned 4B model\n    - Create customized baseline visuals",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.Flux2Klein4BBaseLora",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from."
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "The number of images to generate."
        },
        {
          "name": "image_size",
          "type": {
            "type": "str"
          },
          "default": "landscape_4_3",
          "title": "Image Size",
          "description": "The size of the image to generate."
        },
        {
          "name": "acceleration",
          "type": {
            "type": "enum",
            "values": [
              "none",
              "regular",
              "high"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.Acceleration"
          },
          "default": "regular",
          "title": "Acceleration",
          "description": "The acceleration level to use for image generation."
        },
        {
          "name": "output_format",
          "type": {
            "type": "enum",
            "values": [
              "jpeg",
              "png"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.OutputFormat"
          },
          "default": "png",
          "title": "Output Format",
          "description": "The format of the generated image."
        },
        {
          "name": "loras",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "str"
              }
            ]
          },
          "default": [],
          "title": "Loras",
          "description": "List of LoRA weights to apply (maximum 3)."
        },
        {
          "name": "sync_mode",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Sync Mode",
          "description": "If `True`, the media will be returned as a data URI. Output is not stored when this is True."
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If set to true, the safety checker will be enabled."
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 28,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform."
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The seed to use for the generation. If not provided, a random seed will be used."
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "Negative prompt for classifier-free guidance. Describes what to avoid in the image."
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 5,
          "title": "Guidance Scale",
          "description": "Guidance scale for classifier-free guidance."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt"
      ]
    },
    {
      "title": "Flux 2 Klein 9B",
      "description": "FLUX-2 Klein 9B generates high-quality images with the powerful 9-billion parameter model.\n    image, generation, flux-2, klein, 9b, text-to-image\n\n    Use cases:\n    - Generate high-quality images with 9B model\n    - Create superior visual content\n    - Produce detailed artwork\n    - Generate images with powerful model\n    - Create premium quality visuals",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.Flux2Klein9B",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from."
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "The number of images to generate."
        },
        {
          "name": "image_size",
          "type": {
            "type": "str"
          },
          "default": "landscape_4_3",
          "title": "Image Size",
          "description": "The size of the image to generate."
        },
        {
          "name": "output_format",
          "type": {
            "type": "enum",
            "values": [
              "jpeg",
              "png"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.OutputFormat"
          },
          "default": "png",
          "title": "Output Format",
          "description": "The format of the generated image."
        },
        {
          "name": "sync_mode",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Sync Mode",
          "description": "If `True`, the media will be returned as a data URI. Output is not stored when this is True."
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If set to true, the safety checker will be enabled."
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 4,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform."
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The seed to use for the generation. If not provided, a random seed will be used."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt"
      ]
    },
    {
      "title": "Flux 2 Klein 9B Base",
      "description": "FLUX-2 Klein 9B Base provides foundation generation with the full 9-billion parameter model.\n    image, generation, flux-2, klein, 9b, base\n\n    Use cases:\n    - Generate with base 9B model\n    - Create high-quality foundation content\n    - Produce superior baseline artwork\n    - Generate images with powerful base\n    - Create premium baseline visuals",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.Flux2Klein9BBase",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from."
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "The number of images to generate."
        },
        {
          "name": "image_size",
          "type": {
            "type": "str"
          },
          "default": "landscape_4_3",
          "title": "Image Size",
          "description": "The size of the image to generate."
        },
        {
          "name": "acceleration",
          "type": {
            "type": "enum",
            "values": [
              "none",
              "regular",
              "high"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.Acceleration"
          },
          "default": "regular",
          "title": "Acceleration",
          "description": "The acceleration level to use for image generation."
        },
        {
          "name": "output_format",
          "type": {
            "type": "enum",
            "values": [
              "jpeg",
              "png"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.OutputFormat"
          },
          "default": "png",
          "title": "Output Format",
          "description": "The format of the generated image."
        },
        {
          "name": "sync_mode",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Sync Mode",
          "description": "If `True`, the media will be returned as a data URI. Output is not stored when this is True."
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If set to true, the safety checker will be enabled."
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 28,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform."
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The seed to use for the generation. If not provided, a random seed will be used."
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "Negative prompt for classifier-free guidance. Describes what to avoid in the image."
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 5,
          "title": "Guidance Scale",
          "description": "Guidance scale for classifier-free guidance."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt"
      ]
    },
    {
      "title": "Flux 2 Klein 9B Base Lora",
      "description": "FLUX-2 Klein 9B Base with LoRA combines powerful generation with custom-trained models.\n    image, generation, flux-2, klein, 9b, base, lora\n\n    Use cases:\n    - Generate with custom 9B base model\n    - Create specialized high-quality content\n    - Produce custom superior visuals\n    - Generate with fine-tuned 9B model\n    - Create advanced customized visuals",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.Flux2Klein9BBaseLora",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from."
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "The number of images to generate."
        },
        {
          "name": "image_size",
          "type": {
            "type": "str"
          },
          "default": "landscape_4_3",
          "title": "Image Size",
          "description": "The size of the image to generate."
        },
        {
          "name": "acceleration",
          "type": {
            "type": "enum",
            "values": [
              "none",
              "regular",
              "high"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.Acceleration"
          },
          "default": "regular",
          "title": "Acceleration",
          "description": "The acceleration level to use for image generation."
        },
        {
          "name": "output_format",
          "type": {
            "type": "enum",
            "values": [
              "jpeg",
              "png"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.OutputFormat"
          },
          "default": "png",
          "title": "Output Format",
          "description": "The format of the generated image."
        },
        {
          "name": "loras",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "str"
              }
            ]
          },
          "default": [],
          "title": "Loras",
          "description": "List of LoRA weights to apply (maximum 3)."
        },
        {
          "name": "sync_mode",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Sync Mode",
          "description": "If `True`, the media will be returned as a data URI. Output is not stored when this is True."
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If set to true, the safety checker will be enabled."
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 28,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform."
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The seed to use for the generation. If not provided, a random seed will be used."
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "Negative prompt for classifier-free guidance. Describes what to avoid in the image."
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 5,
          "title": "Guidance Scale",
          "description": "Guidance scale for classifier-free guidance."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt"
      ]
    },
    {
      "title": "Flux 2 Max",
      "description": "FLUX-2 Max generates maximum quality images with the most advanced FLUX-2 model for premium results.\n    image, generation, flux-2, max, premium, text-to-image\n\n    Use cases:\n    - Generate maximum quality images\n    - Create premium visual content\n    - Produce professional-grade artwork\n    - Generate images with best model\n    - Create superior quality visuals",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.Flux2Max",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from."
        },
        {
          "name": "image_size",
          "type": {
            "type": "str"
          },
          "default": "landscape_4_3",
          "title": "Image Size",
          "description": "The size of the generated image."
        },
        {
          "name": "output_format",
          "type": {
            "type": "enum",
            "values": [
              "jpeg",
              "png"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.OutputFormat"
          },
          "default": "jpeg",
          "title": "Output Format",
          "description": "The format of the generated image."
        },
        {
          "name": "sync_mode",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Sync Mode",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history."
        },
        {
          "name": "safety_tolerance",
          "type": {
            "type": "enum",
            "values": [
              "1",
              "2",
              "3",
              "4",
              "5",
              "6"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.SafetyTolerance"
          },
          "default": "2",
          "title": "Safety Tolerance",
          "description": "The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive."
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "Whether to enable the safety checker."
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The seed to use for the generation."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt"
      ]
    },
    {
      "title": "Flux 2 Turbo",
      "description": "FLUX.2 Turbo is a blazing-fast image generation model optimized for speed without sacrificing quality, ideal for real-time applications.\n    image, generation, flux, fast, turbo, text-to-image, txt2img\n\n    Use cases:\n    - Real-time image generation for interactive apps\n    - Rapid prototyping of visual concepts\n    - Generate multiple variations instantly\n    - Live visual effects and augmented reality\n    - High-throughput batch image processing",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.Flux2Turbo",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "Number of images to generate"
        },
        {
          "name": "image_size",
          "type": {
            "type": "enum",
            "values": [
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
          },
          "default": "landscape_4_3",
          "title": "Image Size",
          "description": "Size preset for the generated image"
        },
        {
          "name": "output_format",
          "type": {
            "type": "enum",
            "values": [
              "jpeg",
              "png"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.OutputFormat"
          },
          "default": "png",
          "title": "Output Format",
          "description": "The format of the generated image."
        },
        {
          "name": "sync_mode",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Sync Mode",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history."
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 2.5,
          "title": "Guidance Scale",
          "description": "Guidance Scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you."
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for reproducible results. Use -1 for random"
        },
        {
          "name": "enable_prompt_expansion",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Enable Prompt Expansion",
          "description": "If set to true, the prompt will be expanded for better results."
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If set to true, the safety checker will be enabled."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "image_size",
        "num_images"
      ]
    },
    {
      "title": "Flux Dev",
      "description": "FLUX.1 [dev] is a powerful open-weight text-to-image model with 12 billion parameters. Optimized for prompt following and visual quality.\n    image, generation, flux, text-to-image, txt2img\n\n    Use cases:\n    - Generate high-quality images from text prompts\n    - Create detailed illustrations with precise control\n    - Produce professional artwork and designs\n    - Generate multiple variations from one prompt\n    - Create safe-for-work content with built-in safety checker",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.FluxDev",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "Number of images to generate"
        },
        {
          "name": "image_size",
          "type": {
            "type": "enum",
            "values": [
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
          },
          "default": "landscape_4_3",
          "title": "Image Size",
          "description": "Size preset for the generated image"
        },
        {
          "name": "acceleration",
          "type": {
            "type": "enum",
            "values": [
              "none",
              "regular",
              "high"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.Acceleration"
          },
          "default": "none",
          "title": "Acceleration",
          "description": "The speed of the generation. The higher the speed, the faster the generation."
        },
        {
          "name": "output_format",
          "type": {
            "type": "enum",
            "values": [
              "jpeg",
              "png"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.OutputFormat"
          },
          "default": "jpeg",
          "title": "Output Format",
          "description": "The format of the generated image."
        },
        {
          "name": "sync_mode",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Sync Mode",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history."
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "Enable safety checker to filter unsafe content"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for reproducible results. Use -1 for random"
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 3.5,
          "title": "Guidance Scale",
          "description": "How strictly to follow the prompt. Higher values are more literal"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 28,
          "title": "Num Inference Steps",
          "description": "Number of denoising steps. More steps typically improve quality"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "image_size",
        "num_inference_steps"
      ]
    },
    {
      "title": "Flux Lora",
      "description": "FLUX with LoRA support enables fine-tuned image generation using custom LoRA models for specific styles or subjects.\n    image, generation, flux, lora, fine-tuning, text-to-image, txt2img\n\n    Use cases:\n    - Generate images with custom artistic styles\n    - Create consistent characters across images\n    - Apply brand-specific visual styles\n    - Generate images with specialized subjects\n    - Combine multiple LoRA models for unique results",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.FluxLora",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "The number of images to generate. This is always set to 1 for streaming output."
        },
        {
          "name": "image_size",
          "type": {
            "type": "str"
          },
          "default": "landscape_4_3",
          "title": "Image Size",
          "description": "Size preset for the generated image"
        },
        {
          "name": "output_format",
          "type": {
            "type": "enum",
            "values": [
              "jpeg",
              "png"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.OutputFormat"
          },
          "default": "jpeg",
          "title": "Output Format",
          "description": "The format of the generated image."
        },
        {
          "name": "sync_mode",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Sync Mode",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history."
        },
        {
          "name": "loras",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "str"
              }
            ]
          },
          "default": [],
          "title": "Loras",
          "description": "List of LoRA models to apply with their weights"
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 3.5,
          "title": "Guidance Scale",
          "description": "How strictly to follow the prompt"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 28,
          "title": "Num Inference Steps",
          "description": "Number of denoising steps"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for reproducible results. Use -1 for random"
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "Enable safety checker to filter unsafe content"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "loras",
        "image_size"
      ]
    },
    {
      "title": "Flux Pro New",
      "description": "FLUX.1 Pro New is the latest version of the professional FLUX model with enhanced capabilities and improved output quality.\n    image, generation, flux, professional, text-to-image, txt2img\n\n    Use cases:\n    - Generate professional-grade marketing visuals\n    - Create high-quality product renders\n    - Produce detailed architectural visualizations\n    - Design premium brand assets\n    - Generate photorealistic commercial imagery",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.FluxProNew",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "The number of images to generate."
        },
        {
          "name": "image_size",
          "type": {
            "type": "enum",
            "values": [
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
          },
          "default": "landscape_4_3",
          "title": "Image Size",
          "description": "Size preset for the generated image"
        },
        {
          "name": "output_format",
          "type": {
            "type": "enum",
            "values": [
              "jpeg",
              "png"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.OutputFormat"
          },
          "default": "jpeg",
          "title": "Output Format",
          "description": "The format of the generated image."
        },
        {
          "name": "sync_mode",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Sync Mode",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history."
        },
        {
          "name": "safety_tolerance",
          "type": {
            "type": "enum",
            "values": [
              "1",
              "2",
              "3",
              "4",
              "5",
              "6"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.SafetyTolerance"
          },
          "default": "2",
          "title": "Safety Tolerance",
          "description": "The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive."
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 3.5,
          "title": "Guidance Scale",
          "description": "The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you."
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 28,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform."
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for reproducible results. Use -1 for random"
        },
        {
          "name": "enhance_prompt",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Enhance Prompt",
          "description": "Whether to enhance the prompt for better results."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "image_size"
      ]
    },
    {
      "title": "Flux Schnell",
      "description": "FLUX.1 [schnell] is a fast distilled version of FLUX.1 optimized for speed. Can generate high-quality images in 1-4 steps.\n    image, generation, flux, fast, text-to-image, txt2img\n\n    Use cases:\n    - Generate images quickly for rapid iteration\n    - Create concept art with minimal latency\n    - Produce preview images before final generation\n    - Generate multiple variations efficiently\n    - Real-time image generation applications",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.FluxSchnell",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "Number of images to generate"
        },
        {
          "name": "image_size",
          "type": {
            "type": "enum",
            "values": [
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
          },
          "default": "landscape_4_3",
          "title": "Image Size",
          "description": "Size preset for the generated image"
        },
        {
          "name": "acceleration",
          "type": {
            "type": "enum",
            "values": [
              "none",
              "regular",
              "high"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.Acceleration"
          },
          "default": "none",
          "title": "Acceleration",
          "description": "The speed of the generation. The higher the speed, the faster the generation."
        },
        {
          "name": "output_format",
          "type": {
            "type": "enum",
            "values": [
              "jpeg",
              "png"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.OutputFormat"
          },
          "default": "jpeg",
          "title": "Output Format",
          "description": "The format of the generated image."
        },
        {
          "name": "sync_mode",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Sync Mode",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history."
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "Enable safety checker to filter unsafe content"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for reproducible results. Use -1 for random"
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 3.5,
          "title": "Guidance Scale",
          "description": "The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you."
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 4,
          "title": "Num Inference Steps",
          "description": "Number of denoising steps (1-4 recommended for schnell)"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "image_size",
        "num_inference_steps"
      ]
    },
    {
      "title": "Flux V1 Pro",
      "description": "FLUX.1 Pro is a state-of-the-art image generation model with superior prompt following and image quality.\n    image, generation, flux, pro, text-to-image, txt2img\n\n    Use cases:\n    - Generate professional-grade images for commercial use\n    - Create highly detailed artwork with complex prompts\n    - Produce marketing materials and brand assets\n    - Generate photorealistic images\n    - Create custom visual content with precise control",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.FluxV1Pro",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "Number of images to generate"
        },
        {
          "name": "image_size",
          "type": {
            "type": "str"
          },
          "default": "landscape_4_3",
          "title": "Image Size",
          "description": "Size preset for the generated image"
        },
        {
          "name": "output_format",
          "type": {
            "type": "enum",
            "values": [
              "jpeg",
              "png"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.OutputFormat"
          },
          "default": "jpeg",
          "title": "Output Format",
          "description": "Output image format (jpeg or png)"
        },
        {
          "name": "sync_mode",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Sync Mode",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history."
        },
        {
          "name": "safety_tolerance",
          "type": {
            "type": "enum",
            "values": [
              "1",
              "2",
              "3",
              "4",
              "5",
              "6"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.SafetyTolerance"
          },
          "default": "2",
          "title": "Safety Tolerance",
          "description": "Safety checker tolerance level (1-6). Higher is more permissive"
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "Enable safety checker to filter unsafe content"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for reproducible results. Use -1 for random"
        },
        {
          "name": "enhance_prompt",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Enhance Prompt",
          "description": "Whether to enhance the prompt for better results."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "image_size",
        "guidance_scale"
      ]
    },
    {
      "title": "Flux V1 Pro Ultra",
      "description": "FLUX.1 Pro Ultra delivers the highest quality image generation with enhanced detail and realism.\n    image, generation, flux, pro, ultra, text-to-image, txt2img\n\n    Use cases:\n    - Generate ultra-high quality photorealistic images\n    - Create professional photography-grade visuals\n    - Produce detailed product renders\n    - Generate premium marketing materials\n    - Create artistic masterpieces with fine details",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.FluxV1ProUltra",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "Number of images to generate"
        },
        {
          "name": "aspect_ratio",
          "type": {
            "type": "str"
          },
          "default": "16:9",
          "title": "Aspect Ratio",
          "description": "Aspect ratio for the generated image"
        },
        {
          "name": "enhance_prompt",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Enhance Prompt",
          "description": "Whether to enhance the prompt for better results."
        },
        {
          "name": "output_format",
          "type": {
            "type": "enum",
            "values": [
              "jpeg",
              "png"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.OutputFormat"
          },
          "default": "jpeg",
          "title": "Output Format",
          "description": "The format of the generated image."
        },
        {
          "name": "image_url",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image Url",
          "description": "The image URL to generate an image from."
        },
        {
          "name": "sync_mode",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Sync Mode",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history."
        },
        {
          "name": "safety_tolerance",
          "type": {
            "type": "enum",
            "values": [
              "1",
              "2",
              "3",
              "4",
              "5",
              "6"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.SafetyTolerance"
          },
          "default": "2",
          "title": "Safety Tolerance",
          "description": "The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive."
        },
        {
          "name": "image_prompt_strength",
          "type": {
            "type": "float"
          },
          "default": 0.1,
          "title": "Image Prompt Strength",
          "description": "Strength of image prompt influence (0-1)"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for reproducible results. Use -1 for random"
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If set to true, the safety checker will be enabled."
        },
        {
          "name": "raw",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Raw",
          "description": "Generate less processed, more natural results"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "image_size",
        "aspect_ratio"
      ]
    },
    {
      "title": "Glm Image",
      "description": "GLM Image generates images from text with advanced AI understanding and quality output.\n    image, generation, glm, ai, text-to-image\n\n    Use cases:\n    - Generate images with GLM AI\n    - Create intelligent visual content\n    - Produce AI-powered artwork\n    - Generate images with understanding\n    - Create smart visuals from text",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.GlmImage",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "Text prompt for image generation."
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "Number of images to generate."
        },
        {
          "name": "image_size",
          "type": {
            "type": "str"
          },
          "default": "square_hd",
          "title": "Image Size",
          "description": "Output image size."
        },
        {
          "name": "output_format",
          "type": {
            "type": "enum",
            "values": [
              "jpeg",
              "png"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.OutputFormat"
          },
          "default": "jpeg",
          "title": "Output Format",
          "description": "Output image format."
        },
        {
          "name": "sync_mode",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Sync Mode",
          "description": "If True, the image will be returned as a base64 data URI instead of a URL."
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 1.5,
          "title": "Guidance Scale",
          "description": "Classifier-free guidance scale. Higher values make the model follow the prompt more closely."
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Random seed for reproducibility. The same seed with the same prompt will produce the same image."
        },
        {
          "name": "enable_prompt_expansion",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Enable Prompt Expansion",
          "description": "If True, the prompt will be enhanced using an LLM for more detailed and higher quality results."
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 30,
          "title": "Num Inference Steps",
          "description": "Number of diffusion denoising steps. More steps generally produce higher quality images."
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "Enable NSFW safety checking on the generated images."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt"
      ]
    },
    {
      "title": "Gpt Image 15",
      "description": "GPT Image 1.5 generates images from text with GPT-powered language understanding and visual creation.\n    image, generation, gpt, language-ai, text-to-image\n\n    Use cases:\n    - Generate images with GPT understanding\n    - Create language-aware visual content\n    - Produce intelligent artwork\n    - Generate images with natural language\n    - Create GPT-powered visuals",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.GptImage15",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt for image generation"
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "Number of images to generate"
        },
        {
          "name": "image_size",
          "type": {
            "type": "enum",
            "values": [
              "1024x1024",
              "1536x1024",
              "1024x1536"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.ImageSize"
          },
          "default": "1024x1024",
          "title": "Image Size",
          "description": "Aspect ratio for the generated image"
        },
        {
          "name": "background",
          "type": {
            "type": "enum",
            "values": [
              "auto",
              "transparent",
              "opaque"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.Background"
          },
          "default": "auto",
          "title": "Background",
          "description": "Background for the generated image"
        },
        {
          "name": "quality",
          "type": {
            "type": "enum",
            "values": [
              "low",
              "medium",
              "high"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.Quality"
          },
          "default": "high",
          "title": "Quality",
          "description": "Quality for the generated image"
        },
        {
          "name": "output_format",
          "type": {
            "type": "enum",
            "values": [
              "jpeg",
              "png"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.OutputFormat"
          },
          "default": "png",
          "title": "Output Format",
          "description": "Output format for the images"
        },
        {
          "name": "sync_mode",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Sync Mode",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt"
      ]
    },
    {
      "title": "Hunyuan Image V3 Instruct Text To Image",
      "description": "Hunyuan Image v3 Instruct generates high-quality images from text with advanced instruction understanding.\n    image, generation, hunyuan, v3, instruct, text-to-image\n\n    Use cases:\n    - Generate images with detailed instructions\n    - Create artwork with precise text control\n    - Produce high-quality visual content\n    - Generate images with advanced understanding\n    - Create professional visuals from text",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.HunyuanImageV3InstructTextToImage",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The text prompt to generate an image from."
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "The number of images to generate."
        },
        {
          "name": "image_size",
          "type": {
            "type": "str"
          },
          "default": "auto",
          "title": "Image Size",
          "description": "The desired size of the generated image. If auto, image size will be determined by the model."
        },
        {
          "name": "output_format",
          "type": {
            "type": "enum",
            "values": [
              "jpeg",
              "png"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.OutputFormat"
          },
          "default": "png",
          "title": "Output Format",
          "description": "The format of the generated image."
        },
        {
          "name": "sync_mode",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Sync Mode",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history."
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If set to true, the safety checker will be enabled."
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Random seed for reproducible results. If None, a random seed is used."
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 3.5,
          "title": "Guidance Scale",
          "description": "Controls how much the model adheres to the prompt. Higher values mean stricter adherence."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt"
      ]
    },
    {
      "title": "Ideogram V2",
      "description": "Ideogram V2 is a state-of-the-art image generation model optimized for commercial and creative use, featuring exceptional typography handling and realistic outputs.\n    image, generation, ai, typography, realistic, text-to-image, txt2img\n\n    Use cases:\n    - Create commercial artwork and designs\n    - Generate realistic product visualizations\n    - Design marketing materials with text\n    - Produce high-quality illustrations\n    - Create brand assets and logos",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.IdeogramV2",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "aspect_ratio",
          "type": {
            "type": "enum",
            "values": [
              "10:16",
              "16:10",
              "9:16",
              "16:9",
              "4:3",
              "3:4",
              "1:1",
              "1:3",
              "3:1",
              "3:2",
              "2:3"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.AspectRatio"
          },
          "default": "1:1",
          "title": "Aspect Ratio",
          "description": "The aspect ratio of the generated image"
        },
        {
          "name": "style",
          "type": {
            "type": "enum",
            "values": [
              "auto",
              "general",
              "realistic",
              "design",
              "render_3D",
              "anime"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.Style"
          },
          "default": "auto",
          "title": "Style",
          "description": "The style of the generated image"
        },
        {
          "name": "expand_prompt",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Expand Prompt",
          "description": "Whether to expand the prompt with MagicPrompt functionality"
        },
        {
          "name": "sync_mode",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Sync Mode",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history."
        },
        {
          "name": "seed",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Seed",
          "description": "Seed for reproducible results. Use -1 for random"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "A negative prompt to avoid in the generated image"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "aspect_ratio",
        "style"
      ]
    },
    {
      "title": "Ideogram V2 Turbo",
      "description": "Ideogram V2 Turbo offers faster image generation with the same exceptional quality and typography handling as V2.\n    image, generation, ai, typography, realistic, fast, text-to-image, txt2img\n\n    Use cases:\n    - Rapidly generate commercial designs\n    - Quick iteration on marketing materials\n    - Fast prototyping of visual concepts\n    - Real-time design exploration\n    - Efficient batch generation of branded content",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.IdeogramV2Turbo",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "aspect_ratio",
          "type": {
            "type": "enum",
            "values": [
              "10:16",
              "16:10",
              "9:16",
              "16:9",
              "4:3",
              "3:4",
              "1:1",
              "1:3",
              "3:1",
              "3:2",
              "2:3"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.AspectRatio"
          },
          "default": "1:1",
          "title": "Aspect Ratio",
          "description": "The aspect ratio of the generated image"
        },
        {
          "name": "style",
          "type": {
            "type": "enum",
            "values": [
              "auto",
              "general",
              "realistic",
              "design",
              "render_3D",
              "anime"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.Style"
          },
          "default": "auto",
          "title": "Style",
          "description": "The style of the generated image"
        },
        {
          "name": "expand_prompt",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Expand Prompt",
          "description": "Whether to expand the prompt with MagicPrompt functionality"
        },
        {
          "name": "sync_mode",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Sync Mode",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history."
        },
        {
          "name": "seed",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Seed",
          "description": "Seed for reproducible results. Use -1 for random"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "A negative prompt to avoid in the generated image"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "aspect_ratio",
        "style"
      ]
    },
    {
      "title": "Ideogram V3",
      "description": "Ideogram V3 is the latest generation with enhanced text rendering, superior image quality, and expanded creative controls.\n    image, generation, ideogram, typography, text-rendering, text-to-image, txt2img\n\n    Use cases:\n    - Create professional graphics with embedded text\n    - Design social media posts with perfect typography\n    - Generate logos and brand identities\n    - Produce marketing materials with text overlays\n    - Create educational content with clear text",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.IdeogramV3",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "Number of images to generate."
        },
        {
          "name": "image_size",
          "type": {
            "type": "str"
          },
          "default": "square_hd",
          "title": "Image Size",
          "description": "The resolution of the generated image"
        },
        {
          "name": "style",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Style",
          "description": "The style preset for the generated image"
        },
        {
          "name": "style_preset",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Style Preset",
          "description": "Style preset for generation. The chosen style preset will guide the generation."
        },
        {
          "name": "expand_prompt",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Expand Prompt",
          "description": "Automatically enhance the prompt for better results"
        },
        {
          "name": "rendering_speed",
          "type": {
            "type": "enum",
            "values": [
              "TURBO",
              "BALANCED",
              "QUALITY"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.RenderingSpeed"
          },
          "default": "BALANCED",
          "title": "Rendering Speed",
          "description": "The rendering speed to use."
        },
        {
          "name": "style_codes",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Style Codes",
          "description": "A list of 8 character hexadecimal codes representing the style of the image. Cannot be used in conjunction with style_reference_images or style"
        },
        {
          "name": "color_palette",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Color Palette",
          "description": "A color palette for generation, must EITHER be specified via one of the presets (name) or explicitly via hexadecimal representations of the color with optional weights (members)"
        },
        {
          "name": "sync_mode",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Sync Mode",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history."
        },
        {
          "name": "seed",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Seed",
          "description": "Seed for the random number generator"
        },
        {
          "name": "image_urls",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image Urls",
          "description": "A set of images to use as style references (maximum total size 10MB across all style references). The images should be in JPEG, PNG or WebP format"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "Description of what to exclude from an image. Descriptions in the prompt take precedence to descriptions in the negative prompt."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "aspect_ratio",
        "style"
      ]
    },
    {
      "title": "Longcat Image",
      "description": "Longcat Image generates creative and unique images from text with distinctive AI characteristics.\n    image, generation, longcat, creative, text-to-image\n\n    Use cases:\n    - Generate creative images\n    - Create unique visual content\n    - Produce distinctive artwork\n    - Generate images with character\n    - Create artistic visuals",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.LongcatImage",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from."
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "The number of images to generate."
        },
        {
          "name": "acceleration",
          "type": {
            "type": "enum",
            "values": [
              "none",
              "regular",
              "high"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.Acceleration"
          },
          "default": "regular",
          "title": "Acceleration",
          "description": "The acceleration level to use."
        },
        {
          "name": "image_size",
          "type": {
            "type": "str"
          },
          "default": "landscape_4_3",
          "title": "Image Size",
          "description": "The size of the generated image."
        },
        {
          "name": "output_format",
          "type": {
            "type": "enum",
            "values": [
              "jpeg",
              "png"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.OutputFormat"
          },
          "default": "png",
          "title": "Output Format",
          "description": "The format of the generated image."
        },
        {
          "name": "sync_mode",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Sync Mode",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history."
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If set to true, the safety checker will be enabled."
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 28,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform."
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 4.5,
          "title": "Guidance Scale",
          "description": "The guidance scale to use for the image generation."
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed and the same prompt given to the same version of the model will output the same image every time."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt"
      ]
    },
    {
      "title": "Omni Gen V1",
      "description": "OmniGen V1 is a versatile unified model for multi-modal image generation and editing with text, supporting complex compositional tasks.\n    image, generation, multi-modal, editing, unified, text-to-image, txt2img\n\n    Use cases:\n    - Generate images with multiple input modalities\n    - Edit existing images with text instructions\n    - Create complex compositional scenes\n    - Combine text and image inputs for generation\n    - Perform advanced image manipulations",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.OmniGenV1",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate or edit an image"
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "The number of images to generate."
        },
        {
          "name": "image_size",
          "type": {
            "type": "str"
          },
          "default": "square_hd",
          "title": "Image Size",
          "description": "The size of the generated image."
        },
        {
          "name": "img_guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 1.6,
          "title": "Img Guidance Scale",
          "description": "The Image Guidance scale is a measure of how close you want the model to stick to your input image when looking for a related image to show you."
        },
        {
          "name": "input_image_urls",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "str"
              }
            ]
          },
          "default": [],
          "title": "Input Image Urls",
          "description": "URL of images to use while generating the image, Use <img><|image_1|></img> for the first image and so on."
        },
        {
          "name": "output_format",
          "type": {
            "type": "enum",
            "values": [
              "jpeg",
              "png"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.OutputFormat"
          },
          "default": "jpeg",
          "title": "Output Format",
          "description": "The format of the generated image."
        },
        {
          "name": "sync_mode",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Sync Mode",
          "description": "If set to true, the function will wait for the image to be generated and uploaded before returning the response. This will increase the latency of the function but it allows you to get the image directly in the response without going through the CDN."
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 3,
          "title": "Guidance Scale",
          "description": "How strictly to follow the prompt and inputs"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 50,
          "title": "Num Inference Steps",
          "description": "Number of denoising steps for generation quality"
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If set to true, the safety checker will be enabled."
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for reproducible results. Use -1 for random"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "guidance_scale",
        "num_inference_steps"
      ]
    },
    {
      "title": "Qwen Image 2512",
      "description": "Qwen Image 2512 generates high-resolution images from text with excellent quality and detail.\n    image, generation, qwen, 2512, high-resolution, text-to-image\n\n    Use cases:\n    - Generate high-resolution images\n    - Create detailed visual content\n    - Produce quality artwork from text\n    - Generate images with fine details\n    - Create high-quality visuals",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.QwenImage2512",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from."
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "The number of images to generate."
        },
        {
          "name": "acceleration",
          "type": {
            "type": "enum",
            "values": [
              "none",
              "regular",
              "high"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.Acceleration"
          },
          "default": "regular",
          "title": "Acceleration",
          "description": "The acceleration level to use."
        },
        {
          "name": "image_size",
          "type": {
            "type": "str"
          },
          "default": "landscape_4_3",
          "title": "Image Size",
          "description": "The size of the generated image."
        },
        {
          "name": "output_format",
          "type": {
            "type": "enum",
            "values": [
              "jpeg",
              "png"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.OutputFormat"
          },
          "default": "png",
          "title": "Output Format",
          "description": "The format of the generated image."
        },
        {
          "name": "sync_mode",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Sync Mode",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history."
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If set to true, the safety checker will be enabled."
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed and the same prompt given to the same version of the model will output the same image every time."
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 4,
          "title": "Guidance Scale",
          "description": "The guidance scale to use for the image generation."
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "The negative prompt to generate an image from."
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 28,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt"
      ]
    },
    {
      "title": "Qwen Image 2512 Lora",
      "description": "Qwen Image 2512 with LoRA support enables custom-trained models for specialized image generation.\n    image, generation, qwen, 2512, lora, custom\n\n    Use cases:\n    - Generate images with custom models\n    - Create specialized visual content\n    - Produce domain-specific artwork\n    - Generate images with fine-tuned models\n    - Create customized visuals",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.QwenImage2512Lora",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from."
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "The number of images to generate."
        },
        {
          "name": "acceleration",
          "type": {
            "type": "enum",
            "values": [
              "none",
              "regular",
              "high"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.Acceleration"
          },
          "default": "regular",
          "title": "Acceleration",
          "description": "The acceleration level to use."
        },
        {
          "name": "image_size",
          "type": {
            "type": "str"
          },
          "default": "landscape_4_3",
          "title": "Image Size",
          "description": "The size of the generated image."
        },
        {
          "name": "output_format",
          "type": {
            "type": "enum",
            "values": [
              "jpeg",
              "png"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.OutputFormat"
          },
          "default": "png",
          "title": "Output Format",
          "description": "The format of the generated image."
        },
        {
          "name": "loras",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "str"
              }
            ]
          },
          "default": [],
          "title": "Loras",
          "description": "The LoRAs to use for the image generation. You can use up to 3 LoRAs and they will be merged together to generate the final image."
        },
        {
          "name": "sync_mode",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Sync Mode",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history."
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If set to true, the safety checker will be enabled."
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed and the same prompt given to the same version of the model will output the same image every time."
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 4,
          "title": "Guidance Scale",
          "description": "The guidance scale to use for the image generation."
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "The negative prompt to generate an image from."
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 28,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt"
      ]
    },
    {
      "title": "Qwen Image Max Text To Image",
      "description": "Qwen Image Max generates premium quality images from text with superior detail and accuracy.\n    image, generation, qwen, max, premium, text-to-image\n\n    Use cases:\n    - Generate premium quality images\n    - Create detailed artwork from text\n    - Produce high-fidelity visual content\n    - Generate professional-grade images\n    - Create superior quality visuals",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.QwenImageMaxTextToImage",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "Text prompt describing the desired image. Supports Chinese and English. Max 800 characters."
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "The number of images to generate."
        },
        {
          "name": "image_size",
          "type": {
            "type": "str"
          },
          "default": "square_hd",
          "title": "Image Size",
          "description": "The size of the generated image."
        },
        {
          "name": "output_format",
          "type": {
            "type": "enum",
            "values": [
              "jpeg",
              "png"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.OutputFormat"
          },
          "default": "png",
          "title": "Output Format",
          "description": "The format of the generated image."
        },
        {
          "name": "sync_mode",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Sync Mode",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history."
        },
        {
          "name": "enable_prompt_expansion",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Prompt Expansion",
          "description": "Enable LLM prompt optimization for better results."
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Random seed for reproducibility (0-2147483647)."
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "Enable content moderation for input and output."
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "Content to avoid in the generated image. Max 500 characters."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt"
      ]
    },
    {
      "title": "Recraft V3",
      "description": "Recraft V3 is a powerful image generation model with exceptional control over style and colors, ideal for brand consistency and design work.\n    image, generation, design, branding, style, text-to-image, txt2img\n\n    Use cases:\n    - Create brand-consistent visual assets\n    - Generate designs with specific color palettes\n    - Produce stylized illustrations and artwork\n    - Design marketing materials with brand colors\n    - Create cohesive visual content series",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.RecraftV3",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "image_size",
          "type": {
            "type": "str"
          },
          "default": "square_hd",
          "title": "Image Size",
          "description": "Size preset for the generated image"
        },
        {
          "name": "style",
          "type": {
            "type": "enum",
            "values": [
              "any",
              "realistic_image",
              "digital_illustration",
              "vector_illustration",
              "realistic_image/b_and_w",
              "realistic_image/hard_flash",
              "realistic_image/hdr",
              "realistic_image/natural_light",
              "realistic_image/studio_portrait",
              "realistic_image/enterprise",
              "realistic_image/motion_blur",
              "realistic_image/evening_light",
              "realistic_image/faded_nostalgia",
              "realistic_image/forest_life",
              "realistic_image/mystic_naturalism",
              "realistic_image/natural_tones",
              "realistic_image/organic_calm",
              "realistic_image/real_life_glow",
              "realistic_image/retro_realism",
              "realistic_image/retro_snapshot",
              "realistic_image/urban_drama",
              "realistic_image/village_realism",
              "realistic_image/warm_folk",
              "digital_illustration/pixel_art",
              "digital_illustration/hand_drawn",
              "digital_illustration/grain",
              "digital_illustration/infantile_sketch",
              "digital_illustration/2d_art_poster",
              "digital_illustration/handmade_3d",
              "digital_illustration/hand_drawn_outline",
              "digital_illustration/engraving_color",
              "digital_illustration/2d_art_poster_2",
              "digital_illustration/antiquarian",
              "digital_illustration/bold_fantasy",
              "digital_illustration/child_book",
              "digital_illustration/child_books",
              "digital_illustration/cover",
              "digital_illustration/crosshatch",
              "digital_illustration/digital_engraving",
              "digital_illustration/expressionism",
              "digital_illustration/freehand_details",
              "digital_illustration/grain_20",
              "digital_illustration/graphic_intensity",
              "digital_illustration/hard_comics",
              "digital_illustration/long_shadow",
              "digital_illustration/modern_folk",
              "digital_illustration/multicolor",
              "digital_illustration/neon_calm",
              "digital_illustration/noir",
              "digital_illustration/nostalgic_pastel",
              "digital_illustration/outline_details",
              "digital_illustration/pastel_gradient",
              "digital_illustration/pastel_sketch",
              "digital_illustration/pop_art",
              "digital_illustration/pop_renaissance",
              "digital_illustration/street_art",
              "digital_illustration/tablet_sketch",
              "digital_illustration/urban_glow",
              "digital_illustration/urban_sketching",
              "digital_illustration/vanilla_dreams",
              "digital_illustration/young_adult_book",
              "digital_illustration/young_adult_book_2",
              "vector_illustration/bold_stroke",
              "vector_illustration/chemistry",
              "vector_illustration/colored_stencil",
              "vector_illustration/contour_pop_art",
              "vector_illustration/cosmics",
              "vector_illustration/cutout",
              "vector_illustration/depressive",
              "vector_illustration/editorial",
              "vector_illustration/emotional_flat",
              "vector_illustration/infographical",
              "vector_illustration/marker_outline",
              "vector_illustration/mosaic",
              "vector_illustration/naivector",
              "vector_illustration/roundish_flat",
              "vector_illustration/segmented_colors",
              "vector_illustration/sharp_contrast",
              "vector_illustration/thin",
              "vector_illustration/vector_photo",
              "vector_illustration/vivid_shapes",
              "vector_illustration/engraving",
              "vector_illustration/line_art",
              "vector_illustration/line_circuit",
              "vector_illustration/linocut"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.RecraftV3Style"
          },
          "default": "realistic_image",
          "title": "Style",
          "description": "Visual style preset for the generated image"
        },
        {
          "name": "colors",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "str"
              }
            ]
          },
          "default": [],
          "title": "Colors",
          "description": "Specific color palette to use in the generation"
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Enable Safety Checker",
          "description": "If set to true, the safety checker will be enabled."
        },
        {
          "name": "style_id",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Style Id",
          "description": "Custom style ID for brand-specific styles"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "style",
        "colors"
      ]
    },
    {
      "title": "Sana",
      "description": "Sana is an efficient high-resolution image generation model that balances quality and speed for practical applications.\n    image, generation, efficient, high-resolution, text-to-image, txt2img\n\n    Use cases:\n    - Generate high-resolution images efficiently\n    - Create detailed artwork with good performance\n    - Produce quality visuals with limited compute\n    - Generate images for web and mobile applications\n    - Balanced quality-speed image production",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.Sana",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "The number of images to generate."
        },
        {
          "name": "image_size",
          "type": {
            "type": "enum",
            "values": [
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
          },
          "default": "landscape_4_3",
          "title": "Image Size",
          "description": "Size preset for the generated image"
        },
        {
          "name": "style_name",
          "type": {
            "type": "enum",
            "values": [
              "(No style)",
              "Cinematic",
              "Photographic",
              "Anime",
              "Manga",
              "Digital Art",
              "Pixel art",
              "Fantasy art",
              "Neonpunk",
              "3D Model"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.StyleName"
          },
          "default": "(No style)",
          "title": "Style Name",
          "description": "The style to generate the image in."
        },
        {
          "name": "output_format",
          "type": {
            "type": "enum",
            "values": [
              "jpeg",
              "png"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.OutputFormat"
          },
          "default": "jpeg",
          "title": "Output Format",
          "description": "The format of the generated image."
        },
        {
          "name": "sync_mode",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Sync Mode",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history."
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 5,
          "title": "Guidance Scale",
          "description": "How strictly to follow the prompt"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 18,
          "title": "Num Inference Steps",
          "description": "Number of denoising steps"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed and the same prompt given to the same version of the model will output the same image every time."
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "Elements to avoid in the generated image"
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If set to true, the safety checker will be enabled."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "image_size",
        "guidance_scale"
      ]
    },
    {
      "title": "Stable Diffusion V35 Large",
      "description": "Stable Diffusion 3.5 Large is a powerful open-weight model with excellent prompt adherence and diverse output capabilities.\n    image, generation, stable-diffusion, open-source, text-to-image, txt2img\n\n    Use cases:\n    - Generate diverse artistic styles\n    - Create high-quality illustrations\n    - Produce photorealistic images\n    - Generate concept art and designs\n    - Create custom visual content",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.StableDiffusionV35Large",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "The number of images to generate."
        },
        {
          "name": "image_size",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Image Size",
          "description": "The size of the generated image. Defaults to landscape_4_3 if no controlnet has been passed, otherwise defaults to the size of the controlnet conditioning image."
        },
        {
          "name": "controlnet",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Controlnet",
          "description": "ControlNet for inference."
        },
        {
          "name": "output_format",
          "type": {
            "type": "enum",
            "values": [
              "jpeg",
              "png"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.OutputFormat"
          },
          "default": "jpeg",
          "title": "Output Format",
          "description": "The format of the generated image."
        },
        {
          "name": "ip_adapter",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Ip Adapter",
          "description": "IP-Adapter to use during inference."
        },
        {
          "name": "sync_mode",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Sync Mode",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history."
        },
        {
          "name": "loras",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "str"
              }
            ]
          },
          "default": [],
          "title": "Loras",
          "description": "The LoRAs to use for the image generation. You can use any number of LoRAs and they will be merged together to generate the final image."
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If set to true, the safety checker will be enabled."
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 28,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform."
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 3.5,
          "title": "Guidance Scale",
          "description": "The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you."
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "Elements to avoid in the generated image"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed and the same prompt given to the same version of the model will output the same image every time."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "negative_prompt",
        "aspect_ratio"
      ]
    },
    {
      "title": "Vidu Q2 Text To Image",
      "description": "Vidu Q2 generates quality images from text with optimized performance and consistent results.\n    image, generation, vidu, q2, optimized, text-to-image\n\n    Use cases:\n    - Generate optimized quality images\n    - Create consistent visual content\n    - Produce balanced artwork\n    - Generate images efficiently\n    - Create reliable visuals",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.ViduQ2TextToImage",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "Text prompt for video generation, max 1500 characters"
        },
        {
          "name": "aspect_ratio",
          "type": {
            "type": "enum",
            "values": [
              "10:16",
              "16:10",
              "9:16",
              "16:9",
              "4:3",
              "3:4",
              "1:1",
              "1:3",
              "3:1",
              "3:2",
              "2:3"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.AspectRatio"
          },
          "default": "16:9",
          "title": "Aspect Ratio",
          "description": "The aspect ratio of the output video"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Random seed for generation"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt"
      ]
    },
    {
      "title": "Wan V26 Text To Image",
      "description": "Wan v2.6 generates high-quality images from text with advanced capabilities and consistent results.\n    image, generation, wan, v2.6, quality, text-to-image\n\n    Use cases:\n    - Generate quality images with Wan v2.6\n    - Create consistent visual content\n    - Produce reliable artwork from text\n    - Generate images with advanced model\n    - Create high-quality visuals",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.WanV26TextToImage",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "Text prompt describing the desired image. Supports Chinese and English. Max 2000 characters."
        },
        {
          "name": "image_size",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Image Size",
          "description": "Output image size. If not set: matches input image size (up to 1280*1280). Use presets like 'square_hd', 'landscape_16_9', or specify exact dimensions."
        },
        {
          "name": "max_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Max Images",
          "description": "Maximum number of images to generate (1-5). Actual count may be less depending on model inference."
        },
        {
          "name": "image_url",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image Url",
          "description": "Optional reference image (0 or 1). When provided, can be used for style guidance. Resolution: 384-5000px each dimension. Max size: 10MB. Formats: JPEG, JPG, PNG (no alpha), BMP, WEBP."
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "Enable content moderation for input and output."
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Random seed for reproducibility (0-2147483647)."
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "Content to avoid in the generated image. Max 500 characters."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt"
      ]
    },
    {
      "title": "ZImage Base",
      "description": "Z-Image Base generates quality images from text with efficient processing and good results.\n    image, generation, z-image, base, efficient, text-to-image\n\n    Use cases:\n    - Generate images efficiently\n    - Create quality artwork from text\n    - Produce visual content quickly\n    - Generate images with good performance\n    - Create efficient visuals",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.ZImageBase",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from."
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "The number of images to generate."
        },
        {
          "name": "image_size",
          "type": {
            "type": "str"
          },
          "default": "landscape_4_3",
          "title": "Image Size",
          "description": "The size of the generated image."
        },
        {
          "name": "acceleration",
          "type": {
            "type": "enum",
            "values": [
              "none",
              "regular",
              "high"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.Acceleration"
          },
          "default": "regular",
          "title": "Acceleration",
          "description": "The acceleration level to use."
        },
        {
          "name": "output_format",
          "type": {
            "type": "enum",
            "values": [
              "jpeg",
              "png"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.OutputFormat"
          },
          "default": "png",
          "title": "Output Format",
          "description": "The format of the generated image."
        },
        {
          "name": "sync_mode",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Sync Mode",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history."
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 4,
          "title": "Guidance Scale",
          "description": "The guidance scale to use for the image generation."
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed and the same prompt given to the same version of the model will output the same image every time."
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If set to true, the safety checker will be enabled."
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "The negative prompt to use for the image generation."
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 28,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt"
      ]
    },
    {
      "title": "ZImage Base Lora",
      "description": "Z-Image Base with LoRA enables efficient custom-trained models for specialized generation tasks.\n    image, generation, z-image, base, lora, custom\n\n    Use cases:\n    - Generate images with custom efficient models\n    - Create specialized content quickly\n    - Produce domain-specific visuals\n    - Generate with fine-tuned base model\n    - Create efficient custom visuals",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.ZImageBaseLora",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from."
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "The number of images to generate."
        },
        {
          "name": "image_size",
          "type": {
            "type": "str"
          },
          "default": "landscape_4_3",
          "title": "Image Size",
          "description": "The size of the generated image."
        },
        {
          "name": "acceleration",
          "type": {
            "type": "enum",
            "values": [
              "none",
              "regular",
              "high"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.Acceleration"
          },
          "default": "regular",
          "title": "Acceleration",
          "description": "The acceleration level to use."
        },
        {
          "name": "output_format",
          "type": {
            "type": "enum",
            "values": [
              "jpeg",
              "png"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.OutputFormat"
          },
          "default": "png",
          "title": "Output Format",
          "description": "The format of the generated image."
        },
        {
          "name": "sync_mode",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Sync Mode",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history."
        },
        {
          "name": "loras",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "str"
              }
            ]
          },
          "default": [],
          "title": "Loras",
          "description": "List of LoRA weights to apply (maximum 3)."
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 4,
          "title": "Guidance Scale",
          "description": "The guidance scale to use for the image generation."
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed and the same prompt given to the same version of the model will output the same image every time."
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If set to true, the safety checker will be enabled."
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "The negative prompt to use for the image generation."
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 28,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt"
      ]
    },
    {
      "title": "ZImage Turbo",
      "description": "Z-Image Turbo generates images from text with maximum speed for rapid iteration and prototyping.\n    image, generation, z-image, turbo, fast, text-to-image\n\n    Use cases:\n    - Generate images at maximum speed\n    - Create rapid prototypes from text\n    - Produce quick visual iterations\n    - Generate images for fast workflows\n    - Create instant visual content",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.ZImageTurbo",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from."
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "The number of images to generate."
        },
        {
          "name": "image_size",
          "type": {
            "type": "str"
          },
          "default": "landscape_4_3",
          "title": "Image Size",
          "description": "The size of the generated image."
        },
        {
          "name": "acceleration",
          "type": {
            "type": "enum",
            "values": [
              "none",
              "regular",
              "high"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.Acceleration"
          },
          "default": "regular",
          "title": "Acceleration",
          "description": "The acceleration level to use."
        },
        {
          "name": "output_format",
          "type": {
            "type": "enum",
            "values": [
              "jpeg",
              "png"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.OutputFormat"
          },
          "default": "png",
          "title": "Output Format",
          "description": "The format of the generated image."
        },
        {
          "name": "sync_mode",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Sync Mode",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history."
        },
        {
          "name": "enable_prompt_expansion",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Enable Prompt Expansion",
          "description": "Whether to enable prompt expansion. Note: this will increase the price by 0.0025 credits per request."
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed and the same prompt given to the same version of the model will output the same image every time."
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If set to true, the safety checker will be enabled."
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 8,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt"
      ]
    },
    {
      "title": "ZImage Turbo Lora",
      "description": "Z-Image Turbo with LoRA combines maximum speed with custom models for fast specialized generation.\n    image, generation, z-image, turbo, lora, fast\n\n    Use cases:\n    - Generate custom images at turbo speed\n    - Create specialized content rapidly\n    - Produce quick domain-specific visuals\n    - Generate with fast fine-tuned models\n    - Create instant custom visuals",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.ZImageTurboLora",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from."
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "The number of images to generate."
        },
        {
          "name": "image_size",
          "type": {
            "type": "str"
          },
          "default": "landscape_4_3",
          "title": "Image Size",
          "description": "The size of the generated image."
        },
        {
          "name": "acceleration",
          "type": {
            "type": "enum",
            "values": [
              "none",
              "regular",
              "high"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.Acceleration"
          },
          "default": "regular",
          "title": "Acceleration",
          "description": "The acceleration level to use."
        },
        {
          "name": "output_format",
          "type": {
            "type": "enum",
            "values": [
              "jpeg",
              "png"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.OutputFormat"
          },
          "default": "png",
          "title": "Output Format",
          "description": "The format of the generated image."
        },
        {
          "name": "sync_mode",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Sync Mode",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history."
        },
        {
          "name": "loras",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "str"
              }
            ]
          },
          "default": [],
          "title": "Loras",
          "description": "List of LoRA weights to apply (maximum 3)."
        },
        {
          "name": "enable_prompt_expansion",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Enable Prompt Expansion",
          "description": "Whether to enable prompt expansion. Note: this will increase the price by 0.0025 credits per request."
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed and the same prompt given to the same version of the model will output the same image every time."
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If set to true, the safety checker will be enabled."
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 8,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt"
      ]
    },
    {
      "title": "AIAvatar",
      "description": "MultiTalk generates talking avatar videos from images and audio files.\n    video, avatar, talking-head, multitalk, image-to-video\n\n    Use cases:\n    - Create talking avatar videos\n    - Animate portrait photos with audio\n    - Generate spokesperson videos\n    - Produce avatar presentations\n    - Create personalized video messages",
      "namespace": "fal.image_to_video",
      "node_type": "fal.image_to_video.AIAvatar",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The text prompt to guide video generation."
        },
        {
          "name": "resolution",
          "type": {
            "type": "enum",
            "values": [
              "480p",
              "720p"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.AIAvatarResolution"
          },
          "default": "480p",
          "title": "Resolution",
          "description": "Resolution of the video to generate. Must be either 480p or 720p."
        },
        {
          "name": "acceleration",
          "type": {
            "type": "enum",
            "values": [
              "none",
              "regular",
              "high"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.Acceleration"
          },
          "default": "regular",
          "title": "Acceleration",
          "description": "The acceleration level to use for generation."
        },
        {
          "name": "image_url",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image Url",
          "description": "URL of the input image. If the input image does not match the chosen aspect ratio, it is resized and center cropped."
        },
        {
          "name": "audio_url",
          "type": {
            "type": "audio"
          },
          "default": {
            "type": "audio",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Audio Url",
          "description": "The URL of the audio file."
        },
        {
          "name": "num_frames",
          "type": {
            "type": "int"
          },
          "default": 145,
          "title": "Num Frames",
          "description": "Number of frames to generate. Must be between 81 to 129 (inclusive). If the number of frames is greater than 81, the video will be generated with 1.25x more billing units."
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": 42,
          "title": "Seed",
          "description": "Random seed for reproducibility. If None, a random seed is chosen."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "audio"
      ]
    },
    {
      "title": "AIAvatar Multi",
      "description": "MultiTalk generates multi-speaker avatar videos with audio synchronization.\n    video, avatar, multi-speaker, talking-head, image-to-video\n\n    Use cases:\n    - Create multi-speaker videos with audio\n    - Generate synchronized dialogue\n    - Produce conversation videos\n    - Create interactive characters\n    - Generate multi-avatar content",
      "namespace": "fal.image_to_video",
      "node_type": "fal.image_to_video.AIAvatarMulti",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The text prompt to guide video generation."
        },
        {
          "name": "resolution",
          "type": {
            "type": "enum",
            "values": [
              "480p",
              "720p"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.AIAvatarMultiResolution"
          },
          "default": "480p",
          "title": "Resolution",
          "description": "Resolution of the video to generate. Must be either 480p or 720p."
        },
        {
          "name": "acceleration",
          "type": {
            "type": "enum",
            "values": [
              "none",
              "regular",
              "high"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.Acceleration"
          },
          "default": "regular",
          "title": "Acceleration",
          "description": "The acceleration level to use for generation."
        },
        {
          "name": "first_audio_url",
          "type": {
            "type": "audio"
          },
          "default": {
            "type": "audio",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "First Audio Url",
          "description": "The URL of the Person 1 audio file."
        },
        {
          "name": "image_url",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image Url",
          "description": "URL of the input image. If the input image does not match the chosen aspect ratio, it is resized and center cropped."
        },
        {
          "name": "second_audio_url",
          "type": {
            "type": "audio"
          },
          "default": {
            "type": "audio",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Second Audio Url",
          "description": "The URL of the Person 2 audio file."
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": 81,
          "title": "Seed",
          "description": "Random seed for reproducibility. If None, a random seed is chosen."
        },
        {
          "name": "use_only_first_audio",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Use Only First Audio",
          "description": "Whether to use only the first audio file."
        },
        {
          "name": "num_frames",
          "type": {
            "type": "int"
          },
          "default": 181,
          "title": "Num Frames",
          "description": "Number of frames to generate. Must be between 81 to 129 (inclusive). If the number of frames is greater than 81, the video will be generated with 1.25x more billing units."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "images",
        "audio"
      ]
    },
    {
      "title": "AIAvatar Multi Text",
      "description": "MultiTalk generates multi-speaker avatar videos from images and text.\n    video, avatar, multi-speaker, talking-head, image-to-video\n\n    Use cases:\n    - Create multi-speaker conversations\n    - Generate dialogue between avatars\n    - Produce interactive presentations\n    - Create conversational content\n    - Generate multi-character scenes",
      "namespace": "fal.image_to_video",
      "node_type": "fal.image_to_video.AIAvatarMultiText",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The text prompt to guide video generation."
        },
        {
          "name": "second_text_input",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Second Text Input",
          "description": "The text input to guide video generation."
        },
        {
          "name": "acceleration",
          "type": {
            "type": "enum",
            "values": [
              "none",
              "regular",
              "high"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.Acceleration"
          },
          "default": "regular",
          "title": "Acceleration",
          "description": "The acceleration level to use for generation."
        },
        {
          "name": "resolution",
          "type": {
            "type": "enum",
            "values": [
              "480p",
              "720p"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.AIAvatarMultiTextResolution"
          },
          "default": "480p",
          "title": "Resolution",
          "description": "Resolution of the video to generate. Must be either 480p or 720p."
        },
        {
          "name": "first_text_input",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "First Text Input",
          "description": "The text input to guide video generation."
        },
        {
          "name": "image_url",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image Url",
          "description": "URL of the input image. If the input image does not match the chosen aspect ratio, it is resized and center cropped."
        },
        {
          "name": "voice2",
          "type": {
            "type": "enum",
            "values": [
              "Aria",
              "Roger",
              "Sarah",
              "Laura",
              "Charlie",
              "George",
              "Callum",
              "River",
              "Liam",
              "Charlotte",
              "Alice",
              "Matilda",
              "Will",
              "Jessica",
              "Eric",
              "Chris",
              "Brian",
              "Daniel",
              "Lily",
              "Bill"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.Voice2"
          },
          "default": "Roger",
          "title": "Voice2",
          "description": "The second person's voice to use for speech generation"
        },
        {
          "name": "voice1",
          "type": {
            "type": "enum",
            "values": [
              "Aria",
              "Roger",
              "Sarah",
              "Laura",
              "Charlie",
              "George",
              "Callum",
              "River",
              "Liam",
              "Charlotte",
              "Alice",
              "Matilda",
              "Will",
              "Jessica",
              "Eric",
              "Chris",
              "Brian",
              "Daniel",
              "Lily",
              "Bill"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.Voice1"
          },
          "default": "Sarah",
          "title": "Voice1",
          "description": "The first person's voice to use for speech generation"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": 81,
          "title": "Seed",
          "description": "Random seed for reproducibility. If None, a random seed is chosen."
        },
        {
          "name": "num_frames",
          "type": {
            "type": "int"
          },
          "default": 191,
          "title": "Num Frames",
          "description": "Number of frames to generate. Must be between 81 to 129 (inclusive). If the number of frames is greater than 81, the video will be generated with 1.25x more billing units."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "images",
        "texts"
      ]
    },
    {
      "title": "AIAvatar Single Text",
      "description": "MultiTalk generates talking avatar videos from an image and text input.\n    video, avatar, talking-head, text-to-speech, image-to-video\n\n    Use cases:\n    - Create avatar videos from text\n    - Generate talking heads with TTS\n    - Produce text-driven avatars\n    - Create virtual presenters\n    - Generate automated spokesperson videos",
      "namespace": "fal.image_to_video",
      "node_type": "fal.image_to_video.AIAvatarSingleText",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The text prompt to guide video generation."
        },
        {
          "name": "resolution",
          "type": {
            "type": "enum",
            "values": [
              "480p",
              "720p"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.AIAvatarSingleTextResolution"
          },
          "default": "480p",
          "title": "Resolution",
          "description": "Resolution of the video to generate. Must be either 480p or 720p."
        },
        {
          "name": "acceleration",
          "type": {
            "type": "enum",
            "values": [
              "none",
              "regular",
              "high"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.Acceleration"
          },
          "default": "regular",
          "title": "Acceleration",
          "description": "The acceleration level to use for generation."
        },
        {
          "name": "text_input",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Text Input",
          "description": "The text input to guide video generation."
        },
        {
          "name": "image_url",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image Url",
          "description": "URL of the input image. If the input image does not match the chosen aspect ratio, it is resized and center cropped."
        },
        {
          "name": "voice",
          "type": {
            "type": "enum",
            "values": [
              "Aria",
              "Roger",
              "Sarah",
              "Laura",
              "Charlie",
              "George",
              "Callum",
              "River",
              "Liam",
              "Charlotte",
              "Alice",
              "Matilda",
              "Will",
              "Jessica",
              "Eric",
              "Chris",
              "Brian",
              "Daniel",
              "Lily",
              "Bill"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.Voice"
          },
          "default": "",
          "title": "Voice",
          "description": "The voice to use for speech generation"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": 42,
          "title": "Seed",
          "description": "Random seed for reproducibility. If None, a random seed is chosen."
        },
        {
          "name": "num_frames",
          "type": {
            "type": "int"
          },
          "default": 136,
          "title": "Num Frames",
          "description": "Number of frames to generate. Must be between 81 to 129 (inclusive). If the number of frames is greater than 81, the video will be generated with 1.25x more billing units."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "text"
      ]
    },
    {
      "title": "AMTFrame Interpolation",
      "description": "AMT Frame Interpolation creates smooth transitions between image frames.\n    video, interpolation, frame-generation, amt, image-to-video\n\n    Use cases:\n    - Create smooth transitions between images\n    - Generate intermediate frames\n    - Animate image sequences\n    - Create video from image pairs\n    - Produce smooth motion effects",
      "namespace": "fal.image_to_video",
      "node_type": "fal.image_to_video.AMTFrameInterpolation",
      "properties": [
        {
          "name": "frames",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "str"
              }
            ]
          },
          "default": [],
          "title": "Frames",
          "description": "Frames to interpolate"
        },
        {
          "name": "recursive_interpolation_passes",
          "type": {
            "type": "int"
          },
          "default": 4,
          "title": "Recursive Interpolation Passes",
          "description": "Number of recursive interpolation passes"
        },
        {
          "name": "output_fps",
          "type": {
            "type": "int"
          },
          "default": 24,
          "title": "Output Fps",
          "description": "Output frames per second"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image"
      ]
    },
    {
      "title": "Byte Dance Video Stylize",
      "description": "ByteDance Video Stylize applies artistic styles to image-based video generation.\n    video, style-transfer, artistic, bytedance, image-to-video\n\n    Use cases:\n    - Apply artistic styles to videos\n    - Create stylized video content\n    - Generate artistic animations\n    - Produce style-transferred videos\n    - Create visually unique content",
      "namespace": "fal.image_to_video",
      "node_type": "fal.image_to_video.ByteDanceVideoStylize",
      "properties": [
        {
          "name": "style",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Style",
          "description": "The style for your character in the video. Please use a short description."
        },
        {
          "name": "image_url",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image Url",
          "description": "URL of the image to make the stylized video from."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "any"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "style"
      ]
    },
    {
      "title": "Cog Video X5 BImage To Video",
      "description": "CogVideoX-5B generates high-quality videos from images with advanced motion.\n    video, generation, cogvideo, image-to-video, img2vid\n\n    Use cases:\n    - Generate videos from images\n    - Create dynamic image animations\n    - Produce high-quality video content\n    - Animate static images\n    - Generate motion from photos",
      "namespace": "fal.image_to_video",
      "node_type": "fal.image_to_video.CogVideoX5BImageToVideo",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate the video from."
        },
        {
          "name": "use_rife",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Use Rife",
          "description": "Use RIFE for video interpolation"
        },
        {
          "name": "image_url",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image Url",
          "description": "The URL to the image to generate the video from."
        },
        {
          "name": "loras",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "str"
              }
            ]
          },
          "default": [],
          "title": "Loras",
          "description": "The LoRAs to use for the image generation. We currently support one lora."
        },
        {
          "name": "video_size",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Video Size",
          "description": "The size of the generated video."
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 7,
          "title": "Guidance Scale",
          "description": "The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related video to show you."
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 50,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform."
        },
        {
          "name": "export_fps",
          "type": {
            "type": "int"
          },
          "default": 16,
          "title": "Export Fps",
          "description": "The target FPS of the video"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "The negative prompt to generate video from"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed and the same prompt given to the same version of the model will output the same video every time."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "Creatify Aurora",
      "description": "Creatify Aurora generates creative and visually stunning videos from images with unique effects.\n    video, generation, creatify, aurora, creative, effects\n\n    Use cases:\n    - Generate creative visual effects videos\n    - Create stunning video animations\n    - Produce artistic video content\n    - Generate unique video effects\n    - Create visually impressive videos",
      "namespace": "fal.image_to_video",
      "node_type": "fal.image_to_video.CreatifyAurora",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "A text prompt to guide the video generation process."
        },
        {
          "name": "resolution",
          "type": {
            "type": "enum",
            "values": [
              "480p",
              "720p"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.CreatifyAuroraResolution"
          },
          "default": "720p",
          "title": "Resolution",
          "description": "The resolution of the generated video."
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 1,
          "title": "Guidance Scale",
          "description": "Guidance scale to be used for text prompt adherence."
        },
        {
          "name": "audio_guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 2,
          "title": "Audio Guidance Scale",
          "description": "Guidance scale to be used for audio adherence."
        },
        {
          "name": "audio_url",
          "type": {
            "type": "video"
          },
          "default": {
            "type": "video",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null,
            "duration": null,
            "format": null
          },
          "title": "Audio Url",
          "description": "The URL of the audio file to be used for video generation."
        },
        {
          "name": "image_url",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image Url",
          "description": "The URL of the image file to be used for video generation."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "Hunyuan Video V15 Image To Video",
      "description": "Hunyuan Video v1.5 generates high-quality videos from images with advanced AI capabilities.\n    video, generation, hunyuan, v1.5, advanced\n\n    Use cases:\n    - Generate advanced quality videos\n    - Create sophisticated animations\n    - Produce high-fidelity video content\n    - Generate videos with AI excellence\n    - Create cutting-edge video animations",
      "namespace": "fal.image_to_video",
      "node_type": "fal.image_to_video.HunyuanVideoV15ImageToVideo",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate the video from."
        },
        {
          "name": "aspect_ratio",
          "type": {
            "type": "enum",
            "values": [
              "16:9",
              "9:16",
              "4:3",
              "3:4",
              "21:9",
              "9:21"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.AspectRatio"
          },
          "default": "16:9",
          "title": "Aspect Ratio",
          "description": "The aspect ratio of the video."
        },
        {
          "name": "resolution",
          "type": {
            "type": "enum",
            "values": [
              "480p"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.HunyuanVideoV15Resolution"
          },
          "default": "480p",
          "title": "Resolution",
          "description": "The resolution of the video."
        },
        {
          "name": "image_url",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image Url",
          "description": "URL of the reference image for image-to-video generation."
        },
        {
          "name": "enable_prompt_expansion",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Prompt Expansion",
          "description": "Enable prompt expansion to enhance the input prompt."
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Random seed for reproducibility."
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 28,
          "title": "Num Inference Steps",
          "description": "The number of inference steps."
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "The negative prompt to guide what not to generate."
        },
        {
          "name": "num_frames",
          "type": {
            "type": "int"
          },
          "default": 121,
          "title": "Num Frames",
          "description": "The number of frames to generate."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "Kandinsky 5 Pro Image To Video",
      "description": "Kandinsky5 Pro generates professional quality videos from images with artistic style and control.\n    video, generation, kandinsky, pro, artistic\n\n    Use cases:\n    - Generate artistic videos from images\n    - Create stylized video animations\n    - Produce creative video content\n    - Generate videos with artistic flair\n    - Create professional artistic videos",
      "namespace": "fal.image_to_video",
      "node_type": "fal.image_to_video.Kandinsky5ProImageToVideo",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate the video from."
        },
        {
          "name": "resolution",
          "type": {
            "type": "enum",
            "values": [
              "512P",
              "1024P"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.Kandinsky5ProResolution"
          },
          "default": "512P",
          "title": "Resolution",
          "description": "Video resolution: 512p or 1024p."
        },
        {
          "name": "acceleration",
          "type": {
            "type": "enum",
            "values": [
              "none",
              "regular",
              "high"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.Acceleration"
          },
          "default": "regular",
          "title": "Acceleration",
          "description": "Acceleration level for faster generation."
        },
        {
          "name": "duration",
          "type": {
            "type": "enum",
            "values": [
              "5s"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.Kandinsky5ProDuration"
          },
          "default": "5s",
          "title": "Duration",
          "description": "Video duration."
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 28,
          "title": "Num Inference Steps"
        },
        {
          "name": "image_url",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image Url",
          "description": "The URL of the image to use as a reference for the video generation."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "Kling Video Ai Avatar V2 Pro",
      "description": "Kling Video AI Avatar v2 Pro creates professional quality animated talking avatars with enhanced realism.\n    video, avatar, kling, v2, pro, talking-head\n\n    Use cases:\n    - Create professional talking avatars\n    - Animate portraits with high quality\n    - Generate realistic avatar videos\n    - Produce premium speaking characters\n    - Create pro-grade AI avatars",
      "namespace": "fal.image_to_video",
      "node_type": "fal.image_to_video.KlingVideoAiAvatarV2Pro",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": ".",
          "title": "Prompt",
          "description": "The prompt to use for the video generation."
        },
        {
          "name": "audio_url",
          "type": {
            "type": "audio"
          },
          "default": {
            "type": "audio",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Audio Url",
          "description": "The URL of the audio file."
        },
        {
          "name": "image_url",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image Url",
          "description": "The URL of the image to use as your avatar"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "Kling Video Ai Avatar V2 Standard",
      "description": "Kling Video AI Avatar v2 Standard creates animated talking avatars with standard quality.\n    video, avatar, kling, v2, standard, talking-head\n\n    Use cases:\n    - Create standard quality talking avatars\n    - Animate portraits with speech\n    - Generate avatar presentations\n    - Produce speaking character videos\n    - Create AI-driven avatars",
      "namespace": "fal.image_to_video",
      "node_type": "fal.image_to_video.KlingVideoAiAvatarV2Standard",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": ".",
          "title": "Prompt",
          "description": "The prompt to use for the video generation."
        },
        {
          "name": "audio_url",
          "type": {
            "type": "audio"
          },
          "default": {
            "type": "audio",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Audio Url",
          "description": "The URL of the audio file."
        },
        {
          "name": "image_url",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image Url",
          "description": "The URL of the image to use as your avatar"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "Kling Video O1 Standard Image To Video",
      "description": "Kling Video O1 Standard generates videos with optimized standard quality from images.\n    video, generation, kling, o1, standard\n\n    Use cases:\n    - Generate standard O1 quality videos\n    - Create optimized video animations\n    - Produce efficient video content\n    - Generate balanced quality videos\n    - Create standard tier animations",
      "namespace": "fal.image_to_video",
      "node_type": "fal.image_to_video.KlingVideoO1StandardImageToVideo",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "Use @Image1 to reference the start frame, @Image2 to reference the end frame."
        },
        {
          "name": "duration",
          "type": {
            "type": "enum",
            "values": [
              "3",
              "4",
              "5",
              "6",
              "7",
              "8",
              "9",
              "10"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.KlingVideoO1StandardDuration"
          },
          "default": "5",
          "title": "Duration",
          "description": "Video duration in seconds."
        },
        {
          "name": "start_image_url",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Start Image Url",
          "description": "Image to use as the first frame of the video. Max file size: 10.0MB, Min width: 300px, Min height: 300px, Min aspect ratio: 0.40, Max aspect ratio: 2.50, Timeout: 20.0s"
        },
        {
          "name": "end_image_url",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "End Image Url",
          "description": "Image to use as the last frame of the video. Max file size: 10.0MB, Min width: 300px, Min height: 300px, Min aspect ratio: 0.40, Max aspect ratio: 2.50, Timeout: 20.0s"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "Kling Video O1 Standard Reference To Video",
      "description": "Kling Video O1 Standard generates videos using reference images for style consistency.\n    video, generation, kling, o1, standard, reference\n\n    Use cases:\n    - Generate videos from reference images\n    - Create style-consistent animations\n    - Produce reference-guided content\n    - Generate videos matching examples\n    - Create standardized reference videos",
      "namespace": "fal.image_to_video",
      "node_type": "fal.image_to_video.KlingVideoO1StandardReferenceToVideo",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "Take @Element1, @Element2 to reference elements and @Image1, @Image2 to reference images in order."
        },
        {
          "name": "aspect_ratio",
          "type": {
            "type": "enum",
            "values": [
              "16:9",
              "9:16",
              "4:3",
              "3:4",
              "21:9",
              "9:21"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.AspectRatio"
          },
          "default": "16:9",
          "title": "Aspect Ratio",
          "description": "The aspect ratio of the generated video frame."
        },
        {
          "name": "duration",
          "type": {
            "type": "enum",
            "values": [
              "3",
              "4",
              "5",
              "6",
              "7",
              "8",
              "9",
              "10"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.KlingVideoO1StandardReferenceToVideoDuration"
          },
          "default": "5",
          "title": "Duration",
          "description": "Video duration in seconds."
        },
        {
          "name": "elements",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "str"
              }
            ]
          },
          "default": [],
          "title": "Elements",
          "description": "Elements (characters/objects) to include in the video. Reference in prompt as @Element1, @Element2, etc. Maximum 7 total (elements + reference images + start image)."
        },
        {
          "name": "image_urls",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "str"
              }
            ]
          },
          "default": [],
          "title": "Image Urls",
          "description": "Additional reference images for style/appearance. Reference in prompt as @Image1, @Image2, etc. Maximum 7 total (elements + reference images + start image)."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "Kling Video V1 Standard Image To Video",
      "description": "Kling Video v1 Standard generates videos from images with balanced quality.\n    video, generation, kling, standard, image-to-video\n\n    Use cases:\n    - Generate standard quality videos\n    - Create balanced video animations\n    - Produce efficient video content\n    - Generate videos for web use\n    - Create moderate quality outputs",
      "namespace": "fal.image_to_video",
      "node_type": "fal.image_to_video.KlingVideoV1StandardImageToVideo",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt for the video"
        },
        {
          "name": "duration",
          "type": {
            "type": "enum",
            "values": [
              "5",
              "10"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.KlingVideoV1StandardDuration"
          },
          "default": "5",
          "title": "Duration",
          "description": "The duration of the generated video in seconds"
        },
        {
          "name": "tail_image_url",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Tail Image Url",
          "description": "URL of the image to be used for the end of the video"
        },
        {
          "name": "image_url",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image Url",
          "description": "URL of the image to be used for the video"
        },
        {
          "name": "static_mask_url",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Static Mask Url",
          "description": "URL of the image for Static Brush Application Area (Mask image created by users using the motion brush)"
        },
        {
          "name": "dynamic_masks",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "str"
              }
            ]
          },
          "default": [],
          "title": "Dynamic Masks",
          "description": "List of dynamic masks"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "blur, distort, and low quality",
          "title": "Negative Prompt"
        },
        {
          "name": "cfg_scale",
          "type": {
            "type": "float"
          },
          "default": 0.5,
          "title": "Cfg Scale",
          "description": "The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "Kling Video V26 Pro Image To Video",
      "description": "Kling Video v2.6 Pro generates professional quality videos with latest model improvements.\n    video, generation, kling, v2.6, pro\n\n    Use cases:\n    - Generate professional v2.6 videos\n    - Create latest quality animations\n    - Produce premium video content\n    - Generate advanced videos\n    - Create pro-tier animations",
      "namespace": "fal.image_to_video",
      "node_type": "fal.image_to_video.KlingVideoV26ProImageToVideo",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt"
        },
        {
          "name": "duration",
          "type": {
            "type": "enum",
            "values": [
              "5",
              "10"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.KlingVideoV26ProDuration"
          },
          "default": "5",
          "title": "Duration",
          "description": "The duration of the generated video in seconds"
        },
        {
          "name": "voice_ids",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "str"
              }
            ]
          },
          "default": [],
          "title": "Voice Ids",
          "description": "Optional Voice IDs for video generation. Reference voices in your prompt with <<<voice_1>>> and <<<voice_2>>> (maximum 2 voices per task). Get voice IDs from the kling video create-voice endpoint: https://fal.ai/models/fal-ai/kling-video/create-voice"
        },
        {
          "name": "generate_audio",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Generate Audio",
          "description": "Whether to generate native audio for the video. Supports Chinese and English voice output. Other languages are automatically translated to English. For English speech, use lowercase letters; for acronyms or proper nouns, use uppercase."
        },
        {
          "name": "start_image_url",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Start Image Url",
          "description": "URL of the image to be used for the video"
        },
        {
          "name": "end_image_url",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "End Image Url",
          "description": "URL of the image to be used for the end of the video"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "blur, distort, and low quality",
          "title": "Negative Prompt"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "LTXImage To Video",
      "description": "LTX Video generates temporally consistent videos from images.\n    video, generation, ltx, temporal, image-to-video\n\n    Use cases:\n    - Generate temporally consistent videos\n    - Create smooth image animations\n    - Produce coherent video sequences\n    - Animate with temporal awareness\n    - Generate fluid motion videos",
      "namespace": "fal.image_to_video",
      "node_type": "fal.image_to_video.LTXImageToVideo",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate the video from."
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 3,
          "title": "Guidance Scale",
          "description": "The guidance scale to use."
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The seed to use for random number generation."
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 30,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to take."
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "low quality, worst quality, deformed, distorted, disfigured, motion smear, motion artifacts, fused fingers, bad anatomy, weird hand, ugly",
          "title": "Negative Prompt",
          "description": "The negative prompt to generate the video from."
        },
        {
          "name": "image_url",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image Url",
          "description": "The URL of the image to generate the video from."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "Live Avatar",
      "description": "Live Avatar creates animated talking avatars from portrait images with realistic lip-sync and expressions.\n    video, avatar, talking-head, animation, portrait\n\n    Use cases:\n    - Create talking avatar videos\n    - Animate portrait images\n    - Generate lip-synced avatars\n    - Produce speaking character videos\n    - Create animated presenters",
      "namespace": "fal.image_to_video",
      "node_type": "fal.image_to_video.LiveAvatar",
      "properties": [
        {
          "name": "frames_per_clip",
          "type": {
            "type": "int"
          },
          "default": 48,
          "title": "Frames Per Clip",
          "description": "Number of frames per clip. Must be a multiple of 4. Higher values = smoother but slower generation."
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "A text prompt describing the scene and character. Helps guide the video generation style and context."
        },
        {
          "name": "acceleration",
          "type": {
            "type": "enum",
            "values": [
              "none",
              "regular",
              "high"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.Acceleration"
          },
          "default": "none",
          "title": "Acceleration",
          "description": "Acceleration level for faster video decoding"
        },
        {
          "name": "image_url",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image Url",
          "description": "The URL of the reference image for avatar generation. The character in this image will be animated."
        },
        {
          "name": "num_clips",
          "type": {
            "type": "int"
          },
          "default": 10,
          "title": "Num Clips",
          "description": "Number of video clips to generate. Each clip is approximately 3 seconds. Set higher for longer videos."
        },
        {
          "name": "audio_url",
          "type": {
            "type": "audio"
          },
          "default": {
            "type": "audio",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Audio Url",
          "description": "The URL of the driving audio file (WAV or MP3). The avatar will be animated to match this audio."
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Random seed for reproducible generation."
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 0,
          "title": "Guidance Scale",
          "description": "Classifier-free guidance scale. Higher values follow the prompt more closely."
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "Enable safety checker for content moderation."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "Ltx 219B Distilled Image To Video",
      "description": "LTX-2 19B Distilled generates videos efficiently using knowledge distillation from the 19B model.\n    video, generation, ltx-2, 19b, distilled, efficient\n\n    Use cases:\n    - Generate videos efficiently with distilled model\n    - Create fast quality video animations\n    - Produce optimized video content\n    - Generate videos with good performance\n    - Create balanced quality-speed videos",
      "namespace": "fal.image_to_video",
      "node_type": "fal.image_to_video.Ltx219BDistilledImageToVideo",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt used for the generation."
        },
        {
          "name": "use_multiscale",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Use Multiscale",
          "description": "Whether to use multi-scale generation. If True, the model will generate the video at a smaller scale first, then use the smaller video to guide the generation of a video at or above your requested size. This results in better coherence and details."
        },
        {
          "name": "acceleration",
          "type": {
            "type": "enum",
            "values": [
              "none",
              "regular",
              "high"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.Acceleration"
          },
          "default": "none",
          "title": "Acceleration",
          "description": "The acceleration level to use."
        },
        {
          "name": "generate_audio",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Generate Audio",
          "description": "Whether to generate audio for the video."
        },
        {
          "name": "fps",
          "type": {
            "type": "float"
          },
          "default": 25,
          "title": "Fps",
          "description": "The frames per second of the generated video."
        },
        {
          "name": "camera_lora",
          "type": {
            "type": "enum",
            "values": [
              "dolly_in",
              "dolly_out",
              "dolly_left",
              "dolly_right",
              "jib_up",
              "jib_down",
              "static",
              "none"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.CameraLora"
          },
          "default": "none",
          "title": "Camera Lora",
          "description": "The camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera."
        },
        {
          "name": "video_size",
          "type": {
            "type": "str"
          },
          "default": "auto",
          "title": "Video Size",
          "description": "The size of the generated video."
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "Whether to enable the safety checker."
        },
        {
          "name": "camera_lora_scale",
          "type": {
            "type": "float"
          },
          "default": 1,
          "title": "Camera Lora Scale",
          "description": "The scale of the camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera."
        },
        {
          "name": "image_strength",
          "type": {
            "type": "float"
          },
          "default": 1,
          "title": "Image Strength",
          "description": "The strength of the image to use for the video generation."
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "blurry, out of focus, overexposed, underexposed, low contrast, washed out colors, excessive noise, grainy texture, poor lighting, flickering, motion blur, distorted proportions, unnatural skin tones, deformed facial features, asymmetrical face, missing facial features, extra limbs, disfigured hands, wrong hand count, artifacts around text, inconsistent perspective, camera shake, incorrect depth of field, background too sharp, background clutter, distracting reflections, harsh shadows, inconsistent lighting direction, color banding, cartoonish rendering, 3D CGI look, unrealistic materials, uncanny valley effect, incorrect ethnicity, wrong gender, exaggerated expressions, wrong gaze direction, mismatched lip sync, silent or muted audio, distorted voice, robotic voice, echo, background noise, off-sync audio,incorrect dialogue, added dialogue, repetitive speech, jittery movement, awkward pauses, incorrect timing, unnatural transitions, inconsistent framing, tilted camera, flat lighting, inconsistent tone, cinematic oversaturation, stylized filters, or AI artifacts.",
          "title": "Negative Prompt",
          "description": "The negative prompt to generate the video from."
        },
        {
          "name": "end_image_url",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "End Image Url",
          "description": "The URL of the image to use as the end of the video."
        },
        {
          "name": "video_write_mode",
          "type": {
            "type": "enum",
            "values": [
              "fast",
              "balanced",
              "small"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.VideoWriteMode"
          },
          "default": "balanced",
          "title": "Video Write Mode",
          "description": "The write mode of the generated video."
        },
        {
          "name": "video_output_type",
          "type": {
            "type": "enum",
            "values": [
              "X264 (.mp4)",
              "VP9 (.webm)",
              "PRORES4444 (.mov)",
              "GIF (.gif)"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.VideoOutputType"
          },
          "default": "X264 (.mp4)",
          "title": "Video Output Type",
          "description": "The output type of the generated video."
        },
        {
          "name": "num_frames",
          "type": {
            "type": "int"
          },
          "default": 121,
          "title": "Num Frames",
          "description": "The number of frames to generate."
        },
        {
          "name": "image_url",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image Url",
          "description": "The URL of the image to generate the video from."
        },
        {
          "name": "video_quality",
          "type": {
            "type": "enum",
            "values": [
              "low",
              "medium",
              "high",
              "maximum"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.VideoQuality"
          },
          "default": "high",
          "title": "Video Quality",
          "description": "The quality of the generated video."
        },
        {
          "name": "sync_mode",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Sync Mode",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history."
        },
        {
          "name": "enable_prompt_expansion",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Prompt Expansion",
          "description": "Whether to enable prompt expansion."
        },
        {
          "name": "seed",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Seed",
          "description": "The seed for the random number generator."
        },
        {
          "name": "end_image_strength",
          "type": {
            "type": "float"
          },
          "default": 1,
          "title": "End Image Strength",
          "description": "The strength of the end image to use for the video generation."
        },
        {
          "name": "interpolation_direction",
          "type": {
            "type": "enum",
            "values": [
              "forward",
              "backward"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.InterpolationDirection"
          },
          "default": "forward",
          "title": "Interpolation Direction",
          "description": "The direction to interpolate the image sequence in. 'Forward' goes from the start image to the end image, 'Backward' goes from the end image to the start image."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "Ltx 219B Distilled Image To Video Lora",
      "description": "LTX-2 19B Distilled with LoRA combines efficient generation with custom-trained models.\n    video, generation, ltx-2, 19b, distilled, lora\n\n    Use cases:\n    - Generate videos with custom distilled model\n    - Create efficient specialized content\n    - Produce fast domain-specific videos\n    - Generate with optimized custom model\n    - Create quick customized animations",
      "namespace": "fal.image_to_video",
      "node_type": "fal.image_to_video.Ltx219BDistilledImageToVideoLora",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt used for the generation."
        },
        {
          "name": "use_multiscale",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Use Multiscale",
          "description": "Whether to use multi-scale generation. If True, the model will generate the video at a smaller scale first, then use the smaller video to guide the generation of a video at or above your requested size. This results in better coherence and details."
        },
        {
          "name": "acceleration",
          "type": {
            "type": "enum",
            "values": [
              "none",
              "regular",
              "high"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.Acceleration"
          },
          "default": "none",
          "title": "Acceleration",
          "description": "The acceleration level to use."
        },
        {
          "name": "generate_audio",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Generate Audio",
          "description": "Whether to generate audio for the video."
        },
        {
          "name": "fps",
          "type": {
            "type": "float"
          },
          "default": 25,
          "title": "Fps",
          "description": "The frames per second of the generated video."
        },
        {
          "name": "loras",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "str"
              }
            ]
          },
          "default": [],
          "title": "Loras",
          "description": "The LoRAs to use for the generation."
        },
        {
          "name": "camera_lora",
          "type": {
            "type": "enum",
            "values": [
              "dolly_in",
              "dolly_out",
              "dolly_left",
              "dolly_right",
              "jib_up",
              "jib_down",
              "static",
              "none"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.CameraLora"
          },
          "default": "none",
          "title": "Camera Lora",
          "description": "The camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera."
        },
        {
          "name": "video_size",
          "type": {
            "type": "str"
          },
          "default": "auto",
          "title": "Video Size",
          "description": "The size of the generated video."
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "Whether to enable the safety checker."
        },
        {
          "name": "camera_lora_scale",
          "type": {
            "type": "float"
          },
          "default": 1,
          "title": "Camera Lora Scale",
          "description": "The scale of the camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera."
        },
        {
          "name": "image_strength",
          "type": {
            "type": "float"
          },
          "default": 1,
          "title": "Image Strength",
          "description": "The strength of the image to use for the video generation."
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "blurry, out of focus, overexposed, underexposed, low contrast, washed out colors, excessive noise, grainy texture, poor lighting, flickering, motion blur, distorted proportions, unnatural skin tones, deformed facial features, asymmetrical face, missing facial features, extra limbs, disfigured hands, wrong hand count, artifacts around text, inconsistent perspective, camera shake, incorrect depth of field, background too sharp, background clutter, distracting reflections, harsh shadows, inconsistent lighting direction, color banding, cartoonish rendering, 3D CGI look, unrealistic materials, uncanny valley effect, incorrect ethnicity, wrong gender, exaggerated expressions, wrong gaze direction, mismatched lip sync, silent or muted audio, distorted voice, robotic voice, echo, background noise, off-sync audio,incorrect dialogue, added dialogue, repetitive speech, jittery movement, awkward pauses, incorrect timing, unnatural transitions, inconsistent framing, tilted camera, flat lighting, inconsistent tone, cinematic oversaturation, stylized filters, or AI artifacts.",
          "title": "Negative Prompt",
          "description": "The negative prompt to generate the video from."
        },
        {
          "name": "end_image_url",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "End Image Url",
          "description": "The URL of the image to use as the end of the video."
        },
        {
          "name": "video_write_mode",
          "type": {
            "type": "enum",
            "values": [
              "fast",
              "balanced",
              "small"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.VideoWriteMode"
          },
          "default": "balanced",
          "title": "Video Write Mode",
          "description": "The write mode of the generated video."
        },
        {
          "name": "video_output_type",
          "type": {
            "type": "enum",
            "values": [
              "X264 (.mp4)",
              "VP9 (.webm)",
              "PRORES4444 (.mov)",
              "GIF (.gif)"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.VideoOutputType"
          },
          "default": "X264 (.mp4)",
          "title": "Video Output Type",
          "description": "The output type of the generated video."
        },
        {
          "name": "num_frames",
          "type": {
            "type": "int"
          },
          "default": 121,
          "title": "Num Frames",
          "description": "The number of frames to generate."
        },
        {
          "name": "image_url",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image Url",
          "description": "The URL of the image to generate the video from."
        },
        {
          "name": "sync_mode",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Sync Mode",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history."
        },
        {
          "name": "video_quality",
          "type": {
            "type": "enum",
            "values": [
              "low",
              "medium",
              "high",
              "maximum"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.VideoQuality"
          },
          "default": "high",
          "title": "Video Quality",
          "description": "The quality of the generated video."
        },
        {
          "name": "enable_prompt_expansion",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Prompt Expansion",
          "description": "Whether to enable prompt expansion."
        },
        {
          "name": "seed",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Seed",
          "description": "The seed for the random number generator."
        },
        {
          "name": "end_image_strength",
          "type": {
            "type": "float"
          },
          "default": 1,
          "title": "End Image Strength",
          "description": "The strength of the end image to use for the video generation."
        },
        {
          "name": "interpolation_direction",
          "type": {
            "type": "enum",
            "values": [
              "forward",
              "backward"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.InterpolationDirection"
          },
          "default": "forward",
          "title": "Interpolation Direction",
          "description": "The direction to interpolate the image sequence in. 'Forward' goes from the start image to the end image, 'Backward' goes from the end image to the start image."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "Ltx 219B Image To Video",
      "description": "LTX-2 19B generates high-quality videos from images using the powerful 19-billion parameter model.\n    video, generation, ltx-2, 19b, large-model\n\n    Use cases:\n    - Generate high-quality videos with large model\n    - Create detailed video animations\n    - Produce superior video content\n    - Generate videos with powerful AI\n    - Create premium video animations",
      "namespace": "fal.image_to_video",
      "node_type": "fal.image_to_video.Ltx219BImageToVideo",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt used for the generation."
        },
        {
          "name": "use_multiscale",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Use Multiscale",
          "description": "Whether to use multi-scale generation. If True, the model will generate the video at a smaller scale first, then use the smaller video to guide the generation of a video at or above your requested size. This results in better coherence and details."
        },
        {
          "name": "acceleration",
          "type": {
            "type": "enum",
            "values": [
              "none",
              "regular",
              "high"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.Acceleration"
          },
          "default": "regular",
          "title": "Acceleration",
          "description": "The acceleration level to use."
        },
        {
          "name": "generate_audio",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Generate Audio",
          "description": "Whether to generate audio for the video."
        },
        {
          "name": "fps",
          "type": {
            "type": "float"
          },
          "default": 25,
          "title": "Fps",
          "description": "The frames per second of the generated video."
        },
        {
          "name": "camera_lora",
          "type": {
            "type": "enum",
            "values": [
              "dolly_in",
              "dolly_out",
              "dolly_left",
              "dolly_right",
              "jib_up",
              "jib_down",
              "static",
              "none"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.CameraLora"
          },
          "default": "none",
          "title": "Camera Lora",
          "description": "The camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera."
        },
        {
          "name": "video_size",
          "type": {
            "type": "str"
          },
          "default": "auto",
          "title": "Video Size",
          "description": "The size of the generated video."
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 3,
          "title": "Guidance Scale",
          "description": "The guidance scale to use."
        },
        {
          "name": "camera_lora_scale",
          "type": {
            "type": "float"
          },
          "default": 1,
          "title": "Camera Lora Scale",
          "description": "The scale of the camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera."
        },
        {
          "name": "image_strength",
          "type": {
            "type": "float"
          },
          "default": 1,
          "title": "Image Strength",
          "description": "The strength of the image to use for the video generation."
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "blurry, out of focus, overexposed, underexposed, low contrast, washed out colors, excessive noise, grainy texture, poor lighting, flickering, motion blur, distorted proportions, unnatural skin tones, deformed facial features, asymmetrical face, missing facial features, extra limbs, disfigured hands, wrong hand count, artifacts around text, inconsistent perspective, camera shake, incorrect depth of field, background too sharp, background clutter, distracting reflections, harsh shadows, inconsistent lighting direction, color banding, cartoonish rendering, 3D CGI look, unrealistic materials, uncanny valley effect, incorrect ethnicity, wrong gender, exaggerated expressions, wrong gaze direction, mismatched lip sync, silent or muted audio, distorted voice, robotic voice, echo, background noise, off-sync audio,incorrect dialogue, added dialogue, repetitive speech, jittery movement, awkward pauses, incorrect timing, unnatural transitions, inconsistent framing, tilted camera, flat lighting, inconsistent tone, cinematic oversaturation, stylized filters, or AI artifacts.",
          "title": "Negative Prompt",
          "description": "The negative prompt to generate the video from."
        },
        {
          "name": "end_image_url",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "End Image Url",
          "description": "The URL of the image to use as the end of the video."
        },
        {
          "name": "video_write_mode",
          "type": {
            "type": "enum",
            "values": [
              "fast",
              "balanced",
              "small"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.VideoWriteMode"
          },
          "default": "balanced",
          "title": "Video Write Mode",
          "description": "The write mode of the generated video."
        },
        {
          "name": "video_output_type",
          "type": {
            "type": "enum",
            "values": [
              "X264 (.mp4)",
              "VP9 (.webm)",
              "PRORES4444 (.mov)",
              "GIF (.gif)"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.VideoOutputType"
          },
          "default": "X264 (.mp4)",
          "title": "Video Output Type",
          "description": "The output type of the generated video."
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "Whether to enable the safety checker."
        },
        {
          "name": "num_frames",
          "type": {
            "type": "int"
          },
          "default": 121,
          "title": "Num Frames",
          "description": "The number of frames to generate."
        },
        {
          "name": "image_url",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image Url",
          "description": "The URL of the image to generate the video from."
        },
        {
          "name": "video_quality",
          "type": {
            "type": "enum",
            "values": [
              "low",
              "medium",
              "high",
              "maximum"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.VideoQuality"
          },
          "default": "high",
          "title": "Video Quality",
          "description": "The quality of the generated video."
        },
        {
          "name": "sync_mode",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Sync Mode",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history."
        },
        {
          "name": "enable_prompt_expansion",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Prompt Expansion",
          "description": "Whether to enable prompt expansion."
        },
        {
          "name": "seed",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Seed",
          "description": "The seed for the random number generator."
        },
        {
          "name": "end_image_strength",
          "type": {
            "type": "float"
          },
          "default": 1,
          "title": "End Image Strength",
          "description": "The strength of the end image to use for the video generation."
        },
        {
          "name": "interpolation_direction",
          "type": {
            "type": "enum",
            "values": [
              "forward",
              "backward"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.InterpolationDirection"
          },
          "default": "forward",
          "title": "Interpolation Direction",
          "description": "The direction to interpolate the image sequence in. 'Forward' goes from the start image to the end image, 'Backward' goes from the end image to the start image."
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 40,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to use."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "Ltx 219B Image To Video Lora",
      "description": "LTX-2 19B with LoRA enables custom-trained 19B models for specialized video generation.\n    video, generation, ltx-2, 19b, lora, custom\n\n    Use cases:\n    - Generate videos with custom 19B model\n    - Create specialized video content\n    - Produce domain-specific animations\n    - Generate with fine-tuned large model\n    - Create customized video animations",
      "namespace": "fal.image_to_video",
      "node_type": "fal.image_to_video.Ltx219BImageToVideoLora",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt used for the generation."
        },
        {
          "name": "use_multiscale",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Use Multiscale",
          "description": "Whether to use multi-scale generation. If True, the model will generate the video at a smaller scale first, then use the smaller video to guide the generation of a video at or above your requested size. This results in better coherence and details."
        },
        {
          "name": "acceleration",
          "type": {
            "type": "enum",
            "values": [
              "none",
              "regular",
              "high"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.Acceleration"
          },
          "default": "regular",
          "title": "Acceleration",
          "description": "The acceleration level to use."
        },
        {
          "name": "generate_audio",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Generate Audio",
          "description": "Whether to generate audio for the video."
        },
        {
          "name": "fps",
          "type": {
            "type": "float"
          },
          "default": 25,
          "title": "Fps",
          "description": "The frames per second of the generated video."
        },
        {
          "name": "loras",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "str"
              }
            ]
          },
          "default": [],
          "title": "Loras",
          "description": "The LoRAs to use for the generation."
        },
        {
          "name": "camera_lora",
          "type": {
            "type": "enum",
            "values": [
              "dolly_in",
              "dolly_out",
              "dolly_left",
              "dolly_right",
              "jib_up",
              "jib_down",
              "static",
              "none"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.CameraLora"
          },
          "default": "none",
          "title": "Camera Lora",
          "description": "The camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera."
        },
        {
          "name": "video_size",
          "type": {
            "type": "str"
          },
          "default": "auto",
          "title": "Video Size",
          "description": "The size of the generated video."
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 3,
          "title": "Guidance Scale",
          "description": "The guidance scale to use."
        },
        {
          "name": "camera_lora_scale",
          "type": {
            "type": "float"
          },
          "default": 1,
          "title": "Camera Lora Scale",
          "description": "The scale of the camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera."
        },
        {
          "name": "image_strength",
          "type": {
            "type": "float"
          },
          "default": 1,
          "title": "Image Strength",
          "description": "The strength of the image to use for the video generation."
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "blurry, out of focus, overexposed, underexposed, low contrast, washed out colors, excessive noise, grainy texture, poor lighting, flickering, motion blur, distorted proportions, unnatural skin tones, deformed facial features, asymmetrical face, missing facial features, extra limbs, disfigured hands, wrong hand count, artifacts around text, inconsistent perspective, camera shake, incorrect depth of field, background too sharp, background clutter, distracting reflections, harsh shadows, inconsistent lighting direction, color banding, cartoonish rendering, 3D CGI look, unrealistic materials, uncanny valley effect, incorrect ethnicity, wrong gender, exaggerated expressions, wrong gaze direction, mismatched lip sync, silent or muted audio, distorted voice, robotic voice, echo, background noise, off-sync audio,incorrect dialogue, added dialogue, repetitive speech, jittery movement, awkward pauses, incorrect timing, unnatural transitions, inconsistent framing, tilted camera, flat lighting, inconsistent tone, cinematic oversaturation, stylized filters, or AI artifacts.",
          "title": "Negative Prompt",
          "description": "The negative prompt to generate the video from."
        },
        {
          "name": "end_image_url",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "End Image Url",
          "description": "The URL of the image to use as the end of the video."
        },
        {
          "name": "video_write_mode",
          "type": {
            "type": "enum",
            "values": [
              "fast",
              "balanced",
              "small"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.VideoWriteMode"
          },
          "default": "balanced",
          "title": "Video Write Mode",
          "description": "The write mode of the generated video."
        },
        {
          "name": "video_output_type",
          "type": {
            "type": "enum",
            "values": [
              "X264 (.mp4)",
              "VP9 (.webm)",
              "PRORES4444 (.mov)",
              "GIF (.gif)"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.VideoOutputType"
          },
          "default": "X264 (.mp4)",
          "title": "Video Output Type",
          "description": "The output type of the generated video."
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "Whether to enable the safety checker."
        },
        {
          "name": "num_frames",
          "type": {
            "type": "int"
          },
          "default": 121,
          "title": "Num Frames",
          "description": "The number of frames to generate."
        },
        {
          "name": "image_url",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image Url",
          "description": "The URL of the image to generate the video from."
        },
        {
          "name": "sync_mode",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Sync Mode",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history."
        },
        {
          "name": "video_quality",
          "type": {
            "type": "enum",
            "values": [
              "low",
              "medium",
              "high",
              "maximum"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.VideoQuality"
          },
          "default": "high",
          "title": "Video Quality",
          "description": "The quality of the generated video."
        },
        {
          "name": "enable_prompt_expansion",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Prompt Expansion",
          "description": "Whether to enable prompt expansion."
        },
        {
          "name": "seed",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Seed",
          "description": "The seed for the random number generator."
        },
        {
          "name": "end_image_strength",
          "type": {
            "type": "float"
          },
          "default": 1,
          "title": "End Image Strength",
          "description": "The strength of the end image to use for the video generation."
        },
        {
          "name": "interpolation_direction",
          "type": {
            "type": "enum",
            "values": [
              "forward",
              "backward"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.InterpolationDirection"
          },
          "default": "forward",
          "title": "Interpolation Direction",
          "description": "The direction to interpolate the image sequence in. 'Forward' goes from the start image to the end image, 'Backward' goes from the end image to the start image."
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 40,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to use."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "Luma Dream Machine",
      "description": "Generate video clips from your images using Luma Dream Machine v1.5. Supports various aspect ratios and optional end-frame blending.\n    video, generation, animation, blending, aspect-ratio, img2vid, image-to-video\n\n    Use cases:\n    - Create seamless video loops\n    - Generate video transitions\n    - Transform images into animations\n    - Create motion graphics\n    - Produce video content",
      "namespace": "fal.image_to_video",
      "node_type": "fal.image_to_video.LumaDreamMachine",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt"
        },
        {
          "name": "aspect_ratio",
          "type": {
            "type": "enum",
            "values": [
              "16:9",
              "9:16",
              "4:3",
              "3:4",
              "21:9",
              "9:21"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.AspectRatio"
          },
          "default": "16:9",
          "title": "Aspect Ratio",
          "description": "The aspect ratio of the generated video"
        },
        {
          "name": "loop",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Loop",
          "description": "Whether the video should loop (end of video is blended with the beginning)"
        },
        {
          "name": "end_image_url",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "End Image Url",
          "description": "An image to blend the end of the video with"
        },
        {
          "name": "image_url",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image Url"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt",
        "resolution"
      ]
    },
    {
      "title": "Omni Human V15",
      "description": "OmniHuman v1.5 generates realistic human videos from images.\n    video, human, realistic, bytedance, image-to-video\n\n    Use cases:\n    - Generate realistic human videos\n    - Create human motion animations\n    - Produce lifelike character videos\n    - Generate human performances\n    - Create realistic human content",
      "namespace": "fal.image_to_video",
      "node_type": "fal.image_to_video.OmniHumanV15",
      "properties": [
        {
          "name": "turbo_mode",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Turbo Mode",
          "description": "Generate a video at a faster rate with a slight quality trade-off."
        },
        {
          "name": "resolution",
          "type": {
            "type": "enum",
            "values": [
              "720p",
              "1080p"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.OmniHumanV15Resolution"
          },
          "default": "1080p",
          "title": "Resolution",
          "description": "The resolution of the generated video. Defaults to 1080p. 720p generation is faster and higher in quality. 1080p generation is limited to 30s audio and 720p generation is limited to 60s audio."
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The text prompt used to guide the video generation."
        },
        {
          "name": "audio_url",
          "type": {
            "type": "video"
          },
          "default": {
            "type": "video",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null,
            "duration": null,
            "format": null
          },
          "title": "Audio Url",
          "description": "The URL of the audio file to generate the video. Audio must be under 30s long for 1080p generation and under 60s long for 720p generation."
        },
        {
          "name": "image_url",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image Url",
          "description": "The URL of the image used to generate the video"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "Pixverse V56 Image To Video",
      "description": "Generate high-quality videos from images with Pixverse v5.6.\n    video, generation, pixverse, v5.6, image-to-video, img2vid\n\n    Use cases:\n    - Animate photos into professional video clips\n    - Create dynamic product showcase videos\n    - Generate stylized video content from artwork\n    - Produce high-resolution social media animations\n    - Transform static images with various visual styles",
      "namespace": "fal.image_to_video",
      "node_type": "fal.image_to_video.PixverseV56ImageToVideo",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "Text prompt describing the desired video motion"
        },
        {
          "name": "resolution",
          "type": {
            "type": "enum",
            "values": [
              "360p",
              "540p",
              "720p",
              "1080p"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.PixverseV56Resolution"
          },
          "default": "720p",
          "title": "Resolution",
          "description": "The resolution quality of the output video"
        },
        {
          "name": "duration",
          "type": {
            "type": "enum",
            "values": [
              "5",
              "8",
              "10"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.PixverseV56Duration"
          },
          "default": "5",
          "title": "Duration",
          "description": "The duration of the generated video in seconds"
        },
        {
          "name": "style",
          "type": {
            "type": "enum",
            "optional": true,
            "values": [
              "anime",
              "3d_animation",
              "clay",
              "comic",
              "cyberpunk"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.PixverseV56Style"
          },
          "default": null,
          "title": "Style",
          "description": "Optional visual style for the video"
        },
        {
          "name": "thinking_type",
          "type": {
            "type": "enum",
            "optional": true,
            "values": [
              "enabled",
              "disabled",
              "auto"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.PixverseV56ThinkingType"
          },
          "default": null,
          "title": "Thinking Type",
          "description": "Thinking mode for video generation"
        },
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The image to transform into a video"
        },
        {
          "name": "generate_audio_switch",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Generate Audio Switch",
          "description": "Whether to generate audio for the video"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Optional seed for reproducible generation"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "What to avoid in the generated video"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt",
        "resolution"
      ]
    },
    {
      "title": "Pixverse V56 Transition",
      "description": "Pixverse v5.6 Transition creates smooth video transitions between two images with professional effects.\n    video, transition, pixverse, v5.6, effects\n\n    Use cases:\n    - Create smooth transitions between images\n    - Generate professional video effects\n    - Produce seamless image morphing\n    - Create transition animations\n    - Generate video connecting two scenes",
      "namespace": "fal.image_to_video",
      "node_type": "fal.image_to_video.PixverseV56Transition",
      "properties": [
        {
          "name": "first_image_url",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "First Image Url",
          "description": "URL of the image to use as the first frame"
        },
        {
          "name": "aspect_ratio",
          "type": {
            "type": "enum",
            "values": [
              "16:9",
              "9:16",
              "4:3",
              "3:4",
              "21:9",
              "9:21"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.AspectRatio"
          },
          "default": "16:9",
          "title": "Aspect Ratio",
          "description": "The aspect ratio of the generated video"
        },
        {
          "name": "resolution",
          "type": {
            "type": "enum",
            "values": [
              "360p",
              "540p",
              "720p",
              "1080p"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.PixverseV56TransitionResolution"
          },
          "default": "720p",
          "title": "Resolution",
          "description": "The resolution of the generated video"
        },
        {
          "name": "style",
          "type": {
            "type": "enum",
            "optional": true,
            "values": [
              "anime",
              "3d_animation",
              "clay",
              "comic",
              "cyberpunk"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.Style"
          },
          "default": null,
          "title": "Style",
          "description": "The style of the generated video"
        },
        {
          "name": "thinking_type",
          "type": {
            "type": "enum",
            "optional": true,
            "values": [
              "enabled",
              "disabled",
              "auto"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.ThinkingType"
          },
          "default": null,
          "title": "Thinking Type",
          "description": "Prompt optimization mode: 'enabled' to optimize, 'disabled' to turn off, 'auto' for model decision"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt for the transition"
        },
        {
          "name": "duration",
          "type": {
            "type": "enum",
            "values": [
              "5",
              "8",
              "10"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.PixverseV56TransitionDuration"
          },
          "default": "5",
          "title": "Duration",
          "description": "The duration of the generated video in seconds. 1080p videos are limited to 5 or 8 seconds"
        },
        {
          "name": "generate_audio_switch",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Generate Audio Switch",
          "description": "Enable audio generation (BGM, SFX, dialogue)"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed and the same prompt given to the same version of the model will output the same video every time."
        },
        {
          "name": "end_image_url",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "End Image Url",
          "description": "URL of the image to use as the last frame"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "Negative prompt to be used for the generation"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "See Dance V15 Pro Image To Video",
      "description": "SeeDance v1.5 Pro generates high-quality dance videos from images.\n    video, dance, animation, seedance, bytedance, image-to-video\n\n    Use cases:\n    - Animate photos into dance videos\n    - Create dance choreography from images\n    - Generate dance performances\n    - Produce music video content\n    - Create dance training materials",
      "namespace": "fal.image_to_video",
      "node_type": "fal.image_to_video.SeeDanceV15ProImageToVideo",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The text prompt used to generate the video"
        },
        {
          "name": "resolution",
          "type": {
            "type": "enum",
            "values": [
              "480p",
              "720p",
              "1080p"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.SeeDanceV15ProResolution"
          },
          "default": "720p",
          "title": "Resolution",
          "description": "Video resolution - 480p for faster generation, 720p for balance, 1080p for higher quality"
        },
        {
          "name": "duration",
          "type": {
            "type": "enum",
            "values": [
              "4",
              "5",
              "6",
              "7",
              "8",
              "9",
              "10",
              "11",
              "12"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.SeeDanceV15ProDuration"
          },
          "default": "5",
          "title": "Duration",
          "description": "Duration of the video in seconds"
        },
        {
          "name": "generate_audio",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Generate Audio",
          "description": "Whether to generate audio for the video"
        },
        {
          "name": "aspect_ratio",
          "type": {
            "type": "enum",
            "values": [
              "21:9",
              "16:9",
              "4:3",
              "1:1",
              "3:4",
              "9:16"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.SeeDanceV15ProAspectRatio"
          },
          "default": "16:9",
          "title": "Aspect Ratio",
          "description": "The aspect ratio of the generated video"
        },
        {
          "name": "image_url",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image Url",
          "description": "The URL of the image used to generate video"
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If set to true, the safety checker will be enabled."
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Random seed to control video generation. Use -1 for random."
        },
        {
          "name": "end_image_url",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "End Image Url",
          "description": "The URL of the image the video ends with. Defaults to None."
        },
        {
          "name": "camera_fixed",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Camera Fixed",
          "description": "Whether to fix the camera position"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "See Dance V1 Lite Reference To Video",
      "description": "SeeDance v1 Lite generates lightweight dance videos using reference images.\n    video, dance, lite, reference, seedance, image-to-video\n\n    Use cases:\n    - Generate efficient dance videos\n    - Create reference-based animations\n    - Produce lightweight dance content\n    - Generate quick dance outputs\n    - Create optimized dance videos",
      "namespace": "fal.image_to_video",
      "node_type": "fal.image_to_video.SeeDanceV1LiteReferenceToVideo",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The text prompt used to generate the video"
        },
        {
          "name": "resolution",
          "type": {
            "type": "enum",
            "values": [
              "480p",
              "720p"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.SeeDanceV1LiteResolution"
          },
          "default": "720p",
          "title": "Resolution",
          "description": "Video resolution - 480p for faster generation, 720p for higher quality"
        },
        {
          "name": "duration",
          "type": {
            "type": "enum",
            "values": [
              "2",
              "3",
              "4",
              "5",
              "6",
              "7",
              "8",
              "9",
              "10",
              "11",
              "12"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.SeeDanceV1LiteDuration"
          },
          "default": "5",
          "title": "Duration",
          "description": "Duration of the video in seconds"
        },
        {
          "name": "aspect_ratio",
          "type": {
            "type": "enum",
            "values": [
              "21:9",
              "16:9",
              "4:3",
              "1:1",
              "3:4",
              "9:16",
              "auto"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.SeeDanceV1LiteAspectRatio"
          },
          "default": "auto",
          "title": "Aspect Ratio",
          "description": "The aspect ratio of the generated video"
        },
        {
          "name": "reference_image_urls",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "str"
              }
            ]
          },
          "default": [],
          "title": "Reference Image Urls",
          "description": "Reference images to generate the video with."
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Random seed to control video generation. Use -1 for random."
        },
        {
          "name": "camera_fixed",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Camera Fixed",
          "description": "Whether to fix the camera position"
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If set to true, the safety checker will be enabled."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "reference"
      ]
    },
    {
      "title": "See Dance V1 Pro Fast Image To Video",
      "description": "SeeDance v1 Pro Fast generates dance videos quickly from images.\n    video, dance, fast, seedance, bytedance, image-to-video\n\n    Use cases:\n    - Rapidly generate dance videos\n    - Quick dance animation\n    - Fast dance prototypes\n    - Create dance previews\n    - Efficient dance video generation",
      "namespace": "fal.image_to_video",
      "node_type": "fal.image_to_video.SeeDanceV1ProFastImageToVideo",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The text prompt used to generate the video"
        },
        {
          "name": "resolution",
          "type": {
            "type": "enum",
            "values": [
              "480p",
              "720p",
              "1080p"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.SeeDanceV1ProFastResolution"
          },
          "default": "1080p",
          "title": "Resolution",
          "description": "Video resolution - 480p for faster generation, 720p for balance, 1080p for higher quality"
        },
        {
          "name": "duration",
          "type": {
            "type": "enum",
            "values": [
              "2",
              "3",
              "4",
              "5",
              "6",
              "7",
              "8",
              "9",
              "10",
              "11",
              "12"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.SeeDanceV1ProFastDuration"
          },
          "default": "5",
          "title": "Duration",
          "description": "Duration of the video in seconds"
        },
        {
          "name": "aspect_ratio",
          "type": {
            "type": "enum",
            "values": [
              "21:9",
              "16:9",
              "4:3",
              "1:1",
              "3:4",
              "9:16",
              "auto"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.SeeDanceV1ProFastAspectRatio"
          },
          "default": "auto",
          "title": "Aspect Ratio",
          "description": "The aspect ratio of the generated video"
        },
        {
          "name": "image_url",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image Url",
          "description": "The URL of the image used to generate video"
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If set to true, the safety checker will be enabled."
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Random seed to control video generation. Use -1 for random."
        },
        {
          "name": "camera_fixed",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Camera Fixed",
          "description": "Whether to fix the camera position"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "Stable Video Image To Video",
      "description": "Stable Video generates consistent video animations from images.\n    video, generation, stable, consistent, image-to-video\n\n    Use cases:\n    - Generate stable video animations\n    - Create consistent motion\n    - Produce reliable video outputs\n    - Animate images consistently\n    - Generate predictable videos",
      "namespace": "fal.image_to_video",
      "node_type": "fal.image_to_video.StableVideoImageToVideo",
      "properties": [
        {
          "name": "motion_bucket_id",
          "type": {
            "type": "int"
          },
          "default": 127,
          "title": "Motion Bucket Id",
          "description": "The motion bucket id determines the motion of the generated video. The higher the number, the more motion there will be."
        },
        {
          "name": "fps",
          "type": {
            "type": "int"
          },
          "default": 25,
          "title": "Fps",
          "description": "The frames per second of the generated video."
        },
        {
          "name": "cond_aug",
          "type": {
            "type": "float"
          },
          "default": 0.02,
          "title": "Cond Aug",
          "description": "The conditoning augmentation determines the amount of noise that will be added to the conditioning frame. The higher the number, the more noise there will be, and the less the video will look like the initial image. Increase it for more motion."
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed and the same prompt given to the same version of Stable Diffusion will output the same image every time."
        },
        {
          "name": "image_url",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image Url",
          "description": "The URL of the image to use as a starting point for the generation."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "Vidu Q2 Reference To Video Pro",
      "description": "Vidu Q2 Reference-to-Video Pro generates professional quality videos using reference images for style and content.\n    video, generation, vidu, q2, pro, reference\n\n    Use cases:\n    - Generate pro videos from references\n    - Create style-consistent animations\n    - Produce reference-guided videos\n    - Generate videos matching examples\n    - Create professional reference-based content",
      "namespace": "fal.image_to_video",
      "node_type": "fal.image_to_video.ViduQ2ReferenceToVideoPro",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "Text prompt for video generation, max 2000 characters"
        },
        {
          "name": "resolution",
          "type": {
            "type": "enum",
            "values": [
              "540p",
              "720p",
              "1080p"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.ViduQ2ReferenceToVideoProResolution"
          },
          "default": "720p",
          "title": "Resolution",
          "description": "Output video resolution"
        },
        {
          "name": "aspect_ratio",
          "type": {
            "type": "str"
          },
          "default": "16:9",
          "title": "Aspect Ratio",
          "description": "Aspect ratio of the output video (e.g., auto, 16:9, 9:16, 1:1, or any W:H)"
        },
        {
          "name": "duration",
          "type": {
            "type": "int"
          },
          "default": 4,
          "title": "Duration",
          "description": "Duration of the video in seconds (0 for automatic duration)"
        },
        {
          "name": "reference_video_urls",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "str"
              }
            ]
          },
          "default": [],
          "title": "Reference Video Urls",
          "description": "URLs of the reference videos for video editing or motion reference. Supports up to 2 videos."
        },
        {
          "name": "bgm",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Bgm",
          "description": "Whether to add background music to the generated video"
        },
        {
          "name": "reference_image_urls",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "str"
              }
            ]
          },
          "default": [],
          "title": "Reference Image Urls",
          "description": "URLs of the reference images for subject appearance. If videos are provided, up to 4 images are allowed; otherwise up to 7 images."
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Random seed for reproducibility. If None, a random seed is chosen."
        },
        {
          "name": "movement_amplitude",
          "type": {
            "type": "enum",
            "values": [
              "auto",
              "small",
              "medium",
              "large"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.MovementAmplitude"
          },
          "default": "auto",
          "title": "Movement Amplitude",
          "description": "The movement amplitude of objects in the frame"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "Wan Move",
      "description": "Wan Move generates videos with natural motion and movement from static images.\n    video, generation, wan, motion, animation\n\n    Use cases:\n    - Add natural motion to images\n    - Create animated movements\n    - Produce dynamic video content\n    - Generate moving scenes from stills\n    - Create motion animations",
      "namespace": "fal.image_to_video",
      "node_type": "fal.image_to_video.WanMove",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "Text prompt to guide the video generation."
        },
        {
          "name": "trajectories",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "list",
                "type_args": [
                  {
                    "type": "str"
                  }
                ]
              }
            ]
          },
          "default": [],
          "title": "Trajectories",
          "description": "A list of trajectories. Each trajectory list means the movement of one object."
        },
        {
          "name": "image_url",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image Url",
          "description": "URL of the input image. If the input image does not match the chosen aspect ratio, it is resized and center cropped."
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 3.5,
          "title": "Guidance Scale",
          "description": "Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality."
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 40,
          "title": "Num Inference Steps",
          "description": "Number of inference steps for sampling. Higher values give better quality but take longer."
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Random seed for reproducibility. If None, a random seed is chosen."
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "\u8272\u8c03\u8273\u4e3d\uff0c\u8fc7\u66dd\uff0c\u9759\u6001\uff0c\u7ec6\u8282\u6a21\u7cca\u4e0d\u6e05\uff0c\u5b57\u5e55\uff0c\u98ce\u683c\uff0c\u4f5c\u54c1\uff0c\u753b\u4f5c\uff0c\u753b\u9762\uff0c\u9759\u6b62\uff0c\u6574\u4f53\u53d1\u7070\uff0c\u6700\u5dee\u8d28\u91cf\uff0c\u4f4e\u8d28\u91cf\uff0cJPEG\u538b\u7f29\u6b8b\u7559\uff0c\u4e11\u964b\u7684\uff0c\u6b8b\u7f3a\u7684\uff0c\u591a\u4f59\u7684\u624b\u6307\uff0c\u753b\u5f97\u4e0d\u597d\u7684\u624b\u90e8\uff0c\u753b\u5f97\u4e0d\u597d\u7684\u8138\u90e8\uff0c\u7578\u5f62\u7684\uff0c\u6bc1\u5bb9\u7684\uff0c\u5f62\u6001\u7578\u5f62\u7684\u80a2\u4f53\uff0c\u624b\u6307\u878d\u5408\uff0c\u9759\u6b62\u4e0d\u52a8\u7684\u753b\u9762\uff0c\u6742\u4e71\u7684\u80cc\u666f\uff0c\u4e09\u6761\u817f\uff0c\u80cc\u666f\u4eba\u5f88\u591a\uff0c\u5012\u7740\u8d70",
          "title": "Negative Prompt",
          "description": "Negative prompt to guide the video generation."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "Wan V26 Image To Video",
      "description": "Wan v2.6 generates high-quality videos from images with balanced quality and performance.\n    video, generation, wan, v2.6, image-to-video\n\n    Use cases:\n    - Generate quality videos from images\n    - Create balanced video animations\n    - Produce reliable video content\n    - Generate consistent videos\n    - Create professional animations",
      "namespace": "fal.image_to_video",
      "node_type": "fal.image_to_video.WanV26ImageToVideo",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The text prompt describing the desired video motion. Max 800 characters."
        },
        {
          "name": "duration",
          "type": {
            "type": "enum",
            "values": [
              "5",
              "10",
              "15"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.WanV26Duration"
          },
          "default": "5",
          "title": "Duration",
          "description": "Duration of the generated video in seconds. Choose between 5, 10 or 15 seconds."
        },
        {
          "name": "resolution",
          "type": {
            "type": "enum",
            "values": [
              "720p",
              "1080p"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.WanV26Resolution"
          },
          "default": "1080p",
          "title": "Resolution",
          "description": "Video resolution. Valid values: 720p, 1080p"
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If set to true, the safety checker will be enabled."
        },
        {
          "name": "image_url",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image Url",
          "description": "URL of the image to use as the first frame. Must be publicly accessible or base64 data URI. Image dimensions must be between 240 and 7680."
        },
        {
          "name": "audio_url",
          "type": {
            "type": "video"
          },
          "default": {
            "type": "video",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null,
            "duration": null,
            "format": null
          },
          "title": "Audio Url",
          "description": "URL of the audio to use as the background music. Must be publicly accessible. Limit handling: If the audio duration exceeds the duration value (5, 10, or 15 seconds), the audio is truncated to the first N seconds, and the rest is discarded. If the audio is shorter than the video, the remaining part of the video will be silent. For example, if the audio is 3 seconds long and the video duration is 5 seconds, the first 3 seconds of the output video will have sound, and the last 2 seconds will be silent. - Format: WAV, MP3. - Duration: 3 to 30 s. - File size: Up to 15 MB."
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Random seed for reproducibility. If None, a random seed is chosen."
        },
        {
          "name": "multi_shots",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Multi Shots",
          "description": "When true, enables intelligent multi-shot segmentation. Only active when enable_prompt_expansion is True. Set to false for single-shot generation."
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "Negative prompt to describe content to avoid. Max 500 characters."
        },
        {
          "name": "enable_prompt_expansion",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Prompt Expansion",
          "description": "Whether to enable prompt rewriting using LLM."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "Wan V26 Image To Video Flash",
      "description": "Wan v2.6 Flash generates videos from images with ultra-fast processing for rapid iteration.\n    video, generation, wan, v2.6, flash, fast\n\n    Use cases:\n    - Generate videos at maximum speed\n    - Create rapid video prototypes\n    - Produce instant video previews\n    - Generate quick video iterations\n    - Create fast video animations",
      "namespace": "fal.image_to_video",
      "node_type": "fal.image_to_video.WanV26ImageToVideoFlash",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The text prompt describing the desired video motion. Max 800 characters."
        },
        {
          "name": "duration",
          "type": {
            "type": "enum",
            "values": [
              "5",
              "10",
              "15"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.WanV26FlashDuration"
          },
          "default": "5",
          "title": "Duration",
          "description": "Duration of the generated video in seconds. Choose between 5, 10 or 15 seconds."
        },
        {
          "name": "resolution",
          "type": {
            "type": "enum",
            "values": [
              "720p",
              "1080p"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.WanV26FlashResolution"
          },
          "default": "1080p",
          "title": "Resolution",
          "description": "Video resolution. Valid values: 720p, 1080p"
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If set to true, the safety checker will be enabled."
        },
        {
          "name": "image_url",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image Url",
          "description": "URL of the image to use as the first frame. Must be publicly accessible or base64 data URI. Image dimensions must be between 240 and 7680."
        },
        {
          "name": "audio_url",
          "type": {
            "type": "video"
          },
          "default": {
            "type": "video",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null,
            "duration": null,
            "format": null
          },
          "title": "Audio Url",
          "description": "URL of the audio to use as the background music. Must be publicly accessible. Limit handling: If the audio duration exceeds the duration value (5, 10, or 15 seconds), the audio is truncated to the first N seconds, and the rest is discarded. If the audio is shorter than the video, the remaining part of the video will be silent. For example, if the audio is 3 seconds long and the video duration is 5 seconds, the first 3 seconds of the output video will have sound, and the last 2 seconds will be silent. - Format: WAV, MP3. - Duration: 3 to 30 s. - File size: Up to 15 MB."
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Random seed for reproducibility. If None, a random seed is chosen."
        },
        {
          "name": "multi_shots",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Multi Shots",
          "description": "When true, enables intelligent multi-shot segmentation. Only active when enable_prompt_expansion is True. Set to false for single-shot generation."
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "Negative prompt to describe content to avoid. Max 500 characters."
        },
        {
          "name": "enable_prompt_expansion",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Prompt Expansion",
          "description": "Whether to enable prompt rewriting using LLM."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "Audio Understanding",
      "description": "Audio Understanding analyzes audio content and generates descriptions.\n    audio, understanding, analysis\n\n    Use cases:\n    - Analyze audio content\n    - Generate audio descriptions\n    - Understand sound scenes\n    - Create audio metadata\n    - Identify audio events",
      "namespace": "fal.vision",
      "node_type": "fal.vision.AudioUnderstanding",
      "properties": [
        {
          "name": "audio",
          "type": {
            "type": "audio"
          },
          "default": {
            "type": "audio",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Audio",
          "description": "The audio to analyze"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "Describe what you hear in this audio.",
          "title": "Prompt",
          "description": "The question or prompt about the audio"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "str"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "audio",
        "prompt"
      ]
    },
    {
      "title": "Florence 2 Caption",
      "description": "Florence 2 Caption generates detailed captions for images.\n    vision, caption, understanding, florence, image-to-text\n\n    Use cases:\n    - Generate image descriptions\n    - Create alt text for images\n    - Analyze image content\n    - Produce accessibility content\n    - Create image metadata",
      "namespace": "fal.vision",
      "node_type": "fal.vision.Florence2Caption",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The image to caption"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "str"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image"
      ]
    },
    {
      "title": "Florence 2 Detailed Caption",
      "description": "Florence 2 Detailed Caption generates comprehensive image descriptions.\n    vision, caption, understanding, florence, detailed\n\n    Use cases:\n    - Generate detailed image descriptions\n    - Create comprehensive alt text\n    - Analyze complex images\n    - Produce rich metadata\n    - Create detailed content descriptions",
      "namespace": "fal.vision",
      "node_type": "fal.vision.Florence2DetailedCaption",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The image to caption"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "str"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image"
      ]
    },
    {
      "title": "Florence 2OCR",
      "description": "Florence 2 OCR extracts text from images.\n    vision, ocr, text-extraction, florence\n\n    Use cases:\n    - Extract text from images\n    - Read documents\n    - Process screenshots\n    - Digitize printed text\n    - Extract labels and signs",
      "namespace": "fal.vision",
      "node_type": "fal.vision.Florence2OCR",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The image to extract text from"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "str"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image"
      ]
    },
    {
      "title": "Florence 2 Object Detection",
      "description": "Florence 2 Object Detection identifies and locates objects in images.\n    vision, object-detection, understanding, florence\n\n    Use cases:\n    - Detect objects in images\n    - Identify items in photos\n    - Analyze image content\n    - Create object inventories\n    - Enable visual search",
      "namespace": "fal.vision",
      "node_type": "fal.vision.Florence2ObjectDetection",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The image to analyze"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "list"
          },
          "name": "objects"
        },
        {
          "type": {
            "type": "list"
          },
          "name": "labels"
        }
      ],
      "basic_fields": [
        "image"
      ]
    },
    {
      "title": "Got OCR",
      "description": "GOT-OCR V2 is an advanced OCR model for extracting text from images.\n    vision, ocr, text-extraction, got\n\n    Use cases:\n    - Extract text from complex images\n    - Read handwritten text\n    - Process documents\n    - Digitize printed material\n    - Extract multilingual text",
      "namespace": "fal.vision",
      "node_type": "fal.vision.GotOCR",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The image to extract text from"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "str"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image"
      ]
    },
    {
      "title": "Llava Next",
      "description": "LLaVA-NeXT is an advanced vision-language model for image understanding.\n    vision, vlm, understanding, llava, multimodal\n\n    Use cases:\n    - Complex image analysis\n    - Visual question answering\n    - Image captioning\n    - Scene understanding\n    - Multi-turn visual conversations",
      "namespace": "fal.vision",
      "node_type": "fal.vision.LlavaNext",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The image to analyze"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "Describe this image in detail.",
          "title": "Prompt",
          "description": "The question or prompt about the image"
        },
        {
          "name": "max_tokens",
          "type": {
            "type": "int"
          },
          "default": 64,
          "title": "Max Tokens",
          "description": "Maximum number of tokens to generate"
        },
        {
          "name": "temperature",
          "type": {
            "type": "float"
          },
          "default": 0.2,
          "title": "Temperature",
          "description": "Temperature for sampling"
        },
        {
          "name": "top_p",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Top P",
          "description": "Top P for sampling",
          "min": 0.0,
          "max": 1.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "str"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt",
        "max_tokens"
      ]
    },
    {
      "title": "Moondream 2",
      "description": "Moondream2 is a small but capable vision-language model for image understanding.\n    vision, vlm, understanding, moondream, image-to-text\n\n    Use cases:\n    - Answer questions about images\n    - Analyze image content\n    - Generate descriptions\n    - Visual question answering\n    - Image understanding tasks",
      "namespace": "fal.vision",
      "node_type": "fal.vision.Moondream2",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The image to analyze"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "Describe this image.",
          "title": "Prompt",
          "description": "The question or prompt about the image"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "str"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "Video Prompt Generator",
      "description": "Video Prompt Generator creates detailed prompts for video generation from a concept or image.\n    vision, video, prompt, generation, tool\n\n    Use cases:\n    - Generate detailed video prompts from simple concepts\n    - Enhance video generation prompts\n    - Create prompts from reference images",
      "namespace": "fal.vision",
      "node_type": "fal.vision.VideoPromptGenerator",
      "properties": [
        {
          "name": "input_concept",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Input Concept",
          "description": "Core concept or thematic input for the video prompt"
        },
        {
          "name": "image",
          "type": {
            "type": "image",
            "optional": true
          },
          "default": null,
          "title": "Image",
          "description": "Optional reference image to analyze"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "str"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "input_concept",
        "image"
      ]
    },
    {
      "title": "Video Understanding",
      "description": "Video Understanding analyzes video content and generates descriptions.\n    vision, video, understanding, analysis\n\n    Use cases:\n    - Analyze video content\n    - Generate video summaries\n    - Extract video descriptions\n    - Understand video scenes\n    - Create video metadata",
      "namespace": "fal.vision",
      "node_type": "fal.vision.VideoUnderstanding",
      "properties": [
        {
          "name": "video",
          "type": {
            "type": "video"
          },
          "default": {
            "type": "video",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null,
            "duration": null,
            "format": null
          },
          "title": "Video",
          "description": "The video to analyze"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "Describe what happens in this video.",
          "title": "Prompt",
          "description": "The question or prompt about the video"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "str"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "video",
        "prompt"
      ]
    },
    {
      "title": "Deepfilternet 3",
      "description": "DeepFilterNet3 removes noise and improves audio quality with advanced deep learning filtering.\n    audio, noise-reduction, filtering, cleaning, audio-to-audio\n\n    Use cases:\n    - Remove noise from audio\n    - Clean audio recordings\n    - Filter unwanted sounds\n    - Improve audio clarity\n    - Generate clean audio",
      "namespace": "fal.audio_to_audio",
      "node_type": "fal.audio_to_audio.Deepfilternet3",
      "properties": [
        {
          "name": "sync_mode",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Sync Mode",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history."
        },
        {
          "name": "audio_format",
          "type": {
            "type": "enum",
            "values": [
              "mp3",
              "aac",
              "m4a",
              "ogg",
              "opus",
              "flac",
              "wav"
            ],
            "type_name": "nodetool.nodes.fal.audio_to_audio.AudioFormat"
          },
          "default": "mp3",
          "title": "Audio Format",
          "description": "The format for the output audio."
        },
        {
          "name": "audio_url",
          "type": {
            "type": "audio"
          },
          "default": {
            "type": "audio",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Audio Url",
          "description": "The URL of the audio to enhance."
        },
        {
          "name": "bitrate",
          "type": {
            "type": "str"
          },
          "default": "192k",
          "title": "Bitrate",
          "description": "The bitrate of the output audio."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "dict",
            "type_args": [
              {
                "type": "str"
              },
              {
                "type": "any"
              }
            ]
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "audio"
      ]
    },
    {
      "title": "Demucs",
      "description": "Demucs separates music into vocals, drums, bass, and other instruments with high quality.\n    audio, music-separation, stems, demucs, audio-to-audio\n\n    Use cases:\n    - Separate music into stems\n    - Extract vocals from songs\n    - Isolate instruments in music\n    - Create karaoke tracks\n    - Generate individual audio stems",
      "namespace": "fal.audio_to_audio",
      "node_type": "fal.audio_to_audio.Demucs",
      "properties": [
        {
          "name": "segment_length",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Segment Length",
          "description": "Length in seconds of each segment for processing. Smaller values use less memory but may reduce quality. Default is model-specific."
        },
        {
          "name": "output_format",
          "type": {
            "type": "enum",
            "values": [
              "mp3_22050_32",
              "mp3_44100_32",
              "mp3_44100_64",
              "mp3_44100_96",
              "mp3_44100_128",
              "mp3_44100_192",
              "pcm_8000",
              "pcm_16000",
              "pcm_22050",
              "pcm_24000",
              "pcm_44100",
              "pcm_48000",
              "ulaw_8000",
              "alaw_8000",
              "opus_48000_32",
              "opus_48000_64",
              "opus_48000_96",
              "opus_48000_128",
              "opus_48000_192",
              "wav"
            ],
            "type_name": "nodetool.nodes.fal.audio_to_audio.OutputFormat"
          },
          "default": "mp3_44100_128",
          "title": "Output Format",
          "description": "Output audio format for the separated stems"
        },
        {
          "name": "stems",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Stems",
          "description": "Specific stems to extract. If None, extracts all available stems. Available stems depend on model: vocals, drums, bass, other, guitar, piano (for 6s model)"
        },
        {
          "name": "overlap",
          "type": {
            "type": "float"
          },
          "default": 0.25,
          "title": "Overlap",
          "description": "Overlap between segments (0.0 to 1.0). Higher values may improve quality but increase processing time."
        },
        {
          "name": "model",
          "type": {
            "type": "enum",
            "values": [
              "htdemucs",
              "htdemucs_ft",
              "htdemucs_6s",
              "hdemucs_mmi",
              "mdx",
              "mdx_extra",
              "mdx_q",
              "mdx_extra_q"
            ],
            "type_name": "nodetool.nodes.fal.audio_to_audio.Model"
          },
          "default": "htdemucs_6s",
          "title": "Model",
          "description": "Demucs model to use for separation"
        },
        {
          "name": "audio_url",
          "type": {
            "type": "audio"
          },
          "default": {
            "type": "audio",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Audio Url",
          "description": "URL of the audio file to separate into stems"
        },
        {
          "name": "shifts",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Shifts",
          "description": "Number of random shifts for equivariant stabilization. Higher values improve quality but increase processing time."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "dict",
            "type_args": [
              {
                "type": "str"
              },
              {
                "type": "any"
              }
            ]
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "audio"
      ]
    },
    {
      "title": "Elevenlabs Voice Changer",
      "description": "ElevenLabs Voice Changer transforms voice characteristics in audio with AI-powered voice conversion.\n    audio, voice-change, elevenlabs, transformation, audio-to-audio\n\n    Use cases:\n    - Change voice characteristics in audio\n    - Transform vocal qualities\n    - Create voice variations\n    - Modify speaker identity\n    - Generate voice-changed audio",
      "namespace": "fal.audio_to_audio",
      "node_type": "fal.audio_to_audio.ElevenlabsVoiceChanger",
      "properties": [
        {
          "name": "voice",
          "type": {
            "type": "str"
          },
          "default": "Rachel",
          "title": "Voice",
          "description": "The voice to use for speech generation"
        },
        {
          "name": "audio_url",
          "type": {
            "type": "audio"
          },
          "default": {
            "type": "audio",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Audio Url",
          "description": "The input audio file"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Random seed for reproducibility."
        },
        {
          "name": "output_format",
          "type": {
            "type": "enum",
            "values": [
              "mp3_22050_32",
              "mp3_44100_32",
              "mp3_44100_64",
              "mp3_44100_96",
              "mp3_44100_128",
              "mp3_44100_192",
              "pcm_8000",
              "pcm_16000",
              "pcm_22050",
              "pcm_24000",
              "pcm_44100",
              "pcm_48000",
              "ulaw_8000",
              "alaw_8000",
              "opus_48000_32",
              "opus_48000_64",
              "opus_48000_96",
              "opus_48000_128",
              "opus_48000_192",
              "wav"
            ],
            "type_name": "nodetool.nodes.fal.audio_to_audio.OutputFormat"
          },
          "default": "mp3_44100_128",
          "title": "Output Format",
          "description": "Output format of the generated audio. Formatted as codec_sample_rate_bitrate."
        },
        {
          "name": "remove_background_noise",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Remove Background Noise",
          "description": "If set, will remove the background noise from your audio input using our audio isolation model."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "audio"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "audio"
      ]
    },
    {
      "title": "Nova Sr",
      "description": "Nova SR enhances audio quality through super-resolution processing for clearer and richer sound.\n    audio, enhancement, super-resolution, quality, audio-to-audio\n\n    Use cases:\n    - Enhance audio quality\n    - Improve sound clarity\n    - Upscale audio resolution\n    - Restore degraded audio\n    - Generate high-quality audio",
      "namespace": "fal.audio_to_audio",
      "node_type": "fal.audio_to_audio.NovaSr",
      "properties": [
        {
          "name": "sync_mode",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Sync Mode",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history."
        },
        {
          "name": "bitrate",
          "type": {
            "type": "str"
          },
          "default": "192k",
          "title": "Bitrate",
          "description": "The bitrate of the output audio."
        },
        {
          "name": "audio_url",
          "type": {
            "type": "audio"
          },
          "default": {
            "type": "audio",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Audio Url",
          "description": "The URL of the audio file to enhance."
        },
        {
          "name": "audio_format",
          "type": {
            "type": "enum",
            "values": [
              "mp3",
              "aac",
              "m4a",
              "ogg",
              "opus",
              "flac",
              "wav"
            ],
            "type_name": "nodetool.nodes.fal.audio_to_audio.AudioFormat"
          },
          "default": "mp3",
          "title": "Audio Format",
          "description": "The format for the output audio."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "audio"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "audio"
      ]
    },
    {
      "title": "Sam Audio Separate",
      "description": "SAM Audio Separate isolates and extracts different audio sources from mixed recordings.\n    audio, separation, source-extraction, isolation, audio-to-audio\n\n    Use cases:\n    - Separate audio sources\n    - Extract vocals from music\n    - Isolate instruments\n    - Remove background sounds\n    - Generate separated audio tracks",
      "namespace": "fal.audio_to_audio",
      "node_type": "fal.audio_to_audio.SamAudioSeparate",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "Text prompt describing the sound to isolate."
        },
        {
          "name": "acceleration",
          "type": {
            "type": "enum",
            "values": [
              "fast",
              "balanced",
              "quality"
            ],
            "type_name": "nodetool.nodes.fal.audio_to_audio.Acceleration"
          },
          "default": "balanced",
          "title": "Acceleration",
          "description": "The acceleration level to use."
        },
        {
          "name": "audio_url",
          "type": {
            "type": "audio"
          },
          "default": {
            "type": "audio",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Audio Url",
          "description": "URL of the audio file to process (WAV, MP3, FLAC supported)"
        },
        {
          "name": "predict_spans",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Predict Spans",
          "description": "Automatically predict temporal spans where the target sound occurs."
        },
        {
          "name": "output_format",
          "type": {
            "type": "enum",
            "values": [
              "mp3_22050_32",
              "mp3_44100_32",
              "mp3_44100_64",
              "mp3_44100_96",
              "mp3_44100_128",
              "mp3_44100_192",
              "pcm_8000",
              "pcm_16000",
              "pcm_22050",
              "pcm_24000",
              "pcm_44100",
              "pcm_48000",
              "ulaw_8000",
              "alaw_8000",
              "opus_48000_32",
              "opus_48000_64",
              "opus_48000_96",
              "opus_48000_128",
              "opus_48000_192",
              "wav"
            ],
            "type_name": "nodetool.nodes.fal.audio_to_audio.OutputFormat"
          },
          "default": "wav",
          "title": "Output Format",
          "description": "Output audio format."
        },
        {
          "name": "reranking_candidates",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Reranking Candidates",
          "description": "Number of candidates to generate and rank. Higher improves quality but increases latency and cost."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "dict",
            "type_args": [
              {
                "type": "str"
              },
              {
                "type": "any"
              }
            ]
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "audio"
      ]
    },
    {
      "title": "Sam Audio Span Separate",
      "description": "SAM Audio Span Separate isolates audio sources across time spans with precise temporal control.\n    audio, separation, temporal, span, audio-to-audio\n\n    Use cases:\n    - Separate audio by time spans\n    - Extract sources in specific periods\n    - Isolate temporal audio segments\n    - Remove sounds in time ranges\n    - Generate time-based separations",
      "namespace": "fal.audio_to_audio",
      "node_type": "fal.audio_to_audio.SamAudioSpanSeparate",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "Text prompt describing the sound to isolate. Optional but recommended - helps the model identify what type of sound to extract from the span."
        },
        {
          "name": "acceleration",
          "type": {
            "type": "enum",
            "values": [
              "fast",
              "balanced",
              "quality"
            ],
            "type_name": "nodetool.nodes.fal.audio_to_audio.Acceleration"
          },
          "default": "balanced",
          "title": "Acceleration",
          "description": "The acceleration level to use."
        },
        {
          "name": "spans",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "str"
              }
            ]
          },
          "default": [],
          "title": "Spans",
          "description": "Time spans where the target sound occurs which should be isolated."
        },
        {
          "name": "output_format",
          "type": {
            "type": "enum",
            "values": [
              "mp3_22050_32",
              "mp3_44100_32",
              "mp3_44100_64",
              "mp3_44100_96",
              "mp3_44100_128",
              "mp3_44100_192",
              "pcm_8000",
              "pcm_16000",
              "pcm_22050",
              "pcm_24000",
              "pcm_44100",
              "pcm_48000",
              "ulaw_8000",
              "alaw_8000",
              "opus_48000_32",
              "opus_48000_64",
              "opus_48000_96",
              "opus_48000_128",
              "opus_48000_192",
              "wav"
            ],
            "type_name": "nodetool.nodes.fal.audio_to_audio.OutputFormat"
          },
          "default": "wav",
          "title": "Output Format",
          "description": "Output audio format."
        },
        {
          "name": "trim_to_span",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Trim To Span",
          "description": "Trim output audio to only include the specified span time range. If False, returns the full audio length with the target sound isolated throughout."
        },
        {
          "name": "audio_url",
          "type": {
            "type": "audio"
          },
          "default": {
            "type": "audio",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Audio Url",
          "description": "URL of the audio file to process."
        },
        {
          "name": "reranking_candidates",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Reranking Candidates",
          "description": "Number of candidates to generate and rank. Higher improves quality but increases latency and cost. Requires text prompt; ignored for span-only separation."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "dict",
            "type_args": [
              {
                "type": "str"
              },
              {
                "type": "any"
              }
            ]
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "audio"
      ]
    },
    {
      "title": "Stable Audio 25 Audio To Audio",
      "description": "Stable Audio 2.5 transforms and modifies audio with AI-powered processing and effects.\n    audio, transformation, stable-audio, 2.5, audio-to-audio\n\n    Use cases:\n    - Transform audio characteristics\n    - Apply AI-powered audio effects\n    - Modify audio properties\n    - Generate audio variations\n    - Create processed audio",
      "namespace": "fal.audio_to_audio",
      "node_type": "fal.audio_to_audio.StableAudio25AudioToAudio",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to guide the audio generation"
        },
        {
          "name": "strength",
          "type": {
            "type": "float"
          },
          "default": 0.8,
          "title": "Strength",
          "description": "Sometimes referred to as denoising, this parameter controls how much influence the `audio_url` parameter has on the generated audio. A value of 0 would yield audio that is identical to the input. A value of 1 would be as if you passed in no audio at all."
        },
        {
          "name": "sync_mode",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Sync Mode",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history."
        },
        {
          "name": "audio_url",
          "type": {
            "type": "audio"
          },
          "default": {
            "type": "audio",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Audio Url",
          "description": "The audio clip to transform"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 8,
          "title": "Num Inference Steps",
          "description": "The number of steps to denoise the audio for"
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Guidance Scale",
          "description": "How strictly the diffusion process adheres to the prompt text (higher values make your audio closer to your prompt)."
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": 0,
          "title": "Seed"
        },
        {
          "name": "total_seconds",
          "type": {
            "type": "int"
          },
          "default": 0,
          "title": "Total Seconds",
          "description": "The duration of the audio clip to generate. If not provided, it will be set to the duration of the input audio."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "audio"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "audio",
        "prompt"
      ]
    }
  ]
}