{
  "name": "nodetool-fal",
  "description": "Nodetool FAL nodes",
  "version": "0.6.2-rc.12",
  "authors": [
    "Matthias Georgi <matti.georgi@gmail.com>"
  ],
  "repo_id": "",
  "nodes": [
    {
      "title": "F5 TTS",
      "description": "F5 TTS (Text-to-Speech) model for generating natural-sounding speech from text with voice cloning capabilities.\n    audio, tts, voice-cloning, speech, synthesis, text-to-speech, tts, text-to-audio\n\n    Use cases:\n    - Generate natural speech from text\n    - Clone and replicate voices\n    - Create custom voiceovers\n    - Produce multilingual speech content\n    - Generate personalized audio content",
      "namespace": "fal.text_to_audio",
      "node_type": "fal.text_to_audio.F5TTS",
      "properties": [
        {
          "name": "gen_text",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Gen Text",
          "description": "The text to be converted to speech"
        },
        {
          "name": "ref_audio_url",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Ref Audio Url",
          "description": "URL of the reference audio file to clone the voice from"
        },
        {
          "name": "ref_text",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Ref Text",
          "description": "Optional reference text. If not provided, ASR will be used"
        },
        {
          "name": "model_type",
          "type": {
            "type": "str"
          },
          "default": "F5-TTS",
          "title": "Model Type",
          "description": "Model type to use (F5-TTS or E2-TTS)"
        },
        {
          "name": "remove_silence",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Remove Silence",
          "description": "Whether to remove silence from the generated audio"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "audio"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "gen_text",
        "ref_audio_url",
        "model_type"
      ]
    },
    {
      "title": "MMAudio V2",
      "description": "MMAudio V2 generates synchronized audio given text inputs. It can generate sounds described by a prompt.\n    audio, generation, synthesis, text-to-audio, synchronization\n\n    Use cases:\n    - Generate synchronized audio from text descriptions\n    - Create custom sound effects\n    - Produce ambient soundscapes\n    - Generate audio for multimedia content\n    - Create sound design elements",
      "namespace": "fal.text_to_audio",
      "node_type": "fal.text_to_audio.MMAudioV2",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate the audio for"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "The negative prompt to avoid certain elements in the generated audio"
        },
        {
          "name": "num_steps",
          "type": {
            "type": "int"
          },
          "default": 25,
          "title": "Num Steps",
          "description": "The number of steps to generate the audio for",
          "min": 1.0
        },
        {
          "name": "duration",
          "type": {
            "type": "float"
          },
          "default": 8.0,
          "title": "Duration",
          "description": "The duration of the audio to generate in seconds",
          "min": 1.0
        },
        {
          "name": "cfg_strength",
          "type": {
            "type": "float"
          },
          "default": 4.5,
          "title": "Cfg Strength",
          "description": "The strength of Classifier Free Guidance"
        },
        {
          "name": "mask_away_clip",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Mask Away Clip",
          "description": "Whether to mask away the clip"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed will output the same audio every time"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "audio"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "duration",
        "num_steps"
      ]
    },
    {
      "title": "PlayAI Dialog TTS",
      "description": "PlayAI Dialog TTS generates speech for multi speaker dialogs.\n    audio, tts, dialog, speech, synthesis\n\n    Use cases:\n    - Generate interactive conversations\n    - Create voice overs with multiple characters\n    - Produce spoken dialogs for games\n    - Synthesize narration with distinct voices\n    - Prototype conversational audio",
      "namespace": "fal.text_to_audio",
      "node_type": "fal.text_to_audio.PlayAITTSDialog",
      "properties": [
        {
          "name": "text",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Text",
          "description": "Text to convert into speech"
        },
        {
          "name": "voice",
          "type": {
            "type": "str"
          },
          "default": "nova",
          "title": "Voice",
          "description": "Voice preset to use for the spoken dialog"
        },
        {
          "name": "speed",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Speed",
          "description": "Playback speed of the generated audio",
          "min": 0.5,
          "max": 2.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "audio"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "text",
        "voice"
      ]
    },
    {
      "title": "Stable Audio",
      "description": "Stable Audio generates audio from text prompts. Open source text-to-audio model from fal.ai.\n    audio, generation, synthesis, text-to-audio, open-source\n\n    Use cases:\n    - Generate custom audio content from text\n    - Create background music and sounds\n    - Produce audio assets for projects\n    - Generate sound effects\n    - Create experimental audio content",
      "namespace": "fal.text_to_audio",
      "node_type": "fal.text_to_audio.StableAudio",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate the audio from"
        },
        {
          "name": "seconds_start",
          "type": {
            "type": "int"
          },
          "default": 0,
          "title": "Seconds Start",
          "description": "The start point of the audio clip to generate"
        },
        {
          "name": "seconds_total",
          "type": {
            "type": "int"
          },
          "default": 30,
          "title": "Seconds Total",
          "description": "The duration of the audio clip to generate in seconds"
        },
        {
          "name": "steps",
          "type": {
            "type": "int"
          },
          "default": 100,
          "title": "Steps",
          "description": "The number of steps to denoise the audio for"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "audio"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "seconds_total",
        "steps"
      ]
    },
    {
      "title": "Aura Flow V 03",
      "description": "AuraFlow v0.3 is an open-source flow-based text-to-image generation model that achieves state-of-the-art results on GenEval.\n    image, generation, flow-based, text-to-image, txt2img\n\n    Use cases:\n    - Generate high-quality images\n    - Create artistic visualizations",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.AuraFlowV03",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "The number of images to generate",
          "min": 1.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 3.5,
          "title": "Guidance Scale",
          "description": "Classifier free guidance scale"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 50,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to take",
          "min": 1.0
        },
        {
          "name": "expand_prompt",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Expand Prompt",
          "description": "Whether to perform prompt expansion (recommended)"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The seed to use for generating images"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "guidance_scale",
        "num_inference_steps"
      ]
    },
    {
      "title": "Bria V 1",
      "description": "Bria's Text-to-Image model, trained exclusively on licensed data for safe and risk-free commercial use.\n    Features exceptional image quality and commercial licensing safety.",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.BriaV1",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "The negative prompt to avoid certain elements in the generated image"
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 4,
          "title": "Num Images",
          "description": "How many images to generate. When using guidance, value is set to 1",
          "min": 1.0
        },
        {
          "name": "aspect_ratio",
          "type": {
            "type": "enum",
            "values": [
              "10:16",
              "16:10",
              "9:16",
              "16:9",
              "4:3",
              "3:4",
              "1:1",
              "1:3",
              "3:1",
              "3:2",
              "2:3",
              "4:5",
              "5:4"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.AspectRatio"
          },
          "default": "1:1",
          "title": "Aspect Ratio",
          "description": "The aspect ratio of the image. Ignored when guidance is used"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 30,
          "title": "Num Inference Steps",
          "description": "The number of iterations for refining the generated image",
          "min": 1.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 5.0,
          "title": "Guidance Scale",
          "description": "How closely the model should stick to your prompt (CFG scale)"
        },
        {
          "name": "prompt_enhancement",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Prompt Enhancement",
          "description": "When true, enhances the prompt with more descriptive variations"
        },
        {
          "name": "medium",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Medium",
          "description": "Optional medium specification ('photography' or 'art')"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed and prompt will output the same image every time"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "negative_prompt",
        "aspect_ratio"
      ]
    },
    {
      "title": "Bria V 1 Fast",
      "description": "Bria's Text-to-Image model with perfect harmony of latency and quality.\n    Trained exclusively on licensed data for safe and risk-free commercial use.\n    Features faster inference times while maintaining high image quality.",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.BriaV1Fast",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "The negative prompt to avoid certain elements in the generated image"
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 4,
          "title": "Num Images",
          "description": "How many images to generate. When using guidance, value is set to 1",
          "min": 1.0
        },
        {
          "name": "aspect_ratio",
          "type": {
            "type": "enum",
            "values": [
              "10:16",
              "16:10",
              "9:16",
              "16:9",
              "4:3",
              "3:4",
              "1:1",
              "1:3",
              "3:1",
              "3:2",
              "2:3",
              "4:5",
              "5:4"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.AspectRatio"
          },
          "default": "1:1",
          "title": "Aspect Ratio",
          "description": "The aspect ratio of the image. Ignored when guidance is used"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 8,
          "title": "Num Inference Steps",
          "description": "The number of iterations for refining the generated image",
          "min": 1.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 5.0,
          "title": "Guidance Scale",
          "description": "How closely the model should stick to your prompt (CFG scale)"
        },
        {
          "name": "prompt_enhancement",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Prompt Enhancement",
          "description": "When true, enhances the prompt with more descriptive variations"
        },
        {
          "name": "medium",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Medium",
          "description": "Optional medium specification ('photography' or 'art')"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed and prompt will output the same image every time"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "negative_prompt",
        "aspect_ratio"
      ]
    },
    {
      "title": "Bria V 1 HD",
      "description": "Bria's Text-to-Image model for HD images. Trained exclusively on licensed data for safe and risk-free commercial use. Features exceptional image quality and commercial licensing safety.\n    image, generation, hd, text-to-image, txt2img\n\n    Use cases:\n    - Create commercial marketing materials\n    - Generate licensed artwork\n    - Produce high-definition visuals\n    - Design professional content\n    - Create legally safe visual assets",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.BriaV1HD",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "The negative prompt to avoid certain elements in the generated image"
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 4,
          "title": "Num Images",
          "description": "How many images to generate. When using guidance, value is set to 1",
          "min": 1.0
        },
        {
          "name": "aspect_ratio",
          "type": {
            "type": "enum",
            "values": [
              "10:16",
              "16:10",
              "9:16",
              "16:9",
              "4:3",
              "3:4",
              "1:1",
              "1:3",
              "3:1",
              "3:2",
              "2:3",
              "4:5",
              "5:4"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.AspectRatio"
          },
          "default": "1:1",
          "title": "Aspect Ratio",
          "description": "The aspect ratio of the image. Ignored when guidance is used"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 30,
          "title": "Num Inference Steps",
          "description": "The number of iterations for refining the generated image",
          "min": 1.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 5.0,
          "title": "Guidance Scale",
          "description": "How closely the model should stick to your prompt (CFG scale)"
        },
        {
          "name": "prompt_enhancement",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Prompt Enhancement",
          "description": "When true, enhances the prompt with more descriptive variations"
        },
        {
          "name": "medium",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Medium",
          "description": "Optional medium specification ('photography' or 'art')"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The seed to use for generating images"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "negative_prompt",
        "aspect_ratio"
      ]
    },
    {
      "title": "Diffusion Edge",
      "description": "Diffusion Edge is a diffusion-based high-quality edge detection model that generates\n    edge maps from input images.",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.DiffusionEdge",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Image",
          "description": "The input image to detect edges from"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image"
      ]
    },
    {
      "title": "Fast LCMDiffusion",
      "description": "Fast Latent Consistency Models (v1.5/XL) Text to Image runs SDXL at the speed of light,\n    enabling rapid and high-quality image generation.",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.FastLCMDiffusion",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "model_name",
          "type": {
            "type": "enum",
            "values": [
              "stabilityai/stable-diffusion-xl-base-1.0",
              "runwayml/stable-diffusion-v1-5"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.ModelNameFastLCM"
          },
          "default": "stabilityai/stable-diffusion-xl-base-1.0",
          "title": "Model Name",
          "description": "The name of the model to use"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "Use it to address details that you don't want in the image"
        },
        {
          "name": "image_size",
          "type": {
            "type": "enum",
            "values": [
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
          },
          "default": "square_hd",
          "title": "Image Size",
          "description": "The size of the generated image"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 6,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform",
          "min": 1.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 1.5,
          "title": "Guidance Scale",
          "description": "How closely the model should stick to your prompt"
        },
        {
          "name": "sync_mode",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Sync Mode",
          "description": "If true, wait for image generation and upload before returning"
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "The number of images to generate",
          "min": 1.0
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If true, the safety checker will be enabled"
        },
        {
          "name": "safety_checker_version",
          "type": {
            "type": "enum",
            "values": [
              "v1",
              "v2"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.SafetyCheckerVersion"
          },
          "default": "v1",
          "title": "Safety Checker Version",
          "description": "The version of the safety checker to use"
        },
        {
          "name": "expand_prompt",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Expand Prompt",
          "description": "If true, the prompt will be expanded with additional prompts"
        },
        {
          "name": "guidance_rescale",
          "type": {
            "type": "float"
          },
          "default": 0.0,
          "title": "Guidance Rescale",
          "description": "The rescale factor for the CFG"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed and prompt will output the same image every time"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "model_name",
        "guidance_scale"
      ]
    },
    {
      "title": "Fast Lightning SDXL",
      "description": "Stable Diffusion XL Lightning Text to Image runs SDXL at the speed of light, enabling\n    ultra-fast high-quality image generation.",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.FastLightningSDXL",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "image_size",
          "type": {
            "type": "enum",
            "values": [
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
          },
          "default": "square_hd",
          "title": "Image Size",
          "description": "The size of the generated image"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 4,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform (1, 2, 4, or 8)",
          "min": 1.0,
          "max": 8.0
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed and prompt will output the same image every time"
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If true, the safety checker will be enabled"
        },
        {
          "name": "expand_prompt",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Expand Prompt",
          "description": "If true, the prompt will be expanded with additional prompts"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "image_size",
        "num_inference_steps"
      ]
    },
    {
      "title": "Fast SDXL",
      "description": "Fast SDXL is a high-performance text-to-image model that runs SDXL at exceptional speeds\n    while maintaining high-quality output.",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.FastSDXL",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "Use it to address details that you don't want in the image"
        },
        {
          "name": "image_size",
          "type": {
            "type": "enum",
            "values": [
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
          },
          "default": "square_hd",
          "title": "Image Size",
          "description": "The size of the generated image"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 25,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform",
          "min": 1.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 7.5,
          "title": "Guidance Scale",
          "description": "How closely the model should stick to your prompt (CFG scale)"
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "The number of images to generate",
          "min": 1.0
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed and prompt will output the same image every time"
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If true, the safety checker will be enabled"
        },
        {
          "name": "expand_prompt",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Expand Prompt",
          "description": "If true, the prompt will be expanded with additional prompts"
        },
        {
          "name": "loras",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "lora_weight"
              }
            ]
          },
          "default": [],
          "title": "Loras",
          "description": "The list of LoRA weights to use"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "negative_prompt",
        "guidance_scale"
      ]
    },
    {
      "title": "Fast SDXLControl Net Canny",
      "description": "Fast SDXL ControlNet Canny is a model that generates images using ControlNet with SDXL.",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.FastSDXLControlNetCanny",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "control_image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Control Image",
          "description": "The control image to use for generation"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "Use it to address details that you don't want in the image"
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 7.5,
          "title": "Guidance Scale",
          "description": "How closely the model should stick to your prompt"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 25,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform",
          "min": 1.0
        },
        {
          "name": "image_size",
          "type": {
            "type": "enum",
            "values": [
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
          },
          "default": "square_hd",
          "title": "Image Size",
          "description": "The size of the generated image"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed and prompt will output the same image every time"
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If true, the safety checker will be enabled"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "control_image",
        "guidance_scale"
      ]
    },
    {
      "title": "Fast Turbo Diffusion",
      "description": "Fast Turbo Diffusion runs SDXL at exceptional speeds while maintaining high-quality output.\n    Supports both SDXL Turbo and SD Turbo models for ultra-fast image generation.",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.FastTurboDiffusion",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "model_name",
          "type": {
            "type": "enum",
            "values": [
              "stabilityai/sdxl-turbo",
              "stabilityai/sd-turbo"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.ModelNameEnum"
          },
          "default": "stabilityai/sdxl-turbo",
          "title": "Model Name",
          "description": "The name of the model to use"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "Use it to address details that you don't want in the image"
        },
        {
          "name": "image_size",
          "type": {
            "type": "enum",
            "values": [
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
          },
          "default": "square",
          "title": "Image Size",
          "description": "The size of the generated image"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 2,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform",
          "min": 1.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Guidance Scale",
          "description": "How closely the model should stick to your prompt"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed and prompt will output the same image every time"
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If true, the safety checker will be enabled"
        },
        {
          "name": "expand_prompt",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Expand Prompt",
          "description": "If true, the prompt will be expanded with additional prompts"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "model_name",
        "guidance_scale"
      ]
    },
    {
      "title": "Flux Dev",
      "description": "FLUX.1 [dev] is a 12 billion parameter flow transformer that generates high-quality images from text.\n    It is suitable for personal and commercial use.",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.FluxDev",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "image_size",
          "type": {
            "type": "enum",
            "values": [
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
          },
          "default": "landscape_4_3",
          "title": "Image Size",
          "description": "Either a preset size or a custom {width, height} dictionary"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 28,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform",
          "min": 1.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 3.5,
          "title": "Guidance Scale",
          "description": "The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt"
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "The number of images to generate",
          "min": 1.0
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed and prompt will output the same image every time"
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If true, the safety checker will be enabled"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "image_size",
        "guidance_scale"
      ]
    },
    {
      "title": "Flux Dev Image To Image",
      "description": "FLUX.1 [dev] Image-to-Image is a high-performance endpoint that enables rapid transformation\n    of existing images, delivering high-quality style transfers and image modifications with\n    the core FLUX capabilities.",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.FluxDevImageToImage",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Image",
          "description": "The input image to transform"
        },
        {
          "name": "strength",
          "type": {
            "type": "float"
          },
          "default": 0.95,
          "title": "Strength",
          "description": "The strength of the initial image. Higher strength values are better for this model"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 40,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform",
          "min": 1.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 3.5,
          "title": "Guidance Scale",
          "description": "How closely the model should stick to your prompt"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed and prompt will output the same image every time"
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If true, the safety checker will be enabled"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "image",
        "strength"
      ]
    },
    {
      "title": "Flux General",
      "description": "FLUX.1 [dev] with Controlnets and Loras is a versatile text-to-image model that supports multiple AI extensions including LoRA, ControlNet conditioning, and IP-Adapter integration, enabling comprehensive control over image generation through various guidance methods.\n    image, generation, controlnet, lora, ip-adapter, text-to-image, txt2img\n\n    Use cases:\n    - Create controlled image generations\n    - Apply multiple AI extensions\n    - Generate guided visual content\n    - Produce customized artwork\n    - Design with precise control",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.FluxGeneral",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "image_size",
          "type": {
            "type": "enum",
            "values": [
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
          },
          "default": "square_hd",
          "title": "Image Size",
          "description": "The size of the generated image"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 28,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform",
          "min": 1.0,
          "max": 50.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 3.5,
          "title": "Guidance Scale",
          "description": "How closely the model should stick to your prompt (CFG scale)",
          "min": 1.0,
          "max": 20.0
        },
        {
          "name": "real_cfg_scale",
          "type": {
            "type": "float"
          },
          "default": 3.5,
          "title": "Real Cfg Scale",
          "description": "Classical CFG scale as in SD1.5, SDXL, etc."
        },
        {
          "name": "use_real_cfg",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Use Real Cfg",
          "description": "Uses classical CFG. Increases generation times and price when true"
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "The number of images to generate",
          "min": 1.0
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed and prompt will output the same image every time"
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If true, the safety checker will be enabled"
        },
        {
          "name": "reference_strength",
          "type": {
            "type": "float"
          },
          "default": 0.65,
          "title": "Reference Strength",
          "description": "Strength of reference_only generation. Only used if a reference image is provided"
        },
        {
          "name": "reference_end",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Reference End",
          "description": "The percentage of total timesteps when reference guidance should end"
        },
        {
          "name": "base_shift",
          "type": {
            "type": "float"
          },
          "default": 0.5,
          "title": "Base Shift",
          "description": "Base shift for the scheduled timesteps"
        },
        {
          "name": "max_shift",
          "type": {
            "type": "float"
          },
          "default": 1.15,
          "title": "Max Shift",
          "description": "Max shift for the scheduled timesteps"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "image_size",
        "guidance_scale"
      ]
    },
    {
      "title": "Flux Lora",
      "description": "FLUX.1 [dev] with LoRAs is a text-to-image model that supports LoRA adaptations, enabling rapid and high-quality image generation with pre-trained LoRA weights for personalization, specific styles, brand identities, and product-specific outputs.\n    image, generation, lora, personalization, style-transfer, text-to-image, txt2img\n\n    Use cases:\n    - Create brand-specific visuals\n    - Generate custom styled images\n    - Adapt existing styles to new content\n    - Produce personalized artwork\n    - Design consistent visual identities",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.FluxLora",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "image_size",
          "type": {
            "type": "enum",
            "values": [
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
          },
          "default": "landscape_4_3",
          "title": "Image Size",
          "description": "Either a preset size or a custom {width, height} dictionary"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 28,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform",
          "min": 1.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 3.5,
          "title": "Guidance Scale",
          "description": "The CFG scale to determine how closely the model follows the prompt"
        },
        {
          "name": "loras",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "lora_weight"
              }
            ]
          },
          "default": [],
          "title": "Loras",
          "description": "List of LoRA weights to use for image generation"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed and prompt will output the same image every time"
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If true, the safety checker will be enabled"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "image_size",
        "loras"
      ]
    },
    {
      "title": "Flux Lora Inpainting",
      "description": "FLUX.1 [dev] Inpainting with LoRAs is a text-to-image model that supports inpainting and LoRA adaptations,\n    enabling rapid and high-quality image inpainting using pre-trained LoRA weights for personalization,\n    specific styles, brand identities, and product-specific outputs.",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.FluxLoraInpainting",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Image",
          "description": "The input image to inpaint"
        },
        {
          "name": "mask",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Mask",
          "description": "The mask indicating areas to inpaint (white=inpaint, black=keep)"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 28,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform",
          "min": 1.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 3.5,
          "title": "Guidance Scale",
          "description": "The CFG scale to determine how closely the model follows the prompt"
        },
        {
          "name": "strength",
          "type": {
            "type": "float"
          },
          "default": 0.85,
          "title": "Strength",
          "description": "The strength to use for inpainting. 1.0 completely remakes the image while 0.0 preserves the original",
          "min": 0.0,
          "max": 1.0
        },
        {
          "name": "loras",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "lora_weight"
              }
            ]
          },
          "default": [],
          "title": "Loras",
          "description": "List of LoRA weights to use for image generation"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed and prompt will output the same image every time"
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If true, the safety checker will be enabled"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "image",
        "mask",
        "loras"
      ]
    },
    {
      "title": "Flux Lora TTI",
      "description": "FLUX.1 with LoRAs is a text-to-image model that supports LoRA adaptations,\n    enabling high-quality image generation with customizable LoRA weights for\n    personalization, specific styles, and brand identities.",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.FluxLoraTTI",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "Use it to address details that you don't want in the image"
        },
        {
          "name": "model_name",
          "type": {
            "type": "enum",
            "values": [
              "stabilityai/stable-diffusion-xl-base-1.0",
              "runwayml/stable-diffusion-v1-5",
              "stabilityai/stable-diffusion-2-1",
              "gsdf/Anything-V5.0",
              "lykon/dreamshaper-8",
              "XpucT/Deliberate_v3",
              "SG161222/Realistic_Vision_V5.1_noVAE"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.LoraModel"
          },
          "default": "stabilityai/stable-diffusion-xl-base-1.0",
          "title": "Model Name",
          "description": "The base model to use for generation"
        },
        {
          "name": "image_size",
          "type": {
            "type": "enum",
            "values": [
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
          },
          "default": "square_hd",
          "title": "Image Size",
          "description": "The size of the generated image"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 30,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform",
          "min": 1.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 7.5,
          "title": "Guidance Scale",
          "description": "How closely the model should stick to your prompt"
        },
        {
          "name": "loras",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "lora_weight"
              }
            ]
          },
          "default": [],
          "title": "Loras",
          "description": "List of LoRA weights to use for image generation"
        },
        {
          "name": "prompt_weighting",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Prompt Weighting",
          "description": "If true, prompt weighting syntax will be used and 77 token limit lifted"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed and prompt will output the same image every time"
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If true, the safety checker will be enabled"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "model_name",
        "loras"
      ]
    },
    {
      "title": "Flux Schnell",
      "description": "FLUX.1 [schnell] is a 12 billion parameter flow transformer that generates high-quality images\n    from text in 1 to 4 steps, suitable for personal and commercial use.",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.FluxSchnell",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "image_size",
          "type": {
            "type": "enum",
            "values": [
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
          },
          "default": "landscape_4_3",
          "title": "Image Size",
          "description": "Either a preset size or a custom {width, height} dictionary"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 4,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform",
          "min": 1.0
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "The number of images to generate",
          "min": 1.0
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed and prompt will output the same image every time"
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If true, the safety checker will be enabled"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "image_size",
        "num_inference_steps"
      ]
    },
    {
      "title": "Flux Subject",
      "description": "FLUX.1 Subject is a super fast endpoint for the FLUX.1 [schnell] model with subject input capabilities, enabling rapid and high-quality image generation for personalization, specific styles, brand identities, and product-specific outputs.\n    image, generation, subject-driven, personalization, fast, text-to-image, txt2img\n\n    Use cases:\n    - Create variations of existing subjects\n    - Generate personalized product images\n    - Design brand-specific visuals\n    - Produce custom character artwork\n    - Create subject-based illustrations",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.FluxSubject",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Image",
          "description": "The image of the subject"
        },
        {
          "name": "image_size",
          "type": {
            "type": "enum",
            "values": [
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
          },
          "default": "square_hd",
          "title": "Image Size",
          "description": "Either a preset size or a custom {width, height} dictionary"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 8,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform",
          "min": 1.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 3.5,
          "title": "Guidance Scale",
          "description": "The CFG scale to determine how closely the model follows the prompt"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed and prompt will output the same image every time"
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If true, the safety checker will be enabled"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "image",
        "image_size"
      ]
    },
    {
      "title": "Flux V 1 Pro",
      "description": "FLUX1.1 [pro] is an enhanced version of FLUX.1 [pro], improved image generation capabilities, delivering superior composition, detail, and artistic fidelity compared to its predecessor.\n    image, generation, composition, detail, artistic, text-to-image, txt2img\n\n    Use cases:\n    - Generate high-fidelity artwork\n    - Create detailed illustrations\n    - Design complex compositions\n    - Produce artistic renderings\n    - Generate professional visuals",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.FluxV1Pro",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "image_size",
          "type": {
            "type": "enum",
            "values": [
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
          },
          "default": "square_hd",
          "title": "Image Size",
          "description": "Either a preset size or a custom {width, height} dictionary. Max dimension 14142"
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 3.5,
          "title": "Guidance Scale",
          "description": "The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.",
          "min": 1.0,
          "max": 20.0
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 28,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform.",
          "min": 1.0,
          "max": 50.0
        },
        {
          "name": "seed",
          "type": {
            "type": "int",
            "optional": true
          },
          "default": null,
          "title": "Seed",
          "description": "The same seed and the same prompt given to the same version of the model will output the same image every time."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "image_size",
        "guidance_scale"
      ]
    },
    {
      "title": "Flux V 1 Pro New",
      "description": "FLUX.1 [pro] new is an accelerated version of FLUX.1 [pro], maintaining professional-grade\n    image quality while delivering significantly faster generation speeds.",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.FluxV1ProNew",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "image_size",
          "type": {
            "type": "enum",
            "values": [
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
          },
          "default": "landscape_4_3",
          "title": "Image Size",
          "description": "Either a preset size or a custom {width, height} dictionary"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 28,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform",
          "min": 1.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 3.5,
          "title": "Guidance Scale",
          "description": "The CFG scale to determine how closely the model follows the prompt",
          "min": 1.0,
          "max": 20.0
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "The number of images to generate",
          "min": 1.0
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed and prompt will output the same image every time"
        },
        {
          "name": "safety_tolerance",
          "type": {
            "type": "int"
          },
          "default": 2,
          "title": "Safety Tolerance",
          "description": "Safety tolerance level (1=strict, 6=permissive)",
          "min": 1.0,
          "max": 6.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "image_size",
        "guidance_scale"
      ]
    },
    {
      "title": "Flux V 1 Pro Ultra",
      "description": "FLUX1.1 [ultra] is the latest and most advanced version of FLUX.1 [pro],\n    featuring cutting-edge improvements in image generation, delivering unparalleled\n    composition, detail, and artistic fidelity.",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.FluxV1ProUltra",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "image_size",
          "type": {
            "type": "enum",
            "values": [
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
          },
          "default": "square_hd",
          "title": "Image Size",
          "description": "Either a preset size or a custom {width, height} dictionary. Max dimension 14142"
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 3.5,
          "title": "Guidance Scale",
          "description": "The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.",
          "min": 1.0,
          "max": 20.0
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 28,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform.",
          "min": 1.0,
          "max": 50.0
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed and the same prompt given to the same version of the model will output the same image every time."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "image_size",
        "guidance_scale"
      ]
    },
    {
      "title": "Fooocus",
      "description": "Fooocus is a text-to-image model with default parameters and automated optimizations\n    for quality improvements.",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.Fooocus",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "Use it to address details that you don't want in the image"
        },
        {
          "name": "styles",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "str"
              }
            ]
          },
          "default": [
            "Fooocus Enhance",
            "Fooocus V2",
            "Fooocus Sharp"
          ],
          "title": "Styles",
          "description": "The styles to apply to the generated image"
        },
        {
          "name": "performance",
          "type": {
            "type": "enum",
            "values": [
              "Speed",
              "Quality",
              "Extreme Speed",
              "Lightning"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.PerformanceEnum"
          },
          "default": "Extreme Speed",
          "title": "Performance",
          "description": "You can choose Speed or Quality"
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 4.0,
          "title": "Guidance Scale",
          "description": "How closely the model should stick to your prompt"
        },
        {
          "name": "sharpness",
          "type": {
            "type": "float"
          },
          "default": 2.0,
          "title": "Sharpness",
          "description": "Higher value means image and texture are sharper"
        },
        {
          "name": "aspect_ratio",
          "type": {
            "type": "str"
          },
          "default": "1024x1024",
          "title": "Aspect Ratio",
          "description": "The size of the generated image (must be multiples of 8)"
        },
        {
          "name": "loras",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "lora_weight"
              }
            ]
          },
          "default": [],
          "title": "Loras",
          "description": "Up to 5 LoRAs that will be merged for generation"
        },
        {
          "name": "refiner_model",
          "type": {
            "type": "enum",
            "values": [
              "None",
              "realisticVisionV60B1_v51VAE.safetensors"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.RefinerModelEnum"
          },
          "default": "None",
          "title": "Refiner Model",
          "description": "Refiner model to use (SDXL or SD 1.5)"
        },
        {
          "name": "refiner_switch",
          "type": {
            "type": "float"
          },
          "default": 0.8,
          "title": "Refiner Switch",
          "description": "Switch point for refiner (0.4 for SD1.5 realistic, 0.667 for SD1.5 anime, 0.8 for XL)"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed and prompt will output the same image every time"
        },
        {
          "name": "control_image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Control Image",
          "description": "Reference image for generation"
        },
        {
          "name": "control_type",
          "type": {
            "type": "enum",
            "values": [
              "ImagePrompt",
              "PyraCanny",
              "CPDS",
              "FaceSwap"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.ControlTypeEnum"
          },
          "default": "PyraCanny",
          "title": "Control Type",
          "description": "The type of image control"
        },
        {
          "name": "control_image_weight",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Control Image Weight",
          "description": "Strength of the control image influence"
        },
        {
          "name": "control_image_stop_at",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Control Image Stop At",
          "description": "When to stop applying control image influence"
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If false, the safety checker will be disabled"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "negative_prompt",
        "styles"
      ]
    },
    {
      "title": "Hyper SDXL",
      "description": "Hyper SDXL is a hyper-charged version of SDXL that delivers exceptional performance and creativity\n    while maintaining high-quality output and ultra-fast generation speeds.",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.HyperSDXL",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "image_size",
          "type": {
            "type": "enum",
            "values": [
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
          },
          "default": "square_hd",
          "title": "Image Size",
          "description": "The size of the generated image"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform (1, 2, or 4)",
          "min": 1.0,
          "max": 4.0
        },
        {
          "name": "sync_mode",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Sync Mode",
          "description": "If true, wait for image generation and upload before returning"
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "The number of images to generate",
          "min": 1.0
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If true, the safety checker will be enabled"
        },
        {
          "name": "expand_prompt",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Expand Prompt",
          "description": "If true, the prompt will be expanded with additional prompts"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed and prompt will output the same image every time"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "image_size",
        "num_inference_steps"
      ]
    },
    {
      "title": "Ideogram V 2",
      "description": "Ideogram V2 is a state-of-the-art image generation model optimized for commercial and creative use, featuring exceptional typography handling and realistic outputs.\n    image, generation, ai, typography, realistic, text-to-image, txt2img\n\n    Use cases:\n    - Create commercial artwork and designs\n    - Generate realistic product visualizations\n    - Design marketing materials with text\n    - Produce high-quality illustrations\n    - Create brand assets and logos",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.IdeogramV2",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "aspect_ratio",
          "type": {
            "type": "enum",
            "values": [
              "10:16",
              "16:10",
              "9:16",
              "16:9",
              "4:3",
              "3:4",
              "1:1",
              "1:3",
              "3:1",
              "3:2",
              "2:3",
              "4:5",
              "5:4"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.AspectRatio"
          },
          "default": "1:1",
          "title": "Aspect Ratio",
          "description": "The aspect ratio of the generated image."
        },
        {
          "name": "expand_prompt",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Expand Prompt",
          "description": "Whether to expand the prompt with MagicPrompt functionality."
        },
        {
          "name": "style",
          "type": {
            "type": "enum",
            "values": [
              "auto",
              "general",
              "realistic",
              "design",
              "render_3D",
              "anime"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.IdeogramStyle"
          },
          "default": "auto",
          "title": "Style",
          "description": "The style of the generated image."
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "A negative prompt to avoid in the generated image."
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for the random number generator."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "aspect_ratio",
        "style"
      ]
    },
    {
      "title": "Ideogram V 2 Turbo",
      "description": "Accelerated image generation with Ideogram V2 Turbo. Create high-quality visuals, posters,\n    and logos with enhanced speed while maintaining Ideogram's signature quality.",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.IdeogramV2Turbo",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "aspect_ratio",
          "type": {
            "type": "enum",
            "values": [
              "10:16",
              "16:10",
              "9:16",
              "16:9",
              "4:3",
              "3:4",
              "1:1",
              "1:3",
              "3:1",
              "3:2",
              "2:3",
              "4:5",
              "5:4"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.AspectRatio"
          },
          "default": "1:1",
          "title": "Aspect Ratio",
          "description": "The aspect ratio of the generated image."
        },
        {
          "name": "expand_prompt",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Expand Prompt",
          "description": "Whether to expand the prompt with MagicPrompt functionality."
        },
        {
          "name": "style",
          "type": {
            "type": "enum",
            "values": [
              "auto",
              "general",
              "realistic",
              "design",
              "render_3D",
              "anime"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.IdeogramStyle"
          },
          "default": "auto",
          "title": "Style",
          "description": "The style of the generated image."
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "A negative prompt to avoid in the generated image."
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for the random number generator."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "aspect_ratio",
        "style"
      ]
    },
    {
      "title": "Illusion Diffusion",
      "description": "Illusion Diffusion is a model that creates illusions conditioned on an input image.",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.IllusionDiffusion",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "Use it to address details that you don't want in the image"
        },
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Image",
          "description": "Input image URL for conditioning the generation"
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 7.5,
          "title": "Guidance Scale",
          "description": "How closely the model should stick to your prompt"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 40,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform",
          "min": 1.0
        },
        {
          "name": "image_size",
          "type": {
            "type": "enum",
            "values": [
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
          },
          "default": "square_hd",
          "title": "Image Size",
          "description": "The size of the generated image"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed and prompt will output the same image every time"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "image",
        "guidance_scale"
      ]
    },
    {
      "title": "Imagen 4 Preview",
      "description": "Imagen 4 Preview is the next iteration of Google's Imagen series, offering\n    high quality text-to-image generation with strong prompt adherence and\n    improved realism.\n    image, generation, google, text-to-image, txt2img\n\n    Use cases:\n    - Generate photorealistic artwork and designs\n    - Create marketing and product visuals\n    - Produce concept art or storyboards\n    - Explore creative ideas with high fidelity\n    - Rapid prototyping of imagery",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.Imagen4Preview",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "Elements to avoid in the generated image"
        },
        {
          "name": "aspect_ratio",
          "type": {
            "type": "enum",
            "values": [
              "10:16",
              "16:10",
              "9:16",
              "16:9",
              "4:3",
              "3:4",
              "1:1",
              "1:3",
              "3:1",
              "3:2",
              "2:3",
              "4:5",
              "5:4"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.AspectRatio"
          },
          "default": "1:1",
          "title": "Aspect Ratio",
          "description": "The aspect ratio of the generated image"
        },
        {
          "name": "image_size",
          "type": {
            "type": "enum",
            "values": [
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
          },
          "default": "landscape_4_3",
          "title": "Image Size",
          "description": "The size of the generated image"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 50,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform",
          "min": 1.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 5.0,
          "title": "Guidance Scale",
          "description": "How closely the model should follow the prompt"
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "The number of images to generate",
          "min": 1.0
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed and prompt will output the same image every time"
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If true, the safety checker will be enabled"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "aspect_ratio",
        "guidance_scale"
      ]
    },
    {
      "title": "LCMDiffusion",
      "description": "Latent Consistency Models (SDXL & SDv1.5) Text to Image produces high-quality images\n    with minimal inference steps.",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.LCMDiffusion",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "model",
          "type": {
            "type": "enum",
            "values": [
              "sdxl",
              "sdv1-5"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.ModelNameLCM"
          },
          "default": "sdv1-5",
          "title": "Model",
          "description": "The model to use for generating the image"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "Use it to address details that you don't want in the image"
        },
        {
          "name": "image_size",
          "type": {
            "type": "enum",
            "values": [
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
          },
          "default": "square",
          "title": "Image Size",
          "description": "The size of the generated image"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 4,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform",
          "min": 1.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Guidance Scale",
          "description": "How closely the model should stick to your prompt"
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If true, the safety checker will be enabled"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed and prompt will output the same image every time"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "model",
        "guidance_scale"
      ]
    },
    {
      "title": "Luma Photon",
      "description": "Luma Photon is a creative and personalizable text-to-image model that brings a step-function\n    change in the cost of high-quality image generation, optimized for creatives.",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.LumaPhoton",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "aspect_ratio",
          "type": {
            "type": "enum",
            "values": [
              "16:9",
              "9:16",
              "1:1",
              "4:3",
              "3:4",
              "21:9",
              "9:21"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.AspectRatioLuma"
          },
          "default": "1:1",
          "title": "Aspect Ratio",
          "description": "The aspect ratio of the generated image"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "aspect_ratio"
      ]
    },
    {
      "title": "Luma Photon Flash",
      "description": "Luma Photon Flash is the most creative, personalizable, and intelligent visual model for creatives,\n    bringing a step-function change in the cost of high-quality image generation with faster inference times.",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.LumaPhotonFlash",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "aspect_ratio",
          "type": {
            "type": "enum",
            "values": [
              "16:9",
              "9:16",
              "1:1",
              "4:3",
              "3:4",
              "21:9",
              "9:21"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.AspectRatioLuma"
          },
          "default": "1:1",
          "title": "Aspect Ratio",
          "description": "The aspect ratio of the generated image"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "aspect_ratio"
      ]
    },
    {
      "title": "Omni Gen V 1",
      "description": "OmniGen is a unified image generation model that can generate a wide range of images from multi-modal prompts. It can be used for various tasks such as Image Editing, Personalized Image Generation, Virtual Try-On, Multi Person Generation and more!\n    image, generation, multi-modal, editing, personalization, text-to-image, txt2img\n\n    Use cases:\n    - Edit and modify existing images\n    - Create personalized visual content\n    - Generate virtual try-on images\n    - Create multi-person compositions\n    - Combine multiple images creatively",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.OmniGenV1",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "input_image_1",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Input Image 1",
          "description": "The first input image to use for generation"
        },
        {
          "name": "input_image_2",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Input Image 2",
          "description": "The second input image to use for generation"
        },
        {
          "name": "image_size",
          "type": {
            "type": "enum",
            "values": [
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
          },
          "default": "square_hd",
          "title": "Image Size",
          "description": "The size of the generated image"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 50,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform",
          "min": 1.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 3.0,
          "title": "Guidance Scale",
          "description": "How closely the model should stick to your prompt"
        },
        {
          "name": "img_guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 1.6,
          "title": "Img Guidance Scale",
          "description": "How closely the model should stick to your input image"
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "The number of images to generate",
          "min": 1.0
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed and prompt will output the same image every time"
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If true, the safety checker will be enabled"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "input_image_1",
        "image_size"
      ]
    },
    {
      "title": "Playground V 25",
      "description": "Playground v2.5 is a state-of-the-art open-source model that excels in aesthetic quality\n    for text-to-image generation.",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.PlaygroundV25",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "image_size",
          "type": {
            "type": "enum",
            "values": [
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
          },
          "default": "square_hd",
          "title": "Image Size",
          "description": "The size of the generated image"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 30,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform",
          "min": 1.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 7.5,
          "title": "Guidance Scale",
          "description": "How closely the model should stick to your prompt"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed and prompt will output the same image every time"
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If true, the safety checker will be enabled"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "image_size",
        "guidance_scale"
      ]
    },
    {
      "title": "Recraft 20 B",
      "description": "Recraft 20B is a new and affordable text-to-image model that delivers state-of-the-art results.\n     image, generation, efficient, text-to-image, txt2img\n\n    Use cases:\n    - Generate cost-effective visuals\n    - Create high-quality images\n    - Produce professional artwork\n    - Design marketing materials\n    - Generate commercial content",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.Recraft20B",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "image_size",
          "type": {
            "type": "enum",
            "values": [
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
          },
          "default": "square_hd",
          "title": "Image Size",
          "description": "Either a preset size or a custom {width, height} dictionary"
        },
        {
          "name": "style",
          "type": {
            "type": "enum",
            "values": [
              "any",
              "realistic_image",
              "digital_illustration",
              "vector_illustration",
              "pixel_art",
              "flat_illustration",
              "isometric_illustration",
              "watercolor",
              "line_art",
              "pencil_drawing",
              "oil_painting",
              "anime",
              "comic_book",
              "retro",
              "sticker",
              "3d_render",
              "cinematic",
              "photographic",
              "clay",
              "cutout",
              "origami",
              "pattern",
              "pop_art",
              "renaissance",
              "studio_ghibli",
              "storybook"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.StylePreset"
          },
          "default": "realistic_image",
          "title": "Style",
          "description": "The style of the generated images. Vector images cost 2X as much."
        },
        {
          "name": "colors",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "color"
              }
            ]
          },
          "default": [],
          "title": "Colors",
          "description": "An array of preferable colors"
        },
        {
          "name": "style_id",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Style Id",
          "description": "The ID of the custom style reference (optional)"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "image_size",
        "style"
      ]
    },
    {
      "title": "Recraft V 3",
      "description": "Recraft V3 is a text-to-image model with the ability to generate long texts, vector art, images in brand style, and much more.\n    image, text",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.RecraftV3",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "image_size",
          "type": {
            "type": "enum",
            "values": [
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
          },
          "default": "square_hd",
          "title": "Image Size",
          "description": "Either a preset size or a custom {width, height} dictionary. Max dimension 14142"
        },
        {
          "name": "style",
          "type": {
            "type": "enum",
            "values": [
              "any",
              "realistic_image",
              "digital_illustration",
              "vector_illustration",
              "pixel_art",
              "flat_illustration",
              "isometric_illustration",
              "watercolor",
              "line_art",
              "pencil_drawing",
              "oil_painting",
              "anime",
              "comic_book",
              "retro",
              "sticker",
              "3d_render",
              "cinematic",
              "photographic",
              "clay",
              "cutout",
              "origami",
              "pattern",
              "pop_art",
              "renaissance",
              "studio_ghibli",
              "storybook"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.StylePreset"
          },
          "default": "realistic_image",
          "title": "Style",
          "description": "The style of the generated images. Vector images cost 2X as much."
        },
        {
          "name": "colors",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "color"
              }
            ]
          },
          "default": [],
          "title": "Colors",
          "description": "An array of preferable colors"
        },
        {
          "name": "style_id",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Style Id",
          "description": "The ID of the custom style reference (optional)"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "image_size",
        "style"
      ]
    },
    {
      "title": "Sana V 1",
      "description": "Sana can synthesize high-resolution, high-quality images with strong text-image alignment at a remarkably fast speed, with the ability to generate 4K images in less than a second.\n    image, generation, high-resolution, fast, text-alignment, text-to-image, txt2img\n\n    Use cases:\n    - Generate 4K quality images\n    - Create high-resolution artwork\n    - Produce rapid visual prototypes\n    - Design detailed illustrations\n    - Generate precise text-aligned visuals",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.SanaV1",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "Use it to address details that you don't want in the image"
        },
        {
          "name": "image_size",
          "type": {
            "type": "enum",
            "values": [
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
          },
          "default": "square_hd",
          "title": "Image Size",
          "description": "The size of the generated image"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 18,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform",
          "min": 1.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 5.0,
          "title": "Guidance Scale",
          "description": "How closely the model should stick to your prompt"
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "The number of images to generate",
          "min": 1.0
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed and prompt will output the same image every time"
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If true, the safety checker will be enabled"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "image_size",
        "guidance_scale"
      ]
    },
    {
      "title": "Stable Cascade",
      "description": "Stable Cascade is a state-of-the-art text-to-image model that generates images on a smaller & cheaper\n    latent space while maintaining high quality output.",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.StableCascade",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "Use it to address details that you don't want in the image"
        },
        {
          "name": "first_stage_steps",
          "type": {
            "type": "int"
          },
          "default": 20,
          "title": "First Stage Steps",
          "description": "Number of steps to run the first stage for"
        },
        {
          "name": "second_stage_steps",
          "type": {
            "type": "int"
          },
          "default": 10,
          "title": "Second Stage Steps",
          "description": "Number of steps to run the second stage for"
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 4.0,
          "title": "Guidance Scale",
          "description": "How closely the model should stick to your prompt"
        },
        {
          "name": "second_stage_guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 4.0,
          "title": "Second Stage Guidance Scale",
          "description": "Guidance scale for the second stage of generation"
        },
        {
          "name": "image_size",
          "type": {
            "type": "enum",
            "values": [
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
          },
          "default": "square_hd",
          "title": "Image Size",
          "description": "The size of the generated image"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed and prompt will output the same image every time"
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If true, the safety checker will be enabled"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "negative_prompt",
        "guidance_scale"
      ]
    },
    {
      "title": "Stable Diffusion V 35 Large",
      "description": "Stable Diffusion 3.5 Large is a Multimodal Diffusion Transformer (MMDiT) text-to-image model that features\n    improved performance in image quality, typography, complex prompt understanding, and resource-efficiency.",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.StableDiffusionV35Large",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "Use it to address details that you don't want in the image"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 28,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform",
          "min": 1.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 3.5,
          "title": "Guidance Scale",
          "description": "How closely the model should stick to your prompt"
        },
        {
          "name": "image_size",
          "type": {
            "type": "enum",
            "values": [
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
          },
          "default": "landscape_4_3",
          "title": "Image Size",
          "description": "The size of the generated image"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed and prompt will output the same image every time"
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If true, the safety checker will be enabled"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "negative_prompt",
        "guidance_scale"
      ]
    },
    {
      "title": "Stable Diffusion V 3 Medium",
      "description": "Stable Diffusion 3 Medium (Text to Image) is a Multimodal Diffusion Transformer (MMDiT) model\n    that improves image quality, typography, prompt understanding, and efficiency.",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.StableDiffusionV3Medium",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "The negative prompt to generate an image from"
        },
        {
          "name": "prompt_expansion",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Prompt Expansion",
          "description": "If set to true, prompt will be upsampled with more details"
        },
        {
          "name": "image_size",
          "type": {
            "type": "enum",
            "values": [
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
          },
          "default": "square_hd",
          "title": "Image Size",
          "description": "The size of the generated image"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 28,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform",
          "min": 1.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 5.0,
          "title": "Guidance Scale",
          "description": "How closely the model should stick to your prompt (CFG scale)"
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "The number of images to generate",
          "min": 1.0
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed and prompt will output the same image every time"
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If true, the safety checker will be enabled"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "negative_prompt",
        "guidance_scale"
      ]
    },
    {
      "title": "Switti",
      "description": "Switti is a scale-wise transformer for fast text-to-image generation that outperforms existing T2I AR models and competes with state-of-the-art T2I diffusion models while being faster than distilled diffusion models.\n    image, generation, fast, transformer, efficient, text-to-image, txt2img\n\n    Use cases:\n    - Rapid image prototyping\n    - Real-time image generation\n    - Quick visual concept testing\n    - Fast artistic visualization\n    - Efficient batch image creation",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.Switti",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "Use it to address details that you don't want in the image"
        },
        {
          "name": "sampling_top_k",
          "type": {
            "type": "int"
          },
          "default": 400,
          "title": "Sampling Top K",
          "description": "The number of top-k tokens to sample from"
        },
        {
          "name": "sampling_top_p",
          "type": {
            "type": "float"
          },
          "default": 0.95,
          "title": "Sampling Top P",
          "description": "The top-p probability to sample from"
        },
        {
          "name": "more_smooth",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "More Smooth",
          "description": "Smoothing with Gumbel softmax sampling"
        },
        {
          "name": "more_diverse",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "More Diverse",
          "description": "More diverse sampling"
        },
        {
          "name": "smooth_start_si",
          "type": {
            "type": "int"
          },
          "default": 2,
          "title": "Smooth Start Si",
          "description": "Smoothing starting scale"
        },
        {
          "name": "turn_off_cfg_start_si",
          "type": {
            "type": "int"
          },
          "default": 8,
          "title": "Turn Off Cfg Start Si",
          "description": "Disable CFG starting scale"
        },
        {
          "name": "last_scale_temp",
          "type": {
            "type": "float"
          },
          "default": 0.1,
          "title": "Last Scale Temp",
          "description": "Temperature after disabling CFG"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed and prompt will output the same image every time"
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 6.0,
          "title": "Guidance Scale",
          "description": "How closely the model should stick to your prompt"
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If true, the safety checker will be enabled"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "guidance_scale",
        "negative_prompt"
      ]
    },
    {
      "title": "Kling Text To Video V 2",
      "description": "Generate videos directly from text prompts using Kling Video V2 Master.\n    video, generation, animation, text-to-video, kling-v2\n\n    Use cases:\n    - Visualize scripts or storyboards\n    - Produce short promotional videos from text\n    - Create animated social media content\n    - Generate concept previews for film ideas\n    - Produce text-driven motion graphics",
      "namespace": "fal.text_to_video",
      "node_type": "fal.text_to_video.KlingTextToVideoV2",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt describing the desired video"
        },
        {
          "name": "duration",
          "type": {
            "type": "enum",
            "values": [
              "5",
              "10"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.KlingDuration"
          },
          "default": "5",
          "title": "Duration",
          "description": "The duration of the generated video"
        },
        {
          "name": "aspect_ratio",
          "type": {
            "type": "enum",
            "values": [
              "16:9",
              "9:16",
              "4:3",
              "3:4",
              "21:9",
              "9:21",
              "1:1"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.AspectRatio"
          },
          "default": "16:9",
          "title": "Aspect Ratio",
          "description": "The aspect ratio of the generated video frame"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "duration"
      ]
    },
    {
      "title": "Kling Video V 2",
      "description": "Generate videos from images using Kling Video V2 Master. Create smooth and realistic animations from a single frame.\n    video, generation, animation, img2vid, kling-v2\n\n    Use cases:\n    - Convert artwork into animated clips\n    - Produce dynamic marketing visuals\n    - Generate motion graphics from static scenes\n    - Create short cinematic sequences\n    - Enhance presentations with video content",
      "namespace": "fal.text_to_video",
      "node_type": "fal.text_to_video.KlingVideoV2",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Image",
          "description": "The image to transform into a video"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "A description of the desired video motion and style"
        },
        {
          "name": "duration",
          "type": {
            "type": "enum",
            "values": [
              "5",
              "10"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.KlingDuration"
          },
          "default": "5",
          "title": "Duration",
          "description": "The duration of the generated video"
        },
        {
          "name": "aspect_ratio",
          "type": {
            "type": "enum",
            "values": [
              "16:9",
              "9:16",
              "4:3",
              "3:4",
              "21:9",
              "9:21",
              "1:1"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.AspectRatio"
          },
          "default": "16:9",
          "title": "Aspect Ratio",
          "description": "The aspect ratio of the generated video frame"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt",
        "duration"
      ]
    },
    {
      "title": "Pixverse Effects",
      "description": "Apply text-driven effects to a video with Pixverse 4.5.\n    video, effects, pixverse, text-guided\n\n    Use cases:\n    - Stylize existing footage\n    - Add visual effects via text\n    - Enhance marketing videos\n    - Create experimental clips\n    - Transform user content",
      "namespace": "fal.text_to_video",
      "node_type": "fal.text_to_video.PixverseEffects",
      "properties": [
        {
          "name": "video",
          "type": {
            "type": "video"
          },
          "default": {
            "type": "video",
            "uri": "",
            "asset_id": null,
            "data": null,
            "duration": null,
            "format": null
          },
          "title": "Video",
          "description": "The source video"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "Text describing the effect"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Optional seed for deterministic output"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "video",
        "prompt"
      ]
    },
    {
      "title": "Pixverse Image To Video",
      "description": "Animate an image into a video using Pixverse 4.5.\n    video, generation, pixverse, image-to-video\n\n    Use cases:\n    - Bring photos to life\n    - Create moving artwork\n    - Generate short clips from images\n    - Produce social media animations\n    - Experiment with visual storytelling",
      "namespace": "fal.text_to_video",
      "node_type": "fal.text_to_video.PixverseImageToVideo",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Image",
          "description": "The source image"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "Optional style or motion prompt"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Optional seed for deterministic output"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "Pixverse Text To Video",
      "description": "Generate videos from text prompts with Pixverse 4.5 API.\n    video, generation, pixverse, text-to-video\n\n    Use cases:\n    - Create animated scenes from text\n    - Generate marketing clips\n    - Produce dynamic social posts\n    - Prototype video ideas\n    - Explore creative storytelling",
      "namespace": "fal.text_to_video",
      "node_type": "fal.text_to_video.PixverseTextToVideo",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt describing the video"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Optional seed for deterministic output"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt"
      ]
    },
    {
      "title": "Pixverse Text To Video Fast",
      "description": "Generate videos quickly from text prompts with Pixverse 4.5 Fast.\n    video, generation, pixverse, text-to-video, fast\n\n    Use cases:\n    - Rapid video prototyping\n    - Generate quick social posts\n    - Produce short marketing clips\n    - Test creative ideas fast\n    - Create video drafts",
      "namespace": "fal.text_to_video",
      "node_type": "fal.text_to_video.PixverseTextToVideoFast",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt describing the video"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Optional seed for deterministic output"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt"
      ]
    },
    {
      "title": "Pixverse Transition",
      "description": "Apply Pixverse transitions between images.\n    video, generation, transition, pixverse\n\n    Use cases:\n    - Blend between two images\n    - Create animated transitions\n    - Generate morphing effects\n    - Produce smooth scene changes\n    - Experiment with visual flows",
      "namespace": "fal.text_to_video",
      "node_type": "fal.text_to_video.PixverseTransition",
      "properties": [
        {
          "name": "start_image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Start Image",
          "description": "The starting image"
        },
        {
          "name": "end_image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "End Image",
          "description": "The ending image"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Optional seed for deterministic output"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "start_image",
        "end_image"
      ]
    },
    {
      "title": "Veo 3",
      "description": "Generate high-quality videos from text prompts with Google's Veo 3 model.\n    video, generation, text-to-video, prompt, audio\n\n    Use cases:\n    - Produce short cinematic clips from descriptions\n    - Create social media videos\n    - Generate visual storyboards\n    - Experiment with video concepts\n    - Produce marketing content",
      "namespace": "fal.text_to_video",
      "node_type": "fal.text_to_video.Veo3",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The text prompt describing the video you want to generate"
        },
        {
          "name": "aspect_ratio",
          "type": {
            "type": "enum",
            "values": [
              "16:9",
              "9:16",
              "1:1"
            ],
            "type_name": "nodetool.nodes.fal.text_to_video.Veo3AspectRatio"
          },
          "default": "16:9",
          "title": "Aspect Ratio",
          "description": "The aspect ratio of the generated video. If it is not set to 16:9, the video will be outpainted with Luma Ray 2 Reframe functionality."
        },
        {
          "name": "duration",
          "type": {
            "type": "enum",
            "values": [
              "8s"
            ],
            "type_name": "nodetool.nodes.fal.text_to_video.Veo3Duration"
          },
          "default": "8s",
          "title": "Duration",
          "description": "The duration of the generated video in seconds"
        },
        {
          "name": "generate_audio",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Generate Audio",
          "description": "Whether to generate audio for the video. If false, %33 less credits will be used."
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "A seed to use for the video generation"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "A negative prompt to guide the video generation"
        },
        {
          "name": "enhance_prompt",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enhance Prompt",
          "description": "Whether to enhance the video generation"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "aspect_ratio",
        "duration"
      ]
    },
    {
      "title": "Wan Flf 2 V",
      "description": "Generate video loops from text prompts using WAN-FLF2V.\n    video, generation, wan, text-to-video\n\n    Use cases:\n    - Generate looping videos from descriptions\n    - Produce motion graphics from prompts\n    - Create abstract video ideas\n    - Develop creative transitions\n    - Experiment with AI-generated motion",
      "namespace": "fal.text_to_video",
      "node_type": "fal.text_to_video.WanFlf2V",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt describing the desired video"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Randomization seed for reproducible results"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt"
      ]
    },
    {
      "title": "Wan Pro Image To Video",
      "description": "Convert an image into a short video clip using Wan Pro.\n    video, generation, wan, professional, image-to-video\n\n    Use cases:\n    - Create dynamic videos from product photos\n    - Generate animations from static artwork\n    - Produce short promotional clips\n    - Transform images into motion graphics\n    - Experiment with visual storytelling",
      "namespace": "fal.text_to_video",
      "node_type": "fal.text_to_video.WanProImageToVideo",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Image",
          "description": "The input image to animate"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "Optional prompt describing the desired motion"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Randomization seed for reproducible results"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "Wan Pro Text To Video",
      "description": "Generate a short video clip from a text prompt using Wan Pro.\n    video, generation, wan, professional, text-to-video\n\n    Use cases:\n    - Create animated scenes from descriptions\n    - Generate short creative videos\n    - Produce promotional content\n    - Visualize storyboards\n    - Experiment with narrative ideas",
      "namespace": "fal.text_to_video",
      "node_type": "fal.text_to_video.WanProTextToVideo",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt describing the desired video"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Randomization seed for reproducible results"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt"
      ]
    },
    {
      "title": "Wan T 2 V",
      "description": "Generate videos from text using the WAN-T2V model.\n    video, generation, wan, text-to-video\n\n    Use cases:\n    - Produce creative videos from prompts\n    - Experiment with motion concepts\n    - Generate quick animated drafts\n    - Visualize ideas for stories\n    - Create short social media clips",
      "namespace": "fal.text_to_video",
      "node_type": "fal.text_to_video.WanT2V",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt describing the desired video"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Randomization seed for reproducible results"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt"
      ]
    },
    {
      "title": "Wan V 2 1 13 BText To Video",
      "description": "Create videos from text using WAN v2.1 1.3B, an open-source text-to-video model.\n    video, generation, wan, text-to-video\n\n    Use cases:\n    - Produce short clips from prompts\n    - Generate concept videos\n    - Create quick visualizations\n    - Iterate on storytelling ideas\n    - Experiment with AI video synthesis",
      "namespace": "fal.text_to_video",
      "node_type": "fal.text_to_video.WanV2_1_13BTextToVideo",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt describing the desired video"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Randomization seed for reproducible results"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt"
      ]
    },
    {
      "title": "Whisper",
      "description": "Whisper is a model for speech transcription and translation that can transcribe audio in multiple languages and optionally translate to English.\n    speech, audio, transcription, translation, transcribe, translate, multilingual, speech-to-text, audio-to-text\n\n    Use cases:\n    - Transcribe spoken content to text\n    - Translate speech to English\n    - Generate subtitles and captions\n    - Create text records of audio content\n    - Analyze multilingual audio content",
      "namespace": "fal.speech_to_text",
      "node_type": "fal.speech_to_text.Whisper",
      "properties": [
        {
          "name": "audio",
          "type": {
            "type": "audio"
          },
          "default": {
            "type": "audio",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Audio",
          "description": "The audio file to transcribe"
        },
        {
          "name": "task",
          "type": {
            "type": "enum",
            "values": [
              "transcribe",
              "translate"
            ],
            "type_name": "nodetool.nodes.fal.speech_to_text.TaskEnum"
          },
          "default": "transcribe",
          "title": "Task",
          "description": "Task to perform on the audio file"
        },
        {
          "name": "language",
          "type": {
            "type": "enum",
            "values": [
              "af",
              "am",
              "ar",
              "as",
              "az",
              "ba",
              "be",
              "bg",
              "bn",
              "bo",
              "br",
              "bs",
              "ca",
              "cs",
              "cy",
              "da",
              "de",
              "el",
              "en",
              "es",
              "et",
              "eu",
              "fa",
              "fi",
              "fo",
              "fr",
              "gl",
              "gu",
              "ha",
              "haw",
              "he",
              "hi",
              "hr",
              "ht",
              "hu",
              "hy",
              "id",
              "is",
              "it",
              "ja",
              "jw",
              "ka",
              "kk",
              "km",
              "kn",
              "ko",
              "la",
              "lb",
              "ln",
              "lo",
              "lt",
              "lv",
              "mg",
              "mi",
              "mk",
              "ml",
              "mn",
              "mr",
              "ms",
              "mt",
              "my",
              "ne",
              "nl",
              "nn",
              "no",
              "oc",
              "pa",
              "pl",
              "ps",
              "pt",
              "ro",
              "ru",
              "sa",
              "sd",
              "si",
              "sk",
              "sl",
              "sn",
              "so",
              "sq",
              "sr",
              "su",
              "sv",
              "sw",
              "ta",
              "te",
              "tg",
              "th",
              "tk",
              "tl",
              "tr",
              "tt",
              "uk",
              "ur",
              "uz",
              "vi",
              "yi",
              "yo",
              "yue",
              "zh"
            ],
            "type_name": "nodetool.nodes.fal.speech_to_text.LanguageEnum"
          },
          "default": "en",
          "title": "Language",
          "description": "Language of the audio file. If not set, will be auto-detected"
        },
        {
          "name": "diarize",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Diarize",
          "description": "Whether to perform speaker diarization"
        },
        {
          "name": "chunk_level",
          "type": {
            "type": "enum",
            "values": [
              "segment",
              "word"
            ],
            "type_name": "nodetool.nodes.fal.speech_to_text.ChunkLevelEnum"
          },
          "default": "segment",
          "title": "Chunk Level",
          "description": "Level of detail for timestamp chunks"
        },
        {
          "name": "num_speakers",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Speakers",
          "description": "Number of speakers in the audio. If not set, will be auto-detected",
          "min": 1.0,
          "max": 10.0
        },
        {
          "name": "batch_size",
          "type": {
            "type": "int"
          },
          "default": 64,
          "title": "Batch Size",
          "description": "Batch size for processing"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "Optional prompt to guide the transcription"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "str"
          },
          "name": "text"
        },
        {
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "dict"
              }
            ]
          },
          "name": "chunks"
        },
        {
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "str"
              }
            ]
          },
          "name": "inferred_languages"
        },
        {
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "dict"
              }
            ]
          },
          "name": "diarization_segments"
        }
      ],
      "basic_fields": [
        "audio",
        "task",
        "diarize"
      ]
    },
    {
      "title": "AMTInterpolation",
      "description": "Interpolate between image frames to create smooth video transitions. Supports configurable FPS and recursive interpolation passes for higher quality results.\n    video, interpolation, transitions, frames, smoothing, img2vid, image-to-video\n\n    Use cases:\n    - Create smooth frame transitions\n    - Generate fluid animations\n    - Enhance video frame rates\n    - Produce slow-motion effects\n    - Create seamless video blends",
      "namespace": "fal.image_to_video",
      "node_type": "fal.image_to_video.AMTInterpolation",
      "properties": [
        {
          "name": "frames",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "image"
              }
            ]
          },
          "default": [
            {},
            {}
          ],
          "title": "Frames",
          "description": "List of frames to interpolate between (minimum 2 frames required)"
        },
        {
          "name": "output_fps",
          "type": {
            "type": "int"
          },
          "default": 24,
          "title": "Output Fps",
          "description": "Output frames per second"
        },
        {
          "name": "recursive_interpolation_passes",
          "type": {
            "type": "int"
          },
          "default": 4,
          "title": "Recursive Interpolation Passes",
          "description": "Number of recursive interpolation passes (higher = smoother)"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "frames",
        "output_fps"
      ]
    },
    {
      "title": "Cog Video X",
      "description": "Generate videos from images using CogVideoX-5B. Features high-quality motion synthesis with configurable parameters for fine-tuned control over the output.\n    video, generation, motion, synthesis, control, img2vid, image-to-video\n\n    Use cases:\n    - Create controlled video animations\n    - Generate precise motion effects\n    - Produce customized video content\n    - Create fine-tuned animations\n    - Generate motion sequences",
      "namespace": "fal.image_to_video",
      "node_type": "fal.image_to_video.CogVideoX",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Image",
          "description": "The image to transform into a video"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "A description of the desired video motion and style"
        },
        {
          "name": "video_size",
          "type": {
            "type": "enum",
            "values": [
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.VideoSize"
          },
          "default": "landscape_16_9",
          "title": "Video Size",
          "description": "The size/aspect ratio of the generated video"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "Distorted, discontinuous, Ugly, blurry, low resolution, motionless, static, disfigured, disconnected limbs, Ugly faces, incomplete arms",
          "title": "Negative Prompt",
          "description": "What to avoid in the generated video"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 50,
          "title": "Num Inference Steps",
          "description": "Number of denoising steps (higher = better quality but slower)"
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 7.0,
          "title": "Guidance Scale",
          "description": "How closely to follow the prompt (higher = more faithful but less creative)"
        },
        {
          "name": "use_rife",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Use Rife",
          "description": "Whether to use RIFE for video interpolation"
        },
        {
          "name": "export_fps",
          "type": {
            "type": "int"
          },
          "default": 16,
          "title": "Export Fps",
          "description": "Target frames per second for the output video"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed will output the same video every time"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt",
        "video_size"
      ]
    },
    {
      "title": "Fast SVD",
      "description": "Generate short video clips from your images using SVD v1.1 at Lightning Speed. Features high-quality motion synthesis with configurable parameters for rapid video generation.\n    video, generation, fast, motion, synthesis, img2vid, image-to-video\n\n    Use cases:\n    - Create quick video animations\n    - Generate rapid motion content\n    - Produce fast video transitions\n    - Create instant visual effects\n    - Generate quick previews",
      "namespace": "fal.image_to_video",
      "node_type": "fal.image_to_video.FastSVD",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Image",
          "description": "The image to transform into a video"
        },
        {
          "name": "motion_bucket_id",
          "type": {
            "type": "int"
          },
          "default": 127,
          "title": "Motion Bucket Id",
          "description": "Controls motion intensity (higher = more motion)"
        },
        {
          "name": "cond_aug",
          "type": {
            "type": "float"
          },
          "default": 0.02,
          "title": "Cond Aug",
          "description": "Amount of noise added to conditioning (higher = more motion)"
        },
        {
          "name": "steps",
          "type": {
            "type": "int"
          },
          "default": 4,
          "title": "Steps",
          "description": "Number of inference steps (higher = better quality but slower)"
        },
        {
          "name": "fps",
          "type": {
            "type": "int"
          },
          "default": 10,
          "title": "Fps",
          "description": "Frames per second of the output video (total length is 25 frames)"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed will output the same video every time"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "motion_bucket_id",
        "fps"
      ]
    },
    {
      "title": "Haiper Image To Video",
      "description": "Transform images into hyper-realistic videos with Haiper 2.0. Experience industry-leading resolution, fluid motion, and rapid generation for stunning AI videos.\n    video, generation, hyper-realistic, motion, animation, image-to-video, img2vid\n\n    Use cases:\n    - Create cinematic animations\n    - Generate dynamic video content\n    - Transform static images into motion\n    - Produce high-resolution videos\n    - Create visual effects",
      "namespace": "fal.image_to_video",
      "node_type": "fal.image_to_video.HaiperImageToVideo",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Image",
          "description": "The image to transform into a video"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "A description of the desired video motion and style"
        },
        {
          "name": "duration",
          "type": {
            "type": "enum",
            "values": [
              4,
              6
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.VideoDuration"
          },
          "default": 4,
          "title": "Duration",
          "description": "The duration of the generated video in seconds"
        },
        {
          "name": "prompt_enhancer",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Prompt Enhancer",
          "description": "Whether to use the model's prompt enhancer"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed will output the same video every time"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt",
        "duration"
      ]
    },
    {
      "title": "Kling Video",
      "description": "Generate video clips from your images using Kling 1.6. Supports multiple durations and aspect ratios.\n    video, generation, animation, duration, aspect-ratio, img2vid, image-to-video\n\n    Use cases:\n    - Create custom video content\n    - Generate video animations\n    - Transform static images\n    - Produce motion graphics\n    - Create visual presentations",
      "namespace": "fal.image_to_video",
      "node_type": "fal.image_to_video.KlingVideo",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Image",
          "description": "The image to transform into a video"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "A description of the desired video motion and style"
        },
        {
          "name": "duration",
          "type": {
            "type": "enum",
            "values": [
              "5",
              "10"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.KlingDuration"
          },
          "default": "5",
          "title": "Duration",
          "description": "The duration of the generated video"
        },
        {
          "name": "aspect_ratio",
          "type": {
            "type": "enum",
            "values": [
              "16:9",
              "9:16",
              "4:3",
              "3:4",
              "21:9",
              "9:21",
              "1:1"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.AspectRatio"
          },
          "default": "16:9",
          "title": "Aspect Ratio",
          "description": "The aspect ratio of the generated video frame"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt",
        "duration"
      ]
    },
    {
      "title": "Kling Video Pro",
      "description": "Generate video clips from your images using Kling 1.6 Pro. The professional version offers enhanced quality and performance compared to the standard version.\n    video, generation, professional, quality, performance, img2vid, image-to-video\n\n    Use cases:\n    - Create professional video content\n    - Generate high-quality animations\n    - Produce commercial video assets\n    - Create advanced motion graphics\n    - Generate premium visual content",
      "namespace": "fal.image_to_video",
      "node_type": "fal.image_to_video.KlingVideoPro",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Image",
          "description": "The image to transform into a video"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "A description of the desired video motion and style"
        },
        {
          "name": "duration",
          "type": {
            "type": "enum",
            "values": [
              "5",
              "10"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.KlingDuration"
          },
          "default": "5",
          "title": "Duration",
          "description": "The duration of the generated video"
        },
        {
          "name": "aspect_ratio",
          "type": {
            "type": "enum",
            "values": [
              "16:9",
              "9:16",
              "4:3",
              "3:4",
              "21:9",
              "9:21",
              "1:1"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.AspectRatio"
          },
          "default": "16:9",
          "title": "Aspect Ratio",
          "description": "The aspect ratio of the generated video frame"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt",
        "duration"
      ]
    },
    {
      "title": "LTXVideo",
      "description": "Generate videos from images using LTX Video. Best results with 768x512 images and detailed, chronological descriptions of actions and scenes.\n    video, generation, chronological, scenes, actions, img2vid, image-to-video\n\n    Use cases:\n    - Create scene-based animations\n    - Generate sequential video content\n    - Produce narrative videos\n    - Create storyboard animations\n    - Generate action sequences",
      "namespace": "fal.image_to_video",
      "node_type": "fal.image_to_video.LTXVideo",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Image",
          "description": "The image to transform into a video (768x512 recommended)"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "A detailed description of the desired video motion and style"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "low quality, worst quality, deformed, distorted, disfigured, motion smear, motion artifacts, fused fingers, bad anatomy, weird hand, ugly",
          "title": "Negative Prompt",
          "description": "What to avoid in the generated video"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 30,
          "title": "Num Inference Steps",
          "description": "Number of inference steps (higher = better quality but slower)"
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 3.0,
          "title": "Guidance Scale",
          "description": "How closely to follow the prompt (higher = more faithful)"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed will output the same video every time"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "Luma Dream Machine",
      "description": "Generate video clips from your images using Luma Dream Machine v1.5. Supports various aspect ratios and optional end-frame blending.\n    video, generation, animation, blending, aspect-ratio, img2vid, image-to-video\n\n    Use cases:\n    - Create seamless video loops\n    - Generate video transitions\n    - Transform images into animations\n    - Create motion graphics\n    - Produce video content",
      "namespace": "fal.image_to_video",
      "node_type": "fal.image_to_video.LumaDreamMachine",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Image",
          "description": "The image to transform into a video"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "A description of the desired video motion and style"
        },
        {
          "name": "aspect_ratio",
          "type": {
            "type": "enum",
            "values": [
              "16:9",
              "9:16",
              "4:3",
              "3:4",
              "21:9",
              "9:21",
              "1:1"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.AspectRatio"
          },
          "default": "16:9",
          "title": "Aspect Ratio",
          "description": "The aspect ratio of the generated video"
        },
        {
          "name": "loop",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Loop",
          "description": "Whether the video should loop (end blends with beginning)"
        },
        {
          "name": "end_image",
          "type": {
            "type": "image",
            "optional": true
          },
          "default": null,
          "title": "End Image",
          "description": "Optional image to blend the end of the video with"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt",
        "aspect_ratio"
      ]
    },
    {
      "title": "Mini Max Hailuo 02",
      "description": "Create videos from your images with MiniMax Hailuo-02 Standard. Choose the\n    clip length and optionally enhance prompts for sharper results.\n    video, generation, minimax, prompt-optimizer, img2vid, image-to-video\n\n    Use cases:\n    - Produce social media clips\n    - Generate cinematic sequences\n    - Visualize storyboards\n    - Create promotional videos\n    - Animate still graphics",
      "namespace": "fal.image_to_video",
      "node_type": "fal.image_to_video.MiniMaxHailuo02",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Image",
          "description": "The image to transform into a video"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt describing the video"
        },
        {
          "name": "duration",
          "type": {
            "type": "enum",
            "values": [
              "6",
              "10"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.HailuoDuration"
          },
          "default": "6",
          "title": "Duration",
          "description": "The duration of the video in seconds. 10 seconds videos are not supported for 1080p resolution."
        },
        {
          "name": "prompt_optimizer",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Prompt Optimizer",
          "description": "Whether to use the model's prompt optimizer"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt",
        "duration"
      ]
    },
    {
      "title": "Mini Max Video",
      "description": "Generate video clips from your images using MiniMax Video model. Transform static art into dynamic masterpieces with enhanced smoothness and vivid motion.\n    video, generation, art, motion, smoothness, img2vid, image-to-video\n\n    Use cases:\n    - Transform artwork into videos\n    - Create smooth animations\n    - Generate artistic motion content\n    - Produce dynamic visualizations\n    - Create video art pieces",
      "namespace": "fal.image_to_video",
      "node_type": "fal.image_to_video.MiniMaxVideo",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Image",
          "description": "The image to transform into a video"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "A description of the desired video motion and style"
        },
        {
          "name": "prompt_optimizer",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Prompt Optimizer",
          "description": "Whether to use the model's prompt optimizer"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "Muse Talk",
      "description": "Real-time high quality audio-driven lip-syncing model. Animate a face video with custom audio for natural-looking speech animation.\n    video, lip-sync, animation, speech, real-time, wav2vid, audio-to-video\n\n    Use cases:\n    - Create lip-synced videos\n    - Generate speech animations\n    - Produce dubbed content\n    - Create animated presentations\n    - Generate voice-over videos",
      "namespace": "fal.image_to_video",
      "node_type": "fal.image_to_video.MuseTalk",
      "properties": [
        {
          "name": "video",
          "type": {
            "type": "video"
          },
          "default": {
            "type": "video",
            "uri": "",
            "asset_id": null,
            "data": null,
            "duration": null,
            "format": null
          },
          "title": "Video",
          "description": "URL of the source video to animate"
        },
        {
          "name": "audio",
          "type": {
            "type": "audio"
          },
          "default": {
            "type": "audio",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Audio",
          "description": "URL of the audio file to drive the lip sync"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "video",
        "audio"
      ]
    },
    {
      "title": "Pix Verse",
      "description": "Generate dynamic videos from images with PixVerse v4.5. Create high-quality motion\n    with detailed prompt control and advanced diffusion parameters.\n    video, generation, pixverse, motion, diffusion, img2vid, image-to-video\n\n    Use cases:\n    - Animate illustrations and photos\n    - Produce engaging social media clips\n    - Generate short cinematic shots\n    - Create motion for product showcases\n    - Experiment with creative video effects",
      "namespace": "fal.image_to_video",
      "node_type": "fal.image_to_video.PixVerse",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Image",
          "description": "The image to transform into a video"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "A description of the desired video motion and style"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "low quality, worst quality, distorted, blurred",
          "title": "Negative Prompt",
          "description": "What to avoid in the generated video"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 50,
          "title": "Num Inference Steps",
          "description": "Number of inference steps (higher = better quality but slower)"
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 7.5,
          "title": "Guidance Scale",
          "description": "How closely to follow the prompt (higher = more faithful)"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed will output the same video every time"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt",
        "num_inference_steps"
      ]
    },
    {
      "title": "Sad Talker",
      "description": "Generate talking face animations from a single image and audio file. Features configurable face model resolution and expression controls.\n    video, animation, face, talking, expression, img2vid, image-to-video, audio-to-video, wav2vid\n\n    Use cases:\n    - Create talking head videos\n    - Generate lip-sync animations\n    - Produce character animations\n    - Create video presentations\n    - Generate facial expressions",
      "namespace": "fal.image_to_video",
      "node_type": "fal.image_to_video.SadTalker",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Image",
          "description": "The source image to animate"
        },
        {
          "name": "audio",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Audio",
          "description": "URL of the audio file to drive the animation"
        },
        {
          "name": "face_model_resolution",
          "type": {
            "type": "enum",
            "values": [
              "256",
              "512"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.FaceModelResolution"
          },
          "default": "256",
          "title": "Face Model Resolution",
          "description": "Resolution of the face model"
        },
        {
          "name": "expression_scale",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Expression Scale",
          "description": "Scale of the expression (1.0 = normal)"
        },
        {
          "name": "still_mode",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Still Mode",
          "description": "Reduce head motion (works with preprocess 'full')"
        },
        {
          "name": "preprocess",
          "type": {
            "type": "enum",
            "values": [
              "crop",
              "extcrop",
              "resize",
              "full",
              "extfull"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.PreprocessType"
          },
          "default": "crop",
          "title": "Preprocess",
          "description": "Type of image preprocessing to apply"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "audio",
        "face_model_resolution"
      ]
    },
    {
      "title": "Stable Video",
      "description": "Generate short video clips from your images using Stable Video Diffusion v1.1. Features high-quality motion synthesis with configurable parameters.\n    video, generation, diffusion, motion, synthesis, img2vid, image-to-video\n\n    Use cases:\n    - Create stable video animations\n    - Generate motion content\n    - Transform images into videos\n    - Produce smooth transitions\n    - Create visual effects",
      "namespace": "fal.image_to_video",
      "node_type": "fal.image_to_video.StableVideo",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Image",
          "description": "The image to transform into a video"
        },
        {
          "name": "motion_bucket_id",
          "type": {
            "type": "int"
          },
          "default": 127,
          "title": "Motion Bucket Id",
          "description": "Controls motion intensity (higher = more motion)"
        },
        {
          "name": "cond_aug",
          "type": {
            "type": "float"
          },
          "default": 0.02,
          "title": "Cond Aug",
          "description": "Amount of noise added to conditioning (higher = more motion)"
        },
        {
          "name": "fps",
          "type": {
            "type": "int"
          },
          "default": 25,
          "title": "Fps",
          "description": "Frames per second of the output video"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed will output the same video every time"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "motion_bucket_id",
        "fps"
      ]
    },
    {
      "title": "Veo 2",
      "description": "Generate videos from text prompts using Veo 2. Creates short clips with\n    optional control over duration and aspect ratio.\n    video, text-to-video, generation, prompt, veo2\n\n    Use cases:\n    - Produce cinematic video clips from descriptions\n    - Generate marketing or social media footage\n    - Create animated scenes from storyboards\n    - Experiment with visual concepts rapidly",
      "namespace": "fal.image_to_video",
      "node_type": "fal.image_to_video.Veo2",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate a video from"
        },
        {
          "name": "duration",
          "type": {
            "type": "enum",
            "values": [
              4,
              6
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.VideoDuration"
          },
          "default": 4,
          "title": "Duration",
          "description": "The duration of the generated video in seconds"
        },
        {
          "name": "aspect_ratio",
          "type": {
            "type": "enum",
            "values": [
              "16:9",
              "9:16",
              "4:3",
              "3:4",
              "21:9",
              "9:21",
              "1:1"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.AspectRatio"
          },
          "default": "16:9",
          "title": "Aspect Ratio",
          "description": "The aspect ratio of the generated video"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed will output the same video every time"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "duration",
        "aspect_ratio"
      ]
    },
    {
      "title": "Veo 2 Image To Video",
      "description": "Animate a single image into a Veo 2 video clip. Provides control over\n    duration and aspect ratio while following an optional prompt.\n    video, image-to-video, veo2, animation\n\n    Use cases:\n    - Bring still artwork to life\n    - Create dynamic social media posts\n    - Generate quick product showcase videos\n    - Produce animated storyboards",
      "namespace": "fal.image_to_video",
      "node_type": "fal.image_to_video.Veo2ImageToVideo",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Image",
          "description": "The image to transform into a video"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "Optional description of the desired motion"
        },
        {
          "name": "duration",
          "type": {
            "type": "enum",
            "values": [
              4,
              6
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.VideoDuration"
          },
          "default": 4,
          "title": "Duration",
          "description": "The duration of the generated video in seconds"
        },
        {
          "name": "aspect_ratio",
          "type": {
            "type": "enum",
            "values": [
              "16:9",
              "9:16",
              "4:3",
              "3:4",
              "21:9",
              "9:21",
              "1:1"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.AspectRatio"
          },
          "default": "16:9",
          "title": "Aspect Ratio",
          "description": "The aspect ratio of the generated video"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed will output the same video every time"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt",
        "duration"
      ]
    },
    {
      "title": "Wan Flf 2 v",
      "description": "Generate short video clips from a single image using the WAN FLF2V model. This model converts a still image into an animated clip guided by a text prompt.\n    video, generation, animation, image-to-video, wan\n\n    Use cases:\n    - Animate still images into short clips\n    - Create dynamic content from artwork\n    - Produce promotional video snippets\n    - Generate visual effects for social posts\n    - Explore creative motion ideas",
      "namespace": "fal.image_to_video",
      "node_type": "fal.image_to_video.WanFlf2v",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Image",
          "description": "The source image for video generation"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "Description of the desired motion and style"
        },
        {
          "name": "num_frames",
          "type": {
            "type": "int"
          },
          "default": 16,
          "title": "Num Frames",
          "description": "Number of frames to generate",
          "min": 1.0
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed will output the same video every time"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt",
        "num_frames"
      ]
    },
    {
      "title": "Bria Background Remove",
      "description": "Bria RMBG 2.0 enables seamless removal of backgrounds from images, ideal for professional editing tasks.\n    Trained exclusively on licensed data for safe and risk-free commercial use.",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.BriaBackgroundRemove",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Image",
          "description": "Input image to remove background from"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image"
      ]
    },
    {
      "title": "Bria Background Replace",
      "description": "Bria Background Replace allows for efficient swapping of backgrounds in images via text prompts or reference image, delivering realistic and polished results. Trained exclusively on licensed data for safe and risk-free commercial use.\n    image, background, replacement, swap\n\n    Use cases:\n    - Replace image backgrounds seamlessly\n    - Create professional photo compositions\n    - Generate custom scene settings\n    - Produce commercial-ready images\n    - Create consistent visual environments",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.BriaBackgroundReplace",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Image",
          "description": "Input image to replace background"
        },
        {
          "name": "ref_image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Ref Image",
          "description": "Reference image for the new background"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "Prompt to generate new background"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "Negative prompt for background generation"
        },
        {
          "name": "refine_prompt",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Refine Prompt",
          "description": "Whether to refine the prompt"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed will output the same image every time"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "Bria Eraser",
      "description": "Bria Eraser enables precise removal of unwanted objects from images while maintaining high-quality outputs. Trained exclusively on licensed data for safe and risk-free commercial use.\n    image, removal, cleanup\n\n    Use cases:\n    - Remove unwanted objects from images\n    - Clean up image imperfections\n    - Prepare images for commercial use\n    - Remove distracting elements\n    - Create clean, professional images",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.BriaEraser",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Image",
          "description": "Input image to erase from"
        },
        {
          "name": "mask",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Mask",
          "description": "The mask for areas to be cleaned"
        },
        {
          "name": "mask_type",
          "type": {
            "type": "str"
          },
          "default": "manual",
          "title": "Mask Type",
          "description": "Type of mask - 'manual' for user-created or 'automatic' for algorithm-generated"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "mask"
      ]
    },
    {
      "title": "Bria Expand",
      "description": "Bria Expand expands images beyond their borders in high quality. Trained exclusively on licensed data for safe and risk-free commercial use.\n    image, expansion, outpainting\n\n    Use cases:\n    - Extend image boundaries seamlessly\n    - Create wider or taller compositions\n    - Expand images for different aspect ratios\n    - Generate additional scene content",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.BriaExpand",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Image",
          "description": "The input image to expand"
        },
        {
          "name": "canvas_width",
          "type": {
            "type": "int"
          },
          "default": 1200,
          "title": "Canvas Width",
          "description": "The desired width of the final image, after the expansion"
        },
        {
          "name": "canvas_height",
          "type": {
            "type": "int"
          },
          "default": 674,
          "title": "Canvas Height",
          "description": "The desired height of the final image, after the expansion"
        },
        {
          "name": "original_image_width",
          "type": {
            "type": "int"
          },
          "default": 610,
          "title": "Original Image Width",
          "description": "The desired width of the original image, inside the full canvas"
        },
        {
          "name": "original_image_height",
          "type": {
            "type": "int"
          },
          "default": 855,
          "title": "Original Image Height",
          "description": "The desired height of the original image, inside the full canvas"
        },
        {
          "name": "original_image_x",
          "type": {
            "type": "int"
          },
          "default": 301,
          "title": "Original Image X",
          "description": "The desired x-coordinate of the original image, inside the full canvas"
        },
        {
          "name": "original_image_y",
          "type": {
            "type": "int"
          },
          "default": -66,
          "title": "Original Image Y",
          "description": "The desired y-coordinate of the original image, inside the full canvas"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "Text on which you wish to base the image expansion"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "The negative prompt to use when generating images"
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "Number of images to generate"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed will output the same image every time"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "canvas_width",
        "canvas_height",
        "prompt"
      ]
    },
    {
      "title": "Bria Gen Fill",
      "description": "Bria GenFill enables high-quality object addition or visual transformation. Trained exclusively on licensed data for safe and risk-free commercial use.\n    image, generation, filling, transformation\n\n    Use cases:\n    - Add new objects to existing images\n    - Transform specific image areas\n    - Generate contextual content\n    - Create seamless visual additions\n    - Produce professional image modifications",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.BriaGenFill",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Image",
          "description": "Input image to erase from"
        },
        {
          "name": "mask",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Mask",
          "description": "The mask for areas to be cleaned"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate images"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "The negative prompt to use when generating images"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed will output the same image every time"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "mask",
        "prompt"
      ]
    },
    {
      "title": "Bria Product Shot",
      "description": "Place any product in any scenery with just a prompt or reference image while maintaining high integrity of the product. Trained exclusively on licensed data for safe and risk-free commercial use and optimized for eCommerce.\n    image, product, placement, ecommerce\n\n    Use cases:\n    - Create professional product photography\n    - Generate contextual product shots\n    - Place products in custom environments\n    - Create eCommerce product listings\n    - Generate marketing visuals",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.BriaProductShot",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Image",
          "description": "The product image to be placed"
        },
        {
          "name": "scene_description",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Scene Description",
          "description": "Text description of the new scene/background"
        },
        {
          "name": "ref_image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Ref Image",
          "description": "Reference image for the new scene/background"
        },
        {
          "name": "optimize_description",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Optimize Description",
          "description": "Whether to optimize the scene description"
        },
        {
          "name": "placement_type",
          "type": {
            "type": "str"
          },
          "default": "manual_placement",
          "title": "Placement Type",
          "description": "How to position the product (original, automatic, manual_placement, manual_padding)"
        },
        {
          "name": "manual_placement_selection",
          "type": {
            "type": "str"
          },
          "default": "bottom_center",
          "title": "Manual Placement Selection",
          "description": "Specific placement position when using manual_placement"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "scene_description"
      ]
    },
    {
      "title": "Clarity Upscaler",
      "description": "Upscale images to improve resolution and sharpness.\n\n    clarity, upscale, enhancement\n\n    Use cases:\n    - Increase image resolution for printing\n    - Improve clarity of low-quality images\n    - Enhance textures and graphics",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.ClarityUpscaler",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Image",
          "description": "Input image to upscale"
        },
        {
          "name": "scale",
          "type": {
            "type": "int"
          },
          "default": 2,
          "title": "Scale",
          "description": "Upscaling factor",
          "min": 1.0,
          "max": 4.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "scale"
      ]
    },
    {
      "title": "Flux Dev Redux",
      "description": "FLUX.1 [dev] Redux is a high-performance endpoint that enables rapid transformation of existing images, delivering high-quality style transfers and image modifications.\n    image, transformation, style-transfer, development, flux\n\n    Use cases:\n    - Transform images with advanced controls\n    - Create customized image variations\n    - Apply precise style modifications",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.FluxDevRedux",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Image",
          "description": "The input image to transform"
        },
        {
          "name": "image_size",
          "type": {
            "type": "enum",
            "values": [
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
          },
          "default": "landscape_4_3",
          "title": "Image Size",
          "description": "The size of the generated image"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 28,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform",
          "min": 1.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 3.5,
          "title": "Guidance Scale",
          "description": "How closely the model should stick to your prompt"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed will output the same image every time"
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If true, the safety checker will be enabled"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "image_size",
        "guidance_scale"
      ]
    },
    {
      "title": "Flux Lora Canny",
      "description": "FLUX LoRA Canny enables precise control over composition and style through edge detection and LoRA-based guidance mechanisms.\n    image, edge, lora, style-transfer, control\n\n    Use cases:\n    - Generate stylized images with structural control\n    - Create edge-guided artistic transformations\n    - Apply custom styles while maintaining composition\n    - Produce consistent style variations",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.FluxLoraCanny",
      "properties": [
        {
          "name": "control_image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Control Image",
          "description": "The control image to generate the Canny edge map from"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "image_size",
          "type": {
            "type": "enum",
            "values": [
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
          },
          "default": "landscape_4_3",
          "title": "Image Size",
          "description": "The size of the generated image"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 28,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform",
          "min": 1.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 3.5,
          "title": "Guidance Scale",
          "description": "How closely the model should stick to your prompt"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed will output the same image every time"
        },
        {
          "name": "lora_scale",
          "type": {
            "type": "float"
          },
          "default": 0.6,
          "title": "Lora Scale",
          "description": "The strength of the LoRA adaptation"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "control_image",
        "prompt",
        "image_size"
      ]
    },
    {
      "title": "Flux Lora Depth",
      "description": "FLUX LoRA Depth enables precise control over composition and structure through depth map detection and LoRA-based guidance mechanisms.\n    image, depth, lora, structure, control\n\n    Use cases:\n    - Generate depth-aware stylized images\n    - Create 3D-conscious artistic transformations\n    - Maintain spatial relationships with custom styles\n    - Produce depth-consistent variations\n    - Generate images with controlled perspective",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.FluxLoraDepth",
      "properties": [
        {
          "name": "control_image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Control Image",
          "description": "The control image to generate the depth map from"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "image_size",
          "type": {
            "type": "enum",
            "values": [
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
          },
          "default": "landscape_4_3",
          "title": "Image Size",
          "description": "The size of the generated image"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 28,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform",
          "min": 1.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 3.5,
          "title": "Guidance Scale",
          "description": "How closely the model should stick to your prompt"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed will output the same image every time"
        },
        {
          "name": "lora_scale",
          "type": {
            "type": "float"
          },
          "default": 0.6,
          "title": "Lora Scale",
          "description": "The strength of the LoRA adaptation"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "control_image",
        "prompt",
        "image_size"
      ]
    },
    {
      "title": "Flux Pro Canny",
      "description": "FLUX.1 [pro] Canny enables precise control over composition, style, and structure through advanced edge detection and guidance mechanisms.\n    image, edge, composition, style, control\n\n    Use cases:\n    - Generate images with precise structural control\n    - Create artwork based on edge maps\n    - Transform sketches into detailed images\n    - Maintain specific compositional elements\n    - Generate variations with consistent structure",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.FluxProCanny",
      "properties": [
        {
          "name": "control_image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Control Image",
          "description": "The control image to generate the Canny edge map from"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "image_size",
          "type": {
            "type": "enum",
            "values": [
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
          },
          "default": "landscape_4_3",
          "title": "Image Size",
          "description": "The size of the generated image"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 28,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform",
          "min": 1.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 3.5,
          "title": "Guidance Scale",
          "description": "How closely the model should stick to your prompt"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed will output the same image every time"
        },
        {
          "name": "safety_tolerance",
          "type": {
            "type": "str"
          },
          "default": "2",
          "title": "Safety Tolerance",
          "description": "Safety tolerance level (1-6, 1 being most strict)"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "control_image",
        "prompt",
        "image_size"
      ]
    },
    {
      "title": "Flux Pro Depth",
      "description": "FLUX.1 [pro] Depth enables precise control over composition and structure through depth map detection and guidance mechanisms.\n    image, depth-map, composition, structure, control\n\n    Use cases:\n    - Generate images with controlled depth perception\n    - Create 3D-aware image transformations\n    - Maintain spatial relationships in generated images\n    - Produce images with accurate perspective\n    - Generate variations with consistent depth structure",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.FluxProDepth",
      "properties": [
        {
          "name": "control_image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Control Image",
          "description": "The control image to generate the depth map from"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "image_size",
          "type": {
            "type": "enum",
            "values": [
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
          },
          "default": "landscape_4_3",
          "title": "Image Size",
          "description": "The size of the generated image"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 28,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform",
          "min": 1.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 3.5,
          "title": "Guidance Scale",
          "description": "How closely the model should stick to your prompt"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed will output the same image every time"
        },
        {
          "name": "safety_tolerance",
          "type": {
            "type": "str"
          },
          "default": "2",
          "title": "Safety Tolerance",
          "description": "Safety tolerance level (1-6, 1 being most strict)"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "control_image",
        "prompt",
        "image_size"
      ]
    },
    {
      "title": "Flux Pro Fill",
      "description": "FLUX.1 [pro] Fill is a high-performance endpoint that enables rapid transformation of existing images with inpainting/outpainting capabilities.\n    image, inpainting, outpainting, transformation, professional\n\n    Use cases:\n    - Fill in missing or masked parts of images\n    - Extend images beyond their original boundaries\n    - Remove and replace unwanted elements\n    - Create seamless image completions\n    - Generate context-aware image content",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.FluxProFill",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Image",
          "description": "The input image to transform"
        },
        {
          "name": "mask",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Mask",
          "description": "The mask for inpainting"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to fill the masked part of the image"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 28,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform",
          "min": 1.0
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed will output the same image every time"
        },
        {
          "name": "safety_tolerance",
          "type": {
            "type": "str"
          },
          "default": "2",
          "title": "Safety Tolerance",
          "description": "Safety tolerance level (1-6, 1 being most strict)"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "mask",
        "prompt"
      ]
    },
    {
      "title": "Flux Pro Redux",
      "description": "FLUX.1 [pro] Redux is a high-performance endpoint that enables rapid transformation of existing images, delivering high-quality style transfers and image modifications.\n    image, transformation, style-transfer, flux\n\n    Use cases:\n    - Create professional image transformations\n    - Generate style transfers",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.FluxProRedux",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Image",
          "description": "The input image to transform"
        },
        {
          "name": "image_size",
          "type": {
            "type": "enum",
            "values": [
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
          },
          "default": "landscape_4_3",
          "title": "Image Size",
          "description": "The size of the generated image"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 28,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform",
          "min": 1.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 3.5,
          "title": "Guidance Scale",
          "description": "How closely the model should stick to your prompt"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed will output the same image every time"
        },
        {
          "name": "safety_tolerance",
          "type": {
            "type": "str"
          },
          "default": "2",
          "title": "Safety Tolerance",
          "description": "Safety tolerance level (1-6, 1 being most strict)"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "image_size",
        "guidance_scale"
      ]
    },
    {
      "title": "Flux Pro Ultra Redux",
      "description": "FLUX1.1 [pro] ultra Redux is a high-performance endpoint that enables rapid transformation of existing images, delivering high-quality style transfers and image modifications with the core FLUX capabilities.\n    image, transformation, style-transfer, ultra, professional\n\n    Use cases:\n    - Apply precise image modifications\n    - Process images with maximum control",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.FluxProUltraRedux",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Image",
          "description": "The input image to transform"
        },
        {
          "name": "image_size",
          "type": {
            "type": "enum",
            "values": [
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
          },
          "default": "landscape_4_3",
          "title": "Image Size",
          "description": "The size of the generated image"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 28,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform",
          "min": 1.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 3.5,
          "title": "Guidance Scale",
          "description": "How closely the model should stick to your prompt"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed will output the same image every time"
        },
        {
          "name": "safety_tolerance",
          "type": {
            "type": "str"
          },
          "default": "2",
          "title": "Safety Tolerance",
          "description": "Safety tolerance level (1-6, 1 being most strict)"
        },
        {
          "name": "image_prompt_strength",
          "type": {
            "type": "float"
          },
          "default": 0.1,
          "title": "Image Prompt Strength",
          "description": "The strength of the image prompt, between 0 and 1"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "image_size",
        "guidance_scale"
      ]
    },
    {
      "title": "Flux Schnell Redux",
      "description": "FLUX.1 [schnell] Redux is a high-performance endpoint that enables rapid transformation of existing images, delivering high-quality style transfers and image modifications with the core FLUX capabilities.\n    image, transformation, style-transfer, fast, flux\n\n    Use cases:\n    - Transform images with style transfers\n    - Apply artistic modifications to photos\n    - Create image variations",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.FluxSchnellRedux",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Image",
          "description": "The input image to transform"
        },
        {
          "name": "image_size",
          "type": {
            "type": "enum",
            "values": [
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
          },
          "default": "landscape_4_3",
          "title": "Image Size",
          "description": "The size of the generated image"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 4,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform",
          "min": 1.0
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed will output the same image every time"
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If true, the safety checker will be enabled"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "image_size",
        "num_inference_steps"
      ]
    },
    {
      "title": "Ideogram V 2 Edit",
      "description": "Transform existing images with Ideogram V2's editing capabilities. Modify, adjust, and refine images while maintaining high fidelity and realistic outputs with precise prompt control.\n    image, editing, transformation, fidelity, control\n\n    Use cases:\n    - Edit specific parts of images with precision\n    - Create targeted image modifications\n    - Refine and enhance image details\n    - Generate contextual image edits",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.IdeogramV2Edit",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to fill the masked part of the image"
        },
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Image",
          "description": "The image to edit"
        },
        {
          "name": "mask",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Mask",
          "description": "The mask for editing"
        },
        {
          "name": "style",
          "type": {
            "type": "str"
          },
          "default": "auto",
          "title": "Style",
          "description": "Style of generated image (auto, general, realistic, design, render_3D, anime)"
        },
        {
          "name": "expand_prompt",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Expand Prompt",
          "description": "Whether to expand the prompt with MagicPrompt functionality"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed will output the same image every time"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "image",
        "mask"
      ]
    },
    {
      "title": "Ideogram V 2 Remix",
      "description": "Reimagine existing images with Ideogram V2's remix feature. Create variations and adaptations while preserving core elements and adding new creative directions through prompt guidance.\n    image, remix, variation, creativity, adaptation\n\n    Use cases:\n    - Create artistic variations of images\n    - Generate style-transferred versions\n    - Produce creative image adaptations\n    - Transform images while preserving key elements\n    - Generate alternative interpretations",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.IdeogramV2Remix",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to remix the image with"
        },
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Image",
          "description": "The image to remix"
        },
        {
          "name": "aspect_ratio",
          "type": {
            "type": "str"
          },
          "default": "1:1",
          "title": "Aspect Ratio",
          "description": "The aspect ratio of the generated image"
        },
        {
          "name": "strength",
          "type": {
            "type": "float"
          },
          "default": 0.8,
          "title": "Strength",
          "description": "Strength of the input image in the remix"
        },
        {
          "name": "expand_prompt",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Expand Prompt",
          "description": "Whether to expand the prompt with MagicPrompt functionality"
        },
        {
          "name": "style",
          "type": {
            "type": "str"
          },
          "default": "auto",
          "title": "Style",
          "description": "Style of generated image (auto, general, realistic, design, render_3D, anime)"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed will output the same image every time"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "image",
        "strength"
      ]
    },
    {
      "title": "Wan Effects",
      "description": "Apply stylized effects to an image using the WAN Effects model.\n\n    image, transformation, style, filter\n\n    Use cases:\n    - Add artistic filters to photos\n    - Create stylized social media images\n    - Quickly generate meme-style effects",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.WanEffects",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null
          },
          "title": "Image",
          "description": "Input image to apply the effect to"
        },
        {
          "name": "effect",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Effect",
          "description": "Name of the effect to apply"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "effect"
      ]
    },
    {
      "title": "Any LLM",
      "description": "Use any large language model from a selected catalogue (powered by OpenRouter).\n    Supports various models including Claude 3, Gemini, Llama, and GPT-4.\n    llm, text, generation, ai, language\n\n    Use cases:\n    - Generate natural language responses\n    - Create conversational AI interactions\n    - Process and analyze text content\n    - Generate creative writing\n    - Assist with problem-solving tasks",
      "namespace": "fal.llm",
      "node_type": "fal.llm.AnyLLM",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to send to the language model"
        },
        {
          "name": "system_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "System Prompt",
          "description": "Optional system prompt to provide context or instructions"
        },
        {
          "name": "model",
          "type": {
            "type": "enum",
            "values": [
              "anthropic/claude-3.5-sonnet",
              "anthropic/claude-3-5-haiku",
              "anthropic/claude-3-haiku",
              "google/gemini-pro-1.5",
              "google/gemini-flash-1.5",
              "google/gemini-flash-1.5-8b",
              "meta-llama/llama-3.2-1b-instruct",
              "meta-llama/llama-3.2-3b-instruct",
              "meta-llama/llama-3.1-8b-instruct",
              "meta-llama/llama-3.1-70b-instruct",
              "openai/gpt-4o-mini",
              "openai/gpt-4o"
            ],
            "type_name": "nodetool.nodes.fal.llm.ModelEnum"
          },
          "default": "google/gemini-flash-1.5",
          "title": "Model",
          "description": "The language model to use for the completion"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "str"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "model",
        "system_prompt"
      ]
    }
  ]
}