{
  "name": "nodetool-fal",
  "description": "Nodetool FAL nodes",
  "version": "0.6.3-rc.18",
  "authors": [
    "Matthias Georgi <matti.georgi@gmail.com>"
  ],
  "repo_id": "",
  "nodes": [
    {
      "title": "Fal AI",
      "description": "Dynamic FAL node for running any fal.ai endpoint.\n    fal, schema, dynamic, openapi, inference, runtime, model\n\n    Use cases:\n    - Call new fal.ai endpoints without adding new Python nodes\n    - Prototype workflows with experimental FAL models\n    - Run custom endpoints by sharing model info (llms.txt)\n    - Build flexible pipelines that depend on runtime model selection",
      "namespace": "fal.dynamic_schema",
      "node_type": "fal.dynamic_schema.FalAI",
      "properties": [
        {
          "name": "model_info",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Model Info",
          "description": "Paste the full llms.txt from the fal.ai model page (e.g. fal.ai/models/... \u2192 copy all)."
        }
      ],
      "basic_fields": [
        "model_info"
      ],
      "is_dynamic": true,
      "supports_dynamic_outputs": true
    },
    {
      "title": "Bi Ref Net",
      "description": "BiRefNet is a high-quality background removal model using bilateral reference.\n    image, background-removal, segmentation, matting\n\n    Use cases:\n    - Remove backgrounds from photos\n    - Create product images with transparent backgrounds\n    - Extract subjects from images\n    - Prepare images for compositing\n    - Create stickers and cutouts",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.BiRefNet",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The input image for background removal"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image"
      ]
    },
    {
      "title": "Bi Ref Net V2",
      "description": "BiRefNet V2 is an improved background removal model with better edge detection.\n    image, background-removal, segmentation, matting, v2\n\n    Use cases:\n    - High-quality background removal\n    - Precise edge detection for cutouts\n    - Product photography processing\n    - Portrait extraction\n    - Complex background handling",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.BiRefNetV2",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The input image for background removal"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image"
      ]
    },
    {
      "title": "Bria Background Remove",
      "description": "Bria RMBG 2.0 enables seamless removal of backgrounds from images, ideal for professional editing tasks.\n    Trained exclusively on licensed data for safe and risk-free commercial use.",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.BriaBackgroundRemove",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "Input image to remove background from"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image"
      ]
    },
    {
      "title": "Bria Background Replace",
      "description": "Bria Background Replace allows for efficient swapping of backgrounds in images via text prompts or reference image, delivering realistic and polished results. Trained exclusively on licensed data for safe and risk-free commercial use.\n    image, background, replacement, swap\n\n    Use cases:\n    - Replace image backgrounds seamlessly\n    - Create professional photo compositions\n    - Generate custom scene settings\n    - Produce commercial-ready images\n    - Create consistent visual environments",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.BriaBackgroundReplace",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "Input image to replace background"
        },
        {
          "name": "ref_image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Ref Image",
          "description": "Reference image for the new background"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "Prompt to generate new background"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "Negative prompt for background generation"
        },
        {
          "name": "refine_prompt",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Refine Prompt",
          "description": "Whether to refine the prompt"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed will output the same image every time"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "Bria Eraser",
      "description": "Bria Eraser enables precise removal of unwanted objects from images while maintaining high-quality outputs. Trained exclusively on licensed data for safe and risk-free commercial use.\n    image, removal, cleanup\n\n    Use cases:\n    - Remove unwanted objects from images\n    - Clean up image imperfections\n    - Prepare images for commercial use\n    - Remove distracting elements\n    - Create clean, professional images",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.BriaEraser",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "Input image to erase from"
        },
        {
          "name": "mask",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Mask",
          "description": "The mask for areas to be cleaned"
        },
        {
          "name": "mask_type",
          "type": {
            "type": "str"
          },
          "default": "manual",
          "title": "Mask Type",
          "description": "Type of mask - 'manual' for user-created or 'automatic' for algorithm-generated"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "mask"
      ]
    },
    {
      "title": "Bria Expand",
      "description": "Bria Expand expands images beyond their borders in high quality. Trained exclusively on licensed data for safe and risk-free commercial use.\n    image, expansion, outpainting\n\n    Use cases:\n    - Extend image boundaries seamlessly\n    - Create wider or taller compositions\n    - Expand images for different aspect ratios\n    - Generate additional scene content",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.BriaExpand",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The input image to expand"
        },
        {
          "name": "canvas_width",
          "type": {
            "type": "int"
          },
          "default": 1200,
          "title": "Canvas Width",
          "description": "The desired width of the final image, after the expansion"
        },
        {
          "name": "canvas_height",
          "type": {
            "type": "int"
          },
          "default": 674,
          "title": "Canvas Height",
          "description": "The desired height of the final image, after the expansion"
        },
        {
          "name": "original_image_width",
          "type": {
            "type": "int"
          },
          "default": 610,
          "title": "Original Image Width",
          "description": "The desired width of the original image, inside the full canvas"
        },
        {
          "name": "original_image_height",
          "type": {
            "type": "int"
          },
          "default": 855,
          "title": "Original Image Height",
          "description": "The desired height of the original image, inside the full canvas"
        },
        {
          "name": "original_image_x",
          "type": {
            "type": "int"
          },
          "default": 301,
          "title": "Original Image X",
          "description": "The desired x-coordinate of the original image, inside the full canvas"
        },
        {
          "name": "original_image_y",
          "type": {
            "type": "int"
          },
          "default": -66,
          "title": "Original Image Y",
          "description": "The desired y-coordinate of the original image, inside the full canvas"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "Text on which you wish to base the image expansion"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "The negative prompt to use when generating images"
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "Number of images to generate"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed will output the same image every time"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "canvas_width",
        "canvas_height",
        "prompt"
      ]
    },
    {
      "title": "Bria Fibo Restore",
      "description": "Restore and enhance damaged or low-quality images using AI-powered restoration. Improves clarity, removes artifacts, and enhances overall image quality.\n    image, restoration, enhancement, quality, repair, bria\n\n    Use cases:\n    - Restore old or damaged photographs\n    - Enhance low-quality images\n    - Remove compression artifacts\n    - Improve image clarity\n    - Repair degraded images",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.BriaFiboRestore",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The source image to restore"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image"
      ]
    },
    {
      "title": "Bria Gen Fill",
      "description": "Bria GenFill enables high-quality object addition or visual transformation. Trained exclusively on licensed data for safe and risk-free commercial use.\n    image, generation, filling, transformation\n\n    Use cases:\n    - Add new objects to existing images\n    - Transform specific image areas\n    - Generate contextual content\n    - Create seamless visual additions\n    - Produce professional image modifications",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.BriaGenFill",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "Input image to erase from"
        },
        {
          "name": "mask",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Mask",
          "description": "The mask for areas to be cleaned"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate images"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "The negative prompt to use when generating images"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed will output the same image every time"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "mask",
        "prompt"
      ]
    },
    {
      "title": "Bria Product Shot",
      "description": "Place any product in any scenery with just a prompt or reference image while maintaining high integrity of the product. Trained exclusively on licensed data for safe and risk-free commercial use and optimized for eCommerce.\n    image, product, placement, ecommerce\n\n    Use cases:\n    - Create professional product photography\n    - Generate contextual product shots\n    - Place products in custom environments\n    - Create eCommerce product listings\n    - Generate marketing visuals",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.BriaProductShot",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The product image to be placed"
        },
        {
          "name": "scene_description",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Scene Description",
          "description": "Text description of the new scene/background"
        },
        {
          "name": "ref_image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Ref Image",
          "description": "Reference image for the new scene/background"
        },
        {
          "name": "optimize_description",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Optimize Description",
          "description": "Whether to optimize the scene description"
        },
        {
          "name": "placement_type",
          "type": {
            "type": "str"
          },
          "default": "manual_placement",
          "title": "Placement Type",
          "description": "How to position the product (original, automatic, manual_placement, manual_padding)"
        },
        {
          "name": "manual_placement_selection",
          "type": {
            "type": "str"
          },
          "default": "bottom_center",
          "title": "Manual Placement Selection",
          "description": "Specific placement position when using manual_placement"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "scene_description"
      ]
    },
    {
      "title": "Bria Replace Background",
      "description": "Creates enriched product shots by placing them in various environments using textual descriptions.\n    image, background, replacement, product, enhancement, bria\n\n    Use cases:\n    - Replace product image backgrounds with custom environments\n    - Create professional product photography\n    - Generate contextual product shots\n    - Enhance e-commerce product images\n    - Create marketing visuals with custom backgrounds",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.BriaReplaceBackground",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "Reference image for background replacement"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "Prompt for background replacement"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "Negative prompt for background replacement"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": 4925634,
          "title": "Seed",
          "description": "Random seed for reproducibility"
        },
        {
          "name": "steps_num",
          "type": {
            "type": "int"
          },
          "default": 30,
          "title": "Steps Num",
          "description": "Number of inference steps"
        },
        {
          "name": "sync_mode",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Sync Mode",
          "description": "If true, returns the image directly in the response (increases latency)"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt",
        "steps_num"
      ]
    },
    {
      "title": "CCSR",
      "description": "CCSR (Content-Consistent Super-Resolution) for high-quality image upscaling.\n    image, upscaling, super-resolution, enhancement\n\n    Use cases:\n    - Upscale images with content consistency\n    - Enhance low-resolution photos\n    - Improve image details\n    - Prepare images for printing\n    - Restore compressed images",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.CCSR",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The input image to upscale"
        },
        {
          "name": "scale",
          "type": {
            "type": "int"
          },
          "default": 4,
          "title": "Scale",
          "description": "Upscaling factor",
          "min": 2.0,
          "max": 4.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "scale"
      ]
    },
    {
      "title": "Cartoonify",
      "description": "Cartoonify transforms photos into cartoon-style images.\n    image, cartoon, style-transfer, fun, artistic\n\n    Use cases:\n    - Convert photos to cartoon style\n    - Create animated-style portraits\n    - Design fun profile pictures\n    - Generate cartoon avatars\n    - Create artistic transformations",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.Cartoonify",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The image to cartoonify"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image"
      ]
    },
    {
      "title": "Clarity Upscaler",
      "description": "Upscale images to improve resolution and sharpness.\n\n    clarity, upscale, enhancement\n\n    Use cases:\n    - Increase image resolution for printing\n    - Improve clarity of low-quality images\n    - Enhance textures and graphics",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.ClarityUpscaler",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "Input image to upscale"
        },
        {
          "name": "scale",
          "type": {
            "type": "int"
          },
          "default": 2,
          "title": "Scale",
          "description": "Upscaling factor",
          "min": 1.0,
          "max": 4.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "scale"
      ]
    },
    {
      "title": "Code Former",
      "description": "CodeFormer is a face restoration model for enhancing and restoring face quality.\n    image, face-restoration, enhancement, quality\n\n    Use cases:\n    - Restore old or damaged photos\n    - Enhance low-quality face images\n    - Improve portrait quality\n    - Fix facial artifacts\n    - Upscale face details",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.CodeFormer",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The input image with faces to restore"
        },
        {
          "name": "fidelity",
          "type": {
            "type": "float"
          },
          "default": 0.5,
          "title": "Fidelity",
          "description": "Balance between quality and fidelity (0=quality, 1=fidelity)",
          "min": 0.0,
          "max": 1.0
        },
        {
          "name": "background_enhance",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Background Enhance",
          "description": "Whether to enhance the background"
        },
        {
          "name": "face_upsample",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Face Upsample",
          "description": "Whether to upsample the face"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "fidelity"
      ]
    },
    {
      "title": "Creative Upscaler",
      "description": "Creative Upscaler enhances image resolution while adding creative details.\n    image, upscaling, enhancement, super-resolution, creative\n\n    Use cases:\n    - Upscale low-resolution images\n    - Enhance image details creatively\n    - Improve image quality\n    - Prepare images for print\n    - Restore old or compressed images",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.CreativeUpscaler",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The input image to upscale"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "Optional prompt to guide the upscaling"
        },
        {
          "name": "scale",
          "type": {
            "type": "float"
          },
          "default": 2.0,
          "title": "Scale",
          "description": "Upscaling factor",
          "min": 1.0,
          "max": 4.0
        },
        {
          "name": "creativity",
          "type": {
            "type": "float"
          },
          "default": 0.5,
          "title": "Creativity",
          "description": "Level of creative enhancement",
          "min": 0.0,
          "max": 1.0
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for reproducible generation"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "scale",
        "creativity"
      ]
    },
    {
      "title": "ESRGAN",
      "description": "ESRGAN (Enhanced Super-Resolution GAN) for high-quality image upscaling.\n    image, upscaling, super-resolution, enhancement\n\n    Use cases:\n    - Upscale images to higher resolution\n    - Enhance image details\n    - Improve image quality for printing\n    - Restore low-resolution images\n    - Prepare images for large displays",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.ESRGAN",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The input image to upscale"
        },
        {
          "name": "scale",
          "type": {
            "type": "int"
          },
          "default": 4,
          "title": "Scale",
          "description": "Upscaling factor",
          "min": 2.0,
          "max": 8.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "scale"
      ]
    },
    {
      "title": "Face Swap Image",
      "description": "Swap faces between source and target images. Creates realistic face swaps with optional occlusion prevention for handling objects covering faces.\n    face-swap, face-transfer, image-manipulation, face-replacement, portrait\n\n    Use cases:\n    - Swap faces in photos for creative content\n    - Create fun photo edits with friend's faces\n    - Generate alternative portraits\n    - Test how you'd look with different hairstyles\n    - Create face-swapped memes and social content",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.FaceSwapImage",
      "properties": [
        {
          "name": "source_face",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Source Face",
          "description": "Source face image to swap from"
        },
        {
          "name": "target_image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Target Image",
          "description": "Target image to swap face into"
        },
        {
          "name": "enable_occlusion_prevention",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Enable Occlusion Prevention",
          "description": "Enable occlusion prevention for faces covered by hands/objects (costs 2x more)"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "source_face",
        "target_image"
      ]
    },
    {
      "title": "Face To Sticker",
      "description": "Face to Sticker transforms face photos into fun sticker-style images.\n    image, face, sticker, fun, transformation\n\n    Use cases:\n    - Create fun stickers from photos\n    - Generate emoji-style faces\n    - Design personalized sticker packs\n    - Create cartoon avatars\n    - Produce fun social media content",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.FaceToSticker",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The face image to convert to sticker"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "sticker",
          "title": "Prompt",
          "description": "Optional prompt to guide the sticker style"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for reproducible generation"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image"
      ]
    },
    {
      "title": "Flux 2 Klein 4 b Base Edit",
      "description": "Image-to-image editing with Flux 2 [klein] 4B Base from Black Forest Labs. Precise modifications using natural language descriptions and hex color control.\n    image, editing, flux, klein, 4b, natural-language, color-control\n\n    Use cases:\n    - Edit images with natural language descriptions\n    - Apply precise modifications with hex color control\n    - Style transfer and content edits\n    - Reference-image style application\n    - Targeted image transformations",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.Flux2Klein4bBaseEdit",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The input image to edit"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt describing the edit (e.g. 'Imagine view of Fuji mount. Use style of reference image.')"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "Negative prompt for classifier-free guidance. Describes what to avoid in the image."
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 5.0,
          "title": "Guidance Scale",
          "description": "Guidance scale for classifier-free guidance",
          "min": 0.0,
          "max": 20.0
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 28,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform",
          "min": 4.0,
          "max": 50.0
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "The number of images to generate",
          "min": 1.0,
          "max": 4.0
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for reproducible generation"
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If true, the safety checker will be enabled"
        },
        {
          "name": "output_format",
          "type": {
            "type": "str"
          },
          "default": "png",
          "title": "Output Format",
          "description": "Output format: jpeg, png, or webp"
        },
        {
          "name": "acceleration",
          "type": {
            "type": "str"
          },
          "default": "regular",
          "title": "Acceleration",
          "description": "Acceleration level: none, regular, or high"
        },
        {
          "name": "image_size",
          "type": {
            "type": "enum",
            "optional": true,
            "values": [
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
          },
          "default": null,
          "title": "Image Size",
          "description": "The size of the generated image. If not provided, uses the input image size."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "Flux 2 Klein 4 b Base Edit Lora",
      "description": "Image-to-image editing with LoRA support for FLUX.2 [klein] 4B Base from Black Forest Labs. Specialized style transfer and domain-specific modifications.\n    image, editing, flux, klein, 4b, lora, style-transfer\n\n    Use cases:\n    - Style transfer with custom LoRAs\n    - Domain-specific image modifications\n    - Apply trained LoRA weights to edits\n    - Consistent character or style editing\n    - Specialized editorial transformations",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.Flux2Klein4bBaseEditLora",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The input image to edit"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to edit the image (e.g. 'Change his clothes to casual suit and tie')"
        },
        {
          "name": "loras",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "lora_weight"
              }
            ]
          },
          "default": null,
          "title": "Loras",
          "description": "List of LoRA weights to apply (maximum 3)",
          "required": true
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "Negative prompt for classifier-free guidance"
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 5.0,
          "title": "Guidance Scale",
          "description": "Guidance scale for classifier-free guidance",
          "min": 0.0,
          "max": 20.0
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 28,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform",
          "min": 4.0,
          "max": 50.0
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "The number of images to generate",
          "min": 1.0,
          "max": 4.0
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for reproducible generation"
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If true, the safety checker will be enabled"
        },
        {
          "name": "output_format",
          "type": {
            "type": "str"
          },
          "default": "png",
          "title": "Output Format",
          "description": "Output format: jpeg, png, or webp"
        },
        {
          "name": "acceleration",
          "type": {
            "type": "str"
          },
          "default": "regular",
          "title": "Acceleration",
          "description": "Acceleration level: none, regular, or high"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt",
        "loras"
      ]
    },
    {
      "title": "Flux 2 Klein 9 b Base Edit Lora",
      "description": "Image-to-image editing with LoRA support for FLUX.2 [klein] 9B Base from Black Forest Labs. Specialized style transfer and domain-specific modifications.\n    image, editing, flux, klein, 9b, lora, style-transfer\n\n    Use cases:\n    - Higher-quality style transfer with custom LoRAs\n    - Domain-specific image modifications with 9B model\n    - Apply trained LoRA weights to edits\n    - Consistent character or style editing\n    - Specialized editorial transformations",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.Flux2Klein9bBaseEditLora",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The input image to edit"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to edit the image (e.g. 'Change his clothes to casual suit and tie')"
        },
        {
          "name": "loras",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "lora_weight"
              }
            ]
          },
          "default": null,
          "title": "Loras",
          "description": "List of LoRA weights to apply (maximum 3)",
          "required": true
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "Negative prompt for classifier-free guidance"
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 5.0,
          "title": "Guidance Scale",
          "description": "Guidance scale for classifier-free guidance",
          "min": 0.0,
          "max": 20.0
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 28,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform",
          "min": 4.0,
          "max": 50.0
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "The number of images to generate",
          "min": 1.0,
          "max": 4.0
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for reproducible generation"
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If true, the safety checker will be enabled"
        },
        {
          "name": "output_format",
          "type": {
            "type": "str"
          },
          "default": "png",
          "title": "Output Format",
          "description": "Output format: jpeg, png, or webp"
        },
        {
          "name": "acceleration",
          "type": {
            "type": "str"
          },
          "default": "regular",
          "title": "Acceleration",
          "description": "Acceleration level: none, regular, or high"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt",
        "loras"
      ]
    },
    {
      "title": "Flux 2 Turbo Edit",
      "description": "FLUX 2 Turbo Edit for fast image editing with the FLUX 2 model.\n    image, editing, flux, fast, turbo, text-guided\n\n    Use cases:\n    - Rapid image modifications\n    - Quick style transfers\n    - Fast object editing\n    - Iterative refinement\n    - Real-time editing workflows",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.Flux2TurboEdit",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The input image to edit"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt describing the edit"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 4,
          "title": "Num Inference Steps",
          "description": "Number of inference steps",
          "min": 1.0
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for reproducible generation"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "Flux Dev Redux",
      "description": "FLUX.1 [dev] Redux is a high-performance endpoint that enables rapid transformation of existing images, delivering high-quality style transfers and image modifications.\n    image, transformation, style-transfer, development, flux\n\n    Use cases:\n    - Transform images with advanced controls\n    - Create customized image variations\n    - Apply precise style modifications",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.FluxDevRedux",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The input image to transform"
        },
        {
          "name": "image_size",
          "type": {
            "type": "enum",
            "values": [
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
          },
          "default": "landscape_4_3",
          "title": "Image Size",
          "description": "The size of the generated image"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 28,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform",
          "min": 1.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 3.5,
          "title": "Guidance Scale",
          "description": "How closely the model should stick to your prompt"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed will output the same image every time"
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If true, the safety checker will be enabled"
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "The number of images to generate (1-4)",
          "min": 1.0,
          "max": 4.0
        },
        {
          "name": "output_format",
          "type": {
            "type": "str"
          },
          "default": "jpeg",
          "title": "Output Format",
          "description": "Output format (jpeg or png)"
        },
        {
          "name": "acceleration",
          "type": {
            "type": "str"
          },
          "default": "none",
          "title": "Acceleration",
          "description": "Acceleration speed: 'none', 'regular', or 'high'"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "image_size",
        "guidance_scale"
      ]
    },
    {
      "title": "Flux Lora Canny",
      "description": "FLUX LoRA Canny enables precise control over composition and style through edge detection and LoRA-based guidance mechanisms.\n    image, edge, lora, style-transfer, control\n\n    Use cases:\n    - Generate stylized images with structural control\n    - Create edge-guided artistic transformations\n    - Apply custom styles while maintaining composition\n    - Produce consistent style variations",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.FluxLoraCanny",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The control image to generate the Canny edge map from"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "image_size",
          "type": {
            "type": "enum",
            "values": [
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
          },
          "default": "landscape_4_3",
          "title": "Image Size",
          "description": "The size of the generated image"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 28,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform",
          "min": 1.0,
          "max": 50.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 30,
          "title": "Guidance Scale",
          "description": "The CFG scale - how closely the model should stick to your prompt (20-40)",
          "min": 20.0,
          "max": 40.0
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed will output the same image every time"
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "The number of images to generate (1-4)",
          "min": 1.0,
          "max": 4.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt",
        "guidance_scale"
      ]
    },
    {
      "title": "Flux Lora Depth",
      "description": "FLUX LoRA Depth enables precise control over composition and structure through depth map detection and LoRA-based guidance mechanisms.\n    image, depth, lora, structure, control\n\n    Use cases:\n    - Generate depth-aware stylized images\n    - Create 3D-conscious artistic transformations\n    - Maintain spatial relationships with custom styles\n    - Produce depth-consistent variations\n    - Generate images with controlled perspective",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.FluxLoraDepth",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The control image to generate the depth map from"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "image_size",
          "type": {
            "type": "enum",
            "values": [
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
          },
          "default": "landscape_4_3",
          "title": "Image Size",
          "description": "The size of the generated image"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 28,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform",
          "min": 1.0,
          "max": 50.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 3.5,
          "title": "Guidance Scale",
          "description": "The CFG scale - how closely the model should stick to your prompt (0-35)",
          "min": 0.0,
          "max": 35.0
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed will output the same image every time"
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "The number of images to generate (1-4)",
          "min": 1.0,
          "max": 4.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt",
        "guidance_scale"
      ]
    },
    {
      "title": "Flux Pro Canny",
      "description": "FLUX.1 [pro] Canny enables precise control over composition, style, and structure through advanced edge detection and guidance mechanisms.\n    image, edge, composition, style, control\n\n    Use cases:\n    - Generate images with precise structural control\n    - Create artwork based on edge maps\n    - Transform sketches into detailed images\n    - Maintain specific compositional elements\n    - Generate variations with consistent structure",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.FluxProCanny",
      "properties": [
        {
          "name": "control_image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Control Image",
          "description": "The control image to generate the Canny edge map from"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "image_size",
          "type": {
            "type": "enum",
            "values": [
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
          },
          "default": "landscape_4_3",
          "title": "Image Size",
          "description": "The size of the generated image"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 28,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform",
          "min": 1.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 3.5,
          "title": "Guidance Scale",
          "description": "How closely the model should stick to your prompt"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed will output the same image every time"
        },
        {
          "name": "safety_tolerance",
          "type": {
            "type": "str"
          },
          "default": "2",
          "title": "Safety Tolerance",
          "description": "Safety tolerance level (1-6, 1 being most strict)"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "control_image",
        "prompt",
        "image_size"
      ]
    },
    {
      "title": "Flux Pro Depth",
      "description": "FLUX.1 [pro] Depth enables precise control over composition and structure through depth map detection and guidance mechanisms.\n    image, depth-map, composition, structure, control\n\n    Use cases:\n    - Generate images with controlled depth perception\n    - Create 3D-aware image transformations\n    - Maintain spatial relationships in generated images\n    - Produce images with accurate perspective\n    - Generate variations with consistent depth structure",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.FluxProDepth",
      "properties": [
        {
          "name": "control_image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Control Image",
          "description": "The control image to generate the depth map from"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "image_size",
          "type": {
            "type": "enum",
            "values": [
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
          },
          "default": "landscape_4_3",
          "title": "Image Size",
          "description": "The size of the generated image"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 28,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform",
          "min": 1.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 3.5,
          "title": "Guidance Scale",
          "description": "How closely the model should stick to your prompt"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed will output the same image every time"
        },
        {
          "name": "safety_tolerance",
          "type": {
            "type": "str"
          },
          "default": "2",
          "title": "Safety Tolerance",
          "description": "Safety tolerance level (1-6, 1 being most strict)"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "control_image",
        "prompt",
        "image_size"
      ]
    },
    {
      "title": "Flux Pro Fill",
      "description": "FLUX.1 [pro] Fill is a high-performance endpoint that enables rapid transformation of existing images with inpainting/outpainting capabilities.\n    image, inpainting, outpainting, transformation, professional\n\n    Use cases:\n    - Fill in missing or masked parts of images\n    - Extend images beyond their original boundaries\n    - Remove and replace unwanted elements\n    - Create seamless image completions\n    - Generate context-aware image content",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.FluxProFill",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The input image to transform"
        },
        {
          "name": "mask",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Mask",
          "description": "The mask for inpainting"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to fill the masked part of the image"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 28,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform",
          "min": 1.0
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed will output the same image every time"
        },
        {
          "name": "safety_tolerance",
          "type": {
            "type": "str"
          },
          "default": "2",
          "title": "Safety Tolerance",
          "description": "Safety tolerance level (1-6, 1 being most strict)"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "mask",
        "prompt"
      ]
    },
    {
      "title": "Flux Pro Redux",
      "description": "FLUX.1 [pro] Redux is a high-performance endpoint that enables rapid transformation of existing images, delivering high-quality style transfers and image modifications.\n    image, transformation, style-transfer, flux\n\n    Use cases:\n    - Create professional image transformations\n    - Generate style transfers",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.FluxProRedux",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The input image to transform"
        },
        {
          "name": "image_size",
          "type": {
            "type": "enum",
            "values": [
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
          },
          "default": "landscape_4_3",
          "title": "Image Size",
          "description": "The size of the generated image"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 28,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform",
          "min": 1.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 3.5,
          "title": "Guidance Scale",
          "description": "How closely the model should stick to your prompt"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed will output the same image every time"
        },
        {
          "name": "safety_tolerance",
          "type": {
            "type": "str"
          },
          "default": "2",
          "title": "Safety Tolerance",
          "description": "Safety tolerance level (1-6, 1 being most strict)"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "image_size",
        "guidance_scale"
      ]
    },
    {
      "title": "Flux Pro Ultra Redux",
      "description": "FLUX1.1 [pro] ultra Redux is a high-performance endpoint that enables rapid transformation of existing images, delivering high-quality style transfers and image modifications with the core FLUX capabilities.\n    image, transformation, style-transfer, ultra, professional\n\n    Use cases:\n    - Apply precise image modifications\n    - Process images with maximum control",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.FluxProUltraRedux",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The input image to transform"
        },
        {
          "name": "image_size",
          "type": {
            "type": "enum",
            "values": [
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
          },
          "default": "landscape_4_3",
          "title": "Image Size",
          "description": "The size of the generated image"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 28,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform",
          "min": 1.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 3.5,
          "title": "Guidance Scale",
          "description": "How closely the model should stick to your prompt"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed will output the same image every time"
        },
        {
          "name": "safety_tolerance",
          "type": {
            "type": "str"
          },
          "default": "2",
          "title": "Safety Tolerance",
          "description": "Safety tolerance level (1-6, 1 being most strict)"
        },
        {
          "name": "image_prompt_strength",
          "type": {
            "type": "float"
          },
          "default": 0.1,
          "title": "Image Prompt Strength",
          "description": "The strength of the image prompt, between 0 and 1"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "image_size",
        "guidance_scale"
      ]
    },
    {
      "title": "Flux Schnell Redux",
      "description": "FLUX.1 [schnell] Redux is a high-performance endpoint that enables rapid transformation of existing images, delivering high-quality style transfers and image modifications with the core FLUX capabilities.\n    image, transformation, style-transfer, fast, flux\n\n    Use cases:\n    - Transform images with style transfers\n    - Apply artistic modifications to photos\n    - Create image variations",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.FluxSchnellRedux",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The input image to transform"
        },
        {
          "name": "image_size",
          "type": {
            "type": "enum",
            "values": [
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
          },
          "default": "landscape_4_3",
          "title": "Image Size",
          "description": "The size of the generated image"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 4,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform",
          "min": 1.0
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed will output the same image every time"
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If true, the safety checker will be enabled"
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "The number of images to generate (1-4)",
          "min": 1.0,
          "max": 4.0
        },
        {
          "name": "output_format",
          "type": {
            "type": "str"
          },
          "default": "jpeg",
          "title": "Output Format",
          "description": "Output format (jpeg or png)"
        },
        {
          "name": "acceleration",
          "type": {
            "type": "str"
          },
          "default": "none",
          "title": "Acceleration",
          "description": "Acceleration speed: 'none', 'regular', or 'high'"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "image_size",
        "num_inference_steps",
        "num_images"
      ]
    },
    {
      "title": "GPTImage 1 Edit",
      "description": "OpenAI GPT Image 1 Edit for modifying images with text instructions.\n    image, editing, openai, gpt, text-guided\n\n    Use cases:\n    - Edit images with natural language\n    - Modify specific elements in photos\n    - Add or change objects\n    - Apply creative edits\n    - Refine images iteratively",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.GPTImage1Edit",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The input image to edit"
        },
        {
          "name": "mask",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Mask",
          "description": "The mask for inpainting (optional)"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "Instructions for editing the image"
        },
        {
          "name": "size",
          "type": {
            "type": "str"
          },
          "default": "1024x1024",
          "title": "Size",
          "description": "The size of the output image"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for reproducible generation"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "Gemini Flash Edit",
      "description": "Google Gemini Flash Edit for fast image editing with text prompts.\n    image, editing, google, gemini, fast, text-guided\n\n    Use cases:\n    - Quick image modifications\n    - Fast iterative edits\n    - Object addition or removal\n    - Style adjustments\n    - Rapid prototyping",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.GeminiFlashEdit",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The input image to edit"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "Instructions for editing the image"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for reproducible generation"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "Hunyuan Image V3 Instruct Edit",
      "description": "Hunyuan Image V3 Instruct Edit with reasoning capabilities for advanced image-to-image editing.\n    image, edit, hunyuan, tencent, instruct, reasoning, image-to-image, img2img, advanced\n\n    Use cases:\n    - Edit images with complex instructions\n    - Apply style transfers with reasoning\n    - Modify images with multiple reference images\n    - Create variations with intelligent understanding\n    - Transform images with advanced prompt interpretation",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.HunyuanImageV3InstructEdit",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The text prompt for editing the image"
        },
        {
          "name": "image_urls",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "image"
              }
            ]
          },
          "default": null,
          "title": "Image Urls",
          "description": "Reference images to use (maximum 2 images)",
          "required": true
        },
        {
          "name": "image_size",
          "type": {
            "type": "enum",
            "values": [
              "auto",
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.HunyuanImageSizePreset"
          },
          "default": "auto",
          "title": "Image Size",
          "description": "The desired size of the generated image. If auto, size is determined by the model"
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "The number of images to generate",
          "min": 1.0,
          "max": 4.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 3.5,
          "title": "Guidance Scale",
          "description": "How closely to follow the prompt (higher = stricter adherence)",
          "min": 1.0,
          "max": 20.0
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for reproducible generation"
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "Enable safety checker to filter unsafe content"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "image_urls",
        "guidance_scale"
      ]
    },
    {
      "title": "Ideogram V2 Edit",
      "description": "Transform existing images with Ideogram V2's editing capabilities. Modify, adjust, and refine images while maintaining high fidelity and realistic outputs with precise prompt control.\n    image, editing, transformation, fidelity, control\n\n    Use cases:\n    - Edit specific parts of images with precision\n    - Create targeted image modifications\n    - Refine and enhance image details\n    - Generate contextual image edits",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.IdeogramV2Edit",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to fill the masked part of the image"
        },
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The image to edit"
        },
        {
          "name": "mask",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Mask",
          "description": "The mask for editing"
        },
        {
          "name": "style",
          "type": {
            "type": "str"
          },
          "default": "auto",
          "title": "Style",
          "description": "Style of generated image (auto, general, realistic, design, render_3D, anime)"
        },
        {
          "name": "expand_prompt",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Expand Prompt",
          "description": "Whether to expand the prompt with MagicPrompt functionality"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed will output the same image every time"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "image",
        "mask"
      ]
    },
    {
      "title": "Ideogram V2 Remix",
      "description": "Reimagine existing images with Ideogram V2's remix feature. Create variations and adaptations while preserving core elements and adding new creative directions through prompt guidance.\n    image, remix, variation, creativity, adaptation\n\n    Use cases:\n    - Create artistic variations of images\n    - Generate style-transferred versions\n    - Produce creative image adaptations\n    - Transform images while preserving key elements\n    - Generate alternative interpretations",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.IdeogramV2Remix",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to remix the image with"
        },
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The image to remix"
        },
        {
          "name": "aspect_ratio",
          "type": {
            "type": "str"
          },
          "default": "1:1",
          "title": "Aspect Ratio",
          "description": "The aspect ratio of the generated image"
        },
        {
          "name": "strength",
          "type": {
            "type": "float"
          },
          "default": 0.8,
          "title": "Strength",
          "description": "Strength of the input image in the remix"
        },
        {
          "name": "expand_prompt",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Expand Prompt",
          "description": "Whether to expand the prompt with MagicPrompt functionality"
        },
        {
          "name": "style",
          "type": {
            "type": "str"
          },
          "default": "auto",
          "title": "Style",
          "description": "Style of generated image (auto, general, realistic, design, render_3D, anime)"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed will output the same image every time"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "image",
        "strength"
      ]
    },
    {
      "title": "Ideogram V3 Edit",
      "description": "Ideogram V3 Edit for editing images with text prompts while maintaining structure.\n    image, editing, ideogram, inpainting, text-guided\n\n    Use cases:\n    - Edit specific parts of images with prompts\n    - Modify text in images\n    - Change elements while preserving composition\n    - Add or remove objects from images\n    - Refine generated images",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.IdeogramV3Edit",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The input image to edit"
        },
        {
          "name": "mask",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Mask",
          "description": "The mask indicating areas to edit"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt describing the edit"
        },
        {
          "name": "style",
          "type": {
            "type": "str"
          },
          "default": "auto",
          "title": "Style",
          "description": "The style of the edit"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for reproducible generation"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "mask",
        "prompt"
      ]
    },
    {
      "title": "Image Utils Depth",
      "description": "Depth estimation utility for generating depth maps from images.\n    image, depth-map, estimation, 3d, utility\n\n    Use cases:\n    - Generate depth maps for 3D effects\n    - Create parallax animations\n    - Enable depth-aware editing\n    - Generate ControlNet inputs\n    - Analyze image depth structure",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.ImageUtilsDepth",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The input image for depth estimation"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image"
      ]
    },
    {
      "title": "Image Utils Rembg",
      "description": "Rembg utility for removing image backgrounds with high accuracy.\n    image, background-removal, utility, processing\n\n    Use cases:\n    - Remove backgrounds from product photos\n    - Create transparent PNG images\n    - Extract subjects for compositing\n    - Prepare images for design work\n    - Create profile picture cutouts",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.ImageUtilsRembg",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The input image for background removal"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image"
      ]
    },
    {
      "title": "Kling Image 3 Image To Image",
      "description": "Transform and edit images using Kling Image 3.0. Features powerful image-to-image\n    editing workflows for modifying backgrounds, clothing, subjects, and more.\n    image, editing, kling, v3, image-to-image, transformation, style-transfer\n\n    Use cases:\n    - Change image backgrounds\n    - Modify clothing and subjects in images\n    - Transform image styles\n    - Edit and enhance existing images\n    - Create variations of existing artwork",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.KlingImage3ImageToImage",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The source image to transform"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The text prompt describing the desired transformation (max 2500 characters)"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "What to avoid in the generated image"
        },
        {
          "name": "aspect_ratio",
          "type": {
            "type": "enum",
            "values": [
              "16:9",
              "9:16",
              "4:3",
              "3:4",
              "1:1",
              "3:2",
              "2:3",
              "21:9"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.Kling3ImageAspectRatio"
          },
          "default": "16:9",
          "title": "Aspect Ratio",
          "description": "The aspect ratio of the generated image"
        },
        {
          "name": "resolution",
          "type": {
            "type": "enum",
            "values": [
              "1K",
              "2K"
            ],
            "type_name": "nodetool.nodes.fal.image_to_image.Kling3ImageResolution"
          },
          "default": "1K",
          "title": "Resolution",
          "description": "Image generation resolution. 1K: standard, 2K: high-res"
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "Number of images to generate (1-9)",
          "min": 1.0,
          "max": 9.0
        },
        {
          "name": "elements",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "image"
              }
            ]
          },
          "default": [],
          "title": "Elements",
          "description": "Optional elements for face/character control. Reference as @Element1, @Element2 in prompt"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for reproducible generation"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt",
        "aspect_ratio"
      ]
    },
    {
      "title": "Kolors Image To Image",
      "description": "Kolors Image-to-Image transforms images with the Kolors model.\n    image, transformation, kolors, style-transfer\n\n    Use cases:\n    - Transform image style\n    - Apply artistic effects\n    - Modify image content\n    - Create style variations\n    - Generate image edits",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.KolorsImageToImage",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The input image"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt describing the transformation"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "What to avoid in the generated image"
        },
        {
          "name": "strength",
          "type": {
            "type": "float"
          },
          "default": 0.8,
          "title": "Strength",
          "description": "Transformation strength",
          "min": 0.0,
          "max": 1.0
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 25,
          "title": "Num Inference Steps",
          "description": "Number of inference steps",
          "min": 1.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 5.0,
          "title": "Guidance Scale",
          "description": "How closely to follow the prompt"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for reproducible generation"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt",
        "strength"
      ]
    },
    {
      "title": "Live Portrait",
      "description": "Live Portrait animates a single portrait image based on a driving video.\n    image, animation, portrait, face, motion-transfer\n\n    Use cases:\n    - Animate static portraits\n    - Create talking head videos\n    - Transfer facial expressions\n    - Create avatar animations\n    - Generate video from single photo",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.LivePortrait",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The portrait image to animate"
        },
        {
          "name": "driving_video",
          "type": {
            "type": "video"
          },
          "default": {
            "type": "video",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null,
            "duration": null,
            "format": null
          },
          "title": "Driving Video",
          "description": "The driving video with motion reference"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "driving_video"
      ]
    },
    {
      "title": "Object Removal",
      "description": "Object Removal removes unwanted objects from images using AI.\n    image, inpainting, removal, cleanup\n\n    Use cases:\n    - Remove unwanted objects from photos\n    - Clean up image backgrounds\n    - Remove watermarks or logos\n    - Fix photo imperfections\n    - Create clean product shots",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.ObjectRemoval",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The input image"
        },
        {
          "name": "mask",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Mask",
          "description": "Mask indicating objects to remove"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "mask"
      ]
    },
    {
      "title": "Photo Maker",
      "description": "PhotoMaker generates images with customizable subject identity from reference photos.\n    image, face, identity, customization, generation\n\n    Use cases:\n    - Generate images with specific person identity\n    - Create personalized marketing content\n    - Design custom avatars\n    - Produce character-consistent images\n    - Generate variations of a person",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.PhotoMaker",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The reference image of the subject"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt describing the desired image"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "What to avoid in the generated image"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 50,
          "title": "Num Inference Steps",
          "description": "Number of inference steps",
          "min": 1.0
        },
        {
          "name": "style_strength",
          "type": {
            "type": "float"
          },
          "default": 20.0,
          "title": "Style Strength",
          "description": "Strength of the style transfer"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for reproducible generation"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "Pu LID",
      "description": "PuLID generates images with consistent face identity from a reference face.\n    image, face, identity, generation, consistency\n\n    Use cases:\n    - Generate images with consistent face identity\n    - Create character variations\n    - Design personalized avatars\n    - Produce face-consistent content\n    - Generate marketing images with specific faces",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.PuLID",
      "properties": [
        {
          "name": "face_image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Face Image",
          "description": "The reference face image"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt describing the desired image"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "What to avoid in the generated image"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 20,
          "title": "Num Inference Steps",
          "description": "Number of inference steps",
          "min": 1.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 1.2,
          "title": "Guidance Scale",
          "description": "How closely to follow the prompt"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for reproducible generation"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "face_image",
        "prompt"
      ]
    },
    {
      "title": "Qwen Image Max Edit",
      "description": "Qwen Image Max Edit for advanced image editing with reference images.\n    image, edit, qwen, alibaba, image-to-image, img2img, high-quality\n\n    Use cases:\n    - Edit images with complex instructions\n    - Transform images based on references\n    - Apply style transfers with multiple images\n    - Create variations with intelligent editing\n    - Modify images with detailed prompts",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.QwenImageMaxEdit",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "Text prompt describing the desired edits"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "Content to avoid in the edited image"
        },
        {
          "name": "image_urls",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "image"
              }
            ]
          },
          "default": null,
          "title": "Image Urls",
          "description": "Reference images for editing (1-3 images)",
          "required": true
        },
        {
          "name": "image_size",
          "type": {
            "type": "enum",
            "optional": true,
            "values": [
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
          },
          "default": null,
          "title": "Image Size",
          "description": "The size of the generated image. If not provided, uses input image size"
        },
        {
          "name": "enable_prompt_expansion",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Prompt Expansion",
          "description": "Enable LLM prompt optimization for better results"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for reproducible generation"
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "Enable content moderation"
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "The number of images to generate",
          "min": 1.0,
          "max": 4.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "image_urls",
        "enable_prompt_expansion"
      ]
    },
    {
      "title": "Retoucher",
      "description": "Retoucher enhances and retouches photos with AI-powered corrections.\n    image, enhancement, retouching, beautification\n\n    Use cases:\n    - Enhance portrait photos\n    - Apply skin retouching\n    - Improve photo quality\n    - Fix lighting issues\n    - Professional photo editing",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.Retoucher",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The image to retouch"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "Optional prompt to guide the retouching"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image"
      ]
    },
    {
      "title": "Wan Effects",
      "description": "Apply stylized effects to an image using the WAN Effects model.\n\n    image, transformation, style, filter\n\n    Use cases:\n    - Add artistic filters to photos\n    - Create stylized social media images\n    - Quickly generate meme-style effects",
      "namespace": "fal.image_to_image",
      "node_type": "fal.image_to_image.WanEffects",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "Input image to apply the effect to"
        },
        {
          "name": "effect",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Effect",
          "description": "Name of the effect to apply"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "effect"
      ]
    },
    {
      "title": "AMTInterpolation",
      "description": "Interpolate between image frames to create smooth video transitions. Supports configurable FPS and recursive interpolation passes for higher quality results.\n    video, interpolation, transitions, frames, smoothing, img2vid, image-to-video\n\n    Use cases:\n    - Create smooth frame transitions\n    - Generate fluid animations\n    - Enhance video frame rates\n    - Produce slow-motion effects\n    - Create seamless video blends",
      "namespace": "fal.image_to_video",
      "node_type": "fal.image_to_video.AMTInterpolation",
      "properties": [
        {
          "name": "frames",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "image"
              }
            ]
          },
          "default": [
            {},
            {}
          ],
          "title": "Frames",
          "description": "List of frames to interpolate between (minimum 2 frames required)"
        },
        {
          "name": "output_fps",
          "type": {
            "type": "int"
          },
          "default": 24,
          "title": "Output Fps",
          "description": "Output frames per second"
        },
        {
          "name": "recursive_interpolation_passes",
          "type": {
            "type": "int"
          },
          "default": 4,
          "title": "Recursive Interpolation Passes",
          "description": "Number of recursive interpolation passes (higher = smoother)"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "frames",
        "output_fps"
      ]
    },
    {
      "title": "Cog Video X",
      "description": "Generate videos from images using CogVideoX-5B. Features high-quality motion synthesis with configurable parameters for fine-tuned control over the output.\n    video, generation, motion, synthesis, control, img2vid, image-to-video\n\n    Use cases:\n    - Create controlled video animations\n    - Generate precise motion effects\n    - Produce customized video content\n    - Create fine-tuned animations\n    - Generate motion sequences",
      "namespace": "fal.image_to_video",
      "node_type": "fal.image_to_video.CogVideoX",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The image to transform into a video"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "A description of the desired video motion and style"
        },
        {
          "name": "video_size",
          "type": {
            "type": "enum",
            "values": [
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.VideoSize"
          },
          "default": "landscape_16_9",
          "title": "Video Size",
          "description": "The size/aspect ratio of the generated video"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "Distorted, discontinuous, Ugly, blurry, low resolution, motionless, static, disfigured, disconnected limbs, Ugly faces, incomplete arms",
          "title": "Negative Prompt",
          "description": "What to avoid in the generated video"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 50,
          "title": "Num Inference Steps",
          "description": "Number of denoising steps (higher = better quality but slower)"
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 7.0,
          "title": "Guidance Scale",
          "description": "How closely to follow the prompt (higher = more faithful but less creative)"
        },
        {
          "name": "use_rife",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Use Rife",
          "description": "Whether to use RIFE for video interpolation"
        },
        {
          "name": "export_fps",
          "type": {
            "type": "int"
          },
          "default": 16,
          "title": "Export Fps",
          "description": "Target frames per second for the output video"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed will output the same video every time"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt",
        "video_size"
      ]
    },
    {
      "title": "Fast SVD",
      "description": "Generate short video clips from your images using SVD v1.1 at Lightning Speed. Features high-quality motion synthesis with configurable parameters for rapid video generation.\n    video, generation, fast, motion, synthesis, img2vid, image-to-video\n\n    Use cases:\n    - Create quick video animations\n    - Generate rapid motion content\n    - Produce fast video transitions\n    - Create instant visual effects\n    - Generate quick previews",
      "namespace": "fal.image_to_video",
      "node_type": "fal.image_to_video.FastSVD",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The image to transform into a video"
        },
        {
          "name": "motion_bucket_id",
          "type": {
            "type": "int"
          },
          "default": 127,
          "title": "Motion Bucket Id",
          "description": "Controls motion intensity (higher = more motion)"
        },
        {
          "name": "cond_aug",
          "type": {
            "type": "float"
          },
          "default": 0.02,
          "title": "Cond Aug",
          "description": "Amount of noise added to conditioning (higher = more motion)"
        },
        {
          "name": "steps",
          "type": {
            "type": "int"
          },
          "default": 4,
          "title": "Steps",
          "description": "Number of inference steps (higher = better quality but slower)"
        },
        {
          "name": "fps",
          "type": {
            "type": "int"
          },
          "default": 10,
          "title": "Fps",
          "description": "Frames per second of the output video (total length is 25 frames)"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed will output the same video every time"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "motion_bucket_id",
        "fps"
      ]
    },
    {
      "title": "Haiper Image To Video",
      "description": "Transform images into hyper-realistic videos with Haiper 2.0. Experience industry-leading resolution, fluid motion, and rapid generation for stunning AI videos.\n    video, generation, hyper-realistic, motion, animation, image-to-video, img2vid\n\n    Use cases:\n    - Create cinematic animations\n    - Generate dynamic video content\n    - Transform static images into motion\n    - Produce high-resolution videos\n    - Create visual effects",
      "namespace": "fal.image_to_video",
      "node_type": "fal.image_to_video.HaiperImageToVideo",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The image to transform into a video"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "A description of the desired video motion and style"
        },
        {
          "name": "duration",
          "type": {
            "type": "enum",
            "values": [
              4,
              6
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.VideoDuration"
          },
          "default": 4,
          "title": "Duration",
          "description": "The duration of the generated video in seconds"
        },
        {
          "name": "prompt_enhancer",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Prompt Enhancer",
          "description": "Whether to use the model's prompt enhancer"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed will output the same video every time"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt",
        "duration"
      ]
    },
    {
      "title": "Hunyuan Video Image To Video",
      "description": "Hunyuan Video Image-to-Video generates videos from images with Tencent's model.\n    video, generation, hunyuan, tencent, image-to-video\n\n    Use cases:\n    - Create videos from still images\n    - Generate motion for photos\n    - Produce animated content\n    - Transform artwork into video\n    - Create video transitions",
      "namespace": "fal.image_to_video",
      "node_type": "fal.image_to_video.HunyuanVideoImageToVideo",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The image to transform into a video"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "A description of the desired video motion"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 30,
          "title": "Num Inference Steps",
          "description": "Number of inference steps",
          "min": 1.0
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for reproducible generation"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "Hunyuan Video V15 Image To Video",
      "description": "Hunyuan Video V1.5 Image-to-Video with improved quality and motion.\n    video, generation, hunyuan, v1.5, image-to-video\n\n    Use cases:\n    - Create high-quality video from images\n    - Generate smooth animations\n    - Produce professional video content\n    - Transform photos with motion\n    - Create video effects",
      "namespace": "fal.image_to_video",
      "node_type": "fal.image_to_video.HunyuanVideoV15ImageToVideo",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The image to transform into a video"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "A description of the desired video motion"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 30,
          "title": "Num Inference Steps",
          "description": "Number of inference steps",
          "min": 1.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 7.0,
          "title": "Guidance Scale",
          "description": "How closely to follow the prompt"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for reproducible generation"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "Kling O3 Image To Video",
      "description": "Transform images into cinematic videos using Kling Video O3 Standard with storyboard-first creation and character consistency.\n    video, generation, kling, o3, image-to-video, storyboard, img2vid\n\n    Use cases:\n    - Create story-driven video from images\n    - Generate character-consistent animations\n    - Produce multi-shot sequences from stills\n    - Create structured narrative videos\n    - Generate cinematic content with continuity",
      "namespace": "fal.image_to_video",
      "node_type": "fal.image_to_video.KlingO3ImageToVideo",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The starting image for the video"
        },
        {
          "name": "end_image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "End Image",
          "description": "Optional ending image for the video"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "A description of the desired video motion and style"
        },
        {
          "name": "duration",
          "type": {
            "type": "enum",
            "values": [
              "3",
              "4",
              "5",
              "6",
              "7",
              "8",
              "9",
              "10",
              "11",
              "12",
              "13",
              "14",
              "15"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.Kling3Duration"
          },
          "default": "5",
          "title": "Duration",
          "description": "The duration of the generated video in seconds (3-15)"
        },
        {
          "name": "generate_audio",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Generate Audio",
          "description": "Generate native audio for the video"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt",
        "duration"
      ]
    },
    {
      "title": "Kling O3 Pro Image To Video",
      "description": "Generate a video by taking a start frame and an end frame, animating the transition between them while following text-driven style and scene guidance (Kling O3 Pro).\n    video, generation, kling, o3, pro, image-to-video, start-end-frame, img2vid\n\n    Use cases:\n    - Animate between start and end keyframes\n    - Create guided transitions with text prompts\n    - Generate videos with optional end-frame constraint\n    - Multi-shot video with multi_prompt\n    - Style and scene-driven motion",
      "namespace": "fal.image_to_video",
      "node_type": "fal.image_to_video.KlingO3ProImageToVideo",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "URL of the start frame image"
        },
        {
          "name": "end_image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "End Image",
          "description": "Optional end frame image"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "Text prompt for video generation. Either prompt or multi_prompt must be provided."
        },
        {
          "name": "duration",
          "type": {
            "type": "enum",
            "values": [
              "3",
              "4",
              "5",
              "6",
              "7",
              "8",
              "9",
              "10",
              "11",
              "12",
              "13",
              "14",
              "15"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.Kling3Duration"
          },
          "default": "5",
          "title": "Duration",
          "description": "Video duration in seconds (3-15)"
        },
        {
          "name": "generate_audio",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Generate Audio",
          "description": "Whether to generate native audio for the video"
        },
        {
          "name": "multi_prompt",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "dict",
                "type_args": [
                  {
                    "type": "str"
                  },
                  {
                    "type": "str"
                  }
                ]
              }
            ]
          },
          "default": [],
          "title": "Multi Prompt",
          "description": "List of prompts for multi-shot video. Each item: {prompt, duration?}."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt",
        "duration"
      ]
    },
    {
      "title": "Kling O3 Pro Reference To Video",
      "description": "Generate premium videos with character consistency using Kling Video O3 Pro reference-to-video with enhanced quality.\n    video, generation, kling, o3, pro, reference-to-video, character-consistency, premium\n\n    Use cases:\n    - Create high-quality videos with consistent characters\n    - Generate professional story sequences\n    - Produce premium branded content\n    - Create broadcast-quality serialized content\n    - Generate professional character-driven narratives",
      "namespace": "fal.image_to_video",
      "node_type": "fal.image_to_video.KlingO3ProReferenceToVideo",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "A description of the desired video motion and style"
        },
        {
          "name": "start_image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Start Image",
          "description": "Optional starting image for the video"
        },
        {
          "name": "end_image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "End Image",
          "description": "Optional ending image for the video"
        },
        {
          "name": "reference_images",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "image"
              }
            ]
          },
          "default": [],
          "title": "Reference Images",
          "description": "Reference images for style/appearance (up to 4). Reference as @Image1, @Image2 in prompt"
        },
        {
          "name": "element_images",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "image"
              }
            ]
          },
          "default": [],
          "title": "Element Images",
          "description": "Character/element images for consistency. Reference as @Element1, @Element2 in prompt"
        },
        {
          "name": "duration",
          "type": {
            "type": "enum",
            "values": [
              "3",
              "4",
              "5",
              "6",
              "7",
              "8",
              "9",
              "10",
              "11",
              "12",
              "13",
              "14",
              "15"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.Kling3Duration"
          },
          "default": "5",
          "title": "Duration",
          "description": "The duration of the generated video in seconds (3-15)"
        },
        {
          "name": "aspect_ratio",
          "type": {
            "type": "enum",
            "values": [
              "16:9",
              "9:16",
              "1:1"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.Kling3AspectRatio"
          },
          "default": "16:9",
          "title": "Aspect Ratio",
          "description": "The aspect ratio of the generated video"
        },
        {
          "name": "generate_audio",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Generate Audio",
          "description": "Generate native audio for the video"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "reference_images",
        "duration"
      ]
    },
    {
      "title": "Kling O3 Reference To Video",
      "description": "Generate videos with character consistency using Kling Video O3 reference-to-video with reusable character elements.\n    video, generation, kling, o3, reference-to-video, character-consistency\n\n    Use cases:\n    - Create videos with consistent character appearances\n    - Generate story sequences with recurring characters\n    - Produce branded content with consistent subjects\n    - Create serialized video content\n    - Generate character-driven narratives",
      "namespace": "fal.image_to_video",
      "node_type": "fal.image_to_video.KlingO3ReferenceToVideo",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "A description of the desired video motion and style"
        },
        {
          "name": "start_image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Start Image",
          "description": "Optional starting image for the video"
        },
        {
          "name": "end_image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "End Image",
          "description": "Optional ending image for the video"
        },
        {
          "name": "reference_images",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "image"
              }
            ]
          },
          "default": [],
          "title": "Reference Images",
          "description": "Reference images for style/appearance (up to 4). Reference as @Image1, @Image2 in prompt"
        },
        {
          "name": "element_images",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "image"
              }
            ]
          },
          "default": [],
          "title": "Element Images",
          "description": "Character/element images for consistency. Reference as @Element1, @Element2 in prompt"
        },
        {
          "name": "duration",
          "type": {
            "type": "enum",
            "values": [
              "3",
              "4",
              "5",
              "6",
              "7",
              "8",
              "9",
              "10",
              "11",
              "12",
              "13",
              "14",
              "15"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.Kling3Duration"
          },
          "default": "5",
          "title": "Duration",
          "description": "The duration of the generated video in seconds (3-15)"
        },
        {
          "name": "aspect_ratio",
          "type": {
            "type": "enum",
            "values": [
              "16:9",
              "9:16",
              "1:1"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.Kling3AspectRatio"
          },
          "default": "16:9",
          "title": "Aspect Ratio",
          "description": "The aspect ratio of the generated video"
        },
        {
          "name": "generate_audio",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Generate Audio",
          "description": "Generate native audio for the video"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "reference_images",
        "duration"
      ]
    },
    {
      "title": "Kling V3 Image To Video",
      "description": "Transform images into high-quality videos using Kling Video 3.0 Standard with improved motion and realistic acting.\n    video, generation, kling, v3, image-to-video, animation, img2vid\n\n    Use cases:\n    - Animate still images into cinematic clips\n    - Create dynamic product showcase videos\n    - Generate motion graphics from static designs\n    - Transform artwork into video content\n    - Create engaging social media animations",
      "namespace": "fal.image_to_video",
      "node_type": "fal.image_to_video.KlingV3ImageToVideo",
      "properties": [
        {
          "name": "start_image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Start Image",
          "description": "The starting image for the video"
        },
        {
          "name": "end_image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "End Image",
          "description": "Optional ending image for the video"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "A description of the desired video motion and style"
        },
        {
          "name": "duration",
          "type": {
            "type": "enum",
            "values": [
              "3",
              "4",
              "5",
              "6",
              "7",
              "8",
              "9",
              "10",
              "11",
              "12",
              "13",
              "14",
              "15"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.Kling3Duration"
          },
          "default": "5",
          "title": "Duration",
          "description": "The duration of the generated video in seconds (3-15)"
        },
        {
          "name": "aspect_ratio",
          "type": {
            "type": "enum",
            "values": [
              "16:9",
              "9:16",
              "1:1"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.Kling3AspectRatio"
          },
          "default": "16:9",
          "title": "Aspect Ratio",
          "description": "The aspect ratio of the generated video"
        },
        {
          "name": "generate_audio",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Generate Audio",
          "description": "Generate native audio for the video (supports Chinese/English)"
        },
        {
          "name": "voice_ids",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "str"
              }
            ]
          },
          "default": [],
          "title": "Voice Ids",
          "description": "Voice IDs for audio. Reference in prompt with <<<voice_1>>> (max 2 voices)"
        },
        {
          "name": "reference_images",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "image"
              }
            ]
          },
          "default": [],
          "title": "Reference Images",
          "description": "Reference images for character/element consistency. Reference as @Element1, @Element2 in prompt"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "blur, distort, and low quality",
          "title": "Negative Prompt",
          "description": "What to avoid in the generated video"
        },
        {
          "name": "cfg_scale",
          "type": {
            "type": "float"
          },
          "default": 0.5,
          "title": "Cfg Scale",
          "description": "Classifier Free Guidance scale (0.0 to 1.0)",
          "min": 0.0,
          "max": 1.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "start_image",
        "prompt",
        "duration"
      ]
    },
    {
      "title": "Kling V3 Pro Image To Video",
      "description": "Transform images into premium quality videos using Kling Video 3.0 Pro with enhanced quality and performance.\n    video, generation, kling, v3, pro, image-to-video, premium, img2vid\n\n    Use cases:\n    - Create high-end video content from images\n    - Generate professional product animations\n    - Produce broadcast-quality video from stills\n    - Create premium visual narratives\n    - Generate detailed cinematic sequences",
      "namespace": "fal.image_to_video",
      "node_type": "fal.image_to_video.KlingV3ProImageToVideo",
      "properties": [
        {
          "name": "start_image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Start Image",
          "description": "The starting image for the video"
        },
        {
          "name": "end_image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "End Image",
          "description": "Optional ending image for the video"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "A description of the desired video motion and style"
        },
        {
          "name": "duration",
          "type": {
            "type": "enum",
            "values": [
              "3",
              "4",
              "5",
              "6",
              "7",
              "8",
              "9",
              "10",
              "11",
              "12",
              "13",
              "14",
              "15"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.Kling3Duration"
          },
          "default": "5",
          "title": "Duration",
          "description": "The duration of the generated video in seconds (3-15)"
        },
        {
          "name": "aspect_ratio",
          "type": {
            "type": "enum",
            "values": [
              "16:9",
              "9:16",
              "1:1"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.Kling3AspectRatio"
          },
          "default": "16:9",
          "title": "Aspect Ratio",
          "description": "The aspect ratio of the generated video"
        },
        {
          "name": "generate_audio",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Generate Audio",
          "description": "Generate native audio for the video (supports Chinese/English)"
        },
        {
          "name": "voice_ids",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "str"
              }
            ]
          },
          "default": [],
          "title": "Voice Ids",
          "description": "Voice IDs for audio. Reference in prompt with <<<voice_1>>> (max 2 voices)"
        },
        {
          "name": "reference_images",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "image"
              }
            ]
          },
          "default": [],
          "title": "Reference Images",
          "description": "Reference images for character/element consistency. Reference as @Element1, @Element2 in prompt"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "blur, distort, and low quality",
          "title": "Negative Prompt",
          "description": "What to avoid in the generated video"
        },
        {
          "name": "cfg_scale",
          "type": {
            "type": "float"
          },
          "default": 0.5,
          "title": "Cfg Scale",
          "description": "Classifier Free Guidance scale (0.0 to 1.0)",
          "min": 0.0,
          "max": 1.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "start_image",
        "prompt",
        "duration"
      ]
    },
    {
      "title": "Kling Video",
      "description": "Generate video clips from your images using Kling 1.6. Supports multiple durations and aspect ratios.\n    video, generation, animation, duration, aspect-ratio, img2vid, image-to-video\n\n    Use cases:\n    - Create custom video content\n    - Generate video animations\n    - Transform static images\n    - Produce motion graphics\n    - Create visual presentations",
      "namespace": "fal.image_to_video",
      "node_type": "fal.image_to_video.KlingVideo",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The image to transform into a video"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "A description of the desired video motion and style"
        },
        {
          "name": "duration",
          "type": {
            "type": "enum",
            "values": [
              "5",
              "10"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.KlingDuration"
          },
          "default": "5",
          "title": "Duration",
          "description": "The duration of the generated video"
        },
        {
          "name": "aspect_ratio",
          "type": {
            "type": "enum",
            "values": [
              "16:9",
              "9:16",
              "4:3",
              "3:4",
              "21:9",
              "9:21",
              "1:1"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.AspectRatio"
          },
          "default": "16:9",
          "title": "Aspect Ratio",
          "description": "The aspect ratio of the generated video frame"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt",
        "duration"
      ]
    },
    {
      "title": "Kling Video Pro",
      "description": "Generate video clips from your images using Kling 1.6 Pro. The professional version offers enhanced quality and performance compared to the standard version.\n    video, generation, professional, quality, performance, img2vid, image-to-video\n\n    Use cases:\n    - Create professional video content\n    - Generate high-quality animations\n    - Produce commercial video assets\n    - Create advanced motion graphics\n    - Generate premium visual content",
      "namespace": "fal.image_to_video",
      "node_type": "fal.image_to_video.KlingVideoPro",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The image to transform into a video"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "A description of the desired video motion and style"
        },
        {
          "name": "duration",
          "type": {
            "type": "enum",
            "values": [
              "5",
              "10"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.KlingDuration"
          },
          "default": "5",
          "title": "Duration",
          "description": "The duration of the generated video"
        },
        {
          "name": "aspect_ratio",
          "type": {
            "type": "enum",
            "values": [
              "16:9",
              "9:16",
              "4:3",
              "3:4",
              "21:9",
              "9:21",
              "1:1"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.AspectRatio"
          },
          "default": "16:9",
          "title": "Aspect Ratio",
          "description": "The aspect ratio of the generated video frame"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt",
        "duration"
      ]
    },
    {
      "title": "Kling Video V21 Pro",
      "description": "Kling Video V2.1 Pro Image-to-Video with enhanced quality and motion.\n    video, generation, kling, v2.1, pro, image-to-video\n\n    Use cases:\n    - Create professional video content\n    - Generate high-quality animations\n    - Produce cinematic video clips\n    - Transform images with smooth motion\n    - Create promotional videos",
      "namespace": "fal.image_to_video",
      "node_type": "fal.image_to_video.KlingVideoV21Pro",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The image to transform into a video"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "A description of the desired video motion"
        },
        {
          "name": "duration",
          "type": {
            "type": "enum",
            "values": [
              "5",
              "10"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.KlingDuration"
          },
          "default": "5",
          "title": "Duration",
          "description": "The duration of the generated video"
        },
        {
          "name": "aspect_ratio",
          "type": {
            "type": "enum",
            "values": [
              "16:9",
              "9:16",
              "4:3",
              "3:4",
              "21:9",
              "9:21",
              "1:1"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.AspectRatio"
          },
          "default": "16:9",
          "title": "Aspect Ratio",
          "description": "The aspect ratio of the generated video"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt",
        "duration"
      ]
    },
    {
      "title": "LTX-2 19B Audio to Video",
      "description": "Generate videos from audio with optional text or image prompts using the LTX-2 19B model. Supports advanced camera controls and high-quality video generation.\n    video, audio-to-video, generation, ltx, camera-control, audio-driven\n\n    Use cases:\n    - Generate talking head videos from audio\n    - Create music visualizations from audio tracks\n    - Produce audio-driven animations\n    - Generate synchronized video content from podcasts\n    - Create video content from voice recordings",
      "namespace": "fal.image_to_video",
      "node_type": "fal.image_to_video.LTX219BAudioToVideo",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate the video from"
        },
        {
          "name": "audio",
          "type": {
            "type": "audio"
          },
          "default": {
            "type": "audio",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Audio",
          "description": "The audio to generate the video from"
        },
        {
          "name": "image",
          "type": {
            "type": "image",
            "optional": true
          },
          "default": null,
          "title": "Image",
          "description": "Optional image to use as the first frame"
        },
        {
          "name": "match_audio_length",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Match Audio Length",
          "description": "Calculate frames based on audio duration and FPS"
        },
        {
          "name": "num_frames",
          "type": {
            "type": "int"
          },
          "default": 121,
          "title": "Num Frames",
          "description": "The number of frames to generate"
        },
        {
          "name": "video_size",
          "type": {
            "type": "enum",
            "values": [
              "auto",
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.LTXVideoSize"
          },
          "default": "landscape_4_3",
          "title": "Video Size",
          "description": "The size of the generated video"
        },
        {
          "name": "use_multiscale",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Use Multiscale",
          "description": "Use multi-scale generation for better coherence"
        },
        {
          "name": "fps",
          "type": {
            "type": "float"
          },
          "default": 25.0,
          "title": "Fps",
          "description": "The frames per second of the generated video"
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 3.0,
          "title": "Guidance Scale",
          "description": "The guidance scale to use"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 40,
          "title": "Num Inference Steps",
          "description": "The number of inference steps"
        },
        {
          "name": "acceleration",
          "type": {
            "type": "enum",
            "values": [
              "none",
              "regular",
              "high",
              "full"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.LTXAcceleration"
          },
          "default": "regular",
          "title": "Acceleration",
          "description": "The acceleration level to use"
        },
        {
          "name": "camera_lora",
          "type": {
            "type": "enum",
            "values": [
              "dolly_in",
              "dolly_out",
              "dolly_left",
              "dolly_right",
              "jib_up",
              "jib_down",
              "static",
              "none"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.LTXCameraLoRA"
          },
          "default": "none",
          "title": "Camera Lora",
          "description": "The camera LoRA for movement control"
        },
        {
          "name": "camera_lora_scale",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Camera Lora Scale",
          "description": "The scale of the camera LoRA"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "The negative prompt for video generation"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The seed for the random number generator"
        },
        {
          "name": "enable_prompt_expansion",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Enable Prompt Expansion",
          "description": "Whether to enable prompt expansion"
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "Whether to enable the safety checker"
        },
        {
          "name": "video_output_type",
          "type": {
            "type": "enum",
            "values": [
              "X264 (.mp4)",
              "VP9 (.webm)",
              "PRORES4444 (.mov)",
              "GIF (.gif)"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.LTXVideoOutputType"
          },
          "default": "X264 (.mp4)",
          "title": "Video Output Type",
          "description": "The output type of the generated video"
        },
        {
          "name": "video_quality",
          "type": {
            "type": "enum",
            "values": [
              "low",
              "medium",
              "high",
              "maximum"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.LTXVideoQuality"
          },
          "default": "high",
          "title": "Video Quality",
          "description": "The quality of the generated video"
        },
        {
          "name": "video_write_mode",
          "type": {
            "type": "enum",
            "values": [
              "fast",
              "balanced",
              "small"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.LTXVideoWriteMode"
          },
          "default": "balanced",
          "title": "Video Write Mode",
          "description": "The write mode of the generated video"
        },
        {
          "name": "image_strength",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Image Strength",
          "description": "The strength of the image for video generation"
        },
        {
          "name": "audio_strength",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Audio Strength",
          "description": "Audio conditioning strength"
        },
        {
          "name": "preprocess_audio",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Preprocess Audio",
          "description": "Whether to preprocess the audio"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "audio",
        "video_size"
      ]
    },
    {
      "title": "LTX-2 19B Distilled Audio to Video",
      "description": "Faster audio-to-video generation using the distilled LTX-2 19B model. Provides quicker video generation from audio with optional prompts.\n    video, audio-to-video, generation, ltx, distilled, fast\n\n    Use cases:\n    - Quick audio-driven video generation\n    - Fast talking head video creation\n    - Rapid music visualization\n    - Time-efficient audio-to-video conversion\n    - Fast prototype video generation from audio",
      "namespace": "fal.image_to_video",
      "node_type": "fal.image_to_video.LTX219BDistilledAudioToVideo",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate the video from"
        },
        {
          "name": "audio",
          "type": {
            "type": "audio"
          },
          "default": {
            "type": "audio",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Audio",
          "description": "The audio to generate the video from"
        },
        {
          "name": "image",
          "type": {
            "type": "image",
            "optional": true
          },
          "default": null,
          "title": "Image",
          "description": "Optional image to use as the first frame"
        },
        {
          "name": "match_audio_length",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Match Audio Length",
          "description": "Calculate frames based on audio duration and FPS"
        },
        {
          "name": "num_frames",
          "type": {
            "type": "int"
          },
          "default": 121,
          "title": "Num Frames",
          "description": "The number of frames to generate"
        },
        {
          "name": "video_size",
          "type": {
            "type": "enum",
            "values": [
              "auto",
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.LTXVideoSize"
          },
          "default": "landscape_4_3",
          "title": "Video Size",
          "description": "The size of the generated video"
        },
        {
          "name": "use_multiscale",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Use Multiscale",
          "description": "Use multi-scale generation for better coherence"
        },
        {
          "name": "fps",
          "type": {
            "type": "float"
          },
          "default": 25.0,
          "title": "Fps",
          "description": "The frames per second of the generated video"
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 3.0,
          "title": "Guidance Scale",
          "description": "The guidance scale to use"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 40,
          "title": "Num Inference Steps",
          "description": "The number of inference steps"
        },
        {
          "name": "acceleration",
          "type": {
            "type": "enum",
            "values": [
              "none",
              "regular",
              "high",
              "full"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.LTXAcceleration"
          },
          "default": "regular",
          "title": "Acceleration",
          "description": "The acceleration level to use"
        },
        {
          "name": "camera_lora",
          "type": {
            "type": "enum",
            "values": [
              "dolly_in",
              "dolly_out",
              "dolly_left",
              "dolly_right",
              "jib_up",
              "jib_down",
              "static",
              "none"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.LTXCameraLoRA"
          },
          "default": "none",
          "title": "Camera Lora",
          "description": "The camera LoRA for movement control"
        },
        {
          "name": "camera_lora_scale",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Camera Lora Scale",
          "description": "The scale of the camera LoRA"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "The negative prompt for video generation"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The seed for the random number generator"
        },
        {
          "name": "enable_prompt_expansion",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Enable Prompt Expansion",
          "description": "Whether to enable prompt expansion"
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "Whether to enable the safety checker"
        },
        {
          "name": "video_output_type",
          "type": {
            "type": "enum",
            "values": [
              "X264 (.mp4)",
              "VP9 (.webm)",
              "PRORES4444 (.mov)",
              "GIF (.gif)"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.LTXVideoOutputType"
          },
          "default": "X264 (.mp4)",
          "title": "Video Output Type",
          "description": "The output type of the generated video"
        },
        {
          "name": "video_quality",
          "type": {
            "type": "enum",
            "values": [
              "low",
              "medium",
              "high",
              "maximum"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.LTXVideoQuality"
          },
          "default": "high",
          "title": "Video Quality",
          "description": "The quality of the generated video"
        },
        {
          "name": "video_write_mode",
          "type": {
            "type": "enum",
            "values": [
              "fast",
              "balanced",
              "small"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.LTXVideoWriteMode"
          },
          "default": "balanced",
          "title": "Video Write Mode",
          "description": "The write mode of the generated video"
        },
        {
          "name": "image_strength",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Image Strength",
          "description": "The strength of the image for video generation"
        },
        {
          "name": "audio_strength",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Audio Strength",
          "description": "Audio conditioning strength"
        },
        {
          "name": "preprocess_audio",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Preprocess Audio",
          "description": "Whether to preprocess the audio"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "audio",
        "video_size"
      ]
    },
    {
      "title": "LTX219 BImage To Video",
      "description": "Generate video with audio from images using LTX-2 19B model. A state-of-the-art video generation model with camera motion control and multi-scale generation.\n    video, generation, ltx, ltx-2, image-to-video, motion-control, camera, audio\n\n    Use cases:\n    - Generate high-quality videos from images\n    - Create videos with synchronized audio\n    - Control camera movements with LoRA\n    - Produce professional video content\n    - Animate static images with fluid motion",
      "namespace": "fal.image_to_video",
      "node_type": "fal.image_to_video.LTX219BImageToVideo",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The image to generate the video from"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt describing the desired video motion and style"
        },
        {
          "name": "num_frames",
          "type": {
            "type": "int"
          },
          "default": 121,
          "title": "Num Frames",
          "description": "Number of frames to generate",
          "min": 1.0
        },
        {
          "name": "video_size",
          "type": {
            "type": "enum",
            "values": [
              "auto",
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.LtxVideoSize"
          },
          "default": "auto",
          "title": "Video Size",
          "description": "Size of the generated video"
        },
        {
          "name": "generate_audio",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Generate Audio",
          "description": "Whether to generate audio for the video"
        },
        {
          "name": "use_multiscale",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Use Multiscale",
          "description": "Use multi-scale generation for better coherence"
        },
        {
          "name": "fps",
          "type": {
            "type": "float"
          },
          "default": 25,
          "title": "Fps",
          "description": "Frames per second"
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 3,
          "title": "Guidance Scale",
          "description": "Guidance scale for generation"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 40,
          "title": "Num Inference Steps",
          "description": "Number of inference steps",
          "min": 1.0
        },
        {
          "name": "acceleration",
          "type": {
            "type": "enum",
            "values": [
              "none",
              "regular",
              "high",
              "full"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.LtxAcceleration"
          },
          "default": "regular",
          "title": "Acceleration",
          "description": "Acceleration level"
        },
        {
          "name": "camera_lora",
          "type": {
            "type": "enum",
            "values": [
              "dolly_in",
              "dolly_out",
              "dolly_left",
              "dolly_right",
              "jib_up",
              "jib_down",
              "static",
              "none"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.LtxCameraLora"
          },
          "default": "none",
          "title": "Camera Lora",
          "description": "Camera movement LoRA"
        },
        {
          "name": "camera_lora_scale",
          "type": {
            "type": "float"
          },
          "default": 1,
          "title": "Camera Lora Scale",
          "description": "Camera LoRA scale",
          "min": 0.0,
          "max": 1.0
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "blurry, out of focus, overexposed, underexposed, low contrast, washed out colors, excessive noise, grainy texture, poor lighting, flickering, motion blur",
          "title": "Negative Prompt",
          "description": "Negative prompt to avoid"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Random seed for reproducibility"
        },
        {
          "name": "enable_prompt_expansion",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Enable Prompt Expansion",
          "description": "Enable prompt expansion"
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "Enable safety checker"
        },
        {
          "name": "video_output_type",
          "type": {
            "type": "enum",
            "values": [
              "X264 (.mp4)",
              "VP9 (.webm)",
              "PRORES4444 (.mov)",
              "GIF (.gif)"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.LtxVideoOutputType"
          },
          "default": "X264 (.mp4)",
          "title": "Video Output Type",
          "description": "Output video format"
        },
        {
          "name": "video_quality",
          "type": {
            "type": "enum",
            "values": [
              "low",
              "medium",
              "high",
              "maximum"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.LtxVideoQuality"
          },
          "default": "high",
          "title": "Video Quality",
          "description": "Video quality"
        },
        {
          "name": "video_write_mode",
          "type": {
            "type": "enum",
            "values": [
              "fast",
              "balanced",
              "small"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.LtxVideoWriteMode"
          },
          "default": "balanced",
          "title": "Video Write Mode",
          "description": "Video write mode"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt",
        "generate_audio",
        "video_size"
      ]
    },
    {
      "title": "LTXVideo",
      "description": "Generate videos from images using LTX Video. Best results with 768x512 images and detailed, chronological descriptions of actions and scenes.\n    video, generation, chronological, scenes, actions, img2vid, image-to-video\n\n    Use cases:\n    - Create scene-based animations\n    - Generate sequential video content\n    - Produce narrative videos\n    - Create storyboard animations\n    - Generate action sequences",
      "namespace": "fal.image_to_video",
      "node_type": "fal.image_to_video.LTXVideo",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The image to transform into a video (768x512 recommended)"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "A detailed description of the desired video motion and style"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "low quality, worst quality, deformed, distorted, disfigured, motion smear, motion artifacts, fused fingers, bad anatomy, weird hand, ugly",
          "title": "Negative Prompt",
          "description": "What to avoid in the generated video"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 30,
          "title": "Num Inference Steps",
          "description": "Number of inference steps (higher = better quality but slower)"
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 3.0,
          "title": "Guidance Scale",
          "description": "How closely to follow the prompt (higher = more faithful)"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed will output the same video every time"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "Luma Dream Machine",
      "description": "Generate video clips from your images using Luma Dream Machine v1.5. Supports various aspect ratios and optional end-frame blending.\n    video, generation, animation, blending, aspect-ratio, img2vid, image-to-video\n\n    Use cases:\n    - Create seamless video loops\n    - Generate video transitions\n    - Transform images into animations\n    - Create motion graphics\n    - Produce video content",
      "namespace": "fal.image_to_video",
      "node_type": "fal.image_to_video.LumaDreamMachine",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The image to transform into a video"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "A description of the desired video motion and style"
        },
        {
          "name": "aspect_ratio",
          "type": {
            "type": "enum",
            "values": [
              "16:9",
              "9:16",
              "4:3",
              "3:4",
              "21:9",
              "9:21",
              "1:1"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.AspectRatio"
          },
          "default": "16:9",
          "title": "Aspect Ratio",
          "description": "The aspect ratio of the generated video"
        },
        {
          "name": "loop",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Loop",
          "description": "Whether the video should loop (end blends with beginning)"
        },
        {
          "name": "end_image",
          "type": {
            "type": "image",
            "optional": true
          },
          "default": null,
          "title": "End Image",
          "description": "Optional image to blend the end of the video with"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt",
        "aspect_ratio"
      ]
    },
    {
      "title": "Luma Ray 2 Flash Image To Video",
      "description": "Luma Ray 2 Flash Image-to-Video is a fast version for quick video generation.\n    video, generation, luma, ray2, flash, image-to-video, fast\n\n    Use cases:\n    - Quick video prototyping\n    - Rapid content creation\n    - Fast video iterations\n    - Real-time video generation\n    - Quick motion tests",
      "namespace": "fal.image_to_video",
      "node_type": "fal.image_to_video.LumaRay2FlashImageToVideo",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The image to transform into a video"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "A description of the desired video motion"
        },
        {
          "name": "aspect_ratio",
          "type": {
            "type": "enum",
            "values": [
              "16:9",
              "9:16",
              "4:3",
              "3:4",
              "21:9",
              "9:21",
              "1:1"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.AspectRatio"
          },
          "default": "16:9",
          "title": "Aspect Ratio",
          "description": "The aspect ratio of the generated video"
        },
        {
          "name": "resolution",
          "type": {
            "type": "enum",
            "values": [
              "540p",
              "720p",
              "1080p"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.LumaRay2Resolution"
          },
          "default": "540p",
          "title": "Resolution",
          "description": "The resolution of the generated video"
        },
        {
          "name": "duration",
          "type": {
            "type": "enum",
            "values": [
              "5s",
              "9s"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.LumaRay2Duration"
          },
          "default": "5s",
          "title": "Duration",
          "description": "The duration of the generated video"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for reproducible generation"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt",
        "aspect_ratio",
        "duration"
      ]
    },
    {
      "title": "Luma Ray 2 Image To Video",
      "description": "Luma Ray 2 Image-to-Video generates high-quality videos from images with improved motion.\n    video, generation, luma, ray2, image-to-video, img2vid\n\n    Use cases:\n    - Create cinematic video from images\n    - Generate smooth motion animations\n    - Produce high-quality video content\n    - Transform photos into videos\n    - Create professional video clips",
      "namespace": "fal.image_to_video",
      "node_type": "fal.image_to_video.LumaRay2ImageToVideo",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The image to transform into a video"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "A description of the desired video motion"
        },
        {
          "name": "aspect_ratio",
          "type": {
            "type": "enum",
            "values": [
              "16:9",
              "9:16",
              "4:3",
              "3:4",
              "21:9",
              "9:21",
              "1:1"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.AspectRatio"
          },
          "default": "16:9",
          "title": "Aspect Ratio",
          "description": "The aspect ratio of the generated video"
        },
        {
          "name": "loop",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Loop",
          "description": "Whether the video should loop"
        },
        {
          "name": "resolution",
          "type": {
            "type": "enum",
            "values": [
              "540p",
              "720p",
              "1080p"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.LumaRay2Resolution"
          },
          "default": "540p",
          "title": "Resolution",
          "description": "The resolution of the generated video"
        },
        {
          "name": "duration",
          "type": {
            "type": "enum",
            "values": [
              "5s",
              "9s"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.LumaRay2Duration"
          },
          "default": "5s",
          "title": "Duration",
          "description": "The duration of the generated video"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for reproducible generation"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt",
        "aspect_ratio",
        "duration"
      ]
    },
    {
      "title": "Mini Max Hailuo 02",
      "description": "Create videos from your images with MiniMax Hailuo-02 Standard. Choose the\n    clip length and optionally enhance prompts for sharper results.\n    video, generation, minimax, prompt-optimizer, img2vid, image-to-video\n\n    Use cases:\n    - Produce social media clips\n    - Generate cinematic sequences\n    - Visualize storyboards\n    - Create promotional videos\n    - Animate still graphics",
      "namespace": "fal.image_to_video",
      "node_type": "fal.image_to_video.MiniMaxHailuo02",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The image to transform into a video"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt describing the video"
        },
        {
          "name": "duration",
          "type": {
            "type": "enum",
            "values": [
              "6",
              "10"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.HailuoDuration"
          },
          "default": "6",
          "title": "Duration",
          "description": "The duration of the video in seconds. 10 seconds videos are not supported for 1080p resolution."
        },
        {
          "name": "prompt_optimizer",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Prompt Optimizer",
          "description": "Whether to use the model's prompt optimizer"
        },
        {
          "name": "resolution",
          "type": {
            "type": "enum",
            "values": [
              "512P",
              "768P"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.MiniMaxHailuoResolution"
          },
          "default": "768P",
          "title": "Resolution",
          "description": "The resolution of the generated video"
        },
        {
          "name": "end_image",
          "type": {
            "type": "image",
            "optional": true
          },
          "default": null,
          "title": "End Image",
          "description": "Optional image to use as the last frame"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt",
        "duration"
      ]
    },
    {
      "title": "Mini Max Hailuo 23 Image To Video",
      "description": "MiniMax Hailuo 2.3 Standard Image-to-Video with improved quality.\n    video, generation, minimax, hailuo, 2.3, image-to-video\n\n    Use cases:\n    - Create video from images\n    - Generate smooth animations\n    - Produce video content\n    - Transform photos into clips\n    - Create motion graphics",
      "namespace": "fal.image_to_video",
      "node_type": "fal.image_to_video.MiniMaxHailuo23ImageToVideo",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The image to transform into a video"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "A description of the desired video motion"
        },
        {
          "name": "duration",
          "type": {
            "type": "enum",
            "values": [
              "6",
              "10"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.HailuoDuration"
          },
          "default": "6",
          "title": "Duration",
          "description": "The duration of the video in seconds"
        },
        {
          "name": "prompt_optimizer",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Prompt Optimizer",
          "description": "Whether to use the prompt optimizer"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for reproducible generation"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt",
        "duration"
      ]
    },
    {
      "title": "Mini Max Video",
      "description": "Generate video clips from your images using MiniMax Video model. Transform static art into dynamic masterpieces with enhanced smoothness and vivid motion.\n    video, generation, art, motion, smoothness, img2vid, image-to-video\n\n    Use cases:\n    - Transform artwork into videos\n    - Create smooth animations\n    - Generate artistic motion content\n    - Produce dynamic visualizations\n    - Create video art pieces",
      "namespace": "fal.image_to_video",
      "node_type": "fal.image_to_video.MiniMaxVideo",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The image to transform into a video"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "A description of the desired video motion and style"
        },
        {
          "name": "prompt_optimizer",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Prompt Optimizer",
          "description": "Whether to use the model's prompt optimizer"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "Muse Talk",
      "description": "Real-time high quality audio-driven lip-syncing model. Animate a face video with custom audio for natural-looking speech animation.\n    video, lip-sync, animation, speech, real-time, wav2vid, audio-to-video\n\n    Use cases:\n    - Create lip-synced videos\n    - Generate speech animations\n    - Produce dubbed content\n    - Create animated presentations\n    - Generate voice-over videos",
      "namespace": "fal.image_to_video",
      "node_type": "fal.image_to_video.MuseTalk",
      "properties": [
        {
          "name": "video",
          "type": {
            "type": "video"
          },
          "default": {
            "type": "video",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null,
            "duration": null,
            "format": null
          },
          "title": "Video",
          "description": "URL of the source video to animate"
        },
        {
          "name": "audio",
          "type": {
            "type": "audio"
          },
          "default": {
            "type": "audio",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Audio",
          "description": "URL of the audio file to drive the lip sync"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "video",
        "audio"
      ]
    },
    {
      "title": "Pika V21 Image To Video",
      "description": "Pika V2.1 Image-to-Video generates videos from images with the Pika model.\n    video, generation, pika, v2.1, image-to-video\n\n    Use cases:\n    - Create video content from images\n    - Generate animated clips\n    - Produce motion graphics\n    - Transform still photos\n    - Create video effects",
      "namespace": "fal.image_to_video",
      "node_type": "fal.image_to_video.PikaV21ImageToVideo",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The image to transform into a video"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "A description of the desired video motion"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for reproducible generation"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "Pika V22 Image To Video",
      "description": "Pika V2.2 Image-to-Video generates creative videos from images.\n    video, generation, pika, v2.2, image-to-video, creative\n\n    Use cases:\n    - Create creative video content\n    - Generate artistic animations\n    - Produce stylized videos\n    - Transform images with effects\n    - Create unique video clips",
      "namespace": "fal.image_to_video",
      "node_type": "fal.image_to_video.PikaV22ImageToVideo",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The image to transform into a video"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "A description of the desired video motion"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "What to avoid in the generated video"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for reproducible generation"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "Pix Verse",
      "description": "Generate dynamic videos from images with PixVerse v4.5. Create high-quality motion\n    with detailed prompt control and advanced diffusion parameters.\n    video, generation, pixverse, motion, diffusion, img2vid, image-to-video\n\n    Use cases:\n    - Animate illustrations and photos\n    - Produce engaging social media clips\n    - Generate short cinematic shots\n    - Create motion for product showcases\n    - Experiment with creative video effects",
      "namespace": "fal.image_to_video",
      "node_type": "fal.image_to_video.PixVerse",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The image to transform into a video"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "A description of the desired video motion and style"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "low quality, worst quality, distorted, blurred",
          "title": "Negative Prompt",
          "description": "What to avoid in the generated video"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 50,
          "title": "Num Inference Steps",
          "description": "Number of inference steps (higher = better quality but slower)"
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 7.5,
          "title": "Guidance Scale",
          "description": "How closely to follow the prompt (higher = more faithful)"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed will output the same video every time"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt",
        "num_inference_steps"
      ]
    },
    {
      "title": "Pixverse V56 Image To Video",
      "description": "Generate high-quality videos from images with Pixverse v5.6.\n    video, generation, pixverse, v5.6, image-to-video, img2vid\n\n    Use cases:\n    - Animate photos into professional video clips\n    - Create dynamic product showcase videos\n    - Generate stylized video content from artwork\n    - Produce high-resolution social media animations\n    - Transform static images with various visual styles",
      "namespace": "fal.image_to_video",
      "node_type": "fal.image_to_video.PixverseV56ImageToVideo",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "Text prompt describing the desired video motion"
        },
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The image to transform into a video"
        },
        {
          "name": "resolution",
          "type": {
            "type": "enum",
            "values": [
              "360p",
              "540p",
              "720p",
              "1080p"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.PixverseV56Resolution"
          },
          "default": "720p",
          "title": "Resolution",
          "description": "The resolution quality of the output video"
        },
        {
          "name": "duration",
          "type": {
            "type": "enum",
            "values": [
              "5",
              "8",
              "10"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.PixverseV56Duration"
          },
          "default": "5",
          "title": "Duration",
          "description": "The duration of the generated video in seconds"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "What to avoid in the generated video"
        },
        {
          "name": "style",
          "type": {
            "type": "enum",
            "optional": true,
            "values": [
              "anime",
              "3d_animation",
              "clay",
              "comic",
              "cyberpunk"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.PixverseV56Style"
          },
          "default": null,
          "title": "Style",
          "description": "Optional visual style for the video"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Optional seed for reproducible generation"
        },
        {
          "name": "generate_audio_switch",
          "type": {
            "type": "bool",
            "optional": true
          },
          "default": null,
          "title": "Generate Audio Switch",
          "description": "Whether to generate audio for the video"
        },
        {
          "name": "thinking_type",
          "type": {
            "type": "enum",
            "optional": true,
            "values": [
              "enabled",
              "disabled",
              "auto"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.PixverseV56ThinkingType"
          },
          "default": null,
          "title": "Thinking Type",
          "description": "Thinking mode for video generation"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt",
        "resolution"
      ]
    },
    {
      "title": "Sad Talker",
      "description": "Generate talking face animations from a single image and audio file. Features configurable face model resolution and expression controls.\n    video, animation, face, talking, expression, img2vid, image-to-video, audio-to-video, wav2vid\n\n    Use cases:\n    - Create talking head videos\n    - Generate lip-sync animations\n    - Produce character animations\n    - Create video presentations\n    - Generate facial expressions",
      "namespace": "fal.image_to_video",
      "node_type": "fal.image_to_video.SadTalker",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The source image to animate"
        },
        {
          "name": "audio",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Audio",
          "description": "URL of the audio file to drive the animation"
        },
        {
          "name": "face_model_resolution",
          "type": {
            "type": "enum",
            "values": [
              "256",
              "512"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.FaceModelResolution"
          },
          "default": "256",
          "title": "Face Model Resolution",
          "description": "Resolution of the face model"
        },
        {
          "name": "expression_scale",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Expression Scale",
          "description": "Scale of the expression (1.0 = normal)"
        },
        {
          "name": "still_mode",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Still Mode",
          "description": "Reduce head motion (works with preprocess 'full')"
        },
        {
          "name": "preprocess",
          "type": {
            "type": "enum",
            "values": [
              "crop",
              "extcrop",
              "resize",
              "full",
              "extfull"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.PreprocessType"
          },
          "default": "crop",
          "title": "Preprocess",
          "description": "Type of image preprocessing to apply"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "audio",
        "face_model_resolution"
      ]
    },
    {
      "title": "Seedance V15 Pro Image To Video",
      "description": "ByteDance Seedance V1.5 Pro Image-to-Video with high-quality motion.\n    video, generation, bytedance, seedance, pro, image-to-video\n\n    Use cases:\n    - Create professional video content\n    - Generate high-quality animations\n    - Produce cinematic clips\n    - Transform images with motion\n    - Create promotional videos",
      "namespace": "fal.image_to_video",
      "node_type": "fal.image_to_video.SeedanceV15ProImageToVideo",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The image to transform into a video"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "A description of the desired video motion"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for reproducible generation"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "Sora 2 Image To Video",
      "description": "OpenAI Sora 2 Image-to-Video generates high-quality videos from images.\n    video, generation, openai, sora, sora2, image-to-video\n\n    Use cases:\n    - Create cinematic videos from images\n    - Generate realistic motion\n    - Produce professional video content\n    - Transform photos into movies\n    - Create video narratives",
      "namespace": "fal.image_to_video",
      "node_type": "fal.image_to_video.Sora2ImageToVideo",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The image to transform into a video"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "A description of the desired video motion"
        },
        {
          "name": "aspect_ratio",
          "type": {
            "type": "enum",
            "values": [
              "16:9",
              "9:16",
              "4:3",
              "3:4",
              "21:9",
              "9:21",
              "1:1"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.AspectRatio"
          },
          "default": "16:9",
          "title": "Aspect Ratio",
          "description": "The aspect ratio of the generated video"
        },
        {
          "name": "duration",
          "type": {
            "type": "enum",
            "values": [
              4,
              8,
              12
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.Sora2Duration"
          },
          "default": 4,
          "title": "Duration",
          "description": "Duration of the video in seconds"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for reproducible generation"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt",
        "duration"
      ]
    },
    {
      "title": "Stable Video",
      "description": "Generate short video clips from your images using Stable Video Diffusion v1.1. Features high-quality motion synthesis with configurable parameters.\n    video, generation, diffusion, motion, synthesis, img2vid, image-to-video\n\n    Use cases:\n    - Create stable video animations\n    - Generate motion content\n    - Transform images into videos\n    - Produce smooth transitions\n    - Create visual effects",
      "namespace": "fal.image_to_video",
      "node_type": "fal.image_to_video.StableVideo",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The image to transform into a video"
        },
        {
          "name": "motion_bucket_id",
          "type": {
            "type": "int"
          },
          "default": 127,
          "title": "Motion Bucket Id",
          "description": "Controls motion intensity (higher = more motion)"
        },
        {
          "name": "cond_aug",
          "type": {
            "type": "float"
          },
          "default": 0.02,
          "title": "Cond Aug",
          "description": "Amount of noise added to conditioning (higher = more motion)"
        },
        {
          "name": "fps",
          "type": {
            "type": "int"
          },
          "default": 25,
          "title": "Fps",
          "description": "Frames per second of the output video"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed will output the same video every time"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "motion_bucket_id",
        "fps"
      ]
    },
    {
      "title": "Veo 2",
      "description": "Generate videos from text prompts using Veo 2. Creates short clips with\n    optional control over duration and aspect ratio.\n    video, text-to-video, generation, prompt, veo2\n\n    Use cases:\n    - Produce cinematic video clips from descriptions\n    - Generate marketing or social media footage\n    - Create animated scenes from storyboards\n    - Experiment with visual concepts rapidly",
      "namespace": "fal.image_to_video",
      "node_type": "fal.image_to_video.Veo2",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate a video from"
        },
        {
          "name": "duration",
          "type": {
            "type": "enum",
            "values": [
              4,
              6
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.VideoDuration"
          },
          "default": 4,
          "title": "Duration",
          "description": "The duration of the generated video in seconds"
        },
        {
          "name": "aspect_ratio",
          "type": {
            "type": "enum",
            "values": [
              "16:9",
              "9:16",
              "4:3",
              "3:4",
              "21:9",
              "9:21",
              "1:1"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.AspectRatio"
          },
          "default": "16:9",
          "title": "Aspect Ratio",
          "description": "The aspect ratio of the generated video"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed will output the same video every time"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "duration",
        "aspect_ratio"
      ]
    },
    {
      "title": "Veo 2 Image To Video",
      "description": "Animate a single image into a Veo 2 video clip. Provides control over\n    duration and aspect ratio while following an optional prompt.\n    video, image-to-video, veo2, animation\n\n    Use cases:\n    - Bring still artwork to life\n    - Create dynamic social media posts\n    - Generate quick product showcase videos\n    - Produce animated storyboards",
      "namespace": "fal.image_to_video",
      "node_type": "fal.image_to_video.Veo2ImageToVideo",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The image to transform into a video"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "Optional description of the desired motion"
        },
        {
          "name": "duration",
          "type": {
            "type": "enum",
            "values": [
              4,
              6
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.VideoDuration"
          },
          "default": 4,
          "title": "Duration",
          "description": "The duration of the generated video in seconds"
        },
        {
          "name": "aspect_ratio",
          "type": {
            "type": "enum",
            "values": [
              "16:9",
              "9:16",
              "4:3",
              "3:4",
              "21:9",
              "9:21",
              "1:1"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.AspectRatio"
          },
          "default": "16:9",
          "title": "Aspect Ratio",
          "description": "The aspect ratio of the generated video"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed will output the same video every time"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt",
        "duration"
      ]
    },
    {
      "title": "Vidu Q2 Image To Video",
      "description": "Vidu Q2 Image-to-Video Turbo generates fast videos from images.\n    video, generation, vidu, q2, turbo, image-to-video, fast\n\n    Use cases:\n    - Quick video generation\n    - Rapid prototyping\n    - Fast content creation\n    - Quick motion tests\n    - Real-time video production",
      "namespace": "fal.image_to_video",
      "node_type": "fal.image_to_video.ViduQ2ImageToVideo",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The image to transform into a video"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "A description of the desired video motion"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for reproducible generation"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "Wan Flf 2 v",
      "description": "Generate short video clips from a single image using the WAN FLF2V model. This model converts a still image into an animated clip guided by a text prompt.\n    video, generation, animation, image-to-video, wan\n\n    Use cases:\n    - Animate still images into short clips\n    - Create dynamic content from artwork\n    - Produce promotional video snippets\n    - Generate visual effects for social posts\n    - Explore creative motion ideas",
      "namespace": "fal.image_to_video",
      "node_type": "fal.image_to_video.WanFlf2v",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The source image for video generation"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "Description of the desired motion and style"
        },
        {
          "name": "num_frames",
          "type": {
            "type": "int"
          },
          "default": 16,
          "title": "Num Frames",
          "description": "Number of frames to generate",
          "min": 1.0
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed will output the same video every time"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt",
        "num_frames"
      ]
    },
    {
      "title": "Any LLM",
      "description": "Use any large language model from a selected catalogue (powered by OpenRouter).\n    Supports various models including Claude 3, Gemini, Llama, and GPT-4.\n    llm, text, generation, ai, language\n\n    Use cases:\n    - Generate natural language responses\n    - Create conversational AI interactions\n    - Process and analyze text content\n    - Generate creative writing\n    - Assist with problem-solving tasks",
      "namespace": "fal.llm",
      "node_type": "fal.llm.AnyLLM",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to send to the language model"
        },
        {
          "name": "system_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "System Prompt",
          "description": "Optional system prompt to provide context or instructions"
        },
        {
          "name": "model",
          "type": {
            "type": "enum",
            "values": [
              "anthropic/claude-3.5-sonnet",
              "anthropic/claude-3-5-haiku",
              "anthropic/claude-3-haiku",
              "google/gemini-pro-1.5",
              "google/gemini-flash-1.5",
              "google/gemini-flash-1.5-8b",
              "meta-llama/llama-3.2-1b-instruct",
              "meta-llama/llama-3.2-3b-instruct",
              "meta-llama/llama-3.1-8b-instruct",
              "meta-llama/llama-3.1-70b-instruct",
              "openai/gpt-4o-mini",
              "openai/gpt-4o"
            ],
            "type_name": "nodetool.nodes.fal.llm.ModelEnum"
          },
          "default": "google/gemini-flash-1.5",
          "title": "Model",
          "description": "The language model to use for the completion"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "str"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "model",
        "system_prompt"
      ]
    },
    {
      "title": "Era 3D",
      "description": "Era3D creates multi-view consistent 3D models from images.\n    3d, generation, image-to-3d, era3d, multi-view\n\n    Use cases:\n    - Generate multi-view 3D models\n    - Create consistent 3D assets\n    - Produce 3D content with multiple views\n    - Generate detailed 3D models\n    - Create multi-view 3D for games",
      "namespace": "fal.model3d",
      "node_type": "fal.model3d.Era3D",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The image to convert to 3D"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 40,
          "title": "Num Inference Steps",
          "description": "Number of inference steps",
          "min": 10.0,
          "max": 100.0
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for reproducible generation"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "list"
          },
          "name": "mv_images"
        },
        {
          "type": {
            "type": "model_3d"
          },
          "name": "model"
        }
      ],
      "basic_fields": [
        "image"
      ]
    },
    {
      "title": "Hunyuan 3DV 2",
      "description": "Hunyuan3D V2 generates high-quality 3D models from images.\n    3d, generation, image-to-3d, hunyuan\n\n    Use cases:\n    - Generate detailed 3D models\n    - Create 3D assets from photos\n    - Produce high-quality 3D content\n    - Create 3D visualizations\n    - Generate 3D for productions",
      "namespace": "fal.model3d",
      "node_type": "fal.model3d.Hunyuan3DV2",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The image to convert to 3D"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 50,
          "title": "Num Inference Steps",
          "description": "Number of inference steps",
          "min": 1.0,
          "max": 100.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 2.0,
          "title": "Guidance Scale",
          "description": "Guidance scale for generation",
          "min": 1.0,
          "max": 10.0
        },
        {
          "name": "octree_resolution",
          "type": {
            "type": "int"
          },
          "default": 256,
          "title": "Octree Resolution",
          "description": "Octree resolution for 3D structure"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for reproducible generation"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "model_3d"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image"
      ]
    },
    {
      "title": "Trellis",
      "description": "Trellis generates 3D models from single images.\n    3d, generation, image-to-3d, trellis\n\n    Use cases:\n    - Generate 3D models from images\n    - Create 3D assets from photos\n    - Produce 3D content for games\n    - Create 3D visualizations\n    - Generate 3D for AR/VR",
      "namespace": "fal.model3d",
      "node_type": "fal.model3d.Trellis",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The image to convert to 3D"
        },
        {
          "name": "ss_guidance_strength",
          "type": {
            "type": "float"
          },
          "default": 7.5,
          "title": "Ss Guidance Strength",
          "description": "Guidance strength for sparse structure",
          "min": 0.0,
          "max": 20.0
        },
        {
          "name": "ss_sampling_steps",
          "type": {
            "type": "int"
          },
          "default": 12,
          "title": "Ss Sampling Steps",
          "description": "Sampling steps for sparse structure",
          "min": 1.0,
          "max": 50.0
        },
        {
          "name": "slat_guidance_strength",
          "type": {
            "type": "float"
          },
          "default": 3.0,
          "title": "Slat Guidance Strength",
          "description": "Guidance strength for structured latent",
          "min": 0.0,
          "max": 20.0
        },
        {
          "name": "slat_sampling_steps",
          "type": {
            "type": "int"
          },
          "default": 12,
          "title": "Slat Sampling Steps",
          "description": "Sampling steps for structured latent",
          "min": 1.0,
          "max": 50.0
        },
        {
          "name": "mesh_simplify",
          "type": {
            "type": "float"
          },
          "default": 0.95,
          "title": "Mesh Simplify",
          "description": "Mesh simplification ratio",
          "min": 0.9,
          "max": 0.98
        },
        {
          "name": "texture_size",
          "type": {
            "type": "enum",
            "values": [
              512,
              1024,
              2048
            ],
            "type_name": "nodetool.nodes.fal.model3d.TextureSizeEnum"
          },
          "default": 1024,
          "title": "Texture Size",
          "description": "Texture resolution"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for reproducible generation"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "model_3d"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "texture_size"
      ]
    },
    {
      "title": "Tripo SR",
      "description": "TripoSR generates 3D models from images with fast processing.\n    3d, generation, image-to-3d, triposr, fast\n\n    Use cases:\n    - Quick 3D model generation\n    - Rapid prototyping\n    - Create 3D assets from photos\n    - Generate 3D content quickly\n    - Fast 3D for AR/VR",
      "namespace": "fal.model3d",
      "node_type": "fal.model3d.TripoSR",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The input image to convert to 3D"
        },
        {
          "name": "foreground_ratio",
          "type": {
            "type": "float"
          },
          "default": 0.85,
          "title": "Foreground Ratio",
          "description": "Foreground ratio for cropping",
          "min": 0.5,
          "max": 1.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "model_3d"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image"
      ]
    },
    {
      "title": "DWPose",
      "description": "DWPose detects human poses and keypoints in images.\n    pose, detection, keypoints, human\n\n    Use cases:\n    - Detect human poses\n    - Extract body keypoints\n    - Enable pose-guided generation\n    - Analyze body positions\n    - Create pose references",
      "namespace": "fal.segmentation",
      "node_type": "fal.segmentation.DWPose",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The image to analyze"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "image"
        },
        {
          "type": {
            "type": "list"
          },
          "name": "poses"
        }
      ],
      "basic_fields": [
        "image"
      ]
    },
    {
      "title": "Image Preprocessor Depth Anything V2",
      "description": "Depth Anything V2 generates high-quality depth maps from images.\n    depth, preprocessor, depth-map, estimation\n\n    Use cases:\n    - Generate accurate depth maps\n    - Enable depth-aware effects\n    - Create 3D visualizations\n    - Prepare ControlNet inputs\n    - Analyze image depth",
      "namespace": "fal.segmentation",
      "node_type": "fal.segmentation.ImagePreprocessorDepthAnythingV2",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The image to process"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image"
      ]
    },
    {
      "title": "Marigold Depth",
      "description": "Marigold Depth generates high-quality monocular depth maps.\n    depth, marigold, depth-map, estimation\n\n    Use cases:\n    - Generate precise depth maps\n    - Create depth visualizations\n    - Enable depth-based effects\n    - Prepare 3D conversions\n    - Analyze scene depth",
      "namespace": "fal.segmentation",
      "node_type": "fal.segmentation.MarigoldDepth",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The image to process"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image"
      ]
    },
    {
      "title": "SAM2 Image",
      "description": "SAM 2 Image segments objects in images with high accuracy.\n    segmentation, sam, image, masks\n\n    Use cases:\n    - Segment objects in images\n    - Create object masks\n    - Enable object selection\n    - Generate cutouts\n    - Create selection masks",
      "namespace": "fal.segmentation",
      "node_type": "fal.segmentation.SAM2Image",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The image to segment"
        },
        {
          "name": "point_coords",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "list",
                "type_args": [
                  {
                    "type": "float"
                  }
                ]
              }
            ]
          },
          "default": [],
          "title": "Point Coords",
          "description": "Point coordinates for prompts [[x, y], ...]"
        },
        {
          "name": "point_labels",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "int"
              }
            ]
          },
          "default": [],
          "title": "Point Labels",
          "description": "Labels for points (1=foreground, 0=background)"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "list"
          },
          "name": "masks"
        }
      ],
      "basic_fields": [
        "image"
      ]
    },
    {
      "title": "SAM2 Video",
      "description": "SAM 2 Video segments and tracks objects across video frames.\n    segmentation, sam, video, tracking\n\n    Use cases:\n    - Track objects in videos\n    - Create video masks\n    - Segment moving objects\n    - Generate video cutouts\n    - Enable video object selection",
      "namespace": "fal.segmentation",
      "node_type": "fal.segmentation.SAM2Video",
      "properties": [
        {
          "name": "video",
          "type": {
            "type": "video"
          },
          "default": {
            "type": "video",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null,
            "duration": null,
            "format": null
          },
          "title": "Video",
          "description": "The video to segment"
        },
        {
          "name": "point_coords",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "list",
                "type_args": [
                  {
                    "type": "float"
                  }
                ]
              }
            ]
          },
          "default": [],
          "title": "Point Coords",
          "description": "Point coordinates for prompts [[x, y], ...]"
        },
        {
          "name": "point_labels",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "int"
              }
            ]
          },
          "default": [],
          "title": "Point Labels",
          "description": "Labels for points (1=foreground, 0=background)"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "str"
          },
          "name": "masks_video"
        }
      ],
      "basic_fields": [
        "video"
      ]
    },
    {
      "title": "SAM3 Image",
      "description": "SAM 3 Image provides advanced segmentation with improved accuracy.\n    segmentation, sam3, image, masks, advanced\n\n    Use cases:\n    - High-accuracy object segmentation\n    - Complex scene segmentation\n    - Precise mask generation\n    - Advanced object selection\n    - Detailed cutout creation",
      "namespace": "fal.segmentation",
      "node_type": "fal.segmentation.SAM3Image",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The image to segment"
        },
        {
          "name": "point_coords",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "list",
                "type_args": [
                  {
                    "type": "float"
                  }
                ]
              }
            ]
          },
          "default": [],
          "title": "Point Coords",
          "description": "Point coordinates for prompts [[x, y], ...]"
        },
        {
          "name": "point_labels",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "int"
              }
            ]
          },
          "default": [],
          "title": "Point Labels",
          "description": "Labels for points (1=foreground, 0=background)"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "list"
          },
          "name": "masks"
        }
      ],
      "basic_fields": [
        "image"
      ]
    },
    {
      "title": "Eleven Labs Scribe V2",
      "description": "ElevenLabs Scribe V2 is a state-of-the-art speech-to-text model with improved accuracy, word-level timestamps, and speaker identification.\n    speech, audio, transcription, scribe, elevenlabs, speech-to-text, audio-to-text, diarization\n\n    Use cases:\n    - Transcribe audio with high accuracy\n    - Generate subtitles with word-level timestamps\n    - Identify different speakers in conversations\n    - Support for 99 languages with biasing via keyterms\n    - Tag audio events like laughter and applause",
      "namespace": "fal.speech_to_text",
      "node_type": "fal.speech_to_text.ElevenLabsScribeV2",
      "properties": [
        {
          "name": "audio",
          "type": {
            "type": "audio"
          },
          "default": {
            "type": "audio",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Audio",
          "description": "The audio file to transcribe"
        },
        {
          "name": "language_code",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Language Code",
          "description": "Language code of the audio (e.g., 'eng', 'spa'). Auto-detected if empty"
        },
        {
          "name": "tag_audio_events",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Tag Audio Events",
          "description": "Whether to tag audio events like laughter, applause, etc."
        },
        {
          "name": "diarize",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Diarize",
          "description": "Whether to annotate who is speaking"
        },
        {
          "name": "keyterms",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "str"
              }
            ]
          },
          "default": null,
          "title": "Keyterms",
          "description": "Words or phrases to bias the model towards transcribing (up to 100, max 50 chars each)",
          "required": true
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "str"
          },
          "name": "text"
        },
        {
          "type": {
            "type": "str"
          },
          "name": "language_code"
        },
        {
          "type": {
            "type": "float"
          },
          "name": "language_probability"
        },
        {
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "dict"
              }
            ]
          },
          "name": "words"
        }
      ],
      "basic_fields": [
        "audio",
        "diarize",
        "language_code"
      ]
    },
    {
      "title": "Whisper",
      "description": "Whisper is a model for speech transcription and translation that can transcribe audio in multiple languages and optionally translate to English.\n    speech, audio, transcription, translation, transcribe, translate, multilingual, speech-to-text, audio-to-text\n\n    Use cases:\n    - Transcribe spoken content to text\n    - Translate speech to English\n    - Generate subtitles and captions\n    - Create text records of audio content\n    - Analyze multilingual audio content",
      "namespace": "fal.speech_to_text",
      "node_type": "fal.speech_to_text.Whisper",
      "properties": [
        {
          "name": "audio",
          "type": {
            "type": "audio"
          },
          "default": {
            "type": "audio",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Audio",
          "description": "The audio file to transcribe"
        },
        {
          "name": "task",
          "type": {
            "type": "enum",
            "values": [
              "transcribe",
              "translate"
            ],
            "type_name": "nodetool.nodes.fal.speech_to_text.TaskEnum"
          },
          "default": "transcribe",
          "title": "Task",
          "description": "Task to perform on the audio file"
        },
        {
          "name": "language",
          "type": {
            "type": "enum",
            "values": [
              "af",
              "am",
              "ar",
              "as",
              "az",
              "ba",
              "be",
              "bg",
              "bn",
              "bo",
              "br",
              "bs",
              "ca",
              "cs",
              "cy",
              "da",
              "de",
              "el",
              "en",
              "es",
              "et",
              "eu",
              "fa",
              "fi",
              "fo",
              "fr",
              "gl",
              "gu",
              "ha",
              "haw",
              "he",
              "hi",
              "hr",
              "ht",
              "hu",
              "hy",
              "id",
              "is",
              "it",
              "ja",
              "jw",
              "ka",
              "kk",
              "km",
              "kn",
              "ko",
              "la",
              "lb",
              "ln",
              "lo",
              "lt",
              "lv",
              "mg",
              "mi",
              "mk",
              "ml",
              "mn",
              "mr",
              "ms",
              "mt",
              "my",
              "ne",
              "nl",
              "nn",
              "no",
              "oc",
              "pa",
              "pl",
              "ps",
              "pt",
              "ro",
              "ru",
              "sa",
              "sd",
              "si",
              "sk",
              "sl",
              "sn",
              "so",
              "sq",
              "sr",
              "su",
              "sv",
              "sw",
              "ta",
              "te",
              "tg",
              "th",
              "tk",
              "tl",
              "tr",
              "tt",
              "uk",
              "ur",
              "uz",
              "vi",
              "yi",
              "yo",
              "yue",
              "zh"
            ],
            "type_name": "nodetool.nodes.fal.speech_to_text.LanguageEnum"
          },
          "default": "en",
          "title": "Language",
          "description": "Language of the audio file. If not set, will be auto-detected"
        },
        {
          "name": "diarize",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Diarize",
          "description": "Whether to perform speaker diarization"
        },
        {
          "name": "chunk_level",
          "type": {
            "type": "enum",
            "values": [
              "segment",
              "word"
            ],
            "type_name": "nodetool.nodes.fal.speech_to_text.ChunkLevelEnum"
          },
          "default": "segment",
          "title": "Chunk Level",
          "description": "Level of detail for timestamp chunks"
        },
        {
          "name": "num_speakers",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Speakers",
          "description": "Number of speakers in the audio. If not set, will be auto-detected",
          "min": 1.0,
          "max": 10.0
        },
        {
          "name": "batch_size",
          "type": {
            "type": "int"
          },
          "default": 64,
          "title": "Batch Size",
          "description": "Batch size for processing"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "Optional prompt to guide the transcription"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "str"
          },
          "name": "text"
        },
        {
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "dict"
              }
            ]
          },
          "name": "chunks"
        },
        {
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "str"
              }
            ]
          },
          "name": "inferred_languages"
        },
        {
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "dict"
              }
            ]
          },
          "name": "diarization_segments"
        }
      ],
      "basic_fields": [
        "audio",
        "task",
        "diarize"
      ]
    },
    {
      "title": "Chatterbox TTS",
      "description": "Chatterbox Text-to-Speech with conversational voice synthesis.\n    audio, tts, text-to-speech, chatterbox, conversational\n\n    Use cases:\n    - Generate conversational speech\n    - Create chat bot voices\n    - Produce dialogue audio\n    - Create interactive content\n    - Generate voice assistants",
      "namespace": "fal.text_to_audio",
      "node_type": "fal.text_to_audio.ChatterboxTTS",
      "properties": [
        {
          "name": "text",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Text",
          "description": "The text to convert to speech"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "audio"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "text"
      ]
    },
    {
      "title": "Demucs",
      "description": "Demucs separates audio tracks into stems (vocals, drums, bass, other).\n    audio, separation, stems, demucs\n\n    Use cases:\n    - Separate music into stems\n    - Extract vocals or instruments\n    - Create remix material\n    - Analyze music components\n    - Isolate specific tracks",
      "namespace": "fal.text_to_audio",
      "node_type": "fal.text_to_audio.Demucs",
      "properties": [
        {
          "name": "audio",
          "type": {
            "type": "audio"
          },
          "default": {
            "type": "audio",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Audio",
          "description": "The audio file to separate"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "audio"
          },
          "name": "vocals"
        },
        {
          "type": {
            "type": "audio"
          },
          "name": "drums"
        },
        {
          "type": {
            "type": "audio"
          },
          "name": "bass"
        },
        {
          "type": {
            "type": "audio"
          },
          "name": "other"
        }
      ],
      "basic_fields": [
        "audio"
      ]
    },
    {
      "title": "Dia TTS",
      "description": "Dia TTS generates natural speech with emotion and expression control.\n    audio, tts, text-to-speech, dia, expressive\n\n    Use cases:\n    - Generate expressive speech\n    - Create emotional voiceovers\n    - Produce dynamic audio content\n    - Create character voices\n    - Generate storytelling audio",
      "namespace": "fal.text_to_audio",
      "node_type": "fal.text_to_audio.DiaTTS",
      "properties": [
        {
          "name": "text",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Text",
          "description": "The text to convert to speech"
        },
        {
          "name": "voice",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Voice",
          "description": "The voice preset to use"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "audio"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "text"
      ]
    },
    {
      "title": "Eleven Labs Audio Isolation",
      "description": "ElevenLabs Audio Isolation separates vocals from audio tracks.\n    audio, isolation, separation, elevenlabs\n\n    Use cases:\n    - Extract vocals from music\n    - Remove background noise\n    - Isolate speech\n    - Create acapella tracks\n    - Clean audio recordings",
      "namespace": "fal.text_to_audio",
      "node_type": "fal.text_to_audio.ElevenLabsAudioIsolation",
      "properties": [
        {
          "name": "audio",
          "type": {
            "type": "audio"
          },
          "default": {
            "type": "audio",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Audio",
          "description": "The audio file to process"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "audio"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "audio"
      ]
    },
    {
      "title": "Eleven Labs Multilingual",
      "description": "ElevenLabs Multilingual V2 Text-to-Speech with support for 29 languages.\n    audio, tts, text-to-speech, elevenlabs, multilingual\n\n    Use cases:\n    - Generate speech in multiple languages\n    - Create localized content\n    - Produce multilingual voiceovers\n    - Create international audio\n    - Generate language learning content",
      "namespace": "fal.text_to_audio",
      "node_type": "fal.text_to_audio.ElevenLabsMultilingual",
      "properties": [
        {
          "name": "text",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Text",
          "description": "The text to convert to speech"
        },
        {
          "name": "voice_id",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Voice Id",
          "description": "The voice ID to use for synthesis"
        },
        {
          "name": "language_code",
          "type": {
            "type": "str"
          },
          "default": "en",
          "title": "Language Code",
          "description": "Language code (e.g., en, es, fr)"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "audio"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "text",
        "voice_id",
        "language_code"
      ]
    },
    {
      "title": "Eleven Labs Music",
      "description": "ElevenLabs Music generates music from text descriptions.\n    audio, music, generation, elevenlabs, creative\n\n    Use cases:\n    - Generate custom music tracks\n    - Create background music\n    - Produce jingles\n    - Create audio branding\n    - Generate ambient music",
      "namespace": "fal.text_to_audio",
      "node_type": "fal.text_to_audio.ElevenLabsMusic",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt describing the music to generate"
        },
        {
          "name": "duration",
          "type": {
            "type": "float"
          },
          "default": 30.0,
          "title": "Duration",
          "description": "Duration in seconds",
          "min": 1.0,
          "max": 120.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "audio"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "duration"
      ]
    },
    {
      "title": "Eleven Labs Sound Effects",
      "description": "ElevenLabs Sound Effects V2 generates sound effects from text descriptions.\n    audio, sound-effects, generation, elevenlabs\n\n    Use cases:\n    - Generate custom sound effects\n    - Create audio for videos\n    - Produce game audio\n    - Create ambient sounds\n    - Generate UI sounds",
      "namespace": "fal.text_to_audio",
      "node_type": "fal.text_to_audio.ElevenLabsSoundEffects",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt describing the sound effect"
        },
        {
          "name": "duration",
          "type": {
            "type": "float"
          },
          "default": 5.0,
          "title": "Duration",
          "description": "Duration in seconds",
          "min": 0.5,
          "max": 22.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "audio"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "duration"
      ]
    },
    {
      "title": "Eleven Labs TTSTurbo",
      "description": "ElevenLabs Turbo V2.5 Text-to-Speech for fast voice synthesis.\n    audio, tts, text-to-speech, elevenlabs, fast, turbo\n\n    Use cases:\n    - Quick voice generation\n    - Real-time speech synthesis\n    - Rapid prototyping\n    - Fast audio content\n    - Interactive applications",
      "namespace": "fal.text_to_audio",
      "node_type": "fal.text_to_audio.ElevenLabsTTSTurbo",
      "properties": [
        {
          "name": "text",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Text",
          "description": "The text to convert to speech"
        },
        {
          "name": "voice_id",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Voice Id",
          "description": "The voice ID to use for synthesis"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "audio"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "text",
        "voice_id"
      ]
    },
    {
      "title": "Eleven Labs TTSV3",
      "description": "ElevenLabs Eleven V3 Text-to-Speech with high-quality voice synthesis.\n    audio, tts, text-to-speech, elevenlabs, voice, synthesis\n\n    Use cases:\n    - Generate natural speech from text\n    - Create voiceovers\n    - Produce audio content\n    - Create audiobooks\n    - Generate voice notifications",
      "namespace": "fal.text_to_audio",
      "node_type": "fal.text_to_audio.ElevenLabsTTSV3",
      "properties": [
        {
          "name": "text",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Text",
          "description": "The text to convert to speech"
        },
        {
          "name": "voice_id",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Voice Id",
          "description": "The voice ID to use for synthesis"
        },
        {
          "name": "model_id",
          "type": {
            "type": "str"
          },
          "default": "eleven_multilingual_v2",
          "title": "Model Id",
          "description": "The model ID (e.g., eleven_multilingual_v2)"
        },
        {
          "name": "stability",
          "type": {
            "type": "float"
          },
          "default": 0.5,
          "title": "Stability",
          "description": "Voice stability",
          "min": 0.0,
          "max": 1.0
        },
        {
          "name": "similarity_boost",
          "type": {
            "type": "float"
          },
          "default": 0.75,
          "title": "Similarity Boost",
          "description": "Voice similarity boost",
          "min": 0.0,
          "max": 1.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "audio"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "text",
        "voice_id"
      ]
    },
    {
      "title": "F5 TTS",
      "description": "F5 TTS (Text-to-Speech) model for generating natural-sounding speech from text with voice cloning capabilities.\n    audio, tts, voice-cloning, speech, synthesis, text-to-speech, tts, text-to-audio\n\n    Use cases:\n    - Generate natural speech from text\n    - Clone and replicate voices\n    - Create custom voiceovers\n    - Produce multilingual speech content\n    - Generate personalized audio content",
      "namespace": "fal.text_to_audio",
      "node_type": "fal.text_to_audio.F5TTS",
      "properties": [
        {
          "name": "gen_text",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Gen Text",
          "description": "The text to be converted to speech"
        },
        {
          "name": "ref_audio_url",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Ref Audio Url",
          "description": "URL of the reference audio file to clone the voice from"
        },
        {
          "name": "ref_text",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Ref Text",
          "description": "Optional reference text. If not provided, ASR will be used"
        },
        {
          "name": "model_type",
          "type": {
            "type": "str"
          },
          "default": "F5-TTS",
          "title": "Model Type",
          "description": "Model type to use (F5-TTS or E2-TTS)"
        },
        {
          "name": "remove_silence",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Remove Silence",
          "description": "Whether to remove silence from the generated audio"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "audio"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "gen_text",
        "ref_audio_url",
        "model_type"
      ]
    },
    {
      "title": "Kokoro TTS",
      "description": "Kokoro American English Text-to-Speech with natural voice synthesis.\n    audio, tts, text-to-speech, kokoro, english\n\n    Use cases:\n    - Generate natural English speech\n    - Create voiceovers\n    - Produce audio content\n    - Create educational material\n    - Generate voice notifications",
      "namespace": "fal.text_to_audio",
      "node_type": "fal.text_to_audio.KokoroTTS",
      "properties": [
        {
          "name": "text",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Text",
          "description": "The text to convert to speech"
        },
        {
          "name": "voice",
          "type": {
            "type": "str"
          },
          "default": "af_sky",
          "title": "Voice",
          "description": "The voice to use"
        },
        {
          "name": "speed",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Speed",
          "description": "Speech speed multiplier",
          "min": 0.5,
          "max": 2.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "audio"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "text",
        "voice"
      ]
    },
    {
      "title": "MMAudio V2",
      "description": "MMAudio V2 generates synchronized audio given text inputs. It can generate sounds described by a prompt.\n    audio, generation, synthesis, text-to-audio, synchronization\n\n    Use cases:\n    - Generate synchronized audio from text descriptions\n    - Create custom sound effects\n    - Produce ambient soundscapes\n    - Generate audio for multimedia content\n    - Create sound design elements",
      "namespace": "fal.text_to_audio",
      "node_type": "fal.text_to_audio.MMAudioV2",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate the audio for"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "The negative prompt to avoid certain elements in the generated audio"
        },
        {
          "name": "num_steps",
          "type": {
            "type": "int"
          },
          "default": 25,
          "title": "Num Steps",
          "description": "The number of steps to generate the audio for",
          "min": 1.0
        },
        {
          "name": "duration",
          "type": {
            "type": "float"
          },
          "default": 8.0,
          "title": "Duration",
          "description": "The duration of the audio to generate in seconds",
          "min": 1.0
        },
        {
          "name": "cfg_strength",
          "type": {
            "type": "float"
          },
          "default": 4.5,
          "title": "Cfg Strength",
          "description": "The strength of Classifier Free Guidance"
        },
        {
          "name": "mask_away_clip",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Mask Away Clip",
          "description": "Whether to mask away the clip"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed will output the same audio every time"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "audio"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "duration",
        "num_steps"
      ]
    },
    {
      "title": "Mini Max Music",
      "description": "MiniMax Music generates music tracks from text descriptions.\n    audio, music, generation, minimax\n\n    Use cases:\n    - Generate custom music\n    - Create background tracks\n    - Produce audio content\n    - Create music for videos\n    - Generate jingles",
      "namespace": "fal.text_to_audio",
      "node_type": "fal.text_to_audio.MiniMaxMusic",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt describing the music to generate"
        },
        {
          "name": "reference_audio",
          "type": {
            "type": "audio"
          },
          "default": {
            "type": "audio",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Reference Audio",
          "description": "Reference audio for music generation"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "audio"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "reference_audio"
      ]
    },
    {
      "title": "Mini Max Speech 02HD",
      "description": "MiniMax Speech 02 HD generates high-quality speech synthesis.\n    audio, tts, text-to-speech, minimax, hd\n\n    Use cases:\n    - Generate HD quality speech\n    - Create professional audio\n    - Produce voiceovers\n    - Create content narration\n    - Generate announcements",
      "namespace": "fal.text_to_audio",
      "node_type": "fal.text_to_audio.MiniMaxSpeech02HD",
      "properties": [
        {
          "name": "text",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Text",
          "description": "The text to convert to speech"
        },
        {
          "name": "voice_id",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Voice Id",
          "description": "The voice ID to use"
        },
        {
          "name": "reference_audio_url",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Reference Audio Url",
          "description": "URL of reference audio for voice cloning"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "audio"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "text",
        "voice_id",
        "reference_audio_url"
      ]
    },
    {
      "title": "Nova SR",
      "description": "Nova SR enhances muffled 16 kHz speech audio into crystal-clear 48 kHz audio using super-resolution.\n    audio, enhancement, super-resolution, speech, upsampling, audio-to-audio, nova-sr\n\n    Use cases:\n    - Enhance low-quality speech recordings\n    - Upsample audio from 16kHz to 48kHz\n    - Improve audio clarity for voice content\n    - Prepare speech for downstream processing\n    - Recover details from compressed audio",
      "namespace": "fal.text_to_audio",
      "node_type": "fal.text_to_audio.NovaSR",
      "properties": [
        {
          "name": "audio",
          "type": {
            "type": "audio"
          },
          "default": {
            "type": "audio",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Audio",
          "description": "The audio file to enhance"
        },
        {
          "name": "audio_format",
          "type": {
            "type": "enum",
            "values": [
              "mp3",
              "aac",
              "m4a",
              "ogg",
              "opus",
              "flac",
              "wav"
            ],
            "type_name": "nodetool.nodes.fal.text_to_audio.AudioFormatEnum"
          },
          "default": "mp3",
          "title": "Audio Format",
          "description": "Output audio format"
        },
        {
          "name": "bitrate",
          "type": {
            "type": "str"
          },
          "default": "192k",
          "title": "Bitrate",
          "description": "Output audio bitrate"
        },
        {
          "name": "sync_mode",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Sync Mode",
          "description": "If True, media returned as data URI"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "audio"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "audio",
        "audio_format",
        "bitrate"
      ]
    },
    {
      "title": "Orpheus TTS",
      "description": "Orpheus TTS generates high-quality speech with natural prosody.\n    audio, tts, text-to-speech, orpheus, natural\n\n    Use cases:\n    - Generate natural-sounding speech\n    - Create professional voiceovers\n    - Produce high-quality audio\n    - Create audiobooks\n    - Generate podcast content",
      "namespace": "fal.text_to_audio",
      "node_type": "fal.text_to_audio.OrpheusTTS",
      "properties": [
        {
          "name": "text",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Text",
          "description": "The text to convert to speech"
        },
        {
          "name": "voice",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Voice",
          "description": "The voice to use"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "audio"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "text"
      ]
    },
    {
      "title": "PlayAI Dialog TTS",
      "description": "PlayAI Dialog TTS generates speech for multi speaker dialogs.\n    audio, tts, dialog, speech, synthesis\n\n    Use cases:\n    - Generate interactive conversations\n    - Create voice overs with multiple characters\n    - Produce spoken dialogs for games\n    - Synthesize narration with distinct voices\n    - Prototype conversational audio",
      "namespace": "fal.text_to_audio",
      "node_type": "fal.text_to_audio.PlayAITTSDialog",
      "properties": [
        {
          "name": "text",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Text",
          "description": "Text to convert into speech"
        },
        {
          "name": "voice",
          "type": {
            "type": "str"
          },
          "default": "nova",
          "title": "Voice",
          "description": "Voice preset to use for the spoken dialog"
        },
        {
          "name": "speed",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Speed",
          "description": "Playback speed of the generated audio",
          "min": 0.5,
          "max": 2.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "audio"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "text",
        "voice"
      ]
    },
    {
      "title": "Qwen 3 Clone Voice 0.6B",
      "description": "Clone a voice from an audio sample using the efficient 0.6B model. Creates a speaker embedding for fast voice cloning.\n    tts, voice-cloning, speaker-embedding, fast, qwen\n\n    Use cases:\n    - Quick voice cloning from audio samples\n    - Create lightweight speaker embeddings\n    - Generate fast voice profiles\n    - Clone voices for real-time applications\n    - Create efficient voice profiles",
      "namespace": "fal.text_to_audio",
      "node_type": "fal.text_to_audio.Qwen3CloneVoice06B",
      "properties": [
        {
          "name": "audio",
          "type": {
            "type": "audio"
          },
          "default": {
            "type": "audio",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Audio",
          "description": "Reference audio file used for voice cloning"
        },
        {
          "name": "reference_text",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Reference Text",
          "description": "Optional reference text that corresponds to the audio sample"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "str"
          },
          "name": "speaker_embedding_url"
        }
      ],
      "basic_fields": [
        "audio",
        "reference_text"
      ]
    },
    {
      "title": "Qwen 3 Clone Voice 1.7B",
      "description": "Clone a voice from an audio sample for text-to-speech synthesis. Creates a speaker embedding that can be used with other Qwen 3 TTS models.\n    tts, voice-cloning, speaker-embedding, voice-synthesis, qwen\n\n    Use cases:\n    - Clone custom voices from audio samples\n    - Create personalized text-to-speech voices\n    - Preserve voice characteristics for content creation\n    - Generate speaker embeddings for consistent voices\n    - Create voice profiles for character consistency",
      "namespace": "fal.text_to_audio",
      "node_type": "fal.text_to_audio.Qwen3CloneVoice17B",
      "properties": [
        {
          "name": "audio",
          "type": {
            "type": "audio"
          },
          "default": {
            "type": "audio",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Audio",
          "description": "Reference audio file used for voice cloning"
        },
        {
          "name": "reference_text",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Reference Text",
          "description": "Optional reference text that corresponds to the audio sample"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "str"
          },
          "name": "speaker_embedding_url"
        }
      ],
      "basic_fields": [
        "audio",
        "reference_text"
      ]
    },
    {
      "title": "Qwen 3 TTS 0.6B",
      "description": "Efficient text-to-speech synthesis with the lighter Qwen 3 TTS 0.6B model. Provides fast speech generation with multiple voice options.\n    tts, text-to-speech, voice, synthesis, fast, qwen\n\n    Use cases:\n    - Generate quick speech output from text\n    - Create fast voiceovers for applications\n    - Produce audio content efficiently\n    - Generate speech for real-time applications\n    - Create lightweight audio content",
      "namespace": "fal.text_to_audio",
      "node_type": "fal.text_to_audio.Qwen3TTS06B",
      "properties": [
        {
          "name": "text",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Text",
          "description": "The text to be converted to speech"
        },
        {
          "name": "voice",
          "type": {
            "type": "enum",
            "values": [
              "Vivian",
              "Serena",
              "Uncle_Fu",
              "Dylan",
              "Eric",
              "Ryan",
              "Aiden",
              "Ono_Anna",
              "Sohee"
            ],
            "type_name": "nodetool.nodes.fal.text_to_audio.Qwen3Voice"
          },
          "default": "Vivian",
          "title": "Voice",
          "description": "The voice to be used for speech synthesis"
        },
        {
          "name": "language",
          "type": {
            "type": "enum",
            "values": [
              "Auto",
              "English",
              "Chinese",
              "Spanish",
              "French",
              "German",
              "Italian",
              "Japanese",
              "Korean",
              "Portuguese",
              "Russian"
            ],
            "type_name": "nodetool.nodes.fal.text_to_audio.Qwen3Language"
          },
          "default": "Auto",
          "title": "Language",
          "description": "The language of the voice"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "Optional prompt to guide the style of the generated speech"
        },
        {
          "name": "speaker_voice_embedding_file_url",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Speaker Voice Embedding File Url",
          "description": "URL to a speaker embedding file from clone-voice endpoint"
        },
        {
          "name": "reference_text",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Reference Text",
          "description": "Optional reference text used when creating the speaker embedding"
        },
        {
          "name": "top_k",
          "type": {
            "type": "int"
          },
          "default": 50,
          "title": "Top K",
          "description": "Top-k sampling parameter"
        },
        {
          "name": "top_p",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Top P",
          "description": "Top-p sampling parameter"
        },
        {
          "name": "temperature",
          "type": {
            "type": "float"
          },
          "default": 0.9,
          "title": "Temperature",
          "description": "Sampling temperature; higher => more random"
        },
        {
          "name": "repetition_penalty",
          "type": {
            "type": "float"
          },
          "default": 1.05,
          "title": "Repetition Penalty",
          "description": "Penalty to reduce repeated tokens/codes"
        },
        {
          "name": "max_new_tokens",
          "type": {
            "type": "int"
          },
          "default": 200,
          "title": "Max New Tokens",
          "description": "Maximum number of new codec tokens to generate"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "audio"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "text",
        "voice",
        "language"
      ]
    },
    {
      "title": "Qwen 3 TTS 1.7B",
      "description": "High-quality text-to-speech synthesis with multiple voice options and language support. Uses the Qwen 3 TTS 1.7B model for natural-sounding speech generation.\n    tts, text-to-speech, voice, synthesis, multilingual, qwen\n\n    Use cases:\n    - Generate natural-sounding speech from text\n    - Create voiceovers in multiple languages\n    - Produce audio content with custom voice characteristics\n    - Generate speech with specific emotional tones\n    - Create multilingual audio content",
      "namespace": "fal.text_to_audio",
      "node_type": "fal.text_to_audio.Qwen3TTS17B",
      "properties": [
        {
          "name": "text",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Text",
          "description": "The text to be converted to speech"
        },
        {
          "name": "voice",
          "type": {
            "type": "enum",
            "values": [
              "Vivian",
              "Serena",
              "Uncle_Fu",
              "Dylan",
              "Eric",
              "Ryan",
              "Aiden",
              "Ono_Anna",
              "Sohee"
            ],
            "type_name": "nodetool.nodes.fal.text_to_audio.Qwen3Voice"
          },
          "default": "Vivian",
          "title": "Voice",
          "description": "The voice to be used for speech synthesis"
        },
        {
          "name": "language",
          "type": {
            "type": "enum",
            "values": [
              "Auto",
              "English",
              "Chinese",
              "Spanish",
              "French",
              "German",
              "Italian",
              "Japanese",
              "Korean",
              "Portuguese",
              "Russian"
            ],
            "type_name": "nodetool.nodes.fal.text_to_audio.Qwen3Language"
          },
          "default": "Auto",
          "title": "Language",
          "description": "The language of the voice"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "Optional prompt to guide the style of the generated speech"
        },
        {
          "name": "speaker_voice_embedding_file_url",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Speaker Voice Embedding File Url",
          "description": "URL to a speaker embedding file from clone-voice endpoint"
        },
        {
          "name": "reference_text",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Reference Text",
          "description": "Optional reference text used when creating the speaker embedding"
        },
        {
          "name": "top_k",
          "type": {
            "type": "int"
          },
          "default": 50,
          "title": "Top K",
          "description": "Top-k sampling parameter"
        },
        {
          "name": "top_p",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Top P",
          "description": "Top-p sampling parameter"
        },
        {
          "name": "temperature",
          "type": {
            "type": "float"
          },
          "default": 0.9,
          "title": "Temperature",
          "description": "Sampling temperature; higher => more random"
        },
        {
          "name": "repetition_penalty",
          "type": {
            "type": "float"
          },
          "default": 1.05,
          "title": "Repetition Penalty",
          "description": "Penalty to reduce repeated tokens/codes"
        },
        {
          "name": "max_new_tokens",
          "type": {
            "type": "int"
          },
          "default": 200,
          "title": "Max New Tokens",
          "description": "Maximum number of new codec tokens to generate"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "audio"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "text",
        "voice",
        "language"
      ]
    },
    {
      "title": "Qwen 3 Voice Design 1.7B",
      "description": "Design custom voice styles and emotions using text prompts. Create expressive speech with specific tones and characteristics using the 1.7B model.\n    tts, text-to-speech, voice-design, emotion, synthesis, qwen\n\n    Use cases:\n    - Create speech with specific emotional characteristics\n    - Design custom voice styles for creative content\n    - Generate expressive voiceovers with nuanced tones\n    - Produce character voices with distinct personalities\n    - Create contextually appropriate speech delivery",
      "namespace": "fal.text_to_audio",
      "node_type": "fal.text_to_audio.Qwen3VoiceDesign17B",
      "properties": [
        {
          "name": "text",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Text",
          "description": "The text to be converted to speech"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "Prompt to guide the style and emotion of the generated speech"
        },
        {
          "name": "language",
          "type": {
            "type": "enum",
            "values": [
              "Auto",
              "English",
              "Chinese",
              "Spanish",
              "French",
              "German",
              "Italian",
              "Japanese",
              "Korean",
              "Portuguese",
              "Russian"
            ],
            "type_name": "nodetool.nodes.fal.text_to_audio.Qwen3Language"
          },
          "default": "Auto",
          "title": "Language",
          "description": "The language of the voice to be designed"
        },
        {
          "name": "top_k",
          "type": {
            "type": "int"
          },
          "default": 50,
          "title": "Top K",
          "description": "Top-k sampling parameter"
        },
        {
          "name": "top_p",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Top P",
          "description": "Top-p sampling parameter"
        },
        {
          "name": "temperature",
          "type": {
            "type": "float"
          },
          "default": 0.9,
          "title": "Temperature",
          "description": "Sampling temperature; higher => more random"
        },
        {
          "name": "repetition_penalty",
          "type": {
            "type": "float"
          },
          "default": 1.05,
          "title": "Repetition Penalty",
          "description": "Penalty to reduce repeated tokens/codes"
        },
        {
          "name": "max_new_tokens",
          "type": {
            "type": "int"
          },
          "default": 200,
          "title": "Max New Tokens",
          "description": "Maximum number of new codec tokens to generate"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "audio"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "text",
        "prompt",
        "language"
      ]
    },
    {
      "title": "Stable Audio",
      "description": "Stable Audio generates audio from text prompts. Open source text-to-audio model from fal.ai.\n    audio, generation, synthesis, text-to-audio, open-source\n\n    Use cases:\n    - Generate custom audio content from text\n    - Create background music and sounds\n    - Produce audio assets for projects\n    - Generate sound effects\n    - Create experimental audio content",
      "namespace": "fal.text_to_audio",
      "node_type": "fal.text_to_audio.StableAudio",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate the audio from"
        },
        {
          "name": "seconds_start",
          "type": {
            "type": "int"
          },
          "default": 0,
          "title": "Seconds Start",
          "description": "The start point of the audio clip to generate"
        },
        {
          "name": "seconds_total",
          "type": {
            "type": "int"
          },
          "default": 30,
          "title": "Seconds Total",
          "description": "The duration of the audio clip to generate in seconds"
        },
        {
          "name": "steps",
          "type": {
            "type": "int"
          },
          "default": 100,
          "title": "Steps",
          "description": "The number of steps to denoise the audio for"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "audio"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "seconds_total",
        "steps"
      ]
    },
    {
      "title": "Aura Flow V03",
      "description": "AuraFlow v0.3 is an open-source flow-based text-to-image generation model that achieves state-of-the-art results on GenEval.\n    image, generation, flow-based, text-to-image, txt2img\n\n    Use cases:\n    - Generate high-quality images\n    - Create artistic visualizations",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.AuraFlowV03",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "The number of images to generate",
          "min": 1.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 3.5,
          "title": "Guidance Scale",
          "description": "Classifier free guidance scale"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 50,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to take",
          "min": 1.0
        },
        {
          "name": "expand_prompt",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Expand Prompt",
          "description": "Whether to perform prompt expansion (recommended)"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The seed to use for generating images"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "guidance_scale",
        "num_inference_steps"
      ]
    },
    {
      "title": "Bria V1",
      "description": "Bria's Text-to-Image model, trained exclusively on licensed data for safe and risk-free commercial use.\n    Features exceptional image quality and commercial licensing safety.",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.BriaV1",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "The negative prompt to avoid certain elements in the generated image"
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 4,
          "title": "Num Images",
          "description": "How many images to generate. When using guidance, value is set to 1",
          "min": 1.0
        },
        {
          "name": "aspect_ratio",
          "type": {
            "type": "enum",
            "values": [
              "10:16",
              "16:10",
              "9:16",
              "16:9",
              "4:3",
              "3:4",
              "1:1",
              "1:3",
              "3:1",
              "3:2",
              "2:3",
              "4:5",
              "5:4"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.AspectRatio"
          },
          "default": "1:1",
          "title": "Aspect Ratio",
          "description": "The aspect ratio of the image. Ignored when guidance is used"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 30,
          "title": "Num Inference Steps",
          "description": "The number of iterations for refining the generated image",
          "min": 1.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 5.0,
          "title": "Guidance Scale",
          "description": "How closely the model should stick to your prompt (CFG scale)"
        },
        {
          "name": "prompt_enhancement",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Prompt Enhancement",
          "description": "When true, enhances the prompt with more descriptive variations"
        },
        {
          "name": "medium",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Medium",
          "description": "Optional medium specification ('photography' or 'art')"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed and prompt will output the same image every time"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "negative_prompt",
        "aspect_ratio"
      ]
    },
    {
      "title": "Bria V1 Fast",
      "description": "Bria's Text-to-Image model with perfect harmony of latency and quality.\n    Trained exclusively on licensed data for safe and risk-free commercial use.\n    Features faster inference times while maintaining high image quality.",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.BriaV1Fast",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "The negative prompt to avoid certain elements in the generated image"
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 4,
          "title": "Num Images",
          "description": "How many images to generate. When using guidance, value is set to 1",
          "min": 1.0
        },
        {
          "name": "aspect_ratio",
          "type": {
            "type": "enum",
            "values": [
              "10:16",
              "16:10",
              "9:16",
              "16:9",
              "4:3",
              "3:4",
              "1:1",
              "1:3",
              "3:1",
              "3:2",
              "2:3",
              "4:5",
              "5:4"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.AspectRatio"
          },
          "default": "1:1",
          "title": "Aspect Ratio",
          "description": "The aspect ratio of the image. Ignored when guidance is used"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 8,
          "title": "Num Inference Steps",
          "description": "The number of iterations for refining the generated image",
          "min": 1.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 5.0,
          "title": "Guidance Scale",
          "description": "How closely the model should stick to your prompt (CFG scale)"
        },
        {
          "name": "prompt_enhancement",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Prompt Enhancement",
          "description": "When true, enhances the prompt with more descriptive variations"
        },
        {
          "name": "medium",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Medium",
          "description": "Optional medium specification ('photography' or 'art')"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed and prompt will output the same image every time"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "negative_prompt",
        "aspect_ratio"
      ]
    },
    {
      "title": "Bria V1 HD",
      "description": "Bria's Text-to-Image model for HD images. Trained exclusively on licensed data for safe and risk-free commercial use. Features exceptional image quality and commercial licensing safety.\n    image, generation, hd, text-to-image, txt2img\n\n    Use cases:\n    - Create commercial marketing materials\n    - Generate licensed artwork\n    - Produce high-definition visuals\n    - Design professional content\n    - Create legally safe visual assets",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.BriaV1HD",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "The negative prompt to avoid certain elements in the generated image"
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 4,
          "title": "Num Images",
          "description": "How many images to generate. When using guidance, value is set to 1",
          "min": 1.0
        },
        {
          "name": "aspect_ratio",
          "type": {
            "type": "enum",
            "values": [
              "10:16",
              "16:10",
              "9:16",
              "16:9",
              "4:3",
              "3:4",
              "1:1",
              "1:3",
              "3:1",
              "3:2",
              "2:3",
              "4:5",
              "5:4"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.AspectRatio"
          },
          "default": "1:1",
          "title": "Aspect Ratio",
          "description": "The aspect ratio of the image. Ignored when guidance is used"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 30,
          "title": "Num Inference Steps",
          "description": "The number of iterations for refining the generated image",
          "min": 1.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 5.0,
          "title": "Guidance Scale",
          "description": "How closely the model should stick to your prompt (CFG scale)"
        },
        {
          "name": "prompt_enhancement",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Prompt Enhancement",
          "description": "When true, enhances the prompt with more descriptive variations"
        },
        {
          "name": "medium",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Medium",
          "description": "Optional medium specification ('photography' or 'art')"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The seed to use for generating images"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "negative_prompt",
        "aspect_ratio"
      ]
    },
    {
      "title": "Cog View 4",
      "description": "CogView4 is a powerful text-to-image model with strong understanding and generation capabilities.\n    image, generation, cogview, text-to-image, txt2img, ai\n\n    Use cases:\n    - Generate creative images from descriptions\n    - Create concept art\n    - Design visual content\n    - Produce illustrations\n    - Create artistic images",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.CogView4",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "What to avoid in the generated image"
        },
        {
          "name": "image_size",
          "type": {
            "type": "enum",
            "values": [
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
          },
          "default": "square_hd",
          "title": "Image Size",
          "description": "The size of the generated image"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 50,
          "title": "Num Inference Steps",
          "description": "The number of inference steps",
          "min": 1.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 7.0,
          "title": "Guidance Scale",
          "description": "How closely to follow the prompt"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "image_size",
        "guidance_scale"
      ]
    },
    {
      "title": "Diffusion Edge",
      "description": "Diffusion Edge is a diffusion-based high-quality edge detection model that generates\n    edge maps from input images.",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.DiffusionEdge",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The input image to detect edges from"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image"
      ]
    },
    {
      "title": "Fast LCMDiffusion",
      "description": "Fast Latent Consistency Models (v1.5/XL) Text to Image runs SDXL at the speed of light,\n    enabling rapid and high-quality image generation.",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.FastLCMDiffusion",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "model_name",
          "type": {
            "type": "enum",
            "values": [
              "stabilityai/stable-diffusion-xl-base-1.0",
              "runwayml/stable-diffusion-v1-5"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.ModelNameFastLCM"
          },
          "default": "stabilityai/stable-diffusion-xl-base-1.0",
          "title": "Model Name",
          "description": "The name of the model to use"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "Use it to address details that you don't want in the image"
        },
        {
          "name": "image_size",
          "type": {
            "type": "enum",
            "values": [
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
          },
          "default": "square_hd",
          "title": "Image Size",
          "description": "The size of the generated image"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 6,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform",
          "min": 1.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 1.5,
          "title": "Guidance Scale",
          "description": "How closely the model should stick to your prompt"
        },
        {
          "name": "sync_mode",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Sync Mode",
          "description": "If true, wait for image generation and upload before returning"
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "The number of images to generate",
          "min": 1.0
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If true, the safety checker will be enabled"
        },
        {
          "name": "safety_checker_version",
          "type": {
            "type": "enum",
            "values": [
              "v1",
              "v2"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.SafetyCheckerVersion"
          },
          "default": "v1",
          "title": "Safety Checker Version",
          "description": "The version of the safety checker to use"
        },
        {
          "name": "expand_prompt",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Expand Prompt",
          "description": "If true, the prompt will be expanded with additional prompts"
        },
        {
          "name": "guidance_rescale",
          "type": {
            "type": "float"
          },
          "default": 0.0,
          "title": "Guidance Rescale",
          "description": "The rescale factor for the CFG"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed and prompt will output the same image every time"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "model_name",
        "guidance_scale"
      ]
    },
    {
      "title": "Fast Lightning SDXL",
      "description": "Stable Diffusion XL Lightning Text to Image runs SDXL at the speed of light, enabling\n    ultra-fast high-quality image generation.",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.FastLightningSDXL",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "image_size",
          "type": {
            "type": "enum",
            "values": [
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
          },
          "default": "square_hd",
          "title": "Image Size",
          "description": "The size of the generated image"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 4,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform (1, 2, 4, or 8)",
          "min": 1.0,
          "max": 8.0
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed and prompt will output the same image every time"
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If true, the safety checker will be enabled"
        },
        {
          "name": "expand_prompt",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Expand Prompt",
          "description": "If true, the prompt will be expanded with additional prompts"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "image_size",
        "num_inference_steps"
      ]
    },
    {
      "title": "Fast SDXL",
      "description": "Fast SDXL is a high-performance text-to-image model that runs SDXL at exceptional speeds\n    while maintaining high-quality output.",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.FastSDXL",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "Use it to address details that you don't want in the image"
        },
        {
          "name": "image_size",
          "type": {
            "type": "enum",
            "values": [
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
          },
          "default": "square_hd",
          "title": "Image Size",
          "description": "The size of the generated image"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 25,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform",
          "min": 1.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 7.5,
          "title": "Guidance Scale",
          "description": "How closely the model should stick to your prompt (CFG scale)"
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "The number of images to generate",
          "min": 1.0
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed and prompt will output the same image every time"
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If true, the safety checker will be enabled"
        },
        {
          "name": "expand_prompt",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Expand Prompt",
          "description": "If true, the prompt will be expanded with additional prompts"
        },
        {
          "name": "loras",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "lora_weight"
              }
            ]
          },
          "default": [],
          "title": "Loras",
          "description": "The list of LoRA weights to use"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "negative_prompt",
        "guidance_scale"
      ]
    },
    {
      "title": "Fast SDXLControl Net Canny",
      "description": "Fast SDXL ControlNet Canny is a model that generates images using ControlNet with SDXL.",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.FastSDXLControlNetCanny",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "control_image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Control Image",
          "description": "The control image to use for generation"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "Use it to address details that you don't want in the image"
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 7.5,
          "title": "Guidance Scale",
          "description": "How closely the model should stick to your prompt"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 25,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform",
          "min": 1.0
        },
        {
          "name": "image_size",
          "type": {
            "type": "enum",
            "values": [
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
          },
          "default": "square_hd",
          "title": "Image Size",
          "description": "The size of the generated image"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed and prompt will output the same image every time"
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If true, the safety checker will be enabled"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "control_image",
        "guidance_scale"
      ]
    },
    {
      "title": "Fast Turbo Diffusion",
      "description": "Fast Turbo Diffusion runs SDXL at exceptional speeds while maintaining high-quality output.\n    Supports both SDXL Turbo and SD Turbo models for ultra-fast image generation.",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.FastTurboDiffusion",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "model_name",
          "type": {
            "type": "enum",
            "values": [
              "stabilityai/sdxl-turbo",
              "stabilityai/sd-turbo"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.ModelNameEnum"
          },
          "default": "stabilityai/sdxl-turbo",
          "title": "Model Name",
          "description": "The name of the model to use"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "Use it to address details that you don't want in the image"
        },
        {
          "name": "image_size",
          "type": {
            "type": "enum",
            "values": [
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
          },
          "default": "square",
          "title": "Image Size",
          "description": "The size of the generated image"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 2,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform",
          "min": 1.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Guidance Scale",
          "description": "How closely the model should stick to your prompt"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed and prompt will output the same image every time"
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If true, the safety checker will be enabled"
        },
        {
          "name": "expand_prompt",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Expand Prompt",
          "description": "If true, the prompt will be expanded with additional prompts"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "model_name",
        "guidance_scale"
      ]
    },
    {
      "title": "Flux 2 Flash",
      "description": "FLUX 2 Flash is an ultra-fast text-to-image model optimized for speed while maintaining quality.\n    image, generation, flux, ultra-fast, text-to-image, txt2img, flash\n\n    Use cases:\n    - Real-time image generation\n    - Interactive creative tools\n    - Rapid prototyping\n    - High-throughput applications\n    - Quick visual exploration",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.Flux2Flash",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "image_size",
          "type": {
            "type": "enum",
            "values": [
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
          },
          "default": "square_hd",
          "title": "Image Size",
          "description": "The size of the generated image"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 4,
          "title": "Num Inference Steps",
          "description": "The number of inference steps",
          "min": 1.0,
          "max": 8.0
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for reproducible generation"
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If true, the safety checker will be enabled"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "image_size",
        "num_inference_steps"
      ]
    },
    {
      "title": "Flux 2 Klein 9 b Base",
      "description": "FLUX.2 [klein] 9B Base: fast text-to-image for real-time apps and high volume. Sub-second speed, high quality (not maximum). Supports up to 4 images.\n    flux, text-to-image, klein, black-forest-labs, real-time, fast, high-volume\n\n    Use cases:\n    - Real-time and interactive image generation\n    - High-volume batch or API workloads\n    - Fast iteration and previews\n    - Apps needing sub-second latency\n    - High-quality output where speed matters more than max quality",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.Flux2Klein9bBase",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from."
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str",
            "optional": true
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "Negative prompt for classifier-free guidance. Describes what to avoid in the image."
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 5.0,
          "title": "Guidance Scale",
          "description": "Guidance scale for classifier-free guidance.",
          "min": 0.0,
          "max": 20.0
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The seed to use for the generation. If not provided, a random seed will be used."
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 28,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform.",
          "min": 4.0,
          "max": 50.0
        },
        {
          "name": "image_size",
          "type": {
            "type": "enum",
            "values": [
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
          },
          "default": "landscape_4_3",
          "title": "Image Size",
          "description": "The size of the image to generate."
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "The number of images to generate.",
          "min": 1.0,
          "max": 4.0
        },
        {
          "name": "acceleration",
          "type": {
            "type": "enum",
            "values": [
              "none",
              "regular",
              "high"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.Flux2KleinAcceleration"
          },
          "default": "regular",
          "title": "Acceleration",
          "description": "The acceleration level to use for image generation."
        },
        {
          "name": "sync_mode",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Sync Mode",
          "description": "If True, the media will be returned as a data URI. Output is not stored when this is True."
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If set to true, the safety checker will be enabled."
        },
        {
          "name": "output_format",
          "type": {
            "type": "str"
          },
          "default": "png",
          "title": "Output Format",
          "description": "The format of the generated image."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "image_size",
        "guidance_scale",
        "num_images"
      ]
    },
    {
      "title": "Flux 2 Turbo",
      "description": "FLUX 2 Turbo is a fast text-to-image model delivering high-quality results with reduced generation time.\n    image, generation, flux, fast, text-to-image, txt2img, turbo\n\n    Use cases:\n    - Rapid image prototyping\n    - High-volume image generation\n    - Quick concept visualization\n    - Fast design iterations\n    - Real-time creative workflows",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.Flux2Turbo",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "image_size",
          "type": {
            "type": "enum",
            "values": [
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
          },
          "default": "square_hd",
          "title": "Image Size",
          "description": "The size of the generated image"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 4,
          "title": "Num Inference Steps",
          "description": "The number of inference steps",
          "min": 1.0,
          "max": 12.0
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for reproducible generation"
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If true, the safety checker will be enabled"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "image_size",
        "num_inference_steps"
      ]
    },
    {
      "title": "Flux Dev",
      "description": "FLUX.1 [dev] is a 12 billion parameter flow transformer that generates high-quality images from text.\n    It is suitable for personal and commercial use.",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.FluxDev",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "image_size",
          "type": {
            "type": "enum",
            "values": [
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
          },
          "default": "landscape_4_3",
          "title": "Image Size",
          "description": "Either a preset size or a custom {width, height} dictionary"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 28,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform",
          "min": 1.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 3.5,
          "title": "Guidance Scale",
          "description": "The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt"
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "The number of images to generate",
          "min": 1.0
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed and prompt will output the same image every time"
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If true, the safety checker will be enabled"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "image_size",
        "guidance_scale"
      ]
    },
    {
      "title": "Flux Dev Image To Image",
      "description": "FLUX.1 [dev] Image-to-Image is a high-performance endpoint that enables rapid transformation\n    of existing images, delivering high-quality style transfers and image modifications with\n    the core FLUX capabilities.",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.FluxDevImageToImage",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The input image to transform"
        },
        {
          "name": "strength",
          "type": {
            "type": "float"
          },
          "default": 0.95,
          "title": "Strength",
          "description": "The strength of the initial image. Higher strength values are better for this model"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 40,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform",
          "min": 1.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 3.5,
          "title": "Guidance Scale",
          "description": "How closely the model should stick to your prompt"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed and prompt will output the same image every time"
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If true, the safety checker will be enabled"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "image",
        "strength"
      ]
    },
    {
      "title": "Flux General",
      "description": "FLUX.1 [dev] with Controlnets and Loras is a versatile text-to-image model that supports multiple AI extensions including LoRA, ControlNet conditioning, and IP-Adapter integration, enabling comprehensive control over image generation through various guidance methods.\n    image, generation, controlnet, lora, ip-adapter, text-to-image, txt2img\n\n    Use cases:\n    - Create controlled image generations\n    - Apply multiple AI extensions\n    - Generate guided visual content\n    - Produce customized artwork\n    - Design with precise control",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.FluxGeneral",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "image_size",
          "type": {
            "type": "enum",
            "values": [
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
          },
          "default": "square_hd",
          "title": "Image Size",
          "description": "The size of the generated image"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 28,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform",
          "min": 1.0,
          "max": 50.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 3.5,
          "title": "Guidance Scale",
          "description": "How closely the model should stick to your prompt (CFG scale)",
          "min": 1.0,
          "max": 20.0
        },
        {
          "name": "real_cfg_scale",
          "type": {
            "type": "float"
          },
          "default": 3.5,
          "title": "Real Cfg Scale",
          "description": "Classical CFG scale as in SD1.5, SDXL, etc."
        },
        {
          "name": "use_real_cfg",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Use Real Cfg",
          "description": "Uses classical CFG. Increases generation times and price when true"
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "The number of images to generate",
          "min": 1.0
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed and prompt will output the same image every time"
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If true, the safety checker will be enabled"
        },
        {
          "name": "reference_strength",
          "type": {
            "type": "float"
          },
          "default": 0.65,
          "title": "Reference Strength",
          "description": "Strength of reference_only generation. Only used if a reference image is provided"
        },
        {
          "name": "reference_end",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Reference End",
          "description": "The percentage of total timesteps when reference guidance should end"
        },
        {
          "name": "base_shift",
          "type": {
            "type": "float"
          },
          "default": 0.5,
          "title": "Base Shift",
          "description": "Base shift for the scheduled timesteps"
        },
        {
          "name": "max_shift",
          "type": {
            "type": "float"
          },
          "default": 1.15,
          "title": "Max Shift",
          "description": "Max shift for the scheduled timesteps"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "image_size",
        "guidance_scale"
      ]
    },
    {
      "title": "Flux Lora",
      "description": "FLUX.1 [dev] with LoRAs is a text-to-image model that supports LoRA adaptations, enabling rapid and high-quality image generation with pre-trained LoRA weights for personalization, specific styles, brand identities, and product-specific outputs.\n    image, generation, lora, personalization, style-transfer, text-to-image, txt2img\n\n    Use cases:\n    - Create brand-specific visuals\n    - Generate custom styled images\n    - Adapt existing styles to new content\n    - Produce personalized artwork\n    - Design consistent visual identities",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.FluxLora",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "image_size",
          "type": {
            "type": "enum",
            "values": [
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
          },
          "default": "landscape_4_3",
          "title": "Image Size",
          "description": "Either a preset size or a custom {width, height} dictionary"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 28,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform",
          "min": 1.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 3.5,
          "title": "Guidance Scale",
          "description": "The CFG scale to determine how closely the model follows the prompt"
        },
        {
          "name": "loras",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "lora_weight"
              }
            ]
          },
          "default": [],
          "title": "Loras",
          "description": "List of LoRA weights to use for image generation"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed and prompt will output the same image every time"
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If true, the safety checker will be enabled"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "image_size",
        "loras"
      ]
    },
    {
      "title": "Flux Lora Inpainting",
      "description": "FLUX.1 [dev] Inpainting with LoRAs is a text-to-image model that supports inpainting and LoRA adaptations,\n    enabling rapid and high-quality image inpainting using pre-trained LoRA weights for personalization,\n    specific styles, brand identities, and product-specific outputs.",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.FluxLoraInpainting",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The input image to inpaint"
        },
        {
          "name": "mask",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Mask",
          "description": "The mask indicating areas to inpaint (white=inpaint, black=keep)"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 28,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform",
          "min": 1.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 3.5,
          "title": "Guidance Scale",
          "description": "The CFG scale to determine how closely the model follows the prompt"
        },
        {
          "name": "strength",
          "type": {
            "type": "float"
          },
          "default": 0.85,
          "title": "Strength",
          "description": "The strength to use for inpainting. 1.0 completely remakes the image while 0.0 preserves the original",
          "min": 0.0,
          "max": 1.0
        },
        {
          "name": "loras",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "lora_weight"
              }
            ]
          },
          "default": [],
          "title": "Loras",
          "description": "List of LoRA weights to use for image generation"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed and prompt will output the same image every time"
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If true, the safety checker will be enabled"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "image",
        "mask",
        "loras"
      ]
    },
    {
      "title": "Flux Lora TTI",
      "description": "FLUX.1 with LoRAs is a text-to-image model that supports LoRA adaptations,\n    enabling high-quality image generation with customizable LoRA weights for\n    personalization, specific styles, and brand identities.",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.FluxLoraTTI",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "Use it to address details that you don't want in the image"
        },
        {
          "name": "model_name",
          "type": {
            "type": "enum",
            "values": [
              "stabilityai/stable-diffusion-xl-base-1.0",
              "runwayml/stable-diffusion-v1-5",
              "stabilityai/stable-diffusion-2-1",
              "gsdf/Anything-V5.0",
              "lykon/dreamshaper-8",
              "XpucT/Deliberate_v3",
              "SG161222/Realistic_Vision_V5.1_noVAE"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.LoraModel"
          },
          "default": "stabilityai/stable-diffusion-xl-base-1.0",
          "title": "Model Name",
          "description": "The base model to use for generation"
        },
        {
          "name": "image_size",
          "type": {
            "type": "enum",
            "values": [
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
          },
          "default": "square_hd",
          "title": "Image Size",
          "description": "The size of the generated image"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 30,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform",
          "min": 1.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 7.5,
          "title": "Guidance Scale",
          "description": "How closely the model should stick to your prompt"
        },
        {
          "name": "loras",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "lora_weight"
              }
            ]
          },
          "default": [],
          "title": "Loras",
          "description": "List of LoRA weights to use for image generation"
        },
        {
          "name": "prompt_weighting",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Prompt Weighting",
          "description": "If true, prompt weighting syntax will be used and 77 token limit lifted"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed and prompt will output the same image every time"
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If true, the safety checker will be enabled"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "model_name",
        "loras"
      ]
    },
    {
      "title": "Flux Schnell",
      "description": "FLUX.1 [schnell] is a 12 billion parameter flow transformer that generates high-quality images\n    from text in 1 to 4 steps, suitable for personal and commercial use.",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.FluxSchnell",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "image_size",
          "type": {
            "type": "enum",
            "values": [
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
          },
          "default": "landscape_4_3",
          "title": "Image Size",
          "description": "Either a preset size or a custom {width, height} dictionary"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 4,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform",
          "min": 1.0
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "The number of images to generate",
          "min": 1.0
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed and prompt will output the same image every time"
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If true, the safety checker will be enabled"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "image_size",
        "num_inference_steps"
      ]
    },
    {
      "title": "Flux Subject",
      "description": "FLUX.1 Subject is a super fast endpoint for the FLUX.1 [schnell] model with subject input capabilities, enabling rapid and high-quality image generation for personalization, specific styles, brand identities, and product-specific outputs.\n    image, generation, subject-driven, personalization, fast, text-to-image, txt2img\n\n    Use cases:\n    - Create variations of existing subjects\n    - Generate personalized product images\n    - Design brand-specific visuals\n    - Produce custom character artwork\n    - Create subject-based illustrations",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.FluxSubject",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The image of the subject"
        },
        {
          "name": "image_size",
          "type": {
            "type": "enum",
            "values": [
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
          },
          "default": "square_hd",
          "title": "Image Size",
          "description": "Either a preset size or a custom {width, height} dictionary"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 8,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform",
          "min": 1.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 3.5,
          "title": "Guidance Scale",
          "description": "The CFG scale to determine how closely the model follows the prompt"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed and prompt will output the same image every time"
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If true, the safety checker will be enabled"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "image",
        "image_size"
      ]
    },
    {
      "title": "Flux V1 Pro",
      "description": "FLUX1.1 [pro] is an enhanced version of FLUX.1 [pro], improved image generation capabilities, delivering superior composition, detail, and artistic fidelity compared to its predecessor.\n    image, generation, composition, detail, artistic, text-to-image, txt2img\n\n    Use cases:\n    - Generate high-fidelity artwork\n    - Create detailed illustrations\n    - Design complex compositions\n    - Produce artistic renderings\n    - Generate professional visuals",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.FluxV1Pro",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "image_size",
          "type": {
            "type": "enum",
            "values": [
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
          },
          "default": "square_hd",
          "title": "Image Size",
          "description": "Either a preset size or a custom {width, height} dictionary. Max dimension 14142"
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 3.5,
          "title": "Guidance Scale",
          "description": "The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.",
          "min": 1.0,
          "max": 20.0
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 28,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform.",
          "min": 1.0,
          "max": 50.0
        },
        {
          "name": "seed",
          "type": {
            "type": "int",
            "optional": true
          },
          "default": null,
          "title": "Seed",
          "description": "The same seed and the same prompt given to the same version of the model will output the same image every time."
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "The number of images to generate (1-4)",
          "min": 1.0,
          "max": 4.0
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If true, the safety checker will be enabled"
        },
        {
          "name": "safety_tolerance",
          "type": {
            "type": "str"
          },
          "default": "2",
          "title": "Safety Tolerance",
          "description": "Safety tolerance level (1-6), 1 being strict, 6 being permissive"
        },
        {
          "name": "output_format",
          "type": {
            "type": "str"
          },
          "default": "jpeg",
          "title": "Output Format",
          "description": "Output format (jpeg or png)"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "image_size",
        "guidance_scale",
        "num_images"
      ]
    },
    {
      "title": "Flux V1 Pro New",
      "description": "FLUX.1 [pro] new is an accelerated version of FLUX.1 [pro], maintaining professional-grade\n    image quality while delivering significantly faster generation speeds.",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.FluxV1ProNew",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "image_size",
          "type": {
            "type": "enum",
            "values": [
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
          },
          "default": "landscape_4_3",
          "title": "Image Size",
          "description": "Either a preset size or a custom {width, height} dictionary"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 28,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform",
          "min": 1.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 3.5,
          "title": "Guidance Scale",
          "description": "The CFG scale to determine how closely the model follows the prompt",
          "min": 1.0,
          "max": 20.0
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "The number of images to generate",
          "min": 1.0
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed and prompt will output the same image every time"
        },
        {
          "name": "safety_tolerance",
          "type": {
            "type": "int"
          },
          "default": 2,
          "title": "Safety Tolerance",
          "description": "Safety tolerance level (1=strict, 6=permissive)",
          "min": 1.0,
          "max": 6.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "image_size",
        "guidance_scale"
      ]
    },
    {
      "title": "Flux V1 Pro Ultra",
      "description": "FLUX1.1 [ultra] is the latest and most advanced version of FLUX.1 [pro],\n    featuring cutting-edge improvements in image generation, delivering unparalleled\n    composition, detail, and artistic fidelity.",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.FluxV1ProUltra",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "image_size",
          "type": {
            "type": "enum",
            "values": [
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
          },
          "default": "square_hd",
          "title": "Image Size",
          "description": "Either a preset size or a custom {width, height} dictionary. Max dimension 14142"
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 3.5,
          "title": "Guidance Scale",
          "description": "The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.",
          "min": 1.0,
          "max": 20.0
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 28,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform.",
          "min": 1.0,
          "max": 50.0
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed and the same prompt given to the same version of the model will output the same image every time."
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "The number of images to generate (1-4)",
          "min": 1.0,
          "max": 4.0
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If true, the safety checker will be enabled"
        },
        {
          "name": "safety_tolerance",
          "type": {
            "type": "str"
          },
          "default": "2",
          "title": "Safety Tolerance",
          "description": "Safety tolerance level (1-6), 1 being strict, 6 being permissive"
        },
        {
          "name": "output_format",
          "type": {
            "type": "str"
          },
          "default": "jpeg",
          "title": "Output Format",
          "description": "Output format (jpeg or png)"
        },
        {
          "name": "raw",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Raw",
          "description": "Generate less processed, more natural-looking images"
        },
        {
          "name": "aspect_ratio",
          "type": {
            "type": "str"
          },
          "default": "16:9",
          "title": "Aspect Ratio",
          "description": "Aspect ratio of the generated image"
        },
        {
          "name": "image_prompt_strength",
          "type": {
            "type": "float"
          },
          "default": 0.1,
          "title": "Image Prompt Strength",
          "description": "Strength of the image prompt",
          "min": 0.0,
          "max": 1.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "image_size",
        "guidance_scale",
        "aspect_ratio"
      ]
    },
    {
      "title": "Fooocus",
      "description": "Fooocus is a text-to-image model with default parameters and automated optimizations\n    for quality improvements.",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.Fooocus",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "Use it to address details that you don't want in the image"
        },
        {
          "name": "styles",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "str"
              }
            ]
          },
          "default": [
            "Fooocus Enhance",
            "Fooocus V2",
            "Fooocus Sharp"
          ],
          "title": "Styles",
          "description": "The styles to apply to the generated image"
        },
        {
          "name": "performance",
          "type": {
            "type": "enum",
            "values": [
              "Speed",
              "Quality",
              "Extreme Speed",
              "Lightning"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.PerformanceEnum"
          },
          "default": "Extreme Speed",
          "title": "Performance",
          "description": "You can choose Speed or Quality"
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 4.0,
          "title": "Guidance Scale",
          "description": "How closely the model should stick to your prompt"
        },
        {
          "name": "sharpness",
          "type": {
            "type": "float"
          },
          "default": 2.0,
          "title": "Sharpness",
          "description": "Higher value means image and texture are sharper"
        },
        {
          "name": "aspect_ratio",
          "type": {
            "type": "str"
          },
          "default": "1024x1024",
          "title": "Aspect Ratio",
          "description": "The size of the generated image (must be multiples of 8)"
        },
        {
          "name": "loras",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "lora_weight"
              }
            ]
          },
          "default": [],
          "title": "Loras",
          "description": "Up to 5 LoRAs that will be merged for generation"
        },
        {
          "name": "refiner_model",
          "type": {
            "type": "enum",
            "values": [
              "None",
              "realisticVisionV60B1_v51VAE.safetensors"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.RefinerModelEnum"
          },
          "default": "None",
          "title": "Refiner Model",
          "description": "Refiner model to use (SDXL or SD 1.5)"
        },
        {
          "name": "refiner_switch",
          "type": {
            "type": "float"
          },
          "default": 0.8,
          "title": "Refiner Switch",
          "description": "Switch point for refiner (0.4 for SD1.5 realistic, 0.667 for SD1.5 anime, 0.8 for XL)"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed and prompt will output the same image every time"
        },
        {
          "name": "control_image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Control Image",
          "description": "Reference image for generation"
        },
        {
          "name": "control_type",
          "type": {
            "type": "enum",
            "values": [
              "ImagePrompt",
              "PyraCanny",
              "CPDS",
              "FaceSwap"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.ControlTypeEnum"
          },
          "default": "PyraCanny",
          "title": "Control Type",
          "description": "The type of image control"
        },
        {
          "name": "control_image_weight",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Control Image Weight",
          "description": "Strength of the control image influence"
        },
        {
          "name": "control_image_stop_at",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Control Image Stop At",
          "description": "When to stop applying control image influence"
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If false, the safety checker will be disabled"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "negative_prompt",
        "styles"
      ]
    },
    {
      "title": "GPTImage 1",
      "description": "OpenAI's GPT Image 1 model for generating images from text prompts with high quality and creative outputs.\n    image, generation, openai, gpt, text-to-image, txt2img, creative\n\n    Use cases:\n    - Generate creative illustrations\n    - Create concept art and designs\n    - Produce marketing visuals\n    - Design digital artwork\n    - Create custom graphics",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.GPTImage1",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "size",
          "type": {
            "type": "str"
          },
          "default": "1024x1024",
          "title": "Size",
          "description": "The size of the generated image (e.g., 1024x1024, 1792x1024, 1024x1792)"
        },
        {
          "name": "quality",
          "type": {
            "type": "str"
          },
          "default": "auto",
          "title": "Quality",
          "description": "The quality of the generated image (auto, high, medium, low)"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "size",
        "quality"
      ]
    },
    {
      "title": "Gemini 25 Flash Image",
      "description": "Google's Gemini 2.5 Flash model for fast high-quality image generation from text.\n    image, generation, google, gemini, text-to-image, txt2img, fast\n\n    Use cases:\n    - Generate images quickly\n    - Create visual content at scale\n    - Produce concept visualizations\n    - Design marketing materials\n    - Create educational illustrations",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.Gemini25FlashImage",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "aspect_ratio",
          "type": {
            "type": "enum",
            "values": [
              "10:16",
              "16:10",
              "9:16",
              "16:9",
              "4:3",
              "3:4",
              "1:1",
              "1:3",
              "3:1",
              "3:2",
              "2:3",
              "4:5",
              "5:4"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.AspectRatio"
          },
          "default": "1:1",
          "title": "Aspect Ratio",
          "description": "The aspect ratio of the generated image"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "aspect_ratio"
      ]
    },
    {
      "title": "Hunyuan Image V3",
      "description": "Hunyuan Image V3 is Tencent's advanced text-to-image model with exceptional detail and artistic quality.\n    image, generation, hunyuan, tencent, text-to-image, txt2img, artistic\n\n    Use cases:\n    - Create detailed digital artwork\n    - Generate photorealistic images\n    - Produce high-quality illustrations\n    - Design creative visuals\n    - Create artistic compositions",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.HunyuanImageV3",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "What to avoid in the generated image"
        },
        {
          "name": "image_size",
          "type": {
            "type": "enum",
            "values": [
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
          },
          "default": "square_hd",
          "title": "Image Size",
          "description": "The size of the generated image"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 30,
          "title": "Num Inference Steps",
          "description": "The number of inference steps",
          "min": 1.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 5.0,
          "title": "Guidance Scale",
          "description": "How closely to follow the prompt"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "image_size",
        "guidance_scale"
      ]
    },
    {
      "title": "Hunyuan Image V3 Instruct",
      "description": "Hunyuan Image V3 Instruct with internal reasoning capabilities for advanced text-to-image generation.\n    image, generation, hunyuan, tencent, instruct, reasoning, text-to-image, txt2img, advanced\n\n    Use cases:\n    - Generate highly detailed images with reasoning\n    - Create complex compositions with multiple elements\n    - Produce photorealistic images with fine control\n    - Generate artistic images with advanced understanding\n    - Create images with complex prompt interpretation",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.HunyuanImageV3Instruct",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The text prompt to generate an image from"
        },
        {
          "name": "image_size",
          "type": {
            "type": "enum",
            "values": [
              "auto",
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.HunyuanImageSizePreset"
          },
          "default": "auto",
          "title": "Image Size",
          "description": "The desired size of the generated image. If auto, size is determined by the model"
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "The number of images to generate",
          "min": 1.0,
          "max": 4.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 3.5,
          "title": "Guidance Scale",
          "description": "How closely to follow the prompt (higher = stricter adherence)",
          "min": 1.0,
          "max": 20.0
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for reproducible generation"
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "Enable safety checker to filter unsafe content"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "image_size",
        "guidance_scale"
      ]
    },
    {
      "title": "Hyper SDXL",
      "description": "Hyper SDXL is a hyper-charged version of SDXL that delivers exceptional performance and creativity\n    while maintaining high-quality output and ultra-fast generation speeds.",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.HyperSDXL",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "image_size",
          "type": {
            "type": "enum",
            "values": [
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
          },
          "default": "square_hd",
          "title": "Image Size",
          "description": "The size of the generated image"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform (1, 2, or 4)",
          "min": 1.0,
          "max": 4.0
        },
        {
          "name": "sync_mode",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Sync Mode",
          "description": "If true, wait for image generation and upload before returning"
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "The number of images to generate",
          "min": 1.0
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If true, the safety checker will be enabled"
        },
        {
          "name": "expand_prompt",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Expand Prompt",
          "description": "If true, the prompt will be expanded with additional prompts"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed and prompt will output the same image every time"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "image_size",
        "num_inference_steps"
      ]
    },
    {
      "title": "Ideogram V2",
      "description": "Ideogram V2 is a state-of-the-art image generation model optimized for commercial and creative use, featuring exceptional typography handling and realistic outputs.\n    image, generation, ai, typography, realistic, text-to-image, txt2img\n\n    Use cases:\n    - Create commercial artwork and designs\n    - Generate realistic product visualizations\n    - Design marketing materials with text\n    - Produce high-quality illustrations\n    - Create brand assets and logos",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.IdeogramV2",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "aspect_ratio",
          "type": {
            "type": "enum",
            "values": [
              "10:16",
              "16:10",
              "9:16",
              "16:9",
              "4:3",
              "3:4",
              "1:1",
              "1:3",
              "3:1",
              "3:2",
              "2:3",
              "4:5",
              "5:4"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.AspectRatio"
          },
          "default": "1:1",
          "title": "Aspect Ratio",
          "description": "The aspect ratio of the generated image."
        },
        {
          "name": "expand_prompt",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Expand Prompt",
          "description": "Whether to expand the prompt with MagicPrompt functionality."
        },
        {
          "name": "style",
          "type": {
            "type": "enum",
            "values": [
              "auto",
              "general",
              "realistic",
              "design",
              "render_3D",
              "anime"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.IdeogramStyle"
          },
          "default": "auto",
          "title": "Style",
          "description": "The style of the generated image."
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "A negative prompt to avoid in the generated image."
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for the random number generator."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "aspect_ratio",
        "style"
      ]
    },
    {
      "title": "Ideogram V2 Turbo",
      "description": "Accelerated image generation with Ideogram V2 Turbo. Create high-quality visuals, posters,\n    and logos with enhanced speed while maintaining Ideogram's signature quality.",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.IdeogramV2Turbo",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "aspect_ratio",
          "type": {
            "type": "enum",
            "values": [
              "10:16",
              "16:10",
              "9:16",
              "16:9",
              "4:3",
              "3:4",
              "1:1",
              "1:3",
              "3:1",
              "3:2",
              "2:3",
              "4:5",
              "5:4"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.AspectRatio"
          },
          "default": "1:1",
          "title": "Aspect Ratio",
          "description": "The aspect ratio of the generated image."
        },
        {
          "name": "expand_prompt",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Expand Prompt",
          "description": "Whether to expand the prompt with MagicPrompt functionality."
        },
        {
          "name": "style",
          "type": {
            "type": "enum",
            "values": [
              "auto",
              "general",
              "realistic",
              "design",
              "render_3D",
              "anime"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.IdeogramStyle"
          },
          "default": "auto",
          "title": "Style",
          "description": "The style of the generated image."
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "A negative prompt to avoid in the generated image."
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for the random number generator."
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "aspect_ratio",
        "style"
      ]
    },
    {
      "title": "Ideogram V3",
      "description": "Ideogram V3 is the latest generation text-to-image model with enhanced typography and photorealistic outputs.\n    image, generation, typography, realistic, text-to-image, txt2img, ideogram\n\n    Use cases:\n    - Create professional marketing materials with text\n    - Generate logos and brand assets\n    - Design posters and advertisements\n    - Produce photorealistic product images\n    - Create typography-heavy artwork",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.IdeogramV3",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "aspect_ratio",
          "type": {
            "type": "enum",
            "values": [
              "10:16",
              "16:10",
              "9:16",
              "16:9",
              "4:3",
              "3:4",
              "1:1",
              "1:3",
              "3:1",
              "3:2",
              "2:3",
              "4:5",
              "5:4"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.AspectRatio"
          },
          "default": "1:1",
          "title": "Aspect Ratio",
          "description": "The aspect ratio of the generated image"
        },
        {
          "name": "style",
          "type": {
            "type": "enum",
            "values": [
              "auto",
              "general",
              "realistic",
              "design",
              "render_3D",
              "anime"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.IdeogramStyle"
          },
          "default": "auto",
          "title": "Style",
          "description": "The style of the generated image"
        },
        {
          "name": "expand_prompt",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Expand Prompt",
          "description": "Whether to expand the prompt with MagicPrompt functionality"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "A negative prompt to avoid in the generated image"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "aspect_ratio",
        "style"
      ]
    },
    {
      "title": "Illusion Diffusion",
      "description": "Illusion Diffusion is a model that creates illusions conditioned on an input image.",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.IllusionDiffusion",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "Use it to address details that you don't want in the image"
        },
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "Input image URL for conditioning the generation"
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 7.5,
          "title": "Guidance Scale",
          "description": "How closely the model should stick to your prompt"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 40,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform",
          "min": 1.0
        },
        {
          "name": "image_size",
          "type": {
            "type": "enum",
            "values": [
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
          },
          "default": "square_hd",
          "title": "Image Size",
          "description": "The size of the generated image"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed and prompt will output the same image every time"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "image",
        "guidance_scale"
      ]
    },
    {
      "title": "Imagen 3",
      "description": "Google Imagen 3 is a state-of-the-art text-to-image model with exceptional quality and understanding.\n    image, generation, google, imagen, text-to-image, txt2img, high-quality\n\n    Use cases:\n    - Generate photorealistic images\n    - Create professional marketing content\n    - Design visual assets\n    - Produce high-quality illustrations\n    - Create detailed artwork",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.Imagen3",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "What to avoid in the generated image"
        },
        {
          "name": "aspect_ratio",
          "type": {
            "type": "enum",
            "values": [
              "10:16",
              "16:10",
              "9:16",
              "16:9",
              "4:3",
              "3:4",
              "1:1",
              "1:3",
              "3:1",
              "3:2",
              "2:3",
              "4:5",
              "5:4"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.AspectRatio"
          },
          "default": "1:1",
          "title": "Aspect Ratio",
          "description": "The aspect ratio of the generated image"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "aspect_ratio"
      ]
    },
    {
      "title": "Imagen 4 Preview",
      "description": "Imagen 4 Preview is the next iteration of Google's Imagen series, offering\n    high quality text-to-image generation with strong prompt adherence and\n    improved realism.\n    image, generation, google, text-to-image, txt2img\n\n    Use cases:\n    - Generate photorealistic artwork and designs\n    - Create marketing and product visuals\n    - Produce concept art or storyboards\n    - Explore creative ideas with high fidelity\n    - Rapid prototyping of imagery",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.Imagen4Preview",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "Elements to avoid in the generated image"
        },
        {
          "name": "aspect_ratio",
          "type": {
            "type": "enum",
            "values": [
              "10:16",
              "16:10",
              "9:16",
              "16:9",
              "4:3",
              "3:4",
              "1:1",
              "1:3",
              "3:1",
              "3:2",
              "2:3",
              "4:5",
              "5:4"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.AspectRatio"
          },
          "default": "1:1",
          "title": "Aspect Ratio",
          "description": "The aspect ratio of the generated image"
        },
        {
          "name": "image_size",
          "type": {
            "type": "enum",
            "values": [
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
          },
          "default": "landscape_4_3",
          "title": "Image Size",
          "description": "The size of the generated image"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 50,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform",
          "min": 1.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 5.0,
          "title": "Guidance Scale",
          "description": "How closely the model should follow the prompt"
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "The number of images to generate",
          "min": 1.0
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed and prompt will output the same image every time"
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If true, the safety checker will be enabled"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "aspect_ratio",
        "guidance_scale"
      ]
    },
    {
      "title": "Kling Image 3 Text To Image",
      "description": "Generate high-quality images from text prompts using Kling Image 3.0.\n    Supports sharp outputs up to 2K resolution with strong prompt adherence.\n    image, generation, kling, v3, text-to-image, high-resolution\n\n    Use cases:\n    - Create high-resolution images from descriptions\n    - Generate 2K quality artwork\n    - Produce photorealistic images\n    - Create detailed visual content\n    - Generate images with strong prompt adherence",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.KlingImage3TextToImage",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The text prompt describing the desired image (max 2500 characters)"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "What to avoid in the generated image"
        },
        {
          "name": "aspect_ratio",
          "type": {
            "type": "enum",
            "values": [
              "16:9",
              "9:16",
              "4:3",
              "3:4",
              "1:1",
              "3:2",
              "2:3",
              "21:9"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.Kling3ImageAspectRatio"
          },
          "default": "16:9",
          "title": "Aspect Ratio",
          "description": "The aspect ratio of the generated image"
        },
        {
          "name": "resolution",
          "type": {
            "type": "enum",
            "values": [
              "1K",
              "2K"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.Kling3ImageResolution"
          },
          "default": "1K",
          "title": "Resolution",
          "description": "Image generation resolution. 1K: standard, 2K: high-res"
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "Number of images to generate (1-9)",
          "min": 1.0,
          "max": 9.0
        },
        {
          "name": "elements",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "image"
              }
            ]
          },
          "default": [],
          "title": "Elements",
          "description": "Optional elements for face/character control. Reference as @Element1, @Element2 in prompt"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "aspect_ratio"
      ]
    },
    {
      "title": "Kolors",
      "description": "Kolors is an advanced text-to-image model with excellent color reproduction and artistic style.\n    image, generation, kolors, text-to-image, txt2img, artistic, color\n\n    Use cases:\n    - Create vibrant colorful artwork\n    - Generate stylized illustrations\n    - Design visually striking content\n    - Produce artistic images\n    - Create color-rich visuals",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.Kolors",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "What to avoid in the generated image"
        },
        {
          "name": "image_size",
          "type": {
            "type": "enum",
            "values": [
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
          },
          "default": "square_hd",
          "title": "Image Size",
          "description": "The size of the generated image"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 25,
          "title": "Num Inference Steps",
          "description": "The number of inference steps",
          "min": 1.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 5.0,
          "title": "Guidance Scale",
          "description": "How closely to follow the prompt"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for reproducible generation"
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If true, the safety checker will be enabled"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "image_size",
        "guidance_scale"
      ]
    },
    {
      "title": "LCMDiffusion",
      "description": "Latent Consistency Models (SDXL & SDv1.5) Text to Image produces high-quality images\n    with minimal inference steps.",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.LCMDiffusion",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "model",
          "type": {
            "type": "enum",
            "values": [
              "sdxl",
              "sdv1-5"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.ModelNameLCM"
          },
          "default": "sdv1-5",
          "title": "Model",
          "description": "The model to use for generating the image"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "Use it to address details that you don't want in the image"
        },
        {
          "name": "image_size",
          "type": {
            "type": "enum",
            "values": [
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
          },
          "default": "square",
          "title": "Image Size",
          "description": "The size of the generated image"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 4,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform",
          "min": 1.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Guidance Scale",
          "description": "How closely the model should stick to your prompt"
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If true, the safety checker will be enabled"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed and prompt will output the same image every time"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "model",
        "guidance_scale"
      ]
    },
    {
      "title": "Luma Photon",
      "description": "Luma Photon is a creative and personalizable text-to-image model that brings a step-function\n    change in the cost of high-quality image generation, optimized for creatives.",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.LumaPhoton",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "aspect_ratio",
          "type": {
            "type": "enum",
            "values": [
              "16:9",
              "9:16",
              "1:1",
              "4:3",
              "3:4",
              "21:9",
              "9:21"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.AspectRatioLuma"
          },
          "default": "1:1",
          "title": "Aspect Ratio",
          "description": "The aspect ratio of the generated image"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "aspect_ratio"
      ]
    },
    {
      "title": "Luma Photon Flash",
      "description": "Luma Photon Flash is the most creative, personalizable, and intelligent visual model for creatives,\n    bringing a step-function change in the cost of high-quality image generation with faster inference times.",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.LumaPhotonFlash",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "aspect_ratio",
          "type": {
            "type": "enum",
            "values": [
              "16:9",
              "9:16",
              "1:1",
              "4:3",
              "3:4",
              "21:9",
              "9:21"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.AspectRatioLuma"
          },
          "default": "1:1",
          "title": "Aspect Ratio",
          "description": "The aspect ratio of the generated image"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "aspect_ratio"
      ]
    },
    {
      "title": "Omni Gen V1",
      "description": "OmniGen is a unified image generation model that can generate a wide range of images from multi-modal prompts. It can be used for various tasks such as Image Editing, Personalized Image Generation, Virtual Try-On, Multi Person Generation and more!\n    image, generation, multi-modal, editing, personalization, text-to-image, txt2img\n\n    Use cases:\n    - Edit and modify existing images\n    - Create personalized visual content\n    - Generate virtual try-on images\n    - Create multi-person compositions\n    - Combine multiple images creatively",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.OmniGenV1",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "input_image_1",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Input Image 1",
          "description": "The first input image to use for generation"
        },
        {
          "name": "input_image_2",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Input Image 2",
          "description": "The second input image to use for generation"
        },
        {
          "name": "image_size",
          "type": {
            "type": "enum",
            "values": [
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
          },
          "default": "square_hd",
          "title": "Image Size",
          "description": "The size of the generated image"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 50,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform",
          "min": 1.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 3.0,
          "title": "Guidance Scale",
          "description": "How closely the model should stick to your prompt"
        },
        {
          "name": "img_guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 1.6,
          "title": "Img Guidance Scale",
          "description": "How closely the model should stick to your input image"
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "The number of images to generate",
          "min": 1.0
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed and prompt will output the same image every time"
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If true, the safety checker will be enabled"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "input_image_1",
        "image_size"
      ]
    },
    {
      "title": "Playground V25",
      "description": "Playground v2.5 is a state-of-the-art open-source model that excels in aesthetic quality\n    for text-to-image generation.",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.PlaygroundV25",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "image_size",
          "type": {
            "type": "enum",
            "values": [
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
          },
          "default": "square_hd",
          "title": "Image Size",
          "description": "The size of the generated image"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 30,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform",
          "min": 1.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 7.5,
          "title": "Guidance Scale",
          "description": "How closely the model should stick to your prompt"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed and prompt will output the same image every time"
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If true, the safety checker will be enabled"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "image_size",
        "guidance_scale"
      ]
    },
    {
      "title": "Qwen Image Max",
      "description": "Qwen Image Max is Alibaba's advanced text-to-image model with exceptional quality and detail.\n    image, generation, qwen, alibaba, text-to-image, txt2img, high-quality\n\n    Use cases:\n    - Generate detailed images\n    - Create professional visuals\n    - Design marketing content\n    - Produce high-quality artwork\n    - Create commercial graphics",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.QwenImageMax",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "What to avoid in the generated image"
        },
        {
          "name": "image_size",
          "type": {
            "type": "enum",
            "values": [
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
          },
          "default": "square_hd",
          "title": "Image Size",
          "description": "The size of the generated image"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "image_size"
      ]
    },
    {
      "title": "Recraft 20B",
      "description": "Recraft 20B is a new and affordable text-to-image model that delivers state-of-the-art results.\n     image, generation, efficient, text-to-image, txt2img\n\n    Use cases:\n    - Generate cost-effective visuals\n    - Create high-quality images\n    - Produce professional artwork\n    - Design marketing materials\n    - Generate commercial content",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.Recraft20B",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "image_size",
          "type": {
            "type": "enum",
            "values": [
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
          },
          "default": "square_hd",
          "title": "Image Size",
          "description": "Either a preset size or a custom {width, height} dictionary"
        },
        {
          "name": "style",
          "type": {
            "type": "enum",
            "values": [
              "any",
              "realistic_image",
              "digital_illustration",
              "vector_illustration",
              "pixel_art",
              "flat_illustration",
              "isometric_illustration",
              "watercolor",
              "line_art",
              "pencil_drawing",
              "oil_painting",
              "anime",
              "comic_book",
              "retro",
              "sticker",
              "3d_render",
              "cinematic",
              "photographic",
              "clay",
              "cutout",
              "origami",
              "pattern",
              "pop_art",
              "renaissance",
              "studio_ghibli",
              "storybook"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.StylePreset"
          },
          "default": "realistic_image",
          "title": "Style",
          "description": "The style of the generated images. Vector images cost 2X as much."
        },
        {
          "name": "colors",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "color"
              }
            ]
          },
          "default": [],
          "title": "Colors",
          "description": "An array of preferable colors"
        },
        {
          "name": "style_id",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Style Id",
          "description": "The ID of the custom style reference (optional)"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "image_size",
        "style"
      ]
    },
    {
      "title": "Recraft V3",
      "description": "Recraft V3 is a text-to-image model with the ability to generate long texts, vector art, images in brand style, and much more.\n    image, text",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.RecraftV3",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "image_size",
          "type": {
            "type": "enum",
            "values": [
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
          },
          "default": "square_hd",
          "title": "Image Size",
          "description": "Either a preset size or a custom {width, height} dictionary. Max dimension 14142"
        },
        {
          "name": "style",
          "type": {
            "type": "enum",
            "values": [
              "any",
              "realistic_image",
              "digital_illustration",
              "vector_illustration",
              "pixel_art",
              "flat_illustration",
              "isometric_illustration",
              "watercolor",
              "line_art",
              "pencil_drawing",
              "oil_painting",
              "anime",
              "comic_book",
              "retro",
              "sticker",
              "3d_render",
              "cinematic",
              "photographic",
              "clay",
              "cutout",
              "origami",
              "pattern",
              "pop_art",
              "renaissance",
              "studio_ghibli",
              "storybook"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.StylePreset"
          },
          "default": "realistic_image",
          "title": "Style",
          "description": "The style of the generated images. Vector images cost 2X as much."
        },
        {
          "name": "colors",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "color"
              }
            ]
          },
          "default": [],
          "title": "Colors",
          "description": "An array of preferable colors"
        },
        {
          "name": "style_id",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Style Id",
          "description": "The ID of the custom style reference (optional)"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "image_size",
        "style"
      ]
    },
    {
      "title": "Reve",
      "description": "Reve is a creative text-to-image model with unique artistic capabilities and style.\n    image, generation, reve, text-to-image, txt2img, artistic, creative\n\n    Use cases:\n    - Create artistic illustrations\n    - Generate unique visual content\n    - Design creative artwork\n    - Produce stylized images\n    - Create imaginative visuals",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.Reve",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "What to avoid in the generated image"
        },
        {
          "name": "image_size",
          "type": {
            "type": "enum",
            "values": [
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
          },
          "default": "square_hd",
          "title": "Image Size",
          "description": "The size of the generated image"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 28,
          "title": "Num Inference Steps",
          "description": "The number of inference steps",
          "min": 1.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 3.5,
          "title": "Guidance Scale",
          "description": "How closely to follow the prompt"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "image_size",
        "guidance_scale"
      ]
    },
    {
      "title": "Sana V1",
      "description": "Sana can synthesize high-resolution, high-quality images with strong text-image alignment at a remarkably fast speed, with the ability to generate 4K images in less than a second.\n    image, generation, high-resolution, fast, text-alignment, text-to-image, txt2img\n\n    Use cases:\n    - Generate 4K quality images\n    - Create high-resolution artwork\n    - Produce rapid visual prototypes\n    - Design detailed illustrations\n    - Generate precise text-aligned visuals",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.SanaV1",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "Use it to address details that you don't want in the image"
        },
        {
          "name": "image_size",
          "type": {
            "type": "enum",
            "values": [
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
          },
          "default": "square_hd",
          "title": "Image Size",
          "description": "The size of the generated image"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 18,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform",
          "min": 1.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 5.0,
          "title": "Guidance Scale",
          "description": "How closely the model should stick to your prompt"
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "The number of images to generate",
          "min": 1.0
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed and prompt will output the same image every time"
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If true, the safety checker will be enabled"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "image_size",
        "guidance_scale"
      ]
    },
    {
      "title": "Seedream 45",
      "description": "ByteDance Seedream V4.5 is a state-of-the-art text-to-image model with exceptional detail and artistic quality.\n    image, generation, bytedance, seedream, text-to-image, txt2img, artistic\n\n    Use cases:\n    - Create high-quality digital art\n    - Generate photorealistic images\n    - Design marketing visuals\n    - Produce detailed illustrations\n    - Create professional graphics",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.Seedream45",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "What to avoid in the generated image"
        },
        {
          "name": "image_size",
          "type": {
            "type": "enum",
            "values": [
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
          },
          "default": "square_hd",
          "title": "Image Size",
          "description": "The size of the generated image"
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 5.0,
          "title": "Guidance Scale",
          "description": "How closely to follow the prompt"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "image_size",
        "guidance_scale"
      ]
    },
    {
      "title": "Stable Cascade",
      "description": "Stable Cascade is a state-of-the-art text-to-image model that generates images on a smaller & cheaper\n    latent space while maintaining high quality output.",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.StableCascade",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "Use it to address details that you don't want in the image"
        },
        {
          "name": "first_stage_steps",
          "type": {
            "type": "int"
          },
          "default": 20,
          "title": "First Stage Steps",
          "description": "Number of steps to run the first stage for"
        },
        {
          "name": "second_stage_steps",
          "type": {
            "type": "int"
          },
          "default": 10,
          "title": "Second Stage Steps",
          "description": "Number of steps to run the second stage for"
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 4.0,
          "title": "Guidance Scale",
          "description": "How closely the model should stick to your prompt"
        },
        {
          "name": "second_stage_guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 4.0,
          "title": "Second Stage Guidance Scale",
          "description": "Guidance scale for the second stage of generation"
        },
        {
          "name": "image_size",
          "type": {
            "type": "enum",
            "values": [
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
          },
          "default": "square_hd",
          "title": "Image Size",
          "description": "The size of the generated image"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed and prompt will output the same image every time"
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If true, the safety checker will be enabled"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "negative_prompt",
        "guidance_scale"
      ]
    },
    {
      "title": "Stable Diffusion V35 Large",
      "description": "Stable Diffusion 3.5 Large is a Multimodal Diffusion Transformer (MMDiT) text-to-image model that features\n    improved performance in image quality, typography, complex prompt understanding, and resource-efficiency.",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.StableDiffusionV35Large",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "Use it to address details that you don't want in the image"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 28,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform",
          "min": 1.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 3.5,
          "title": "Guidance Scale",
          "description": "How closely the model should stick to your prompt"
        },
        {
          "name": "image_size",
          "type": {
            "type": "enum",
            "values": [
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
          },
          "default": "landscape_4_3",
          "title": "Image Size",
          "description": "The size of the generated image"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed and prompt will output the same image every time"
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If true, the safety checker will be enabled"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "negative_prompt",
        "guidance_scale"
      ]
    },
    {
      "title": "Stable Diffusion V3 Medium",
      "description": "Stable Diffusion 3 Medium (Text to Image) is a Multimodal Diffusion Transformer (MMDiT) model\n    that improves image quality, typography, prompt understanding, and efficiency.",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.StableDiffusionV3Medium",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "The negative prompt to generate an image from"
        },
        {
          "name": "prompt_expansion",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Prompt Expansion",
          "description": "If set to true, prompt will be upsampled with more details"
        },
        {
          "name": "image_size",
          "type": {
            "type": "enum",
            "values": [
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
          },
          "default": "square_hd",
          "title": "Image Size",
          "description": "The size of the generated image"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 28,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform",
          "min": 1.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 5.0,
          "title": "Guidance Scale",
          "description": "How closely the model should stick to your prompt (CFG scale)"
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "The number of images to generate",
          "min": 1.0
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed and prompt will output the same image every time"
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If true, the safety checker will be enabled"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "negative_prompt",
        "guidance_scale"
      ]
    },
    {
      "title": "Switti",
      "description": "Switti is a scale-wise transformer for fast text-to-image generation that outperforms existing T2I AR models and competes with state-of-the-art T2I diffusion models while being faster than distilled diffusion models.\n    image, generation, fast, transformer, efficient, text-to-image, txt2img\n\n    Use cases:\n    - Rapid image prototyping\n    - Real-time image generation\n    - Quick visual concept testing\n    - Fast artistic visualization\n    - Efficient batch image creation",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.Switti",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "Use it to address details that you don't want in the image"
        },
        {
          "name": "sampling_top_k",
          "type": {
            "type": "int"
          },
          "default": 400,
          "title": "Sampling Top K",
          "description": "The number of top-k tokens to sample from"
        },
        {
          "name": "sampling_top_p",
          "type": {
            "type": "float"
          },
          "default": 0.95,
          "title": "Sampling Top P",
          "description": "The top-p probability to sample from"
        },
        {
          "name": "more_smooth",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "More Smooth",
          "description": "Smoothing with Gumbel softmax sampling"
        },
        {
          "name": "more_diverse",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "More Diverse",
          "description": "More diverse sampling"
        },
        {
          "name": "smooth_start_si",
          "type": {
            "type": "int"
          },
          "default": 2,
          "title": "Smooth Start Si",
          "description": "Smoothing starting scale"
        },
        {
          "name": "turn_off_cfg_start_si",
          "type": {
            "type": "int"
          },
          "default": 8,
          "title": "Turn Off Cfg Start Si",
          "description": "Disable CFG starting scale"
        },
        {
          "name": "last_scale_temp",
          "type": {
            "type": "float"
          },
          "default": 0.1,
          "title": "Last Scale Temp",
          "description": "Temperature after disabling CFG"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed and prompt will output the same image every time"
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 6.0,
          "title": "Guidance Scale",
          "description": "How closely the model should stick to your prompt"
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If true, the safety checker will be enabled"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "guidance_scale",
        "negative_prompt"
      ]
    },
    {
      "title": "ZImage Base",
      "description": "Generate high-quality images using the Z-Image Base model. Provides detailed image generation with multiple acceleration and quality options.\n    image, generation, text-to-image, z-image, detailed, quality\n\n    Use cases:\n    - Generate detailed images from text prompts\n    - Create high-quality artwork\n    - Produce professional illustrations\n    - Generate concept art\n    - Create visual content for projects",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.ZImageBase",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "image_size",
          "type": {
            "type": "enum",
            "values": [
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
          },
          "default": "landscape_4_3",
          "title": "Image Size",
          "description": "The size of the generated image"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 28,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed will output the same image every time"
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "The number of images to generate"
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If true, the safety checker will be enabled"
        },
        {
          "name": "output_format",
          "type": {
            "type": "enum",
            "values": [
              "jpeg",
              "png",
              "webp"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.OutputFormat"
          },
          "default": "png",
          "title": "Output Format",
          "description": "The format of the generated image"
        },
        {
          "name": "acceleration",
          "type": {
            "type": "enum",
            "values": [
              "none",
              "regular",
              "high"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.ZImageAcceleration"
          },
          "default": "regular",
          "title": "Acceleration",
          "description": "The acceleration level to use"
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 4.0,
          "title": "Guidance Scale",
          "description": "The guidance scale to use for image generation"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "The negative prompt to use for image generation"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "image_size",
        "num_inference_steps"
      ]
    },
    {
      "title": "ZImage Base Lora",
      "description": "Generate high-quality images using the Z-Image Base model with LoRA support. Allows fine-tuned image generation with custom LoRA models.\n    image, generation, text-to-image, z-image, lora, fine-tuning\n\n    Use cases:\n    - Generate images with custom LoRA fine-tuning\n    - Create specialized style images\n    - Produce character-consistent artwork\n    - Generate images matching specific aesthetics\n    - Create brand-aligned visual content",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.ZImageBaseLora",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "image_size",
          "type": {
            "type": "enum",
            "values": [
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
          },
          "default": "landscape_4_3",
          "title": "Image Size",
          "description": "The size of the generated image"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 28,
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "The same seed will output the same image every time"
        },
        {
          "name": "num_images",
          "type": {
            "type": "int"
          },
          "default": 1,
          "title": "Num Images",
          "description": "The number of images to generate"
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "If true, the safety checker will be enabled"
        },
        {
          "name": "output_format",
          "type": {
            "type": "enum",
            "values": [
              "jpeg",
              "png",
              "webp"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.OutputFormat"
          },
          "default": "png",
          "title": "Output Format",
          "description": "The format of the generated image"
        },
        {
          "name": "acceleration",
          "type": {
            "type": "enum",
            "values": [
              "none",
              "regular",
              "high"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.ZImageAcceleration"
          },
          "default": "regular",
          "title": "Acceleration",
          "description": "The acceleration level to use"
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 4.0,
          "title": "Guidance Scale",
          "description": "The guidance scale to use for image generation"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "The negative prompt to use for image generation"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "image_size",
        "num_inference_steps"
      ]
    },
    {
      "title": "ZImage Turbo",
      "description": "Z-Image Turbo is a fast text-to-image model optimized for quick generation with good quality.\n    image, generation, z-image, text-to-image, txt2img, fast, turbo\n\n    Use cases:\n    - Rapid image generation\n    - Quick prototyping\n    - High-volume content creation\n    - Fast design iterations\n    - Real-time applications",
      "namespace": "fal.text_to_image",
      "node_type": "fal.text_to_image.ZImageTurbo",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt to generate an image from"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "What to avoid in the generated image"
        },
        {
          "name": "image_size",
          "type": {
            "type": "enum",
            "values": [
              "square_hd",
              "square",
              "portrait_4_3",
              "portrait_16_9",
              "landscape_4_3",
              "landscape_16_9"
            ],
            "type_name": "nodetool.nodes.fal.text_to_image.ImageSizePreset"
          },
          "default": "square_hd",
          "title": "Image Size",
          "description": "The size of the generated image"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 4,
          "title": "Num Inference Steps",
          "description": "The number of inference steps",
          "min": 1.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "image"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "image_size",
        "num_inference_steps"
      ]
    },
    {
      "title": "Hunyuan Video",
      "description": "Hunyuan Video generates videos from text prompts using Tencent's model.\n    video, generation, hunyuan, tencent, text-to-video\n\n    Use cases:\n    - Create videos from descriptions\n    - Generate animated content\n    - Produce motion graphics\n    - Create promotional clips\n    - Generate concept videos",
      "namespace": "fal.text_to_video",
      "node_type": "fal.text_to_video.HunyuanVideo",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt describing the desired video"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 30,
          "title": "Num Inference Steps",
          "description": "Number of inference steps",
          "min": 1.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 7.0,
          "title": "Guidance Scale",
          "description": "How closely to follow the prompt"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for reproducible generation"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "guidance_scale"
      ]
    },
    {
      "title": "Hunyuan Video V15 Text To Video",
      "description": "Hunyuan Video V1.5 Text-to-Video with improved quality and motion.\n    video, generation, hunyuan, v1.5, text-to-video\n\n    Use cases:\n    - Create high-quality video content\n    - Generate smooth animations\n    - Produce professional videos\n    - Create motion graphics\n    - Generate video effects",
      "namespace": "fal.text_to_video",
      "node_type": "fal.text_to_video.HunyuanVideoV15TextToVideo",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt describing the desired video"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 30,
          "title": "Num Inference Steps",
          "description": "Number of inference steps",
          "min": 1.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 7.0,
          "title": "Guidance Scale",
          "description": "How closely to follow the prompt"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for reproducible generation"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "guidance_scale"
      ]
    },
    {
      "title": "Kandinsky 5 Text To Video",
      "description": "Kandinsky 5 Text-to-Video generates creative videos from text prompts.\n    video, generation, kandinsky, text-to-video, artistic\n\n    Use cases:\n    - Create artistic video content\n    - Generate creative animations\n    - Produce stylized videos\n    - Create video art\n    - Generate experimental content",
      "namespace": "fal.text_to_video",
      "node_type": "fal.text_to_video.Kandinsky5TextToVideo",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt describing the desired video"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "What to avoid in the generated video"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 50,
          "title": "Num Inference Steps",
          "description": "Number of inference steps",
          "min": 1.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 4.0,
          "title": "Guidance Scale",
          "description": "How closely to follow the prompt"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for reproducible generation"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "guidance_scale"
      ]
    },
    {
      "title": "Kling O3 Pro Text To Video",
      "description": "Generate premium cinematic videos with Kling Video O3 Pro featuring higher-end customization and storyboard-first creation.\n    video, generation, kling, o3, pro, text-to-video, premium, storyboard\n\n    Use cases:\n    - Create professional multi-shot sequences\n    - Generate premium story-driven content\n    - Produce high-quality character-consistent videos\n    - Create broadcast-quality narrative videos\n    - Generate cinematic content with advanced controls",
      "namespace": "fal.text_to_video",
      "node_type": "fal.text_to_video.KlingO3ProTextToVideo",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The text prompt describing the desired video"
        },
        {
          "name": "duration",
          "type": {
            "type": "enum",
            "values": [
              "3",
              "4",
              "5",
              "6",
              "7",
              "8",
              "9",
              "10",
              "11",
              "12",
              "13",
              "14",
              "15"
            ],
            "type_name": "nodetool.nodes.fal.text_to_video.Kling3Duration"
          },
          "default": "5",
          "title": "Duration",
          "description": "The duration of the generated video in seconds (3-15)"
        },
        {
          "name": "aspect_ratio",
          "type": {
            "type": "enum",
            "values": [
              "16:9",
              "9:16",
              "1:1"
            ],
            "type_name": "nodetool.nodes.fal.text_to_video.Kling3AspectRatio"
          },
          "default": "16:9",
          "title": "Aspect Ratio",
          "description": "The aspect ratio of the generated video"
        },
        {
          "name": "generate_audio",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Generate Audio",
          "description": "Generate native audio for the video"
        },
        {
          "name": "voice_ids",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "str"
              }
            ]
          },
          "default": [],
          "title": "Voice Ids",
          "description": "Voice IDs for audio. Reference in prompt with <<<voice_1>>> (max 2 voices)"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "duration",
        "aspect_ratio"
      ]
    },
    {
      "title": "Kling O3 Text To Video",
      "description": "Generate cinematic videos with Kling Video O3 Standard supporting storyboard-first creation and character consistency.\n    video, generation, kling, o3, text-to-video, storyboard, cinematic\n\n    Use cases:\n    - Create multi-shot video sequences\n    - Generate story-driven content\n    - Produce character-consistent videos\n    - Create structured narrative videos\n    - Generate cinematic sequences with continuity",
      "namespace": "fal.text_to_video",
      "node_type": "fal.text_to_video.KlingO3TextToVideo",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The text prompt describing the desired video"
        },
        {
          "name": "duration",
          "type": {
            "type": "enum",
            "values": [
              "3",
              "4",
              "5",
              "6",
              "7",
              "8",
              "9",
              "10",
              "11",
              "12",
              "13",
              "14",
              "15"
            ],
            "type_name": "nodetool.nodes.fal.text_to_video.Kling3Duration"
          },
          "default": "5",
          "title": "Duration",
          "description": "The duration of the generated video in seconds (3-15)"
        },
        {
          "name": "aspect_ratio",
          "type": {
            "type": "enum",
            "values": [
              "16:9",
              "9:16",
              "1:1"
            ],
            "type_name": "nodetool.nodes.fal.text_to_video.Kling3AspectRatio"
          },
          "default": "16:9",
          "title": "Aspect Ratio",
          "description": "The aspect ratio of the generated video"
        },
        {
          "name": "generate_audio",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Generate Audio",
          "description": "Generate native audio for the video"
        },
        {
          "name": "voice_ids",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "str"
              }
            ]
          },
          "default": [],
          "title": "Voice Ids",
          "description": "Voice IDs for audio. Reference in prompt with <<<voice_1>>> (max 2 voices)"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "duration",
        "aspect_ratio"
      ]
    },
    {
      "title": "Kling Text To Video V2",
      "description": "Generate videos directly from text prompts using Kling Video V2 Master.\n    video, generation, animation, text-to-video, kling-v2\n\n    Use cases:\n    - Visualize scripts or storyboards\n    - Produce short promotional videos from text\n    - Create animated social media content\n    - Generate concept previews for film ideas\n    - Produce text-driven motion graphics",
      "namespace": "fal.text_to_video",
      "node_type": "fal.text_to_video.KlingTextToVideoV2",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt describing the desired video"
        },
        {
          "name": "duration",
          "type": {
            "type": "enum",
            "values": [
              "5",
              "10"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.KlingDuration"
          },
          "default": "5",
          "title": "Duration",
          "description": "The duration of the generated video"
        },
        {
          "name": "aspect_ratio",
          "type": {
            "type": "enum",
            "values": [
              "16:9",
              "9:16",
              "4:3",
              "3:4",
              "21:9",
              "9:21",
              "1:1"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.AspectRatio"
          },
          "default": "16:9",
          "title": "Aspect Ratio",
          "description": "The aspect ratio of the generated video frame"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "blur, distort, and low quality",
          "title": "Negative Prompt",
          "description": "Negative prompt to be used for the generation"
        },
        {
          "name": "cfg_scale",
          "type": {
            "type": "float"
          },
          "default": 0.5,
          "title": "Cfg Scale",
          "description": "Classifier Free Guidance scale (0.0 to 1.0)",
          "min": 0.0,
          "max": 1.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "duration"
      ]
    },
    {
      "title": "Kling V3 Pro Text To Video",
      "description": "Generate premium quality videos from text prompts using Kling Video 3.0 Pro with enhanced quality and performance.\n    video, generation, kling, v3, pro, text-to-video, premium\n\n    Use cases:\n    - Create high-end promotional content\n    - Generate professional cinematic sequences\n    - Produce premium marketing videos\n    - Create detailed visual narratives\n    - Generate broadcast-quality content",
      "namespace": "fal.text_to_video",
      "node_type": "fal.text_to_video.KlingV3ProTextToVideo",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The text prompt describing the desired video"
        },
        {
          "name": "duration",
          "type": {
            "type": "enum",
            "values": [
              "3",
              "4",
              "5",
              "6",
              "7",
              "8",
              "9",
              "10",
              "11",
              "12",
              "13",
              "14",
              "15"
            ],
            "type_name": "nodetool.nodes.fal.text_to_video.Kling3Duration"
          },
          "default": "5",
          "title": "Duration",
          "description": "The duration of the generated video in seconds (3-15)"
        },
        {
          "name": "aspect_ratio",
          "type": {
            "type": "enum",
            "values": [
              "16:9",
              "9:16",
              "1:1"
            ],
            "type_name": "nodetool.nodes.fal.text_to_video.Kling3AspectRatio"
          },
          "default": "16:9",
          "title": "Aspect Ratio",
          "description": "The aspect ratio of the generated video"
        },
        {
          "name": "generate_audio",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Generate Audio",
          "description": "Generate native audio for the video (supports Chinese/English)"
        },
        {
          "name": "voice_ids",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "str"
              }
            ]
          },
          "default": [],
          "title": "Voice Ids",
          "description": "Voice IDs for audio. Reference in prompt with <<<voice_1>>> (max 2 voices)"
        },
        {
          "name": "shot_type",
          "type": {
            "type": "enum",
            "values": [
              "customize",
              "intelligent"
            ],
            "type_name": "nodetool.nodes.fal.text_to_video.Kling3ShotType"
          },
          "default": "customize",
          "title": "Shot Type",
          "description": "Shot type for multi-shot generation"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "blur, distort, and low quality",
          "title": "Negative Prompt",
          "description": "What to avoid in the generated video"
        },
        {
          "name": "cfg_scale",
          "type": {
            "type": "float"
          },
          "default": 0.5,
          "title": "Cfg Scale",
          "description": "Classifier Free Guidance scale (0.0 to 1.0)",
          "min": 0.0,
          "max": 1.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "duration",
        "aspect_ratio"
      ]
    },
    {
      "title": "Kling V3 Text To Video",
      "description": "Generate high-quality videos from text prompts using Kling Video 3.0 Standard with improved motion and realistic acting.\n    video, generation, kling, v3, text-to-video, cinematic\n\n    Use cases:\n    - Create cinematic video clips from descriptions\n    - Generate marketing and promotional videos\n    - Produce dynamic social media content\n    - Visualize creative concepts and storyboards\n    - Create professional video content",
      "namespace": "fal.text_to_video",
      "node_type": "fal.text_to_video.KlingV3TextToVideo",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The text prompt describing the desired video"
        },
        {
          "name": "duration",
          "type": {
            "type": "enum",
            "values": [
              "3",
              "4",
              "5",
              "6",
              "7",
              "8",
              "9",
              "10",
              "11",
              "12",
              "13",
              "14",
              "15"
            ],
            "type_name": "nodetool.nodes.fal.text_to_video.Kling3Duration"
          },
          "default": "5",
          "title": "Duration",
          "description": "The duration of the generated video in seconds (3-15)"
        },
        {
          "name": "aspect_ratio",
          "type": {
            "type": "enum",
            "values": [
              "16:9",
              "9:16",
              "1:1"
            ],
            "type_name": "nodetool.nodes.fal.text_to_video.Kling3AspectRatio"
          },
          "default": "16:9",
          "title": "Aspect Ratio",
          "description": "The aspect ratio of the generated video"
        },
        {
          "name": "generate_audio",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Generate Audio",
          "description": "Generate native audio for the video (supports Chinese/English)"
        },
        {
          "name": "voice_ids",
          "type": {
            "type": "list",
            "type_args": [
              {
                "type": "str"
              }
            ]
          },
          "default": [],
          "title": "Voice Ids",
          "description": "Voice IDs for audio. Reference in prompt with <<<voice_1>>> (max 2 voices)"
        },
        {
          "name": "shot_type",
          "type": {
            "type": "enum",
            "values": [
              "customize",
              "intelligent"
            ],
            "type_name": "nodetool.nodes.fal.text_to_video.Kling3ShotType"
          },
          "default": "customize",
          "title": "Shot Type",
          "description": "Shot type for multi-shot generation"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "blur, distort, and low quality",
          "title": "Negative Prompt",
          "description": "What to avoid in the generated video"
        },
        {
          "name": "cfg_scale",
          "type": {
            "type": "float"
          },
          "default": 0.5,
          "title": "Cfg Scale",
          "description": "Classifier Free Guidance scale (0.0 to 1.0)",
          "min": 0.0,
          "max": 1.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "duration",
        "aspect_ratio"
      ]
    },
    {
      "title": "Kling Video V2",
      "description": "Generate videos from images using Kling Video V2 Master. Create smooth and realistic animations from a single frame.\n    video, generation, animation, img2vid, kling-v2\n\n    Use cases:\n    - Convert artwork into animated clips\n    - Produce dynamic marketing visuals\n    - Generate motion graphics from static scenes\n    - Create short cinematic sequences\n    - Enhance presentations with video content",
      "namespace": "fal.text_to_video",
      "node_type": "fal.text_to_video.KlingVideoV2",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The image to transform into a video"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "A description of the desired video motion and style"
        },
        {
          "name": "duration",
          "type": {
            "type": "enum",
            "values": [
              "5",
              "10"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.KlingDuration"
          },
          "default": "5",
          "title": "Duration",
          "description": "The duration of the generated video"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "blur, distort, and low quality",
          "title": "Negative Prompt",
          "description": "Negative prompt to be used for the generation"
        },
        {
          "name": "cfg_scale",
          "type": {
            "type": "float"
          },
          "default": 0.5,
          "title": "Cfg Scale",
          "description": "Classifier Free Guidance scale (0.0 to 1.0)",
          "min": 0.0,
          "max": 1.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt",
        "duration"
      ]
    },
    {
      "title": "Kling Video V21 Text To Video",
      "description": "Kling Video V2.1 Master Text-to-Video with enhanced quality and motion.\n    video, generation, kling, v2.1, text-to-video\n\n    Use cases:\n    - Create professional video content\n    - Generate high-quality animations\n    - Produce cinematic clips\n    - Create promotional videos\n    - Generate concept previews",
      "namespace": "fal.text_to_video",
      "node_type": "fal.text_to_video.KlingVideoV21TextToVideo",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt describing the desired video"
        },
        {
          "name": "duration",
          "type": {
            "type": "enum",
            "values": [
              "5",
              "10"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.KlingDuration"
          },
          "default": "5",
          "title": "Duration",
          "description": "The duration of the generated video"
        },
        {
          "name": "aspect_ratio",
          "type": {
            "type": "enum",
            "values": [
              "16:9",
              "9:16",
              "4:3",
              "3:4",
              "21:9",
              "9:21",
              "1:1"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.AspectRatio"
          },
          "default": "16:9",
          "title": "Aspect Ratio",
          "description": "The aspect ratio of the generated video"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "duration"
      ]
    },
    {
      "title": "LTX2 Text To Video",
      "description": "LTX 2 Text-to-Video generates videos from text with the LTX model.\n    video, generation, ltx, text-to-video\n\n    Use cases:\n    - Create videos from descriptions\n    - Generate animated content\n    - Produce motion graphics\n    - Create video clips\n    - Generate promotional content",
      "namespace": "fal.text_to_video",
      "node_type": "fal.text_to_video.LTX2TextToVideo",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt describing the desired video"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "What to avoid in the generated video"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 30,
          "title": "Num Inference Steps",
          "description": "Number of inference steps",
          "min": 1.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 3.0,
          "title": "Guidance Scale",
          "description": "How closely to follow the prompt"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for reproducible generation"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "guidance_scale"
      ]
    },
    {
      "title": "Luma Ray 2 Flash Text To Video",
      "description": "Luma Ray 2 Flash Text-to-Video is a fast version for quick video generation.\n    video, generation, luma, ray2, flash, text-to-video, fast\n\n    Use cases:\n    - Quick video prototyping\n    - Rapid content creation\n    - Fast video iterations\n    - Real-time video generation\n    - Quick concept tests",
      "namespace": "fal.text_to_video",
      "node_type": "fal.text_to_video.LumaRay2FlashTextToVideo",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt describing the desired video"
        },
        {
          "name": "aspect_ratio",
          "type": {
            "type": "enum",
            "values": [
              "16:9",
              "9:16",
              "4:3",
              "3:4",
              "21:9",
              "9:21",
              "1:1"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.AspectRatio"
          },
          "default": "16:9",
          "title": "Aspect Ratio",
          "description": "The aspect ratio of the generated video"
        },
        {
          "name": "resolution",
          "type": {
            "type": "enum",
            "values": [
              "540p",
              "720p",
              "1080p"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.LumaRay2Resolution"
          },
          "default": "540p",
          "title": "Resolution",
          "description": "The resolution of the generated video"
        },
        {
          "name": "duration",
          "type": {
            "type": "enum",
            "values": [
              "5s",
              "9s"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.LumaRay2Duration"
          },
          "default": "5s",
          "title": "Duration",
          "description": "The duration of the generated video"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for reproducible generation"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "aspect_ratio",
        "duration",
        "resolution"
      ]
    },
    {
      "title": "Luma Ray 2 Text To Video",
      "description": "Luma Ray 2 Text-to-Video generates high-quality videos from text prompts.\n    video, generation, luma, ray2, text-to-video, txt2vid\n\n    Use cases:\n    - Create videos from descriptions\n    - Generate cinematic content\n    - Produce creative videos\n    - Create marketing clips\n    - Generate concept videos",
      "namespace": "fal.text_to_video",
      "node_type": "fal.text_to_video.LumaRay2TextToVideo",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt describing the desired video"
        },
        {
          "name": "aspect_ratio",
          "type": {
            "type": "enum",
            "values": [
              "16:9",
              "9:16",
              "4:3",
              "3:4",
              "21:9",
              "9:21",
              "1:1"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.AspectRatio"
          },
          "default": "16:9",
          "title": "Aspect Ratio",
          "description": "The aspect ratio of the generated video"
        },
        {
          "name": "loop",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Loop",
          "description": "Whether the video should loop"
        },
        {
          "name": "resolution",
          "type": {
            "type": "enum",
            "values": [
              "540p",
              "720p",
              "1080p"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.LumaRay2Resolution"
          },
          "default": "540p",
          "title": "Resolution",
          "description": "The resolution of the generated video"
        },
        {
          "name": "duration",
          "type": {
            "type": "enum",
            "values": [
              "5s",
              "9s"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.LumaRay2Duration"
          },
          "default": "5s",
          "title": "Duration",
          "description": "The duration of the generated video"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for reproducible generation"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "aspect_ratio",
        "duration",
        "resolution"
      ]
    },
    {
      "title": "Mini Max Hailuo 23 Text To Video",
      "description": "MiniMax Hailuo 2.3 Standard Text-to-Video with improved quality.\n    video, generation, minimax, hailuo, 2.3, text-to-video\n\n    Use cases:\n    - Create videos from text\n    - Generate smooth animations\n    - Produce video content\n    - Create motion graphics\n    - Generate promotional clips",
      "namespace": "fal.text_to_video",
      "node_type": "fal.text_to_video.MiniMaxHailuo23TextToVideo",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt describing the desired video"
        },
        {
          "name": "prompt_optimizer",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Prompt Optimizer",
          "description": "Whether to use the prompt optimizer"
        },
        {
          "name": "duration",
          "type": {
            "type": "enum",
            "values": [
              "6",
              "10"
            ],
            "type_name": "nodetool.nodes.fal.text_to_video.MiniMaxDuration"
          },
          "default": "6",
          "title": "Duration",
          "description": "The duration of the video in seconds"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for reproducible generation"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "duration"
      ]
    },
    {
      "title": "Mochi V1",
      "description": "Mochi V1 generates creative videos from text prompts with unique style.\n    video, generation, mochi, text-to-video, creative\n\n    Use cases:\n    - Create creative video content\n    - Generate artistic animations\n    - Produce stylized videos\n    - Create experimental clips\n    - Generate unique video effects",
      "namespace": "fal.text_to_video",
      "node_type": "fal.text_to_video.MochiV1",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt describing the desired video"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "What to avoid in the generated video"
        },
        {
          "name": "num_inference_steps",
          "type": {
            "type": "int"
          },
          "default": 50,
          "title": "Num Inference Steps",
          "description": "Number of inference steps",
          "min": 1.0
        },
        {
          "name": "guidance_scale",
          "type": {
            "type": "float"
          },
          "default": 4.5,
          "title": "Guidance Scale",
          "description": "How closely to follow the prompt"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for reproducible generation"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "guidance_scale"
      ]
    },
    {
      "title": "Pika V21 Text To Video",
      "description": "Pika V2.1 Text-to-Video generates videos from text prompts.\n    video, generation, pika, v2.1, text-to-video\n\n    Use cases:\n    - Create video content from text\n    - Generate animated clips\n    - Produce motion graphics\n    - Create video effects\n    - Generate promotional content",
      "namespace": "fal.text_to_video",
      "node_type": "fal.text_to_video.PikaV21TextToVideo",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt describing the desired video"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for reproducible generation"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt"
      ]
    },
    {
      "title": "Pika V22 Text To Video",
      "description": "Pika V2.2 Text-to-Video generates creative videos from text prompts.\n    video, generation, pika, v2.2, text-to-video, creative\n\n    Use cases:\n    - Create creative video content\n    - Generate artistic animations\n    - Produce stylized videos\n    - Create unique video clips\n    - Generate experimental content",
      "namespace": "fal.text_to_video",
      "node_type": "fal.text_to_video.PikaV22TextToVideo",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt describing the desired video"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "What to avoid in the generated video"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for reproducible generation"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt"
      ]
    },
    {
      "title": "Pixverse Effects",
      "description": "Apply text-driven effects to a video with Pixverse 4.5.\n    video, effects, pixverse, text-guided\n\n    Use cases:\n    - Stylize existing footage\n    - Add visual effects via text\n    - Enhance marketing videos\n    - Create experimental clips\n    - Transform user content",
      "namespace": "fal.text_to_video",
      "node_type": "fal.text_to_video.PixverseEffects",
      "properties": [
        {
          "name": "video",
          "type": {
            "type": "video"
          },
          "default": {
            "type": "video",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null,
            "duration": null,
            "format": null
          },
          "title": "Video",
          "description": "The source video"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "Text describing the effect"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Optional seed for deterministic output"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "video",
        "prompt"
      ]
    },
    {
      "title": "Pixverse Image To Video",
      "description": "Animate an image into a video using Pixverse 4.5.\n    video, generation, pixverse, image-to-video\n\n    Use cases:\n    - Bring photos to life\n    - Create moving artwork\n    - Generate short clips from images\n    - Produce social media animations\n    - Experiment with visual storytelling",
      "namespace": "fal.text_to_video",
      "node_type": "fal.text_to_video.PixverseImageToVideo",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The source image"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "Optional style or motion prompt"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Optional seed for deterministic output"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "Pixverse Text To Video",
      "description": "Generate videos from text prompts with Pixverse 4.5 API.\n    video, generation, pixverse, text-to-video\n\n    Use cases:\n    - Create animated scenes from text\n    - Generate marketing clips\n    - Produce dynamic social posts\n    - Prototype video ideas\n    - Explore creative storytelling",
      "namespace": "fal.text_to_video",
      "node_type": "fal.text_to_video.PixverseTextToVideo",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt describing the video"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Optional seed for deterministic output"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt"
      ]
    },
    {
      "title": "Pixverse Text To Video Fast",
      "description": "Generate videos quickly from text prompts with Pixverse 4.5 Fast.\n    video, generation, pixverse, text-to-video, fast\n\n    Use cases:\n    - Rapid video prototyping\n    - Generate quick social posts\n    - Produce short marketing clips\n    - Test creative ideas fast\n    - Create video drafts",
      "namespace": "fal.text_to_video",
      "node_type": "fal.text_to_video.PixverseTextToVideoFast",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt describing the video"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Optional seed for deterministic output"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt"
      ]
    },
    {
      "title": "Pixverse Transition",
      "description": "Apply Pixverse transitions between images.\n    video, generation, transition, pixverse\n\n    Use cases:\n    - Blend between two images\n    - Create animated transitions\n    - Generate morphing effects\n    - Produce smooth scene changes\n    - Experiment with visual flows",
      "namespace": "fal.text_to_video",
      "node_type": "fal.text_to_video.PixverseTransition",
      "properties": [
        {
          "name": "start_image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Start Image",
          "description": "The starting image"
        },
        {
          "name": "end_image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "End Image",
          "description": "The ending image"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Optional seed for deterministic output"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "start_image",
        "end_image"
      ]
    },
    {
      "title": "Pixverse V56 Text To Video",
      "description": "Generate high-quality videos from text prompts with Pixverse v5.6.\n    video, generation, pixverse, v5.6, text-to-video, creative\n\n    Use cases:\n    - Create professional animated scenes from descriptions\n    - Generate marketing and promotional videos\n    - Produce dynamic social media content\n    - Prototype video concepts with various styles\n    - Create stylized video content with anime or cyberpunk themes",
      "namespace": "fal.text_to_video",
      "node_type": "fal.text_to_video.PixverseV56TextToVideo",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The text prompt describing the desired video"
        },
        {
          "name": "aspect_ratio",
          "type": {
            "type": "enum",
            "values": [
              "16:9",
              "4:3",
              "1:1",
              "3:4",
              "9:16"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.PixverseV56AspectRatio"
          },
          "default": "16:9",
          "title": "Aspect Ratio",
          "description": "The aspect ratio of the generated video"
        },
        {
          "name": "resolution",
          "type": {
            "type": "enum",
            "values": [
              "360p",
              "540p",
              "720p",
              "1080p"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.PixverseV56Resolution"
          },
          "default": "720p",
          "title": "Resolution",
          "description": "The resolution quality of the output video"
        },
        {
          "name": "duration",
          "type": {
            "type": "enum",
            "values": [
              "5",
              "8",
              "10"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.PixverseV56Duration"
          },
          "default": "5",
          "title": "Duration",
          "description": "The duration of the generated video in seconds"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "What to avoid in the generated video"
        },
        {
          "name": "style",
          "type": {
            "type": "enum",
            "optional": true,
            "values": [
              "anime",
              "3d_animation",
              "clay",
              "comic",
              "cyberpunk"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.PixverseV56Style"
          },
          "default": null,
          "title": "Style",
          "description": "Optional visual style for the video"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Optional seed for reproducible generation"
        },
        {
          "name": "generate_audio_switch",
          "type": {
            "type": "bool",
            "optional": true
          },
          "default": null,
          "title": "Generate Audio Switch",
          "description": "Whether to generate audio for the video"
        },
        {
          "name": "thinking_type",
          "type": {
            "type": "enum",
            "optional": true,
            "values": [
              "enabled",
              "disabled",
              "auto"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.PixverseV56ThinkingType"
          },
          "default": null,
          "title": "Thinking Type",
          "description": "Thinking mode for video generation"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "resolution",
        "duration"
      ]
    },
    {
      "title": "Pixverse V56 Transition",
      "description": "Create smooth transitions between images with Pixverse v5.6.\n    video, generation, transition, pixverse, v5.6, morphing\n\n    Use cases:\n    - Create seamless transitions between two images\n    - Generate morphing effects for presentations\n    - Produce smooth scene changes for videos\n    - Create animated visual flows\n    - Generate creative blending effects",
      "namespace": "fal.text_to_video",
      "node_type": "fal.text_to_video.PixverseV56Transition",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "Text prompt describing the transition style"
        },
        {
          "name": "first_image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "First Image",
          "description": "The starting image for the transition"
        },
        {
          "name": "end_image",
          "type": {
            "type": "image",
            "optional": true
          },
          "default": null,
          "title": "End Image",
          "description": "Optional ending image for the transition"
        },
        {
          "name": "aspect_ratio",
          "type": {
            "type": "enum",
            "values": [
              "16:9",
              "4:3",
              "1:1",
              "3:4",
              "9:16"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.PixverseV56AspectRatio"
          },
          "default": "16:9",
          "title": "Aspect Ratio",
          "description": "The aspect ratio of the generated video"
        },
        {
          "name": "resolution",
          "type": {
            "type": "enum",
            "values": [
              "360p",
              "540p",
              "720p",
              "1080p"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.PixverseV56Resolution"
          },
          "default": "720p",
          "title": "Resolution",
          "description": "The resolution quality of the output video"
        },
        {
          "name": "duration",
          "type": {
            "type": "int"
          },
          "default": 5,
          "title": "Duration",
          "description": "Duration in seconds (5 or 8)",
          "min": 5.0,
          "max": 8.0
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "What to avoid in the generated transition"
        },
        {
          "name": "style",
          "type": {
            "type": "enum",
            "optional": true,
            "values": [
              "anime",
              "3d_animation",
              "clay",
              "comic",
              "cyberpunk"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.PixverseV56Style"
          },
          "default": null,
          "title": "Style",
          "description": "Optional visual style for the transition"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Optional seed for reproducible generation"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "first_image",
        "resolution"
      ]
    },
    {
      "title": "Sora 2 Text To Video",
      "description": "OpenAI Sora 2 Text-to-Video generates high-quality videos from text.\n    video, generation, openai, sora, sora2, text-to-video\n\n    Use cases:\n    - Create cinematic videos from text\n    - Generate realistic motion\n    - Produce professional video content\n    - Create video narratives\n    - Generate concept videos",
      "namespace": "fal.text_to_video",
      "node_type": "fal.text_to_video.Sora2TextToVideo",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt describing the desired video"
        },
        {
          "name": "aspect_ratio",
          "type": {
            "type": "enum",
            "values": [
              "16:9",
              "9:16",
              "4:3",
              "3:4",
              "21:9",
              "9:21",
              "1:1"
            ],
            "type_name": "nodetool.nodes.fal.image_to_video.AspectRatio"
          },
          "default": "16:9",
          "title": "Aspect Ratio",
          "description": "The aspect ratio of the generated video"
        },
        {
          "name": "duration",
          "type": {
            "type": "enum",
            "values": [
              4,
              8,
              12
            ],
            "type_name": "nodetool.nodes.fal.text_to_video.Sora2Duration"
          },
          "default": 4,
          "title": "Duration",
          "description": "Duration of the video in seconds"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Seed for reproducible generation"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "duration"
      ]
    },
    {
      "title": "Veo 3",
      "description": "Generate high-quality videos from text prompts with Google's Veo 3 model.\n    video, generation, text-to-video, prompt, audio\n\n    Use cases:\n    - Produce short cinematic clips from descriptions\n    - Create social media videos\n    - Generate visual storyboards\n    - Experiment with video concepts\n    - Produce marketing content",
      "namespace": "fal.text_to_video",
      "node_type": "fal.text_to_video.Veo3",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The text prompt describing the video you want to generate"
        },
        {
          "name": "aspect_ratio",
          "type": {
            "type": "enum",
            "values": [
              "16:9",
              "9:16"
            ],
            "type_name": "nodetool.nodes.fal.text_to_video.Veo3AspectRatio"
          },
          "default": "16:9",
          "title": "Aspect Ratio",
          "description": "The aspect ratio of the generated video."
        },
        {
          "name": "duration",
          "type": {
            "type": "enum",
            "values": [
              "4s",
              "6s",
              "8s"
            ],
            "type_name": "nodetool.nodes.fal.text_to_video.Veo3Duration"
          },
          "default": "8s",
          "title": "Duration",
          "description": "The duration of the generated video in seconds"
        },
        {
          "name": "resolution",
          "type": {
            "type": "enum",
            "values": [
              "720p",
              "1080p"
            ],
            "type_name": "nodetool.nodes.fal.text_to_video.Veo3Resolution"
          },
          "default": "720p",
          "title": "Resolution",
          "description": "The resolution of the generated video"
        },
        {
          "name": "generate_audio",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Generate Audio",
          "description": "Whether to generate audio for the video. If false, %33 less credits will be used."
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "A seed to use for the video generation"
        },
        {
          "name": "negative_prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Negative Prompt",
          "description": "A negative prompt to guide the video generation"
        },
        {
          "name": "auto_fix",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Auto Fix",
          "description": "Whether to automatically attempt to fix prompts"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt",
        "aspect_ratio",
        "duration"
      ]
    },
    {
      "title": "Wan Flf 2V",
      "description": "Generate video loops from text prompts using WAN-FLF2V.\n    video, generation, wan, text-to-video\n\n    Use cases:\n    - Generate looping videos from descriptions\n    - Produce motion graphics from prompts\n    - Create abstract video ideas\n    - Develop creative transitions\n    - Experiment with AI-generated motion",
      "namespace": "fal.text_to_video",
      "node_type": "fal.text_to_video.WanFlf2V",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt describing the desired video"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Randomization seed for reproducible results"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt"
      ]
    },
    {
      "title": "Wan Pro Image To Video",
      "description": "Convert an image into a short video clip using Wan Pro.\n    video, generation, wan, professional, image-to-video\n\n    Use cases:\n    - Create dynamic videos from product photos\n    - Generate animations from static artwork\n    - Produce short promotional clips\n    - Transform images into motion graphics\n    - Experiment with visual storytelling",
      "namespace": "fal.text_to_video",
      "node_type": "fal.text_to_video.WanProImageToVideo",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The input image to animate"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "Optional prompt describing the desired motion"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Randomization seed for reproducible results"
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "Whether to enable the safety checker"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "Wan Pro Text To Video",
      "description": "Generate a short video clip from a text prompt using Wan Pro.\n    video, generation, wan, professional, text-to-video\n\n    Use cases:\n    - Create animated scenes from descriptions\n    - Generate short creative videos\n    - Produce promotional content\n    - Visualize storyboards\n    - Experiment with narrative ideas",
      "namespace": "fal.text_to_video",
      "node_type": "fal.text_to_video.WanProTextToVideo",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt describing the desired video"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Randomization seed for reproducible results"
        },
        {
          "name": "enable_safety_checker",
          "type": {
            "type": "bool"
          },
          "default": true,
          "title": "Enable Safety Checker",
          "description": "Whether to enable the safety checker"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt"
      ]
    },
    {
      "title": "Wan T2 V",
      "description": "Generate videos from text using the WAN-T2V model.\n    video, generation, wan, text-to-video\n\n    Use cases:\n    - Produce creative videos from prompts\n    - Experiment with motion concepts\n    - Generate quick animated drafts\n    - Visualize ideas for stories\n    - Create short social media clips",
      "namespace": "fal.text_to_video",
      "node_type": "fal.text_to_video.WanT2V",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt describing the desired video"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Randomization seed for reproducible results"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt"
      ]
    },
    {
      "title": "Wan V2 1 13B Text To Video",
      "description": "Create videos from text using WAN v2.1 1.3B, an open-source text-to-video model.\n    video, generation, wan, text-to-video\n\n    Use cases:\n    - Produce short clips from prompts\n    - Generate concept videos\n    - Create quick visualizations\n    - Iterate on storytelling ideas\n    - Experiment with AI video synthesis",
      "namespace": "fal.text_to_video",
      "node_type": "fal.text_to_video.WanV2_1_13BTextToVideo",
      "properties": [
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Prompt",
          "description": "The prompt describing the desired video"
        },
        {
          "name": "seed",
          "type": {
            "type": "int"
          },
          "default": -1,
          "title": "Seed",
          "description": "Randomization seed for reproducible results"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "prompt"
      ]
    },
    {
      "title": "Face Swap Video",
      "description": "Swap faces in videos using a source face image. Replaces faces in the target video with the source face while maintaining natural motion and expressions.\n    face-swap, video-editing, face-replacement, deep-fake, video-manipulation\n\n    Use cases:\n    - Create face-swapped video content\n    - Generate creative video edits\n    - Produce entertainment content\n    - Test different faces in video footage\n    - Create video memes and parodies",
      "namespace": "fal.video_processing",
      "node_type": "fal.video_processing.FaceSwapVideo",
      "properties": [
        {
          "name": "source_face",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Source Face",
          "description": "Source face image to swap into video"
        },
        {
          "name": "target_video",
          "type": {
            "type": "video"
          },
          "default": {
            "type": "video",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null,
            "duration": null,
            "format": null
          },
          "title": "Target Video",
          "description": "Target video to swap face in (max 25 minutes)"
        },
        {
          "name": "enable_occlusion_prevention",
          "type": {
            "type": "bool"
          },
          "default": false,
          "title": "Enable Occlusion Prevention",
          "description": "Enable occlusion prevention for faces covered by hands/objects (costs 2x more)"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "source_face",
        "target_video"
      ]
    },
    {
      "title": "Live Avatar",
      "description": "Live Avatar creates animated avatars from images and audio.\n    video, avatar, animation, audio-driven\n\n    Use cases:\n    - Create talking avatars\n    - Generate animated presentations\n    - Produce video content from photos\n    - Create virtual presenters\n    - Generate video messages",
      "namespace": "fal.video_processing",
      "node_type": "fal.video_processing.LiveAvatar",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The avatar image"
        },
        {
          "name": "audio",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Audio",
          "description": "URL to the driving audio"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "audio"
      ]
    },
    {
      "title": "RIFE",
      "description": "RIFE (Real-time Intermediate Flow Estimation) interpolates frames for smooth video.\n    video, interpolation, frame-rate, smoothing\n\n    Use cases:\n    - Increase video frame rate\n    - Create smooth slow motion\n    - Improve video fluidity\n    - Generate intermediate frames\n    - Enhance animation smoothness",
      "namespace": "fal.video_processing",
      "node_type": "fal.video_processing.RIFE",
      "properties": [
        {
          "name": "start_image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Start Image",
          "description": "The start frame"
        },
        {
          "name": "end_image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "End Image",
          "description": "The end frame"
        },
        {
          "name": "num_frames",
          "type": {
            "type": "int"
          },
          "default": 2,
          "title": "Num Frames",
          "description": "Number of intermediate frames",
          "min": 1.0,
          "max": 16.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "list"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "start_image",
        "end_image",
        "num_frames"
      ]
    },
    {
      "title": "RIFEVideo",
      "description": "RIFE Video interpolates video frames for increased frame rate.\n    video, interpolation, frame-rate, enhancement\n\n    Use cases:\n    - Double video frame rate\n    - Create slow motion videos\n    - Improve video smoothness\n    - Enhance low-fps footage\n    - Generate high-fps content",
      "namespace": "fal.video_processing",
      "node_type": "fal.video_processing.RIFEVideo",
      "properties": [
        {
          "name": "video",
          "type": {
            "type": "video"
          },
          "default": {
            "type": "video",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null,
            "duration": null,
            "format": null
          },
          "title": "Video",
          "description": "The video to interpolate"
        },
        {
          "name": "multiplier",
          "type": {
            "type": "int"
          },
          "default": 2,
          "title": "Multiplier",
          "description": "Frame rate multiplier",
          "min": 2.0,
          "max": 4.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "video",
        "multiplier"
      ]
    },
    {
      "title": "Sync Lipsync V2",
      "description": "Sync Lipsync V2 synchronizes lip movements to audio.\n    video, lipsync, audio, synchronization\n\n    Use cases:\n    - Sync lips to new audio\n    - Create talking head videos\n    - Dub videos in other languages\n    - Generate speaking animations\n    - Create video voice-overs",
      "namespace": "fal.video_processing",
      "node_type": "fal.video_processing.SyncLipsyncV2",
      "properties": [
        {
          "name": "video",
          "type": {
            "type": "video"
          },
          "default": {
            "type": "video",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null,
            "duration": null,
            "format": null
          },
          "title": "Video",
          "description": "The video with the face"
        },
        {
          "name": "audio",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Audio",
          "description": "URL to the audio file for lipsync"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "video",
        "audio"
      ]
    },
    {
      "title": "Topaz Video Upscale",
      "description": "Topaz Video Upscale enhances video quality using advanced AI.\n    video, upscaling, enhancement, topaz, professional\n\n    Use cases:\n    - Professional video upscaling\n    - Restore archival footage\n    - Enhance video for broadcast\n    - Improve video quality\n    - Prepare videos for 4K display",
      "namespace": "fal.video_processing",
      "node_type": "fal.video_processing.TopazVideoUpscale",
      "properties": [
        {
          "name": "video",
          "type": {
            "type": "video"
          },
          "default": {
            "type": "video",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null,
            "duration": null,
            "format": null
          },
          "title": "Video",
          "description": "The video to upscale"
        },
        {
          "name": "scale",
          "type": {
            "type": "int"
          },
          "default": 2,
          "title": "Scale",
          "description": "Upscaling factor",
          "min": 2.0,
          "max": 4.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "video",
        "scale"
      ]
    },
    {
      "title": "Video Upscaler",
      "description": "Video Upscaler enhances video resolution using AI.\n    video, upscaling, enhancement, super-resolution\n\n    Use cases:\n    - Upscale low-resolution videos\n    - Enhance video quality\n    - Improve video for larger displays\n    - Restore old videos\n    - Prepare videos for high-res output",
      "namespace": "fal.video_processing",
      "node_type": "fal.video_processing.VideoUpscaler",
      "properties": [
        {
          "name": "video",
          "type": {
            "type": "video"
          },
          "default": {
            "type": "video",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null,
            "duration": null,
            "format": null
          },
          "title": "Video",
          "description": "The video to upscale"
        },
        {
          "name": "scale",
          "type": {
            "type": "float"
          },
          "default": 2.0,
          "title": "Scale",
          "description": "Upscaling factor (1-8)",
          "min": 1.0,
          "max": 8.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "video"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "video",
        "scale"
      ]
    },
    {
      "title": "Audio Understanding",
      "description": "Audio Understanding analyzes audio content and generates descriptions.\n    audio, understanding, analysis\n\n    Use cases:\n    - Analyze audio content\n    - Generate audio descriptions\n    - Understand sound scenes\n    - Create audio metadata\n    - Identify audio events",
      "namespace": "fal.vision",
      "node_type": "fal.vision.AudioUnderstanding",
      "properties": [
        {
          "name": "audio",
          "type": {
            "type": "audio"
          },
          "default": {
            "type": "audio",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Audio",
          "description": "The audio to analyze"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "Describe what you hear in this audio.",
          "title": "Prompt",
          "description": "The question or prompt about the audio"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "str"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "audio",
        "prompt"
      ]
    },
    {
      "title": "Florence 2 Caption",
      "description": "Florence 2 Caption generates detailed captions for images.\n    vision, caption, understanding, florence, image-to-text\n\n    Use cases:\n    - Generate image descriptions\n    - Create alt text for images\n    - Analyze image content\n    - Produce accessibility content\n    - Create image metadata",
      "namespace": "fal.vision",
      "node_type": "fal.vision.Florence2Caption",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The image to caption"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "str"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image"
      ]
    },
    {
      "title": "Florence 2 Detailed Caption",
      "description": "Florence 2 Detailed Caption generates comprehensive image descriptions.\n    vision, caption, understanding, florence, detailed\n\n    Use cases:\n    - Generate detailed image descriptions\n    - Create comprehensive alt text\n    - Analyze complex images\n    - Produce rich metadata\n    - Create detailed content descriptions",
      "namespace": "fal.vision",
      "node_type": "fal.vision.Florence2DetailedCaption",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The image to caption"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "str"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image"
      ]
    },
    {
      "title": "Florence 2OCR",
      "description": "Florence 2 OCR extracts text from images.\n    vision, ocr, text-extraction, florence\n\n    Use cases:\n    - Extract text from images\n    - Read documents\n    - Process screenshots\n    - Digitize printed text\n    - Extract labels and signs",
      "namespace": "fal.vision",
      "node_type": "fal.vision.Florence2OCR",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The image to extract text from"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "str"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image"
      ]
    },
    {
      "title": "Florence 2 Object Detection",
      "description": "Florence 2 Object Detection identifies and locates objects in images.\n    vision, object-detection, understanding, florence\n\n    Use cases:\n    - Detect objects in images\n    - Identify items in photos\n    - Analyze image content\n    - Create object inventories\n    - Enable visual search",
      "namespace": "fal.vision",
      "node_type": "fal.vision.Florence2ObjectDetection",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The image to analyze"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "list"
          },
          "name": "objects"
        },
        {
          "type": {
            "type": "list"
          },
          "name": "labels"
        }
      ],
      "basic_fields": [
        "image"
      ]
    },
    {
      "title": "Got OCR",
      "description": "GOT-OCR V2 is an advanced OCR model for extracting text from images.\n    vision, ocr, text-extraction, got\n\n    Use cases:\n    - Extract text from complex images\n    - Read handwritten text\n    - Process documents\n    - Digitize printed material\n    - Extract multilingual text",
      "namespace": "fal.vision",
      "node_type": "fal.vision.GotOCR",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The image to extract text from"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "str"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image"
      ]
    },
    {
      "title": "Llava Next",
      "description": "LLaVA-NeXT is an advanced vision-language model for image understanding.\n    vision, vlm, understanding, llava, multimodal\n\n    Use cases:\n    - Complex image analysis\n    - Visual question answering\n    - Image captioning\n    - Scene understanding\n    - Multi-turn visual conversations",
      "namespace": "fal.vision",
      "node_type": "fal.vision.LlavaNext",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The image to analyze"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "Describe this image in detail.",
          "title": "Prompt",
          "description": "The question or prompt about the image"
        },
        {
          "name": "max_tokens",
          "type": {
            "type": "int"
          },
          "default": 64,
          "title": "Max Tokens",
          "description": "Maximum number of tokens to generate"
        },
        {
          "name": "temperature",
          "type": {
            "type": "float"
          },
          "default": 0.2,
          "title": "Temperature",
          "description": "Temperature for sampling"
        },
        {
          "name": "top_p",
          "type": {
            "type": "float"
          },
          "default": 1.0,
          "title": "Top P",
          "description": "Top P for sampling",
          "min": 0.0,
          "max": 1.0
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "str"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt",
        "max_tokens"
      ]
    },
    {
      "title": "Moondream 2",
      "description": "Moondream2 is a small but capable vision-language model for image understanding.\n    vision, vlm, understanding, moondream, image-to-text\n\n    Use cases:\n    - Answer questions about images\n    - Analyze image content\n    - Generate descriptions\n    - Visual question answering\n    - Image understanding tasks",
      "namespace": "fal.vision",
      "node_type": "fal.vision.Moondream2",
      "properties": [
        {
          "name": "image",
          "type": {
            "type": "image"
          },
          "default": {
            "type": "image",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null
          },
          "title": "Image",
          "description": "The image to analyze"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "Describe this image.",
          "title": "Prompt",
          "description": "The question or prompt about the image"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "str"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "image",
        "prompt"
      ]
    },
    {
      "title": "Video Prompt Generator",
      "description": "Video Prompt Generator creates detailed prompts for video generation from a concept or image.\n    vision, video, prompt, generation, tool\n\n    Use cases:\n    - Generate detailed video prompts from simple concepts\n    - Enhance video generation prompts\n    - Create prompts from reference images",
      "namespace": "fal.vision",
      "node_type": "fal.vision.VideoPromptGenerator",
      "properties": [
        {
          "name": "input_concept",
          "type": {
            "type": "str"
          },
          "default": "",
          "title": "Input Concept",
          "description": "Core concept or thematic input for the video prompt"
        },
        {
          "name": "image",
          "type": {
            "type": "image",
            "optional": true
          },
          "default": null,
          "title": "Image",
          "description": "Optional reference image to analyze"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "str"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "input_concept",
        "image"
      ]
    },
    {
      "title": "Video Understanding",
      "description": "Video Understanding analyzes video content and generates descriptions.\n    vision, video, understanding, analysis\n\n    Use cases:\n    - Analyze video content\n    - Generate video summaries\n    - Extract video descriptions\n    - Understand video scenes\n    - Create video metadata",
      "namespace": "fal.vision",
      "node_type": "fal.vision.VideoUnderstanding",
      "properties": [
        {
          "name": "video",
          "type": {
            "type": "video"
          },
          "default": {
            "type": "video",
            "uri": "",
            "asset_id": null,
            "data": null,
            "metadata": null,
            "duration": null,
            "format": null
          },
          "title": "Video",
          "description": "The video to analyze"
        },
        {
          "name": "prompt",
          "type": {
            "type": "str"
          },
          "default": "Describe what happens in this video.",
          "title": "Prompt",
          "description": "The question or prompt about the video"
        }
      ],
      "outputs": [
        {
          "type": {
            "type": "str"
          },
          "name": "output"
        }
      ],
      "basic_fields": [
        "video",
        "prompt"
      ]
    }
  ]
}