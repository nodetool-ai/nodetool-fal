# This file is auto-generated by nodetool.dsl.codegen.
# Please do not edit this file manually.

# Instead, edit the node class in the source module and run the following commands to regenerate the DSL:
# nodetool package scan
# nodetool codegen

from pydantic import BaseModel, Field
import typing
from typing import Any
import nodetool.metadata.types
import nodetool.metadata.types as types
from nodetool.dsl.graph import GraphNode, SingleOutputGraphNode

import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.fal.speech_to_speech
from nodetool.workflows.base_node import BaseNode


class ChatterboxSpeechToSpeech(
    SingleOutputGraphNode[types.AudioRef], GraphNode[types.AudioRef]
):
    """

    Whether you're working on memes, videos, games, or AI agents, Chatterbox brings your content to life. Use the first tts from resemble ai.
    speech, voice, transformation, cloning

    Use cases:
    - Voice cloning and transformation
    - Real-time voice conversion
    - Voice style transfer
    - Speech enhancement
    - Accent conversion
    """

    source_audio_url: types.AudioRef | OutputHandle[types.AudioRef] = connect_field(
        default=types.AudioRef(
            type="audio", uri="", asset_id=None, data=None, metadata=None
        ),
        description=None,
    )
    target_voice_audio_url: types.AudioRef | OutputHandle[types.AudioRef] = (
        connect_field(
            default=types.AudioRef(
                type="audio", uri="", asset_id=None, data=None, metadata=None
            ),
            description="Optional URL to an audio file to use as a reference for the generated speech. If provided, the model will try to match the style and tone of the reference audio.",
        )
    )

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.fal.speech_to_speech.ChatterboxSpeechToSpeech

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.fal.speech_to_speech
from nodetool.workflows.base_node import BaseNode


class ResembleAiChatterboxhdSpeechToSpeech(
    SingleOutputGraphNode[types.AudioRef], GraphNode[types.AudioRef]
):
    """

    Transform voices using Resemble AI's Chatterbox. Convert audio to new voices or your own samples, with expressive results and built-in perceptual watermarking.
    speech, voice, transformation, cloning

    Use cases:
    - Voice cloning and transformation
    - Real-time voice conversion
    - Voice style transfer
    - Speech enhancement
    - Accent conversion
    """

    high_quality_audio: bool | OutputHandle[bool] = connect_field(
        default=False,
        description="If True, the generated audio will be upscaled to 48kHz. The generation of the audio will take longer, but the quality will be higher. If False, the generated audio will be 24kHz.",
    )
    target_voice_audio_url: types.AudioRef | OutputHandle[types.AudioRef] = (
        connect_field(
            default=types.AudioRef(
                type="audio", uri="", asset_id=None, data=None, metadata=None
            ),
            description="URL to the audio file which represents the voice of the output audio. If provided, this will override the target_voice setting. If neither target_voice nor target_voice_audio_url are provided, the default target voice will be used.",
        )
    )
    source_audio_url: types.AudioRef | OutputHandle[types.AudioRef] = connect_field(
        default=types.AudioRef(
            type="audio", uri="", asset_id=None, data=None, metadata=None
        ),
        description="URL to the source audio file to be voice-converted.",
    )
    target_voice: (
        nodetool.nodes.fal.speech_to_speech.ResembleAiChatterboxhdSpeechToSpeech.TargetVoice
        | OutputHandle[
            nodetool.nodes.fal.speech_to_speech.ResembleAiChatterboxhdSpeechToSpeech.TargetVoice
        ]
        | None
    ) = connect_field(
        default=None,
        description="The voice to use for the speech-to-speech request. If neither target_voice nor target_voice_audio_url are provided, a random target voice will be used.",
    )

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.fal.speech_to_speech.ResembleAiChatterboxhdSpeechToSpeech

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()
