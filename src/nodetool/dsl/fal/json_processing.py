# This file is auto-generated by nodetool.dsl.codegen.
# Please do not edit this file manually.

# Instead, edit the node class in the source module and run the following commands to regenerate the DSL:
# nodetool package scan
# nodetool codegen

from pydantic import BaseModel, Field
import typing
from typing import Any
import nodetool.metadata.types
import nodetool.metadata.types as types
from nodetool.dsl.graph import GraphNode, SingleOutputGraphNode

import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.fal.json_processing
from nodetool.workflows.base_node import BaseNode


class FfmpegApiLoudnorm(
    SingleOutputGraphNode[types.AudioRef], GraphNode[types.AudioRef]
):
    """

    Get EBU R128 loudness normalization from audio files using FFmpeg API.
    json, processing, data, utility

    Use cases:
    - JSON data processing
    - Data transformation
    - Metadata extraction
    - Audio analysis
    - Media processing utilities
    """

    measured_tp: str | OutputHandle[str] = connect_field(
        default="",
        description="Measured true peak of input file in dBTP. Required for linear mode.",
    )
    offset: float | OutputHandle[float] = connect_field(
        default=0, description="Offset gain in dB applied before the true-peak limiter"
    )
    print_summary: bool | OutputHandle[bool] = connect_field(
        default=False,
        description="Return loudness measurement summary with the normalized audio",
    )
    measured_i: str | OutputHandle[str] = connect_field(
        default="",
        description="Measured integrated loudness of input file in LUFS. Required for linear mode.",
    )
    linear: bool | OutputHandle[bool] = connect_field(
        default=False,
        description="Use linear normalization mode (single-pass). If false, uses dynamic mode (two-pass for better quality).",
    )
    measured_lra: str | OutputHandle[str] = connect_field(
        default="",
        description="Measured loudness range of input file in LU. Required for linear mode.",
    )
    dual_mono: bool | OutputHandle[bool] = connect_field(
        default=False,
        description="Treat mono input files as dual-mono for correct EBU R128 measurement on stereo systems",
    )
    measured_thresh: str | OutputHandle[str] = connect_field(
        default="",
        description="Measured threshold of input file in LUFS. Required for linear mode.",
    )
    true_peak: float | OutputHandle[float] = connect_field(
        default=-0.1, description="Maximum true peak in dBTP."
    )
    audio: types.AudioRef | OutputHandle[types.AudioRef] = connect_field(
        default=types.AudioRef(
            type="audio", uri="", asset_id=None, data=None, metadata=None
        ),
        description="URL of the audio file to normalize",
    )
    integrated_loudness: float | OutputHandle[float] = connect_field(
        default=-18, description="Integrated loudness target in LUFS."
    )
    loudness_range: float | OutputHandle[float] = connect_field(
        default=7, description="Loudness range target in LU"
    )

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.fal.json_processing.FfmpegApiLoudnorm

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.fal.json_processing
from nodetool.workflows.base_node import BaseNode


class FfmpegApiMetadata(SingleOutputGraphNode[Any], GraphNode[Any]):
    """

    Get encoding metadata from video and audio files using FFmpeg API.
    json, processing, data, utility

    Use cases:
    - JSON data processing
    - Data transformation
    - Metadata extraction
    - Audio analysis
    - Media processing utilities
    """

    extract_frames: bool | OutputHandle[bool] = connect_field(
        default=False,
        description="Whether to extract the start and end frames for videos. Note that when true the request will be slower.",
    )
    media: types.VideoRef | OutputHandle[types.VideoRef] = connect_field(
        default=types.VideoRef(
            type="video",
            uri="",
            asset_id=None,
            data=None,
            metadata=None,
            duration=None,
            format=None,
        ),
        description="URL of the media file (video or audio) to analyze",
    )

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.fal.json_processing.FfmpegApiMetadata

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.fal.json_processing
from nodetool.workflows.base_node import BaseNode


class FfmpegApiWaveform(
    SingleOutputGraphNode[dict[str, Any]], GraphNode[dict[str, Any]]
):
    """

    Get waveform data from audio files using FFmpeg API.
    json, processing, data, utility

    Use cases:
    - JSON data processing
    - Data transformation
    - Metadata extraction
    - Audio analysis
    - Media processing utilities
    """

    precision: int | OutputHandle[int] = connect_field(
        default=2,
        description="Number of decimal places for the waveform values. Higher values provide more precision but increase payload size.",
    )
    smoothing_window: int | OutputHandle[int] = connect_field(
        default=3,
        description="Size of the smoothing window. Higher values create a smoother waveform. Must be an odd number.",
    )
    media: types.AudioRef | OutputHandle[types.AudioRef] = connect_field(
        default=types.AudioRef(
            type="audio", uri="", asset_id=None, data=None, metadata=None
        ),
        description="URL of the audio file to analyze",
    )
    points_per_second: float | OutputHandle[float] = connect_field(
        default=4,
        description="Controls how many points are sampled per second of audio. Lower values (e.g. 1-2) create a coarser waveform, higher values (e.g. 4-10) create a more detailed one.",
    )

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.fal.json_processing.FfmpegApiWaveform

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()
