# This file is auto-generated by nodetool.dsl.codegen.
# Please do not edit this file manually.

# Instead, edit the node class in the source module and run the following commands to regenerate the DSL:
# nodetool package scan
# nodetool codegen

from pydantic import BaseModel, Field
import typing
from typing import Any
import nodetool.metadata.types
import nodetool.metadata.types as types
from nodetool.dsl.graph import GraphNode, SingleOutputGraphNode

import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.fal.segmentation
from nodetool.workflows.base_node import BaseNode

class DWPose(SingleOutputGraphNode[typing.Any], GraphNode[typing.Any]):
    """

        DWPose detects human poses and keypoints in images.
        pose, detection, keypoints, human

        Use cases:
        - Detect human poses
        - Extract body keypoints
        - Enable pose-guided generation
        - Analyze body positions
        - Create pose references
    """

    image: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(default=types.ImageRef(type='image', uri='', asset_id=None, data=None, metadata=None), description='The image to analyze')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.fal.segmentation.DWPose

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.fal.segmentation
from nodetool.workflows.base_node import BaseNode

class ImagePreprocessorDepthAnythingV2(SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]):
    """

        Depth Anything V2 generates high-quality depth maps from images.
        depth, preprocessor, depth-map, estimation

        Use cases:
        - Generate accurate depth maps
        - Enable depth-aware effects
        - Create 3D visualizations
        - Prepare ControlNet inputs
        - Analyze image depth
    """

    image: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(default=types.ImageRef(type='image', uri='', asset_id=None, data=None, metadata=None), description='The image to process')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.fal.segmentation.ImagePreprocessorDepthAnythingV2

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.fal.segmentation
from nodetool.workflows.base_node import BaseNode

class MarigoldDepth(SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]):
    """

        Marigold Depth generates high-quality monocular depth maps.
        depth, marigold, depth-map, estimation

        Use cases:
        - Generate precise depth maps
        - Create depth visualizations
        - Enable depth-based effects
        - Prepare 3D conversions
        - Analyze scene depth
    """

    image: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(default=types.ImageRef(type='image', uri='', asset_id=None, data=None, metadata=None), description='The image to process')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.fal.segmentation.MarigoldDepth

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.fal.segmentation
from nodetool.workflows.base_node import BaseNode

class SAM2Image(SingleOutputGraphNode[typing.Any], GraphNode[typing.Any]):
    """

        SAM 2 Image segments objects in images with high accuracy.
        segmentation, sam, image, masks

        Use cases:
        - Segment objects in images
        - Create object masks
        - Enable object selection
        - Generate cutouts
        - Create selection masks
    """

    image: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(default=types.ImageRef(type='image', uri='', asset_id=None, data=None, metadata=None), description='The image to segment')
    point_coords: list[list[float]] | OutputHandle[list[list[float]]] = connect_field(default=[], description='Point coordinates for prompts [[x, y], ...]')
    point_labels: list[int] | OutputHandle[list[int]] = connect_field(default=[], description='Labels for points (1=foreground, 0=background)')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.fal.segmentation.SAM2Image

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.fal.segmentation
from nodetool.workflows.base_node import BaseNode

class SAM2Video(SingleOutputGraphNode[typing.Any], GraphNode[typing.Any]):
    """

        SAM 2 Video segments and tracks objects across video frames.
        segmentation, sam, video, tracking

        Use cases:
        - Track objects in videos
        - Create video masks
        - Segment moving objects
        - Generate video cutouts
        - Enable video object selection
    """

    video: types.VideoRef | OutputHandle[types.VideoRef] = connect_field(default=types.VideoRef(type='video', uri='', asset_id=None, data=None, metadata=None, duration=None, format=None), description='The video to segment')
    point_coords: list[list[float]] | OutputHandle[list[list[float]]] = connect_field(default=[], description='Point coordinates for prompts [[x, y], ...]')
    point_labels: list[int] | OutputHandle[list[int]] = connect_field(default=[], description='Labels for points (1=foreground, 0=background)')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.fal.segmentation.SAM2Video

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.fal.segmentation
from nodetool.workflows.base_node import BaseNode

class SAM3Image(SingleOutputGraphNode[typing.Any], GraphNode[typing.Any]):
    """

        SAM 3 Image provides advanced segmentation with improved accuracy.
        segmentation, sam3, image, masks, advanced

        Use cases:
        - High-accuracy object segmentation
        - Complex scene segmentation
        - Precise mask generation
        - Advanced object selection
        - Detailed cutout creation
    """

    image: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(default=types.ImageRef(type='image', uri='', asset_id=None, data=None, metadata=None), description='The image to segment')
    point_coords: list[list[float]] | OutputHandle[list[list[float]]] = connect_field(default=[], description='Point coordinates for prompts [[x, y], ...]')
    point_labels: list[int] | OutputHandle[list[int]] = connect_field(default=[], description='Labels for points (1=foreground, 0=background)')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.fal.segmentation.SAM3Image

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


