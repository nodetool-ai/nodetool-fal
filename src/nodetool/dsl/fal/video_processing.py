# This file is auto-generated by nodetool.dsl.codegen.
# Please do not edit this file manually.

# Instead, edit the node class in the source module and run the following commands to regenerate the DSL:
# nodetool package scan
# nodetool codegen

from pydantic import BaseModel, Field
import typing
from typing import Any
import nodetool.metadata.types
import nodetool.metadata.types as types
from nodetool.dsl.graph import GraphNode, SingleOutputGraphNode

import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.fal.video_processing
from nodetool.workflows.base_node import BaseNode


class FaceSwapVideo(SingleOutputGraphNode[types.VideoRef], GraphNode[types.VideoRef]):
    """

    Swap faces in videos using a source face image. Replaces faces in the target video with the source face while maintaining natural motion and expressions.
    face-swap, video-editing, face-replacement, deep-fake, video-manipulation

    Use cases:
    - Create face-swapped video content
    - Generate creative video edits
    - Produce entertainment content
    - Test different faces in video footage
    - Create video memes and parodies
    """

    source_face: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(
        default=types.ImageRef(
            type="image", uri="", asset_id=None, data=None, metadata=None
        ),
        description="Source face image to swap into video",
    )
    target_video: types.VideoRef | OutputHandle[types.VideoRef] = connect_field(
        default=types.VideoRef(
            type="video",
            uri="",
            asset_id=None,
            data=None,
            metadata=None,
            duration=None,
            format=None,
        ),
        description="Target video to swap face in (max 25 minutes)",
    )
    enable_occlusion_prevention: bool | OutputHandle[bool] = connect_field(
        default=False,
        description="Enable occlusion prevention for faces covered by hands/objects (costs 2x more)",
    )

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.fal.video_processing.FaceSwapVideo

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.fal.video_processing
from nodetool.workflows.base_node import BaseNode


class LiveAvatar(SingleOutputGraphNode[types.VideoRef], GraphNode[types.VideoRef]):
    """

    Live Avatar creates animated avatars from images and audio.
    video, avatar, animation, audio-driven

    Use cases:
    - Create talking avatars
    - Generate animated presentations
    - Produce video content from photos
    - Create virtual presenters
    - Generate video messages
    """

    image: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(
        default=types.ImageRef(
            type="image", uri="", asset_id=None, data=None, metadata=None
        ),
        description="The avatar image",
    )
    audio: str | OutputHandle[str] = connect_field(
        default="", description="URL to the driving audio"
    )

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.fal.video_processing.LiveAvatar

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.fal.video_processing
from nodetool.workflows.base_node import BaseNode


class RIFE(SingleOutputGraphNode[list], GraphNode[list]):
    """

    RIFE (Real-time Intermediate Flow Estimation) interpolates frames for smooth video.
    video, interpolation, frame-rate, smoothing

    Use cases:
    - Increase video frame rate
    - Create smooth slow motion
    - Improve video fluidity
    - Generate intermediate frames
    - Enhance animation smoothness
    """

    start_image: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(
        default=types.ImageRef(
            type="image", uri="", asset_id=None, data=None, metadata=None
        ),
        description="The start frame",
    )
    end_image: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(
        default=types.ImageRef(
            type="image", uri="", asset_id=None, data=None, metadata=None
        ),
        description="The end frame",
    )
    num_frames: int | OutputHandle[int] = connect_field(
        default=2, description="Number of intermediate frames"
    )

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.fal.video_processing.RIFE

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.fal.video_processing
from nodetool.workflows.base_node import BaseNode


class RIFEVideo(SingleOutputGraphNode[types.VideoRef], GraphNode[types.VideoRef]):
    """

    RIFE Video interpolates video frames for increased frame rate.
    video, interpolation, frame-rate, enhancement

    Use cases:
    - Double video frame rate
    - Create slow motion videos
    - Improve video smoothness
    - Enhance low-fps footage
    - Generate high-fps content
    """

    video: types.VideoRef | OutputHandle[types.VideoRef] = connect_field(
        default=types.VideoRef(
            type="video",
            uri="",
            asset_id=None,
            data=None,
            metadata=None,
            duration=None,
            format=None,
        ),
        description="The video to interpolate",
    )
    multiplier: int | OutputHandle[int] = connect_field(
        default=2, description="Frame rate multiplier"
    )

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.fal.video_processing.RIFEVideo

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.fal.video_processing
from nodetool.workflows.base_node import BaseNode


class SyncLipsyncV2(SingleOutputGraphNode[types.VideoRef], GraphNode[types.VideoRef]):
    """

    Sync Lipsync V2 synchronizes lip movements to audio.
    video, lipsync, audio, synchronization

    Use cases:
    - Sync lips to new audio
    - Create talking head videos
    - Dub videos in other languages
    - Generate speaking animations
    - Create video voice-overs
    """

    video: types.VideoRef | OutputHandle[types.VideoRef] = connect_field(
        default=types.VideoRef(
            type="video",
            uri="",
            asset_id=None,
            data=None,
            metadata=None,
            duration=None,
            format=None,
        ),
        description="The video with the face",
    )
    audio: str | OutputHandle[str] = connect_field(
        default="", description="URL to the audio file for lipsync"
    )

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.fal.video_processing.SyncLipsyncV2

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.fal.video_processing
from nodetool.workflows.base_node import BaseNode


class TopazVideoUpscale(
    SingleOutputGraphNode[types.VideoRef], GraphNode[types.VideoRef]
):
    """

    Topaz Video Upscale enhances video quality using advanced AI.
    video, upscaling, enhancement, topaz, professional

    Use cases:
    - Professional video upscaling
    - Restore archival footage
    - Enhance video for broadcast
    - Improve video quality
    - Prepare videos for 4K display
    """

    video: types.VideoRef | OutputHandle[types.VideoRef] = connect_field(
        default=types.VideoRef(
            type="video",
            uri="",
            asset_id=None,
            data=None,
            metadata=None,
            duration=None,
            format=None,
        ),
        description="The video to upscale",
    )
    scale: int | OutputHandle[int] = connect_field(
        default=2, description="Upscaling factor"
    )

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.fal.video_processing.TopazVideoUpscale

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.fal.video_processing
from nodetool.workflows.base_node import BaseNode


class VideoUpscaler(SingleOutputGraphNode[types.VideoRef], GraphNode[types.VideoRef]):
    """

    Video Upscaler enhances video resolution using AI.
    video, upscaling, enhancement, super-resolution

    Use cases:
    - Upscale low-resolution videos
    - Enhance video quality
    - Improve video for larger displays
    - Restore old videos
    - Prepare videos for high-res output
    """

    video: types.VideoRef | OutputHandle[types.VideoRef] = connect_field(
        default=types.VideoRef(
            type="video",
            uri="",
            asset_id=None,
            data=None,
            metadata=None,
            duration=None,
            format=None,
        ),
        description="The video to upscale",
    )
    scale: float | OutputHandle[float] = connect_field(
        default=2.0, description="Upscaling factor (1-8)"
    )

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.fal.video_processing.VideoUpscaler

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()
