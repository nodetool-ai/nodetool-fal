# This file is auto-generated by nodetool.dsl.codegen.
# Please do not edit this file manually.

# Instead, edit the node class in the source module and run the following commands to regenerate the DSL:
# nodetool package scan
# nodetool codegen

from pydantic import BaseModel, Field
import typing
from typing import Any
import nodetool.metadata.types
import nodetool.metadata.types as types
from nodetool.dsl.graph import GraphNode, SingleOutputGraphNode

import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.fal.audio_to_text
from nodetool.workflows.base_node import BaseNode


class NemotronAsr(SingleOutputGraphNode[dict[str, Any]], GraphNode[dict[str, Any]]):
    """

    Use the fast speed and pin point accuracy of nemotron to transcribe your texts.
    speech, recognition, transcription, audio-analysis

    Use cases:
    - Speech recognition
    - Audio transcription
    - Speaker diarization
    - Voice activity detection
    - Meeting transcription
    """

    Acceleration: typing.ClassVar[type] = (
        nodetool.nodes.fal.audio_to_text.NemotronAsr.Acceleration
    )

    acceleration: nodetool.nodes.fal.audio_to_text.NemotronAsr.Acceleration = Field(
        default=nodetool.nodes.fal.audio_to_text.NemotronAsr.Acceleration.NONE,
        description="Controls the speed/accuracy trade-off. 'none' = best accuracy (1.12s chunks, ~7.16% WER), 'low' = balanced (0.56s chunks, ~7.22% WER), 'medium' = faster (0.16s chunks, ~7.84% WER), 'high' = fastest (0.08s chunks, ~8.53% WER).",
    )
    audio: types.AudioRef | OutputHandle[types.AudioRef] = connect_field(
        default=types.AudioRef(
            type="audio", uri="", asset_id=None, data=None, metadata=None
        ),
        description="URL of the audio file.",
    )

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.fal.audio_to_text.NemotronAsr

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.fal.audio_to_text
from nodetool.workflows.base_node import BaseNode


class NemotronAsrStream(SingleOutputGraphNode[Any], GraphNode[Any]):
    """

    Use the fast speed and pin point accuracy of nemotron to transcribe your texts.
    speech, recognition, transcription, audio-analysis

    Use cases:
    - Speech recognition
    - Audio transcription
    - Speaker diarization
    - Voice activity detection
    - Meeting transcription
    """

    Acceleration: typing.ClassVar[type] = (
        nodetool.nodes.fal.audio_to_text.NemotronAsrStream.Acceleration
    )

    acceleration: nodetool.nodes.fal.audio_to_text.NemotronAsrStream.Acceleration = (
        Field(
            default=nodetool.nodes.fal.audio_to_text.NemotronAsrStream.Acceleration.NONE,
            description="Controls the speed/accuracy trade-off. 'none' = best accuracy (1.12s chunks, ~7.16% WER), 'low' = balanced (0.56s chunks, ~7.22% WER), 'medium' = faster (0.16s chunks, ~7.84% WER), 'high' = fastest (0.08s chunks, ~8.53% WER).",
        )
    )
    audio: types.AudioRef | OutputHandle[types.AudioRef] = connect_field(
        default=types.AudioRef(
            type="audio", uri="", asset_id=None, data=None, metadata=None
        ),
        description="URL of the audio file.",
    )

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.fal.audio_to_text.NemotronAsrStream

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.fal.audio_to_text
from nodetool.workflows.base_node import BaseNode


class SileroVad(SingleOutputGraphNode[dict[str, Any]], GraphNode[dict[str, Any]]):
    """

    Detect speech presence and timestamps with accuracy and speed using the ultra-lightweight Silero VAD model
    speech, recognition, transcription, audio-analysis

    Use cases:
    - Speech recognition
    - Audio transcription
    - Speaker diarization
    - Voice activity detection
    - Meeting transcription
    """

    audio: types.AudioRef | OutputHandle[types.AudioRef] = connect_field(
        default=types.AudioRef(
            type="audio", uri="", asset_id=None, data=None, metadata=None
        ),
        description="The URL of the audio to get speech timestamps from.",
    )

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.fal.audio_to_text.SileroVad

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()
