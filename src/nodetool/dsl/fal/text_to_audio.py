# This file is auto-generated by nodetool.dsl.codegen.
# Please do not edit this file manually.

# Instead, edit the node class in the source module and run the following commands to regenerate the DSL:
# nodetool package scan
# nodetool codegen

from pydantic import BaseModel, Field
import typing
from typing import Any
import nodetool.metadata.types
import nodetool.metadata.types as types
from nodetool.dsl.graph import GraphNode, SingleOutputGraphNode

import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.fal.text_to_audio
from nodetool.workflows.base_node import BaseNode


class F5TTS(SingleOutputGraphNode[types.AudioRef], GraphNode[types.AudioRef]):
    """

    F5 TTS (Text-to-Speech) model for generating natural-sounding speech from text with voice cloning capabilities.
    audio, tts, voice-cloning, speech, synthesis, text-to-speech, tts, text-to-audio

    Use cases:
    - Generate natural speech from text
    - Clone and replicate voices
    - Create custom voiceovers
    - Produce multilingual speech content
    - Generate personalized audio content
    """

    gen_text: str | OutputHandle[str] = connect_field(
        default="", description="The text to be converted to speech"
    )
    ref_audio_url: str | OutputHandle[str] = connect_field(
        default="",
        description="URL of the reference audio file to clone the voice from",
    )
    ref_text: str | OutputHandle[str] = connect_field(
        default="",
        description="Optional reference text. If not provided, ASR will be used",
    )
    model_type: str | OutputHandle[str] = connect_field(
        default="F5-TTS", description="Model type to use (F5-TTS or E2-TTS)"
    )
    remove_silence: bool | OutputHandle[bool] = connect_field(
        default=True, description="Whether to remove silence from the generated audio"
    )

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.fal.text_to_audio.F5TTS

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.fal.text_to_audio
from nodetool.workflows.base_node import BaseNode


class MMAudioV2(SingleOutputGraphNode[types.AudioRef], GraphNode[types.AudioRef]):
    """

    MMAudio V2 generates synchronized audio given text inputs. It can generate sounds described by a prompt.
    audio, generation, synthesis, text-to-audio, synchronization

    Use cases:
    - Generate synchronized audio from text descriptions
    - Create custom sound effects
    - Produce ambient soundscapes
    - Generate audio for multimedia content
    - Create sound design elements
    """

    prompt: str | OutputHandle[str] = connect_field(
        default="", description="The prompt to generate the audio for"
    )
    negative_prompt: str | OutputHandle[str] = connect_field(
        default="",
        description="The negative prompt to avoid certain elements in the generated audio",
    )
    num_steps: int | OutputHandle[int] = connect_field(
        default=25, description="The number of steps to generate the audio for"
    )
    duration: float | OutputHandle[float] = connect_field(
        default=8.0, description="The duration of the audio to generate in seconds"
    )
    cfg_strength: float | OutputHandle[float] = connect_field(
        default=4.5, description="The strength of Classifier Free Guidance"
    )
    mask_away_clip: bool | OutputHandle[bool] = connect_field(
        default=False, description="Whether to mask away the clip"
    )
    seed: int | OutputHandle[int] = connect_field(
        default=-1, description="The same seed will output the same audio every time"
    )

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.fal.text_to_audio.MMAudioV2

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.fal.text_to_audio
from nodetool.workflows.base_node import BaseNode


class NovaSR(SingleOutputGraphNode[types.AudioRef], GraphNode[types.AudioRef]):
    """

    Nova SR enhances muffled 16 kHz speech audio into crystal-clear 48 kHz audio using super-resolution.
    audio, enhancement, super-resolution, speech, upsampling, audio-to-audio, nova-sr

    Use cases:
    - Enhance low-quality speech recordings
    - Upsample audio from 16kHz to 48kHz
    - Improve audio clarity for voice content
    - Prepare speech for downstream processing
    - Recover details from compressed audio
    """

    AudioFormatEnum: typing.ClassVar[type] = (
        nodetool.nodes.fal.text_to_audio.AudioFormatEnum
    )

    audio: types.AudioRef | OutputHandle[types.AudioRef] = connect_field(
        default=types.AudioRef(
            type="audio", uri="", asset_id=None, data=None, metadata=None
        ),
        description="The audio file to enhance",
    )
    audio_format: nodetool.nodes.fal.text_to_audio.AudioFormatEnum = Field(
        default=nodetool.nodes.fal.text_to_audio.AudioFormatEnum.MP3,
        description="Output audio format",
    )
    bitrate: str | OutputHandle[str] = connect_field(
        default="192k", description="Output audio bitrate"
    )
    sync_mode: bool | OutputHandle[bool] = connect_field(
        default=False, description="If True, media returned as data URI"
    )

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.fal.text_to_audio.NovaSR

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.fal.text_to_audio
from nodetool.workflows.base_node import BaseNode


class PlayAITTSDialog(SingleOutputGraphNode[types.AudioRef], GraphNode[types.AudioRef]):
    """
    PlayAI Dialog TTS generates speech for multi speaker dialogs.
        audio, tts, dialog, speech, synthesis

        Use cases:
        - Generate interactive conversations
        - Create voice overs with multiple characters
        - Produce spoken dialogs for games
        - Synthesize narration with distinct voices
        - Prototype conversational audio
    """

    text: str | OutputHandle[str] = connect_field(
        default="", description="Text to convert into speech"
    )
    voice: str | OutputHandle[str] = connect_field(
        default="nova", description="Voice preset to use for the spoken dialog"
    )
    speed: float | OutputHandle[float] = connect_field(
        default=1.0, description="Playback speed of the generated audio"
    )

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.fal.text_to_audio.PlayAITTSDialog

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.fal.text_to_audio
from nodetool.workflows.base_node import BaseNode


class StableAudio(SingleOutputGraphNode[types.AudioRef], GraphNode[types.AudioRef]):
    """

    Stable Audio generates audio from text prompts. Open source text-to-audio model from fal.ai.
    audio, generation, synthesis, text-to-audio, open-source

    Use cases:
    - Generate custom audio content from text
    - Create background music and sounds
    - Produce audio assets for projects
    - Generate sound effects
    - Create experimental audio content
    """

    prompt: str | OutputHandle[str] = connect_field(
        default="", description="The prompt to generate the audio from"
    )
    seconds_start: int | OutputHandle[int] = connect_field(
        default=0, description="The start point of the audio clip to generate"
    )
    seconds_total: int | OutputHandle[int] = connect_field(
        default=30, description="The duration of the audio clip to generate in seconds"
    )
    steps: int | OutputHandle[int] = connect_field(
        default=100, description="The number of steps to denoise the audio for"
    )

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.fal.text_to_audio.StableAudio

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()
