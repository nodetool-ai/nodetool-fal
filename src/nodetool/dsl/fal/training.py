# This file is auto-generated by nodetool.dsl.codegen.
# Please do not edit this file manually.

# Instead, edit the node class in the source module and run the following commands to regenerate the DSL:
# nodetool package scan
# nodetool codegen

from pydantic import BaseModel, Field
import typing
from typing import Any
import nodetool.metadata.types
import nodetool.metadata.types as types
from nodetool.dsl.graph import GraphNode, SingleOutputGraphNode

import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.fal.training
from nodetool.workflows.base_node import BaseNode

class Flux2Klein4BBaseTrainer(SingleOutputGraphNode[dict[str, Any]], GraphNode[dict[str, Any]]):
    """

        Flux 2 Klein 4B Base Trainer
        flux, training, fine-tuning, lora, model-training

        Use cases:
        - Automated content generation
        - Creative workflows
        - Batch processing
        - Professional applications
        - Rapid prototyping
    """

    OutputLoraFormat: typing.ClassVar[type] = nodetool.nodes.fal.training.Flux2Klein4BBaseTrainer.OutputLoraFormat

    steps: int | OutputHandle[int] = connect_field(default=1000, description='Total number of training steps.')
    image_data_url: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(default=types.ImageRef(type='image', uri='', asset_id=None, data=None, metadata=None), description='URL to zip archive with images of a consistent style. Try to use at least 10 images, although more is better. The zip can also contain a text file for each image. The text file should be named: ROOT.txt For example: photo.txt This text file can be used to specify the edit instructions for the image pair. If no text file is provided, the default_caption will be used. If no default_caption is provided, the training will fail.')
    learning_rate: float | OutputHandle[float] = connect_field(default=5e-05, description='Learning rate applied to trainable parameters.')
    default_caption: str | OutputHandle[str] = connect_field(default='', description='Default caption to use when caption files are missing. If None, missing captions will cause an error.')
    output_lora_format: nodetool.nodes.fal.training.Flux2Klein4BBaseTrainer.OutputLoraFormat = Field(default=nodetool.nodes.fal.training.Flux2Klein4BBaseTrainer.OutputLoraFormat.FAL, description='Dictates the naming scheme for the output weights')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.fal.training.Flux2Klein4BBaseTrainer

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.fal.training
from nodetool.workflows.base_node import BaseNode

class Flux2Klein4BBaseTrainerEdit(SingleOutputGraphNode[dict[str, Any]], GraphNode[dict[str, Any]]):
    """

        Flux 2 Klein 4B Base Trainer
        flux, training, fine-tuning, lora, model-training

        Use cases:
        - Automated content generation
        - Creative workflows
        - Batch processing
        - Professional applications
        - Rapid prototyping
    """

    OutputLoraFormat: typing.ClassVar[type] = nodetool.nodes.fal.training.Flux2Klein4BBaseTrainerEdit.OutputLoraFormat

    steps: int | OutputHandle[int] = connect_field(default=1000, description='Total number of training steps.')
    image_data_url: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(default=types.ImageRef(type='image', uri='', asset_id=None, data=None, metadata=None), description='URL to the input data zip archive. The zip should contain pairs of images. The images should be named: ROOT_start.EXT and ROOT_end.EXT For example: photo_start.jpg and photo_end.jpg The zip can also contain up to four reference image for each image pair. The reference images should be named: ROOT_start.EXT, ROOT_start2.EXT, ROOT_start3.EXT, ROOT_start4.EXT, ROOT_end.EXT For example: photo_start.jpg, photo_start2.jpg, photo_end.jpg The zip can also contain a text file for each image pair. The text file should be named: ROOT.txt For example: photo.txt This text file can be used to specify the edit instructions for the image pair. If no text file is provided, the default_caption will be used. If no default_caption is provided, the training will fail.')
    learning_rate: float | OutputHandle[float] = connect_field(default=5e-05, description='Learning rate applied to trainable parameters.')
    default_caption: str | OutputHandle[str] = connect_field(default='', description='Default caption to use when caption files are missing. If None, missing captions will cause an error.')
    output_lora_format: nodetool.nodes.fal.training.Flux2Klein4BBaseTrainerEdit.OutputLoraFormat = Field(default=nodetool.nodes.fal.training.Flux2Klein4BBaseTrainerEdit.OutputLoraFormat.FAL, description='Dictates the naming scheme for the output weights')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.fal.training.Flux2Klein4BBaseTrainerEdit

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.fal.training
from nodetool.workflows.base_node import BaseNode

class Flux2Klein9BBaseTrainer(SingleOutputGraphNode[dict[str, Any]], GraphNode[dict[str, Any]]):
    """

        Flux 2 Klein 9B Base Trainer
        flux, training, fine-tuning, lora, model-training

        Use cases:
        - Automated content generation
        - Creative workflows
        - Batch processing
        - Professional applications
        - Rapid prototyping
    """

    OutputLoraFormat: typing.ClassVar[type] = nodetool.nodes.fal.training.Flux2Klein9BBaseTrainer.OutputLoraFormat

    steps: int | OutputHandle[int] = connect_field(default=1000, description='Total number of training steps.')
    image_data_url: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(default=types.ImageRef(type='image', uri='', asset_id=None, data=None, metadata=None), description='URL to zip archive with images of a consistent style. Try to use at least 10 images, although more is better. The zip can also contain a text file for each image. The text file should be named: ROOT.txt For example: photo.txt This text file can be used to specify the edit instructions for the image pair. If no text file is provided, the default_caption will be used. If no default_caption is provided, the training will fail.')
    learning_rate: float | OutputHandle[float] = connect_field(default=5e-05, description='Learning rate applied to trainable parameters.')
    default_caption: str | OutputHandle[str] = connect_field(default='', description='Default caption to use when caption files are missing. If None, missing captions will cause an error.')
    output_lora_format: nodetool.nodes.fal.training.Flux2Klein9BBaseTrainer.OutputLoraFormat = Field(default=nodetool.nodes.fal.training.Flux2Klein9BBaseTrainer.OutputLoraFormat.FAL, description='Dictates the naming scheme for the output weights')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.fal.training.Flux2Klein9BBaseTrainer

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.fal.training
from nodetool.workflows.base_node import BaseNode

class Flux2Klein9BBaseTrainerEdit(SingleOutputGraphNode[dict[str, Any]], GraphNode[dict[str, Any]]):
    """

        Flux 2 Klein 9B Base Trainer
        flux, training, fine-tuning, lora, model-training

        Use cases:
        - Automated content generation
        - Creative workflows
        - Batch processing
        - Professional applications
        - Rapid prototyping
    """

    OutputLoraFormat: typing.ClassVar[type] = nodetool.nodes.fal.training.Flux2Klein9BBaseTrainerEdit.OutputLoraFormat

    steps: int | OutputHandle[int] = connect_field(default=1000, description='Total number of training steps.')
    image_data_url: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(default=types.ImageRef(type='image', uri='', asset_id=None, data=None, metadata=None), description='URL to the input data zip archive. The zip should contain pairs of images. The images should be named: ROOT_start.EXT and ROOT_end.EXT For example: photo_start.jpg and photo_end.jpg The zip can also contain up to four reference image for each image pair. The reference images should be named: ROOT_start.EXT, ROOT_start2.EXT, ROOT_start3.EXT, ROOT_start4.EXT, ROOT_end.EXT For example: photo_start.jpg, photo_start2.jpg, photo_end.jpg The zip can also contain a text file for each image pair. The text file should be named: ROOT.txt For example: photo.txt This text file can be used to specify the edit instructions for the image pair. If no text file is provided, the default_caption will be used. If no default_caption is provided, the training will fail.')
    learning_rate: float | OutputHandle[float] = connect_field(default=5e-05, description='Learning rate applied to trainable parameters.')
    default_caption: str | OutputHandle[str] = connect_field(default='', description='Default caption to use when caption files are missing. If None, missing captions will cause an error.')
    output_lora_format: nodetool.nodes.fal.training.Flux2Klein9BBaseTrainerEdit.OutputLoraFormat = Field(default=nodetool.nodes.fal.training.Flux2Klein9BBaseTrainerEdit.OutputLoraFormat.FAL, description='Dictates the naming scheme for the output weights')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.fal.training.Flux2Klein9BBaseTrainerEdit

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.fal.training
from nodetool.workflows.base_node import BaseNode

class Flux2TrainerV2(SingleOutputGraphNode[dict[str, Any]], GraphNode[dict[str, Any]]):
    """

        Flux 2 Trainer V2
        flux, training, fine-tuning, lora, model-training

        Use cases:
        - Automated content generation
        - Creative workflows
        - Batch processing
        - Professional applications
        - Rapid prototyping
    """

    OutputLoraFormat: typing.ClassVar[type] = nodetool.nodes.fal.training.Flux2TrainerV2.OutputLoraFormat

    steps: int | OutputHandle[int] = connect_field(default=1000, description='Total number of training steps.')
    image_data_url: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(default=types.ImageRef(type='image', uri='', asset_id=None, data=None, metadata=None), description='URL to zip archive with images of a consistent style. Try to use at least 10 images, although more is better. The zip can also contain a text file for each image. The text file should be named: ROOT.txt For example: photo.txt This text file can be used to specify the edit instructions for the image pair. If no text file is provided, the default_caption will be used. If no default_caption is provided, the training will fail.')
    learning_rate: float | OutputHandle[float] = connect_field(default=5e-05, description='Learning rate applied to trainable parameters.')
    default_caption: str | OutputHandle[str] = connect_field(default='', description='Default caption to use when caption files are missing. If None, missing captions will cause an error.')
    output_lora_format: nodetool.nodes.fal.training.Flux2TrainerV2.OutputLoraFormat = Field(default=nodetool.nodes.fal.training.Flux2TrainerV2.OutputLoraFormat.FAL, description='Dictates the naming scheme for the output weights')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.fal.training.Flux2TrainerV2

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.fal.training
from nodetool.workflows.base_node import BaseNode

class Flux2TrainerV2Edit(SingleOutputGraphNode[dict[str, Any]], GraphNode[dict[str, Any]]):
    """

        Flux 2 Trainer V2
        flux, training, fine-tuning, lora, model-training

        Use cases:
        - Automated content generation
        - Creative workflows
        - Batch processing
        - Professional applications
        - Rapid prototyping
    """

    OutputLoraFormat: typing.ClassVar[type] = nodetool.nodes.fal.training.Flux2TrainerV2Edit.OutputLoraFormat

    steps: int | OutputHandle[int] = connect_field(default=1000, description='Total number of training steps.')
    image_data_url: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(default=types.ImageRef(type='image', uri='', asset_id=None, data=None, metadata=None), description='URL to the input data zip archive. The zip should contain pairs of images. The images should be named: ROOT_start.EXT and ROOT_end.EXT For example: photo_start.jpg and photo_end.jpg The zip can also contain up to four reference image for each image pair. The reference images should be named: ROOT_start.EXT, ROOT_start2.EXT, ROOT_start3.EXT, ROOT_start4.EXT, ROOT_end.EXT For example: photo_start.jpg, photo_start2.jpg, photo_end.jpg The zip can also contain a text file for each image pair. The text file should be named: ROOT.txt For example: photo.txt This text file can be used to specify the edit instructions for the image pair. If no text file is provided, the default_caption will be used. If no default_caption is provided, the training will fail.')
    learning_rate: float | OutputHandle[float] = connect_field(default=5e-05, description='Learning rate applied to trainable parameters.')
    default_caption: str | OutputHandle[str] = connect_field(default='', description='Default caption to use when caption files are missing. If None, missing captions will cause an error.')
    output_lora_format: nodetool.nodes.fal.training.Flux2TrainerV2Edit.OutputLoraFormat = Field(default=nodetool.nodes.fal.training.Flux2TrainerV2Edit.OutputLoraFormat.FAL, description='Dictates the naming scheme for the output weights')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.fal.training.Flux2TrainerV2Edit

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.fal.training
from nodetool.workflows.base_node import BaseNode

class QwenImage2512Trainer(SingleOutputGraphNode[dict[str, Any]], GraphNode[dict[str, Any]]):
    """

        Qwen Image 2512 Trainer
        training, fine-tuning, lora, model-training

        Use cases:
        - Automated content generation
        - Creative workflows
        - Batch processing
        - Professional applications
        - Rapid prototyping
    """

    steps: int | OutputHandle[int] = connect_field(default=1000, description='Number of steps to train for')
    image_data_url: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(default=types.ImageRef(type='image', uri='', asset_id=None, data=None, metadata=None), description='URL to the input data zip archive for text-to-image training. The zip should contain images with their corresponding text captions: image.EXT and image.txt For example: photo.jpg and photo.txt The text file contains the caption/prompt describing the target image. If no text file is provided for an image, the default_caption will be used. If no default_caption is provided and a text file is missing, the training will fail.')
    learning_rate: float | OutputHandle[float] = connect_field(default=0.0005, description='Learning rate for LoRA parameters.')
    default_caption: str | OutputHandle[str] = connect_field(default='', description='Default caption to use when caption files are missing. If None, missing captions will cause an error.')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.fal.training.QwenImage2512Trainer

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.fal.training
from nodetool.workflows.base_node import BaseNode

class QwenImage2512TrainerV2(SingleOutputGraphNode[dict[str, Any]], GraphNode[dict[str, Any]]):
    """

        Qwen Image 2512 Trainer V2
        training, fine-tuning, lora, model-training

        Use cases:
        - Automated content generation
        - Creative workflows
        - Batch processing
        - Professional applications
        - Rapid prototyping
    """

    steps: int | OutputHandle[int] = connect_field(default=2000, description='Number of steps to train for')
    image_data_url: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(default=types.ImageRef(type='image', uri='', asset_id=None, data=None, metadata=None), description='URL to the input data zip archive. The zip should contain pairs of images and corresponding captions. The images should be named: ROOT.EXT. For example: 001.jpg The corresponding captions should be named: ROOT.txt. For example: 001.txt If no text file is provided for an image, the default_caption will be used.')
    learning_rate: float | OutputHandle[float] = connect_field(default=0.0005, description='Learning rate.')
    default_caption: str | OutputHandle[str] = connect_field(default='', description='Default caption to use when caption files are missing. If None, missing captions will cause an error.')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.fal.training.QwenImage2512TrainerV2

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.fal.training
from nodetool.workflows.base_node import BaseNode

class QwenImageEdit2509Trainer(SingleOutputGraphNode[dict[str, Any]], GraphNode[dict[str, Any]]):
    """

        Qwen Image Edit 2509 Trainer
        training, fine-tuning, lora, model-training

        Use cases:
        - Automated content generation
        - Creative workflows
        - Batch processing
        - Professional applications
        - Rapid prototyping
    """

    steps: int | OutputHandle[int] = connect_field(default=1000, description='Number of steps to train for')
    image_data_url: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(default=types.ImageRef(type='image', uri='', asset_id=None, data=None, metadata=None), description='URL to the input data zip archive. The zip should contain pairs of images. The images should be named: ROOT_start.EXT and ROOT_end.EXT For example: photo_start.jpg and photo_end.jpg The zip can also contain more than one reference image for each image pair. The reference images should be named: ROOT_start.EXT, ROOT_start2.EXT, ROOT_start3.EXT, ..., ROOT_end.EXT For example: photo_start.jpg, photo_start2.jpg, photo_end.jpg The Reference Image Count field should be set to the number of reference images. The zip can also contain a text file for each image pair. The text file should be named: ROOT.txt For example: photo.txt This text file can be used to specify the edit instructions for the image pair. If no text file is provided, the default_caption will be used. If no default_caption is provided, the training will fail.')
    learning_rate: float | OutputHandle[float] = connect_field(default=0.0001, description='Learning rate for LoRA parameters.')
    default_caption: str | OutputHandle[str] = connect_field(default='', description='Default caption to use when caption files are missing. If None, missing captions will cause an error.')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.fal.training.QwenImageEdit2509Trainer

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.fal.training
from nodetool.workflows.base_node import BaseNode

class QwenImageEdit2511Trainer(SingleOutputGraphNode[dict[str, Any]], GraphNode[dict[str, Any]]):
    """

        Qwen Image Edit 2511 Trainer
        training, fine-tuning, lora, model-training

        Use cases:
        - Automated content generation
        - Creative workflows
        - Batch processing
        - Professional applications
        - Rapid prototyping
    """

    steps: int | OutputHandle[int] = connect_field(default=1000, description='Number of steps to train for')
    image_data_url: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(default=types.ImageRef(type='image', uri='', asset_id=None, data=None, metadata=None), description='URL to the input data zip archive. The zip should contain pairs of images. The images should be named: ROOT_start.EXT and ROOT_end.EXT For example: photo_start.jpg and photo_end.jpg The zip can also contain more than one reference image for each image pair. The reference images should be named: ROOT_start.EXT, ROOT_start2.EXT, ROOT_start3.EXT, ..., ROOT_end.EXT For example: photo_start.jpg, photo_start2.jpg, photo_end.jpg The Reference Image Count field should be set to the number of reference images. The zip can also contain a text file for each image pair. The text file should be named: ROOT.txt For example: photo.txt This text file can be used to specify the edit instructions for the image pair. If no text file is provided, the default_caption will be used. If no default_caption is provided, the training will fail.')
    learning_rate: float | OutputHandle[float] = connect_field(default=0.0001, description='Learning rate for LoRA parameters.')
    default_caption: str | OutputHandle[str] = connect_field(default='', description='Default caption to use when caption files are missing. If None, missing captions will cause an error.')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.fal.training.QwenImageEdit2511Trainer

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.fal.training
from nodetool.workflows.base_node import BaseNode

class QwenImageLayeredTrainer(SingleOutputGraphNode[dict[str, Any]], GraphNode[dict[str, Any]]):
    """

        Qwen Image Layered Trainer
        training, fine-tuning, lora, model-training

        Use cases:
        - Automated content generation
        - Creative workflows
        - Batch processing
        - Professional applications
        - Rapid prototyping
    """

    steps: int | OutputHandle[int] = connect_field(default=1000, description='Number of steps to train for')
    image_data_url: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(default=types.ImageRef(type='image', uri='', asset_id=None, data=None, metadata=None), description='URL to the input data zip archive. The zip should contain groups of images. The images should be named: ROOT_start.EXT, ROOT_end.EXT, ROOT_end2.EXT, ..., ROOT_endN.EXT For example: photo_start.png, photo_end.png, photo_end2.png, ..., photo_endN.png The start image is the base image that will be decomposed into layers. The end images are the layers that will be added to the base image. ROOT_end.EXT is the first layer, ROOT_end2.EXT is the second layer, and so on. You can have up to 8 layers. All image groups must have the same number of output layers. The end images can contain transparent regions. Only PNG and WebP images are supported since these are the only formats that support transparency. The zip can also contain a text file for each image group. The text file should be named: ROOT.txt For example: photo.txt This text file can be used to specify a description of the base image. If no text file is provided, the default_caption will be used. If no default_caption is provided, the training will fail.')
    learning_rate: float | OutputHandle[float] = connect_field(default=0.0001, description='Learning rate for LoRA parameters.')
    default_caption: str | OutputHandle[str] = connect_field(default='', description='Default caption to use when caption files are missing. If None, missing captions will cause an error.')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.fal.training.QwenImageLayeredTrainer

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.fal.training
from nodetool.workflows.base_node import BaseNode

class ZImageBaseTrainer(SingleOutputGraphNode[dict[str, Any]], GraphNode[dict[str, Any]]):
    """

        Z-Image Trainer
        training, fine-tuning, lora, model-training

        Use cases:
        - Automated content generation
        - Creative workflows
        - Batch processing
        - Professional applications
        - Rapid prototyping
    """

    steps: int | OutputHandle[int] = connect_field(default=2000, description='Number of steps to train for')
    image_data_url: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(default=types.ImageRef(type='image', uri='', asset_id=None, data=None, metadata=None), description='URL to the input data zip archive. The zip should contain pairs of images and corresponding captions. The images should be named: ROOT.EXT. For example: 001.jpg The corresponding captions should be named: ROOT.txt. For example: 001.txt If no text file is provided for an image, the default_caption will be used.')
    learning_rate: float | OutputHandle[float] = connect_field(default=0.0005, description='Learning rate.')
    default_caption: str | OutputHandle[str] = connect_field(default='', description='Default caption to use when caption files are missing. If None, missing captions will cause an error.')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.fal.training.ZImageBaseTrainer

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.fal.training
from nodetool.workflows.base_node import BaseNode

class ZImageTurboTrainerV2(SingleOutputGraphNode[dict[str, Any]], GraphNode[dict[str, Any]]):
    """

        Z Image Turbo Trainer V2
        training, fine-tuning, lora, model-training, fast

        Use cases:
        - Automated content generation
        - Creative workflows
        - Batch processing
        - Professional applications
        - Rapid prototyping
    """

    steps: int | OutputHandle[int] = connect_field(default=2000, description='Number of steps to train for')
    image_data_url: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(default=types.ImageRef(type='image', uri='', asset_id=None, data=None, metadata=None), description='URL to the input data zip archive. The zip should contain pairs of images and corresponding captions. The images should be named: ROOT.EXT. For example: 001.jpg The corresponding captions should be named: ROOT.txt. For example: 001.txt If no text file is provided for an image, the default_caption will be used.')
    learning_rate: float | OutputHandle[float] = connect_field(default=0.0005, description='Learning rate.')
    default_caption: str | OutputHandle[str] = connect_field(default='', description='Default caption to use when caption files are missing. If None, missing captions will cause an error.')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.fal.training.ZImageTurboTrainerV2

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


