# This file is auto-generated by nodetool.dsl.codegen.
# Please do not edit this file manually.

# Instead, edit the node class in the source module and run the following commands to regenerate the DSL:
# nodetool package scan
# nodetool codegen

from pydantic import BaseModel, Field
import typing
from typing import Any
import nodetool.metadata.types
import nodetool.metadata.types as types
from nodetool.dsl.graph import GraphNode, SingleOutputGraphNode

import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.fal.image_to_image
from nodetool.workflows.base_node import BaseNode

class BiRefNet(SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]):
    """

        BiRefNet is a high-quality background removal model using bilateral reference.
        image, background-removal, segmentation, matting

        Use cases:
        - Remove backgrounds from photos
        - Create product images with transparent backgrounds
        - Extract subjects from images
        - Prepare images for compositing
        - Create stickers and cutouts
    """

    image: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(default=types.ImageRef(type='image', uri='', asset_id=None, data=None, metadata=None), description='The input image for background removal')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.fal.image_to_image.BiRefNet

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.fal.image_to_image
from nodetool.workflows.base_node import BaseNode

class BiRefNetV2(SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]):
    """

        BiRefNet V2 is an improved background removal model with better edge detection.
        image, background-removal, segmentation, matting, v2

        Use cases:
        - High-quality background removal
        - Precise edge detection for cutouts
        - Product photography processing
        - Portrait extraction
        - Complex background handling
    """

    image: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(default=types.ImageRef(type='image', uri='', asset_id=None, data=None, metadata=None), description='The input image for background removal')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.fal.image_to_image.BiRefNetV2

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.fal.image_to_image
from nodetool.workflows.base_node import BaseNode

class BriaBackgroundRemove(SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]):
    """

        Bria RMBG 2.0 enables seamless removal of backgrounds from images, ideal for professional editing tasks.
        Trained exclusively on licensed data for safe and risk-free commercial use.
    """

    image: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(default=types.ImageRef(type='image', uri='', asset_id=None, data=None, metadata=None), description='Input image to remove background from')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.fal.image_to_image.BriaBackgroundRemove

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.fal.image_to_image
from nodetool.workflows.base_node import BaseNode

class BriaBackgroundReplace(SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]):
    """
    Bria Background Replace allows for efficient swapping of backgrounds in images via text prompts or reference image, delivering realistic and polished results. Trained exclusively on licensed data for safe and risk-free commercial use.
        image, background, replacement, swap

        Use cases:
        - Replace image backgrounds seamlessly
        - Create professional photo compositions
        - Generate custom scene settings
        - Produce commercial-ready images
        - Create consistent visual environments
    """

    image: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(default=types.ImageRef(type='image', uri='', asset_id=None, data=None, metadata=None), description='Input image to replace background')
    ref_image: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(default=types.ImageRef(type='image', uri='', asset_id=None, data=None, metadata=None), description='Reference image for the new background')
    prompt: str | OutputHandle[str] = connect_field(default='', description='Prompt to generate new background')
    negative_prompt: str | OutputHandle[str] = connect_field(default='', description='Negative prompt for background generation')
    refine_prompt: bool | OutputHandle[bool] = connect_field(default=True, description='Whether to refine the prompt')
    seed: int | OutputHandle[int] = connect_field(default=-1, description='The same seed will output the same image every time')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.fal.image_to_image.BriaBackgroundReplace

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.fal.image_to_image
from nodetool.workflows.base_node import BaseNode

class BriaEraser(SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]):
    """

        Bria Eraser enables precise removal of unwanted objects from images while maintaining high-quality outputs. Trained exclusively on licensed data for safe and risk-free commercial use.
        image, removal, cleanup

        Use cases:
        - Remove unwanted objects from images
        - Clean up image imperfections
        - Prepare images for commercial use
        - Remove distracting elements
        - Create clean, professional images
    """

    image: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(default=types.ImageRef(type='image', uri='', asset_id=None, data=None, metadata=None), description='Input image to erase from')
    mask: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(default=types.ImageRef(type='image', uri='', asset_id=None, data=None, metadata=None), description='The mask for areas to be cleaned')
    mask_type: str | OutputHandle[str] = connect_field(default='manual', description="Type of mask - 'manual' for user-created or 'automatic' for algorithm-generated")

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.fal.image_to_image.BriaEraser

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.fal.image_to_image
from nodetool.workflows.base_node import BaseNode

class BriaExpand(SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]):
    """
    Bria Expand expands images beyond their borders in high quality. Trained exclusively on licensed data for safe and risk-free commercial use.
        image, expansion, outpainting

        Use cases:
        - Extend image boundaries seamlessly
        - Create wider or taller compositions
        - Expand images for different aspect ratios
        - Generate additional scene content
    """

    image: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(default=types.ImageRef(type='image', uri='', asset_id=None, data=None, metadata=None), description='The input image to expand')
    canvas_width: int | OutputHandle[int] = connect_field(default=1200, description='The desired width of the final image, after the expansion')
    canvas_height: int | OutputHandle[int] = connect_field(default=674, description='The desired height of the final image, after the expansion')
    original_image_width: int | OutputHandle[int] = connect_field(default=610, description='The desired width of the original image, inside the full canvas')
    original_image_height: int | OutputHandle[int] = connect_field(default=855, description='The desired height of the original image, inside the full canvas')
    original_image_x: int | OutputHandle[int] = connect_field(default=301, description='The desired x-coordinate of the original image, inside the full canvas')
    original_image_y: int | OutputHandle[int] = connect_field(default=-66, description='The desired y-coordinate of the original image, inside the full canvas')
    prompt: str | OutputHandle[str] = connect_field(default='', description='Text on which you wish to base the image expansion')
    negative_prompt: str | OutputHandle[str] = connect_field(default='', description='The negative prompt to use when generating images')
    num_images: int | OutputHandle[int] = connect_field(default=1, description='Number of images to generate')
    seed: int | OutputHandle[int] = connect_field(default=-1, description='The same seed will output the same image every time')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.fal.image_to_image.BriaExpand

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.fal.image_to_image
from nodetool.workflows.base_node import BaseNode

class BriaGenFill(SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]):
    """
    Bria GenFill enables high-quality object addition or visual transformation. Trained exclusively on licensed data for safe and risk-free commercial use.
        image, generation, filling, transformation

        Use cases:
        - Add new objects to existing images
        - Transform specific image areas
        - Generate contextual content
        - Create seamless visual additions
        - Produce professional image modifications
    """

    image: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(default=types.ImageRef(type='image', uri='', asset_id=None, data=None, metadata=None), description='Input image to erase from')
    mask: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(default=types.ImageRef(type='image', uri='', asset_id=None, data=None, metadata=None), description='The mask for areas to be cleaned')
    prompt: str | OutputHandle[str] = connect_field(default='', description='The prompt to generate images')
    negative_prompt: str | OutputHandle[str] = connect_field(default='', description='The negative prompt to use when generating images')
    seed: int | OutputHandle[int] = connect_field(default=-1, description='The same seed will output the same image every time')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.fal.image_to_image.BriaGenFill

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.fal.image_to_image
from nodetool.workflows.base_node import BaseNode

class BriaProductShot(SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]):
    """
    Place any product in any scenery with just a prompt or reference image while maintaining high integrity of the product. Trained exclusively on licensed data for safe and risk-free commercial use and optimized for eCommerce.
        image, product, placement, ecommerce

        Use cases:
        - Create professional product photography
        - Generate contextual product shots
        - Place products in custom environments
        - Create eCommerce product listings
        - Generate marketing visuals
    """

    image: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(default=types.ImageRef(type='image', uri='', asset_id=None, data=None, metadata=None), description='The product image to be placed')
    scene_description: str | OutputHandle[str] = connect_field(default='', description='Text description of the new scene/background')
    ref_image: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(default=types.ImageRef(type='image', uri='', asset_id=None, data=None, metadata=None), description='Reference image for the new scene/background')
    optimize_description: bool | OutputHandle[bool] = connect_field(default=True, description='Whether to optimize the scene description')
    placement_type: str | OutputHandle[str] = connect_field(default='manual_placement', description='How to position the product (original, automatic, manual_placement, manual_padding)')
    manual_placement_selection: str | OutputHandle[str] = connect_field(default='bottom_center', description='Specific placement position when using manual_placement')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.fal.image_to_image.BriaProductShot

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.fal.image_to_image
from nodetool.workflows.base_node import BaseNode

class BriaReplaceBackground(SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]):
    """

        Creates enriched product shots by placing them in various environments using textual descriptions.
        image, background, replacement, product, enhancement, bria

        Use cases:
        - Replace product image backgrounds with custom environments
        - Create professional product photography
        - Generate contextual product shots
        - Enhance e-commerce product images
        - Create marketing visuals with custom backgrounds
    """

    image: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(default=types.ImageRef(type='image', uri='', asset_id=None, data=None, metadata=None), description='Reference image for background replacement')
    prompt: str | OutputHandle[str] = connect_field(default='', description='Prompt for background replacement')
    negative_prompt: str | OutputHandle[str] = connect_field(default='', description='Negative prompt for background replacement')
    seed: int | OutputHandle[int] = connect_field(default=4925634, description='Random seed for reproducibility')
    steps_num: int | OutputHandle[int] = connect_field(default=30, description='Number of inference steps')
    sync_mode: bool | OutputHandle[bool] = connect_field(default=False, description='If true, returns the image directly in the response (increases latency)')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.fal.image_to_image.BriaReplaceBackground

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.fal.image_to_image
from nodetool.workflows.base_node import BaseNode

class CCSR(SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]):
    """

        CCSR (Content-Consistent Super-Resolution) for high-quality image upscaling.
        image, upscaling, super-resolution, enhancement

        Use cases:
        - Upscale images with content consistency
        - Enhance low-resolution photos
        - Improve image details
        - Prepare images for printing
        - Restore compressed images
    """

    image: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(default=types.ImageRef(type='image', uri='', asset_id=None, data=None, metadata=None), description='The input image to upscale')
    scale: int | OutputHandle[int] = connect_field(default=4, description='Upscaling factor')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.fal.image_to_image.CCSR

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.fal.image_to_image
from nodetool.workflows.base_node import BaseNode

class Cartoonify(SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]):
    """

        Cartoonify transforms photos into cartoon-style images.
        image, cartoon, style-transfer, fun, artistic

        Use cases:
        - Convert photos to cartoon style
        - Create animated-style portraits
        - Design fun profile pictures
        - Generate cartoon avatars
        - Create artistic transformations
    """

    image: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(default=types.ImageRef(type='image', uri='', asset_id=None, data=None, metadata=None), description='The image to cartoonify')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.fal.image_to_image.Cartoonify

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.fal.image_to_image
from nodetool.workflows.base_node import BaseNode

class ClarityUpscaler(SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]):
    """
    Upscale images to improve resolution and sharpness.

        clarity, upscale, enhancement

        Use cases:
        - Increase image resolution for printing
        - Improve clarity of low-quality images
        - Enhance textures and graphics
    """

    image: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(default=types.ImageRef(type='image', uri='', asset_id=None, data=None, metadata=None), description='Input image to upscale')
    scale: int | OutputHandle[int] = connect_field(default=2, description='Upscaling factor')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.fal.image_to_image.ClarityUpscaler

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.fal.image_to_image
from nodetool.workflows.base_node import BaseNode

class CodeFormer(SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]):
    """

        CodeFormer is a face restoration model for enhancing and restoring face quality.
        image, face-restoration, enhancement, quality

        Use cases:
        - Restore old or damaged photos
        - Enhance low-quality face images
        - Improve portrait quality
        - Fix facial artifacts
        - Upscale face details
    """

    image: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(default=types.ImageRef(type='image', uri='', asset_id=None, data=None, metadata=None), description='The input image with faces to restore')
    fidelity: float | OutputHandle[float] = connect_field(default=0.5, description='Balance between quality and fidelity (0=quality, 1=fidelity)')
    background_enhance: bool | OutputHandle[bool] = connect_field(default=True, description='Whether to enhance the background')
    face_upsample: bool | OutputHandle[bool] = connect_field(default=True, description='Whether to upsample the face')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.fal.image_to_image.CodeFormer

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.fal.image_to_image
from nodetool.workflows.base_node import BaseNode

class CreativeUpscaler(SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]):
    """

        Creative Upscaler enhances image resolution while adding creative details.
        image, upscaling, enhancement, super-resolution, creative

        Use cases:
        - Upscale low-resolution images
        - Enhance image details creatively
        - Improve image quality
        - Prepare images for print
        - Restore old or compressed images
    """

    image: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(default=types.ImageRef(type='image', uri='', asset_id=None, data=None, metadata=None), description='The input image to upscale')
    prompt: str | OutputHandle[str] = connect_field(default='', description='Optional prompt to guide the upscaling')
    scale: float | OutputHandle[float] = connect_field(default=2.0, description='Upscaling factor')
    creativity: float | OutputHandle[float] = connect_field(default=0.5, description='Level of creative enhancement')
    seed: int | OutputHandle[int] = connect_field(default=-1, description='Seed for reproducible generation')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.fal.image_to_image.CreativeUpscaler

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.fal.image_to_image
from nodetool.workflows.base_node import BaseNode

class ESRGAN(SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]):
    """

        ESRGAN (Enhanced Super-Resolution GAN) for high-quality image upscaling.
        image, upscaling, super-resolution, enhancement

        Use cases:
        - Upscale images to higher resolution
        - Enhance image details
        - Improve image quality for printing
        - Restore low-resolution images
        - Prepare images for large displays
    """

    image: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(default=types.ImageRef(type='image', uri='', asset_id=None, data=None, metadata=None), description='The input image to upscale')
    scale: int | OutputHandle[int] = connect_field(default=4, description='Upscaling factor')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.fal.image_to_image.ESRGAN

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.fal.image_to_image
from nodetool.workflows.base_node import BaseNode

class FaceToSticker(SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]):
    """

        Face to Sticker transforms face photos into fun sticker-style images.
        image, face, sticker, fun, transformation

        Use cases:
        - Create fun stickers from photos
        - Generate emoji-style faces
        - Design personalized sticker packs
        - Create cartoon avatars
        - Produce fun social media content
    """

    image: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(default=types.ImageRef(type='image', uri='', asset_id=None, data=None, metadata=None), description='The face image to convert to sticker')
    prompt: str | OutputHandle[str] = connect_field(default='sticker', description='Optional prompt to guide the sticker style')
    seed: int | OutputHandle[int] = connect_field(default=-1, description='Seed for reproducible generation')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.fal.image_to_image.FaceToSticker

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.fal.image_to_image
from nodetool.workflows.base_node import BaseNode

class Flux2TurboEdit(SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]):
    """

        FLUX 2 Turbo Edit for fast image editing with the FLUX 2 model.
        image, editing, flux, fast, turbo, text-guided

        Use cases:
        - Rapid image modifications
        - Quick style transfers
        - Fast object editing
        - Iterative refinement
        - Real-time editing workflows
    """

    image: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(default=types.ImageRef(type='image', uri='', asset_id=None, data=None, metadata=None), description='The input image to edit')
    prompt: str | OutputHandle[str] = connect_field(default='', description='The prompt describing the edit')
    num_inference_steps: int | OutputHandle[int] = connect_field(default=4, description='Number of inference steps')
    seed: int | OutputHandle[int] = connect_field(default=-1, description='Seed for reproducible generation')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.fal.image_to_image.Flux2TurboEdit

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.fal.image_to_image
from nodetool.workflows.base_node import BaseNode
import nodetool.nodes.fal.text_to_image

class FluxDevRedux(SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]):
    """

        FLUX.1 [dev] Redux is a high-performance endpoint that enables rapid transformation of existing images, delivering high-quality style transfers and image modifications.
        image, transformation, style-transfer, development, flux

        Use cases:
        - Transform images with advanced controls
        - Create customized image variations
        - Apply precise style modifications
    """

    ImageSizePreset: typing.ClassVar[type] = nodetool.nodes.fal.text_to_image.ImageSizePreset

    image: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(default=types.ImageRef(type='image', uri='', asset_id=None, data=None, metadata=None), description='The input image to transform')
    image_size: nodetool.nodes.fal.text_to_image.ImageSizePreset = Field(default=nodetool.nodes.fal.text_to_image.ImageSizePreset.LANDSCAPE_4_3, description='The size of the generated image')
    num_inference_steps: int | OutputHandle[int] = connect_field(default=28, description='The number of inference steps to perform')
    guidance_scale: float | OutputHandle[float] = connect_field(default=3.5, description='How closely the model should stick to your prompt')
    seed: int | OutputHandle[int] = connect_field(default=-1, description='The same seed will output the same image every time')
    enable_safety_checker: bool | OutputHandle[bool] = connect_field(default=True, description='If true, the safety checker will be enabled')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.fal.image_to_image.FluxDevRedux

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.fal.image_to_image
from nodetool.workflows.base_node import BaseNode
import nodetool.nodes.fal.text_to_image

class FluxLoraCanny(SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]):
    """
    FLUX LoRA Canny enables precise control over composition and style through edge detection and LoRA-based guidance mechanisms.
        image, edge, lora, style-transfer, control

        Use cases:
        - Generate stylized images with structural control
        - Create edge-guided artistic transformations
        - Apply custom styles while maintaining composition
        - Produce consistent style variations
    """

    ImageSizePreset: typing.ClassVar[type] = nodetool.nodes.fal.text_to_image.ImageSizePreset

    control_image: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(default=types.ImageRef(type='image', uri='', asset_id=None, data=None, metadata=None), description='The control image to generate the Canny edge map from')
    prompt: str | OutputHandle[str] = connect_field(default='', description='The prompt to generate an image from')
    image_size: nodetool.nodes.fal.text_to_image.ImageSizePreset = Field(default=nodetool.nodes.fal.text_to_image.ImageSizePreset.LANDSCAPE_4_3, description='The size of the generated image')
    num_inference_steps: int | OutputHandle[int] = connect_field(default=28, description='The number of inference steps to perform')
    guidance_scale: float | OutputHandle[float] = connect_field(default=3.5, description='How closely the model should stick to your prompt')
    seed: int | OutputHandle[int] = connect_field(default=-1, description='The same seed will output the same image every time')
    lora_scale: float | OutputHandle[float] = connect_field(default=0.6, description='The strength of the LoRA adaptation')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.fal.image_to_image.FluxLoraCanny

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.fal.image_to_image
from nodetool.workflows.base_node import BaseNode
import nodetool.nodes.fal.text_to_image

class FluxLoraDepth(SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]):
    """
    FLUX LoRA Depth enables precise control over composition and structure through depth map detection and LoRA-based guidance mechanisms.
        image, depth, lora, structure, control

        Use cases:
        - Generate depth-aware stylized images
        - Create 3D-conscious artistic transformations
        - Maintain spatial relationships with custom styles
        - Produce depth-consistent variations
        - Generate images with controlled perspective
    """

    ImageSizePreset: typing.ClassVar[type] = nodetool.nodes.fal.text_to_image.ImageSizePreset

    control_image: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(default=types.ImageRef(type='image', uri='', asset_id=None, data=None, metadata=None), description='The control image to generate the depth map from')
    prompt: str | OutputHandle[str] = connect_field(default='', description='The prompt to generate an image from')
    image_size: nodetool.nodes.fal.text_to_image.ImageSizePreset = Field(default=nodetool.nodes.fal.text_to_image.ImageSizePreset.LANDSCAPE_4_3, description='The size of the generated image')
    num_inference_steps: int | OutputHandle[int] = connect_field(default=28, description='The number of inference steps to perform')
    guidance_scale: float | OutputHandle[float] = connect_field(default=3.5, description='How closely the model should stick to your prompt')
    seed: int | OutputHandle[int] = connect_field(default=-1, description='The same seed will output the same image every time')
    lora_scale: float | OutputHandle[float] = connect_field(default=0.6, description='The strength of the LoRA adaptation')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.fal.image_to_image.FluxLoraDepth

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.fal.image_to_image
from nodetool.workflows.base_node import BaseNode
import nodetool.nodes.fal.text_to_image

class FluxProCanny(SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]):
    """
    FLUX.1 [pro] Canny enables precise control over composition, style, and structure through advanced edge detection and guidance mechanisms.
        image, edge, composition, style, control

        Use cases:
        - Generate images with precise structural control
        - Create artwork based on edge maps
        - Transform sketches into detailed images
        - Maintain specific compositional elements
        - Generate variations with consistent structure
    """

    ImageSizePreset: typing.ClassVar[type] = nodetool.nodes.fal.text_to_image.ImageSizePreset

    control_image: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(default=types.ImageRef(type='image', uri='', asset_id=None, data=None, metadata=None), description='The control image to generate the Canny edge map from')
    prompt: str | OutputHandle[str] = connect_field(default='', description='The prompt to generate an image from')
    image_size: nodetool.nodes.fal.text_to_image.ImageSizePreset = Field(default=nodetool.nodes.fal.text_to_image.ImageSizePreset.LANDSCAPE_4_3, description='The size of the generated image')
    num_inference_steps: int | OutputHandle[int] = connect_field(default=28, description='The number of inference steps to perform')
    guidance_scale: float | OutputHandle[float] = connect_field(default=3.5, description='How closely the model should stick to your prompt')
    seed: int | OutputHandle[int] = connect_field(default=-1, description='The same seed will output the same image every time')
    safety_tolerance: str | OutputHandle[str] = connect_field(default='2', description='Safety tolerance level (1-6, 1 being most strict)')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.fal.image_to_image.FluxProCanny

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.fal.image_to_image
from nodetool.workflows.base_node import BaseNode
import nodetool.nodes.fal.text_to_image

class FluxProDepth(SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]):
    """
    FLUX.1 [pro] Depth enables precise control over composition and structure through depth map detection and guidance mechanisms.
        image, depth-map, composition, structure, control

        Use cases:
        - Generate images with controlled depth perception
        - Create 3D-aware image transformations
        - Maintain spatial relationships in generated images
        - Produce images with accurate perspective
        - Generate variations with consistent depth structure
    """

    ImageSizePreset: typing.ClassVar[type] = nodetool.nodes.fal.text_to_image.ImageSizePreset

    control_image: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(default=types.ImageRef(type='image', uri='', asset_id=None, data=None, metadata=None), description='The control image to generate the depth map from')
    prompt: str | OutputHandle[str] = connect_field(default='', description='The prompt to generate an image from')
    image_size: nodetool.nodes.fal.text_to_image.ImageSizePreset = Field(default=nodetool.nodes.fal.text_to_image.ImageSizePreset.LANDSCAPE_4_3, description='The size of the generated image')
    num_inference_steps: int | OutputHandle[int] = connect_field(default=28, description='The number of inference steps to perform')
    guidance_scale: float | OutputHandle[float] = connect_field(default=3.5, description='How closely the model should stick to your prompt')
    seed: int | OutputHandle[int] = connect_field(default=-1, description='The same seed will output the same image every time')
    safety_tolerance: str | OutputHandle[str] = connect_field(default='2', description='Safety tolerance level (1-6, 1 being most strict)')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.fal.image_to_image.FluxProDepth

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.fal.image_to_image
from nodetool.workflows.base_node import BaseNode

class FluxProFill(SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]):
    """
    FLUX.1 [pro] Fill is a high-performance endpoint that enables rapid transformation of existing images with inpainting/outpainting capabilities.
        image, inpainting, outpainting, transformation, professional

        Use cases:
        - Fill in missing or masked parts of images
        - Extend images beyond their original boundaries
        - Remove and replace unwanted elements
        - Create seamless image completions
        - Generate context-aware image content
    """

    image: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(default=types.ImageRef(type='image', uri='', asset_id=None, data=None, metadata=None), description='The input image to transform')
    mask: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(default=types.ImageRef(type='image', uri='', asset_id=None, data=None, metadata=None), description='The mask for inpainting')
    prompt: str | OutputHandle[str] = connect_field(default='', description='The prompt to fill the masked part of the image')
    num_inference_steps: int | OutputHandle[int] = connect_field(default=28, description='The number of inference steps to perform')
    seed: int | OutputHandle[int] = connect_field(default=-1, description='The same seed will output the same image every time')
    safety_tolerance: str | OutputHandle[str] = connect_field(default='2', description='Safety tolerance level (1-6, 1 being most strict)')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.fal.image_to_image.FluxProFill

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.fal.image_to_image
from nodetool.workflows.base_node import BaseNode
import nodetool.nodes.fal.text_to_image

class FluxProRedux(SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]):
    """

        FLUX.1 [pro] Redux is a high-performance endpoint that enables rapid transformation of existing images, delivering high-quality style transfers and image modifications.
        image, transformation, style-transfer, flux

        Use cases:
        - Create professional image transformations
        - Generate style transfers
    """

    ImageSizePreset: typing.ClassVar[type] = nodetool.nodes.fal.text_to_image.ImageSizePreset

    image: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(default=types.ImageRef(type='image', uri='', asset_id=None, data=None, metadata=None), description='The input image to transform')
    image_size: nodetool.nodes.fal.text_to_image.ImageSizePreset = Field(default=nodetool.nodes.fal.text_to_image.ImageSizePreset.LANDSCAPE_4_3, description='The size of the generated image')
    num_inference_steps: int | OutputHandle[int] = connect_field(default=28, description='The number of inference steps to perform')
    guidance_scale: float | OutputHandle[float] = connect_field(default=3.5, description='How closely the model should stick to your prompt')
    seed: int | OutputHandle[int] = connect_field(default=-1, description='The same seed will output the same image every time')
    safety_tolerance: str | OutputHandle[str] = connect_field(default='2', description='Safety tolerance level (1-6, 1 being most strict)')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.fal.image_to_image.FluxProRedux

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.fal.image_to_image
from nodetool.workflows.base_node import BaseNode
import nodetool.nodes.fal.text_to_image

class FluxProUltraRedux(SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]):
    """

        FLUX1.1 [pro] ultra Redux is a high-performance endpoint that enables rapid transformation of existing images, delivering high-quality style transfers and image modifications with the core FLUX capabilities.
        image, transformation, style-transfer, ultra, professional

        Use cases:
        - Apply precise image modifications
        - Process images with maximum control
    """

    ImageSizePreset: typing.ClassVar[type] = nodetool.nodes.fal.text_to_image.ImageSizePreset

    image: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(default=types.ImageRef(type='image', uri='', asset_id=None, data=None, metadata=None), description='The input image to transform')
    image_size: nodetool.nodes.fal.text_to_image.ImageSizePreset = Field(default=nodetool.nodes.fal.text_to_image.ImageSizePreset.LANDSCAPE_4_3, description='The size of the generated image')
    num_inference_steps: int | OutputHandle[int] = connect_field(default=28, description='The number of inference steps to perform')
    guidance_scale: float | OutputHandle[float] = connect_field(default=3.5, description='How closely the model should stick to your prompt')
    seed: int | OutputHandle[int] = connect_field(default=-1, description='The same seed will output the same image every time')
    safety_tolerance: str | OutputHandle[str] = connect_field(default='2', description='Safety tolerance level (1-6, 1 being most strict)')
    image_prompt_strength: float | OutputHandle[float] = connect_field(default=0.1, description='The strength of the image prompt, between 0 and 1')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.fal.image_to_image.FluxProUltraRedux

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.fal.image_to_image
from nodetool.workflows.base_node import BaseNode
import nodetool.nodes.fal.text_to_image

class FluxSchnellRedux(SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]):
    """

        FLUX.1 [schnell] Redux is a high-performance endpoint that enables rapid transformation of existing images, delivering high-quality style transfers and image modifications with the core FLUX capabilities.
        image, transformation, style-transfer, fast, flux

        Use cases:
        - Transform images with style transfers
        - Apply artistic modifications to photos
        - Create image variations
    """

    ImageSizePreset: typing.ClassVar[type] = nodetool.nodes.fal.text_to_image.ImageSizePreset

    image: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(default=types.ImageRef(type='image', uri='', asset_id=None, data=None, metadata=None), description='The input image to transform')
    image_size: nodetool.nodes.fal.text_to_image.ImageSizePreset = Field(default=nodetool.nodes.fal.text_to_image.ImageSizePreset.LANDSCAPE_4_3, description='The size of the generated image')
    num_inference_steps: int | OutputHandle[int] = connect_field(default=4, description='The number of inference steps to perform')
    seed: int | OutputHandle[int] = connect_field(default=-1, description='The same seed will output the same image every time')
    enable_safety_checker: bool | OutputHandle[bool] = connect_field(default=True, description='If true, the safety checker will be enabled')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.fal.image_to_image.FluxSchnellRedux

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.fal.image_to_image
from nodetool.workflows.base_node import BaseNode

class GPTImage1Edit(SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]):
    """

        OpenAI GPT Image 1 Edit for modifying images with text instructions.
        image, editing, openai, gpt, text-guided

        Use cases:
        - Edit images with natural language
        - Modify specific elements in photos
        - Add or change objects
        - Apply creative edits
        - Refine images iteratively
    """

    image: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(default=types.ImageRef(type='image', uri='', asset_id=None, data=None, metadata=None), description='The input image to edit')
    mask: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(default=types.ImageRef(type='image', uri='', asset_id=None, data=None, metadata=None), description='The mask for inpainting (optional)')
    prompt: str | OutputHandle[str] = connect_field(default='', description='Instructions for editing the image')
    size: str | OutputHandle[str] = connect_field(default='1024x1024', description='The size of the output image')
    seed: int | OutputHandle[int] = connect_field(default=-1, description='Seed for reproducible generation')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.fal.image_to_image.GPTImage1Edit

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.fal.image_to_image
from nodetool.workflows.base_node import BaseNode

class GeminiFlashEdit(SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]):
    """

        Google Gemini Flash Edit for fast image editing with text prompts.
        image, editing, google, gemini, fast, text-guided

        Use cases:
        - Quick image modifications
        - Fast iterative edits
        - Object addition or removal
        - Style adjustments
        - Rapid prototyping
    """

    image: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(default=types.ImageRef(type='image', uri='', asset_id=None, data=None, metadata=None), description='The input image to edit')
    prompt: str | OutputHandle[str] = connect_field(default='', description='Instructions for editing the image')
    seed: int | OutputHandle[int] = connect_field(default=-1, description='Seed for reproducible generation')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.fal.image_to_image.GeminiFlashEdit

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.fal.image_to_image
from nodetool.workflows.base_node import BaseNode
import nodetool.nodes.fal.text_to_image

class HunyuanImageV3InstructEdit(SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]):
    """

        Hunyuan Image V3 Instruct Edit with reasoning capabilities for advanced image-to-image editing.
        image, edit, hunyuan, tencent, instruct, reasoning, image-to-image, img2img, advanced

        Use cases:
        - Edit images with complex instructions
        - Apply style transfers with reasoning
        - Modify images with multiple reference images
        - Create variations with intelligent understanding
        - Transform images with advanced prompt interpretation
    """

    HunyuanImageSizePreset: typing.ClassVar[type] = nodetool.nodes.fal.text_to_image.HunyuanImageSizePreset

    prompt: str | OutputHandle[str] = connect_field(default='', description='The text prompt for editing the image')
    image_urls: list[types.ImageRef] | OutputHandle[list[types.ImageRef]] = connect_field(default=PydanticUndefined, description='Reference images to use (maximum 2 images)')
    image_size: nodetool.nodes.fal.text_to_image.HunyuanImageSizePreset = Field(default=nodetool.nodes.fal.text_to_image.HunyuanImageSizePreset.AUTO, description='The desired size of the generated image. If auto, size is determined by the model')
    num_images: int | OutputHandle[int] = connect_field(default=1, description='The number of images to generate')
    guidance_scale: float | OutputHandle[float] = connect_field(default=3.5, description='How closely to follow the prompt (higher = stricter adherence)')
    seed: int | OutputHandle[int] = connect_field(default=-1, description='Seed for reproducible generation')
    enable_safety_checker: bool | OutputHandle[bool] = connect_field(default=True, description='Enable safety checker to filter unsafe content')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.fal.image_to_image.HunyuanImageV3InstructEdit

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.fal.image_to_image
from nodetool.workflows.base_node import BaseNode

class IdeogramV2Edit(SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]):
    """
    Transform existing images with Ideogram V2's editing capabilities. Modify, adjust, and refine images while maintaining high fidelity and realistic outputs with precise prompt control.
        image, editing, transformation, fidelity, control

        Use cases:
        - Edit specific parts of images with precision
        - Create targeted image modifications
        - Refine and enhance image details
        - Generate contextual image edits
    """

    prompt: str | OutputHandle[str] = connect_field(default='', description='The prompt to fill the masked part of the image')
    image: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(default=types.ImageRef(type='image', uri='', asset_id=None, data=None, metadata=None), description='The image to edit')
    mask: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(default=types.ImageRef(type='image', uri='', asset_id=None, data=None, metadata=None), description='The mask for editing')
    style: str | OutputHandle[str] = connect_field(default='auto', description='Style of generated image (auto, general, realistic, design, render_3D, anime)')
    expand_prompt: bool | OutputHandle[bool] = connect_field(default=True, description='Whether to expand the prompt with MagicPrompt functionality')
    seed: int | OutputHandle[int] = connect_field(default=-1, description='The same seed will output the same image every time')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.fal.image_to_image.IdeogramV2Edit

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.fal.image_to_image
from nodetool.workflows.base_node import BaseNode

class IdeogramV2Remix(SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]):
    """
    Reimagine existing images with Ideogram V2's remix feature. Create variations and adaptations while preserving core elements and adding new creative directions through prompt guidance.
        image, remix, variation, creativity, adaptation

        Use cases:
        - Create artistic variations of images
        - Generate style-transferred versions
        - Produce creative image adaptations
        - Transform images while preserving key elements
        - Generate alternative interpretations
    """

    prompt: str | OutputHandle[str] = connect_field(default='', description='The prompt to remix the image with')
    image: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(default=types.ImageRef(type='image', uri='', asset_id=None, data=None, metadata=None), description='The image to remix')
    aspect_ratio: str | OutputHandle[str] = connect_field(default='1:1', description='The aspect ratio of the generated image')
    strength: float | OutputHandle[float] = connect_field(default=0.8, description='Strength of the input image in the remix')
    expand_prompt: bool | OutputHandle[bool] = connect_field(default=True, description='Whether to expand the prompt with MagicPrompt functionality')
    style: str | OutputHandle[str] = connect_field(default='auto', description='Style of generated image (auto, general, realistic, design, render_3D, anime)')
    seed: int | OutputHandle[int] = connect_field(default=-1, description='The same seed will output the same image every time')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.fal.image_to_image.IdeogramV2Remix

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.fal.image_to_image
from nodetool.workflows.base_node import BaseNode

class IdeogramV3Edit(SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]):
    """

        Ideogram V3 Edit for editing images with text prompts while maintaining structure.
        image, editing, ideogram, inpainting, text-guided

        Use cases:
        - Edit specific parts of images with prompts
        - Modify text in images
        - Change elements while preserving composition
        - Add or remove objects from images
        - Refine generated images
    """

    image: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(default=types.ImageRef(type='image', uri='', asset_id=None, data=None, metadata=None), description='The input image to edit')
    mask: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(default=types.ImageRef(type='image', uri='', asset_id=None, data=None, metadata=None), description='The mask indicating areas to edit')
    prompt: str | OutputHandle[str] = connect_field(default='', description='The prompt describing the edit')
    style: str | OutputHandle[str] = connect_field(default='auto', description='The style of the edit')
    seed: int | OutputHandle[int] = connect_field(default=-1, description='Seed for reproducible generation')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.fal.image_to_image.IdeogramV3Edit

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.fal.image_to_image
from nodetool.workflows.base_node import BaseNode

class ImageUtilsDepth(SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]):
    """

        Depth estimation utility for generating depth maps from images.
        image, depth-map, estimation, 3d, utility

        Use cases:
        - Generate depth maps for 3D effects
        - Create parallax animations
        - Enable depth-aware editing
        - Generate ControlNet inputs
        - Analyze image depth structure
    """

    image: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(default=types.ImageRef(type='image', uri='', asset_id=None, data=None, metadata=None), description='The input image for depth estimation')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.fal.image_to_image.ImageUtilsDepth

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.fal.image_to_image
from nodetool.workflows.base_node import BaseNode

class ImageUtilsRembg(SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]):
    """

        Rembg utility for removing image backgrounds with high accuracy.
        image, background-removal, utility, processing

        Use cases:
        - Remove backgrounds from product photos
        - Create transparent PNG images
        - Extract subjects for compositing
        - Prepare images for design work
        - Create profile picture cutouts
    """

    image: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(default=types.ImageRef(type='image', uri='', asset_id=None, data=None, metadata=None), description='The input image for background removal')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.fal.image_to_image.ImageUtilsRembg

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.fal.image_to_image
from nodetool.workflows.base_node import BaseNode

class KolorsImageToImage(SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]):
    """

        Kolors Image-to-Image transforms images with the Kolors model.
        image, transformation, kolors, style-transfer

        Use cases:
        - Transform image style
        - Apply artistic effects
        - Modify image content
        - Create style variations
        - Generate image edits
    """

    image: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(default=types.ImageRef(type='image', uri='', asset_id=None, data=None, metadata=None), description='The input image')
    prompt: str | OutputHandle[str] = connect_field(default='', description='The prompt describing the transformation')
    negative_prompt: str | OutputHandle[str] = connect_field(default='', description='What to avoid in the generated image')
    strength: float | OutputHandle[float] = connect_field(default=0.8, description='Transformation strength')
    num_inference_steps: int | OutputHandle[int] = connect_field(default=25, description='Number of inference steps')
    guidance_scale: float | OutputHandle[float] = connect_field(default=5.0, description='How closely to follow the prompt')
    seed: int | OutputHandle[int] = connect_field(default=-1, description='Seed for reproducible generation')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.fal.image_to_image.KolorsImageToImage

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.fal.image_to_image
from nodetool.workflows.base_node import BaseNode

class LivePortrait(SingleOutputGraphNode[types.VideoRef], GraphNode[types.VideoRef]):
    """

        Live Portrait animates a single portrait image based on a driving video.
        image, animation, portrait, face, motion-transfer

        Use cases:
        - Animate static portraits
        - Create talking head videos
        - Transfer facial expressions
        - Create avatar animations
        - Generate video from single photo
    """

    image: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(default=types.ImageRef(type='image', uri='', asset_id=None, data=None, metadata=None), description='The portrait image to animate')
    driving_video: types.VideoRef | OutputHandle[types.VideoRef] = connect_field(default=types.VideoRef(type='video', uri='', asset_id=None, data=None, metadata=None, duration=None, format=None), description='The driving video with motion reference')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.fal.image_to_image.LivePortrait

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.fal.image_to_image
from nodetool.workflows.base_node import BaseNode

class ObjectRemoval(SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]):
    """

        Object Removal removes unwanted objects from images using AI.
        image, inpainting, removal, cleanup

        Use cases:
        - Remove unwanted objects from photos
        - Clean up image backgrounds
        - Remove watermarks or logos
        - Fix photo imperfections
        - Create clean product shots
    """

    image: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(default=types.ImageRef(type='image', uri='', asset_id=None, data=None, metadata=None), description='The input image')
    mask: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(default=types.ImageRef(type='image', uri='', asset_id=None, data=None, metadata=None), description='Mask indicating objects to remove')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.fal.image_to_image.ObjectRemoval

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.fal.image_to_image
from nodetool.workflows.base_node import BaseNode

class PhotoMaker(SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]):
    """

        PhotoMaker generates images with customizable subject identity from reference photos.
        image, face, identity, customization, generation

        Use cases:
        - Generate images with specific person identity
        - Create personalized marketing content
        - Design custom avatars
        - Produce character-consistent images
        - Generate variations of a person
    """

    image: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(default=types.ImageRef(type='image', uri='', asset_id=None, data=None, metadata=None), description='The reference image of the subject')
    prompt: str | OutputHandle[str] = connect_field(default='', description='The prompt describing the desired image')
    negative_prompt: str | OutputHandle[str] = connect_field(default='', description='What to avoid in the generated image')
    num_inference_steps: int | OutputHandle[int] = connect_field(default=50, description='Number of inference steps')
    style_strength: float | OutputHandle[float] = connect_field(default=20.0, description='Strength of the style transfer')
    seed: int | OutputHandle[int] = connect_field(default=-1, description='Seed for reproducible generation')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.fal.image_to_image.PhotoMaker

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.fal.image_to_image
from nodetool.workflows.base_node import BaseNode

class PuLID(SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]):
    """

        PuLID generates images with consistent face identity from a reference face.
        image, face, identity, generation, consistency

        Use cases:
        - Generate images with consistent face identity
        - Create character variations
        - Design personalized avatars
        - Produce face-consistent content
        - Generate marketing images with specific faces
    """

    face_image: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(default=types.ImageRef(type='image', uri='', asset_id=None, data=None, metadata=None), description='The reference face image')
    prompt: str | OutputHandle[str] = connect_field(default='', description='The prompt describing the desired image')
    negative_prompt: str | OutputHandle[str] = connect_field(default='', description='What to avoid in the generated image')
    num_inference_steps: int | OutputHandle[int] = connect_field(default=20, description='Number of inference steps')
    guidance_scale: float | OutputHandle[float] = connect_field(default=1.2, description='How closely to follow the prompt')
    seed: int | OutputHandle[int] = connect_field(default=-1, description='Seed for reproducible generation')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.fal.image_to_image.PuLID

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.fal.image_to_image
from nodetool.workflows.base_node import BaseNode

class QwenImageMaxEdit(SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]):
    """

        Qwen Image Max Edit for advanced image editing with reference images.
        image, edit, qwen, alibaba, image-to-image, img2img, high-quality

        Use cases:
        - Edit images with complex instructions
        - Transform images based on references
        - Apply style transfers with multiple images
        - Create variations with intelligent editing
        - Modify images with detailed prompts
    """

    prompt: str | OutputHandle[str] = connect_field(default='', description='Text prompt describing the desired edits')
    negative_prompt: str | OutputHandle[str] = connect_field(default='', description='Content to avoid in the edited image')
    image_urls: list[types.ImageRef] | OutputHandle[list[types.ImageRef]] = connect_field(default=PydanticUndefined, description='Reference images for editing (1-3 images)')
    image_size: nodetool.nodes.fal.text_to_image.ImageSizePreset | OutputHandle[nodetool.nodes.fal.text_to_image.ImageSizePreset] | None = connect_field(default=None, description='The size of the generated image. If not provided, uses input image size')
    enable_prompt_expansion: bool | OutputHandle[bool] = connect_field(default=True, description='Enable LLM prompt optimization for better results')
    seed: int | OutputHandle[int] = connect_field(default=-1, description='Seed for reproducible generation')
    enable_safety_checker: bool | OutputHandle[bool] = connect_field(default=True, description='Enable content moderation')
    num_images: int | OutputHandle[int] = connect_field(default=1, description='The number of images to generate')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.fal.image_to_image.QwenImageMaxEdit

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.fal.image_to_image
from nodetool.workflows.base_node import BaseNode

class Retoucher(SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]):
    """

        Retoucher enhances and retouches photos with AI-powered corrections.
        image, enhancement, retouching, beautification

        Use cases:
        - Enhance portrait photos
        - Apply skin retouching
        - Improve photo quality
        - Fix lighting issues
        - Professional photo editing
    """

    image: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(default=types.ImageRef(type='image', uri='', asset_id=None, data=None, metadata=None), description='The image to retouch')
    prompt: str | OutputHandle[str] = connect_field(default='', description='Optional prompt to guide the retouching')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.fal.image_to_image.Retoucher

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.fal.image_to_image
from nodetool.workflows.base_node import BaseNode

class WanEffects(SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]):
    """
    Apply stylized effects to an image using the WAN Effects model.

        image, transformation, style, filter

        Use cases:
        - Add artistic filters to photos
        - Create stylized social media images
        - Quickly generate meme-style effects
    """

    image: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(default=types.ImageRef(type='image', uri='', asset_id=None, data=None, metadata=None), description='Input image to apply the effect to')
    effect: str | OutputHandle[str] = connect_field(default='', description='Name of the effect to apply')

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.fal.image_to_image.WanEffects

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


