"""
Configuration for vision module.

This config file defines overrides and customizations for vision/image understanding nodes.
"""

from typing import Any


# Map of endpoint_id to config overrides
CONFIGS: dict[str, dict[str, Any]] = {
    "half-moon-ai/ai-detector/detect-image": {
        "class_name": "AIDetectorImage",
        "docstring": "AI Detector analyzes images to determine if they were generated by AI or are real photos.",
        "tags": ["vision", "ai-detection", "analysis", "classification"],
        "use_cases": [
            "Detect AI-generated images",
            "Verify image authenticity",
            "Filter synthetic content",
            "Content moderation for AI images",
            "Analyze image provenance"
        ],
        "basic_fields": ["image"]
    },
    
    "fal-ai/arbiter/image/text": {
        "class_name": "ArbiterImageText",
        "docstring": "Arbiter measures semantic alignment between images and text descriptions.",
        "tags": ["vision", "alignment", "similarity", "text-image", "analysis"],
        "use_cases": [
            "Measure image-text alignment",
            "Verify prompt accuracy",
            "Quality control for generated images",
            "Rank images by text relevance",
            "Evaluate caption accuracy"
        ],
        "basic_fields": ["image", "text"]
    },
    
    "fal-ai/arbiter/image/image": {
        "class_name": "ArbiterImageImage",
        "docstring": "Arbiter measures similarity and alignment between reference images.",
        "tags": ["vision", "similarity", "comparison", "image-matching", "analysis"],
        "use_cases": [
            "Compare image similarity",
            "Measure visual alignment",
            "Find duplicate images",
            "Rank image variations",
            "Evaluate image consistency"
        ],
        "basic_fields": ["image1", "image2"]
    },
    
    "fal-ai/arbiter/image": {
        "class_name": "ArbiterImage",
        "docstring": "Arbiter provides comprehensive image analysis and quality metrics.",
        "tags": ["vision", "analysis", "quality", "metrics", "image-evaluation"],
        "use_cases": [
            "Analyze image quality",
            "Extract image metrics",
            "Evaluate visual properties",
            "Assess image characteristics",
            "Generate quality reports"
        ],
        "basic_fields": ["image"]
    },
    
    "fal-ai/florence-2-large/region-to-description": {
        "class_name": "Florence2RegionToDescription",
        "docstring": "Florence-2 Large generates detailed descriptions of specific image regions.",
        "tags": ["vision", "captioning", "region-description", "florence", "ocr"],
        "use_cases": [
            "Describe specific image regions",
            "Generate region captions",
            "Extract region information",
            "Annotate image areas",
            "Create detailed region descriptions"
        ],
        "basic_fields": ["image", "region"]
    },
    
    "fal-ai/florence-2-large/ocr": {
        "class_name": "Florence2OCR",
        "docstring": "Florence-2 Large performs optical character recognition to extract text from images.",
        "tags": ["vision", "ocr", "text-extraction", "florence", "reading"],
        "use_cases": [
            "Extract text from images",
            "Read document images",
            "Digitize printed text",
            "Parse image text content",
            "Convert images to text"
        ],
        "basic_fields": ["image"]
    },
    
    "fal-ai/florence-2-large/more-detailed-caption": {
        "class_name": "Florence2MoreDetailedCaption",
        "docstring": "Florence-2 Large generates highly detailed, comprehensive image captions.",
        "tags": ["vision", "captioning", "detailed-description", "florence", "analysis"],
        "use_cases": [
            "Generate detailed image descriptions",
            "Create comprehensive captions",
            "Produce rich image narratives",
            "Analyze image content thoroughly",
            "Generate long-form descriptions"
        ],
        "basic_fields": ["image"]
    },
    
    "fal-ai/florence-2-large/region-to-category": {
        "class_name": "Florence2RegionToCategory",
        "docstring": "Florence-2 Large classifies image regions into semantic categories.",
        "tags": ["vision", "classification", "region-analysis", "florence", "categorization"],
        "use_cases": [
            "Classify image regions",
            "Categorize image areas",
            "Label image segments",
            "Identify region types",
            "Semantic region analysis"
        ],
        "basic_fields": ["image", "region"]
    },
    
    "fal-ai/florence-2-large/caption": {
        "class_name": "Florence2Caption",
        "docstring": "Florence-2 Large generates concise, accurate captions for images.",
        "tags": ["vision", "captioning", "description", "florence", "analysis"],
        "use_cases": [
            "Generate image captions",
            "Create alt text for images",
            "Describe images concisely",
            "Automate image descriptions",
            "Produce accessibility captions"
        ],
        "basic_fields": ["image"]
    },
    
    "fal-ai/florence-2-large/detailed-caption": {
        "class_name": "Florence2DetailedCaption",
        "docstring": "Florence-2 Large generates detailed captions with rich contextual information.",
        "tags": ["vision", "captioning", "detailed-description", "florence", "analysis"],
        "use_cases": [
            "Generate detailed captions",
            "Create rich image descriptions",
            "Produce comprehensive captions",
            "Analyze image context",
            "Generate informative descriptions"
        ],
        "basic_fields": ["image"]
    },
    
    "fal-ai/omdet-turbo": {
        "class_name": "OmDetTurbo",
        "docstring": "OmDet Turbo performs fast object detection and classification in images.",
        "tags": ["vision", "object-detection", "detection", "classification", "fast"],
        "use_cases": [
            "Detect objects in images quickly",
            "Real-time object detection",
            "Fast image analysis",
            "Identify multiple objects",
            "Efficient object classification"
        ],
        "basic_fields": ["image"]
    },
    
    "fal-ai/owl-v2": {
        "class_name": "OwlV2",
        "docstring": "OWL-v2 performs open-vocabulary object detection using text queries.",
        "tags": ["vision", "object-detection", "open-vocabulary", "owl", "detection"],
        "use_cases": [
            "Detect objects by text description",
            "Open-vocabulary object detection",
            "Find arbitrary objects in images",
            "Query-based detection",
            "Flexible object identification"
        ],
        "basic_fields": ["image", "query"]
    },
    
    "fal-ai/vision/gpt4o": {
        "class_name": "VisionGPT4O",
        "docstring": "GPT-4O Vision provides advanced image understanding and analysis with language model reasoning.",
        "tags": ["vision", "understanding", "gpt4", "multimodal", "analysis"],
        "use_cases": [
            "Analyze images with AI reasoning",
            "Answer questions about images",
            "Extract complex image information",
            "Understand image context",
            "Generate detailed image insights"
        ],
        "basic_fields": ["image", "prompt"]
    },
    
    "fal-ai/vision/gpt4o-mini": {
        "class_name": "VisionGPT4OMini",
        "docstring": "GPT-4O Mini Vision provides efficient image understanding with reduced resource usage.",
        "tags": ["vision", "understanding", "gpt4", "mini", "efficient", "analysis"],
        "use_cases": [
            "Efficient image analysis",
            "Quick image understanding",
            "Cost-effective vision tasks",
            "Fast image reasoning",
            "Lightweight image processing"
        ],
        "basic_fields": ["image", "prompt"]
    },
    
    "fal-ai/pixtral/large": {
        "class_name": "PixtralLarge",
        "docstring": "Pixtral Large provides powerful multimodal understanding for complex image analysis.",
        "tags": ["vision", "understanding", "pixtral", "multimodal", "analysis"],
        "use_cases": [
            "Complex image analysis",
            "Detailed image understanding",
            "Advanced visual reasoning",
            "Comprehensive image interpretation",
            "Sophisticated image tasks"
        ],
        "basic_fields": ["image", "prompt"]
    },
    
    "fal-ai/moondream/v2": {
        "class_name": "MoondreamV2",
        "docstring": "Moondream v2 provides efficient vision-language understanding for image analysis.",
        "tags": ["vision", "understanding", "moondream", "efficient", "analysis"],
        "use_cases": [
            "Efficient image understanding",
            "Quick visual question answering",
            "Lightweight image analysis",
            "Fast image interpretation",
            "Compact vision model"
        ],
        "basic_fields": ["image", "prompt"]
    },
    
    "fal-ai/llama-vision/free": {
        "class_name": "LlamaVisionFree",
        "docstring": "Llama Vision Free provides accessible vision-language understanding at no cost.",
        "tags": ["vision", "understanding", "llama", "free", "multimodal", "analysis"],
        "use_cases": [
            "Free image analysis",
            "Accessible vision tasks",
            "No-cost image understanding",
            "Budget-friendly vision processing",
            "Open access image reasoning"
        ],
        "basic_fields": ["image", "prompt"]
    },
    
    "fal-ai/blip-2": {
        "class_name": "BLIP2",
        "docstring": "BLIP-2 provides vision-language understanding for image captioning and VQA.",
        "tags": ["vision", "captioning", "vqa", "blip", "understanding"],
        "use_cases": [
            "Generate image captions",
            "Answer visual questions",
            "Image-text understanding",
            "Visual question answering",
            "Image description generation"
        ],
        "basic_fields": ["image"]
    },
    
    "fal-ai/deepseek-vl2": {
        "class_name": "DeepSeekVL2",
        "docstring": "DeepSeek VL2 provides advanced vision-language understanding with deep reasoning.",
        "tags": ["vision", "understanding", "deepseek", "reasoning", "analysis"],
        "use_cases": [
            "Deep image analysis",
            "Advanced visual reasoning",
            "Complex image understanding",
            "Detailed image interpretation",
            "Sophisticated vision tasks"
        ],
        "basic_fields": ["image", "prompt"]
    },
    
    "fal-ai/hunyuan-vision": {
        "class_name": "HunyuanVision",
        "docstring": "Hunyuan Vision provides powerful image understanding from Tencent.",
        "tags": ["vision", "understanding", "hunyuan", "analysis", "tencent"],
        "use_cases": [
            "Comprehensive image analysis",
            "Advanced image understanding",
            "Visual content interpretation",
            "Image reasoning tasks",
            "Detailed visual analysis"
        ],
        "basic_fields": ["image", "prompt"]
    },
}


def get_config(endpoint_id: str) -> dict[str, Any]:
    """Get config for an endpoint."""
    return CONFIGS.get(endpoint_id, {})
